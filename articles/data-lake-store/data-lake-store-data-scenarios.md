---
title: "데이터 레이크 저장소를 포함 하는 aaaData 시나리오 | Microsoft Docs"
description: "수집 된 처리, 다운로드 하 여 데이터 레이크 저장소에서 시각화 hello 다양 한 시나리오 및 데이터를 사용 하 여 도구 수를 이해합니다"
services: data-lake-store
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
ms.assetid: 37409a71-a563-4bb7-bc46-2cbd426a2ece
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 05/10/2017
ms.author: nitinme
ms.openlocfilehash: caaa3979b8a2532089778c3e3db3c711714d3c42
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="using-azure-data-lake-store-for-big-data-requirements"></a><span data-ttu-id="97fb4-103">빅 데이터 요구 사항에 Azure Data Lake 저장소 사용</span><span class="sxs-lookup"><span data-stu-id="97fb4-103">Using Azure Data Lake Store for big data requirements</span></span>
<span data-ttu-id="97fb4-104">빅 데이터 처리에는 네 가지 주요 단계가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-104">There are four key stages in big data processing:</span></span>

* <span data-ttu-id="97fb4-105">실시간으로 또는 배치로 대량의 데이터를 데이터 저장소에 수집</span><span class="sxs-lookup"><span data-stu-id="97fb4-105">Ingesting large amounts of data into a data store, at real-time or in batches</span></span>
* <span data-ttu-id="97fb4-106">Hello 데이터 처리</span><span class="sxs-lookup"><span data-stu-id="97fb4-106">Processing hello data</span></span>
* <span data-ttu-id="97fb4-107">Hello 데이터 다운로드</span><span class="sxs-lookup"><span data-stu-id="97fb4-107">Downloading hello data</span></span>
* <span data-ttu-id="97fb4-108">Hello 데이터 시각화</span><span class="sxs-lookup"><span data-stu-id="97fb4-108">Visualizing hello data</span></span>

<span data-ttu-id="97fb4-109">이 문서에서는 의견에 귀 이러한 단계에서 존중 tooAzure 데이터 레이크 저장소 toounderstand hello 옵션 및 도구 사용 가능한 toomeet와 빅 데이터 요구 사항입니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-109">In this article, we look at these stages with respect tooAzure Data Lake Store toounderstand hello options and tools available toomeet your big data needs.</span></span>

## <a name="ingest-data-into-data-lake-store"></a><span data-ttu-id="97fb4-110">Data Lake 저장소에 데이터 수집</span><span class="sxs-lookup"><span data-stu-id="97fb4-110">Ingest data into Data Lake Store</span></span>
<span data-ttu-id="97fb4-111">이 섹션에는 hello 다양 한 원본 데이터와 hello 다양 한 방법으로 데이터 레이크 저장소 계정에 해당 데이터를 ingested 수 있는 강조 표시 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-111">This section highlights hello different sources of data and hello different ways in which that data can be ingested into a Data Lake Store account.</span></span>

<span data-ttu-id="97fb4-112">![Data Lake Store에 데이터 수집](./media/data-lake-store-data-scenarios/ingest-data.png "Data Lake Store에 데이터 수집")</span><span class="sxs-lookup"><span data-stu-id="97fb4-112">![Ingest data into Data Lake Store](./media/data-lake-store-data-scenarios/ingest-data.png "Ingest data into Data Lake Store")</span></span>

### <a name="ad-hoc-data"></a><span data-ttu-id="97fb4-113">임시 데이터</span><span class="sxs-lookup"><span data-stu-id="97fb4-113">Ad hoc data</span></span>
<span data-ttu-id="97fb4-114">빅 데이터 응용 프로그램의 프로토타입 제작에 사용되는 작은 데이터 집합을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-114">This represents smaller data sets that are used for prototyping a big data application.</span></span> <span data-ttu-id="97fb4-115">여러 가지 방법으로 hello hello 데이터 원본에 따라 임시 데이터를 수집 하는 방법의 수입니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-115">There are different ways of ingesting ad hoc data depending on hello source of hello data.</span></span>

| <span data-ttu-id="97fb4-116">데이터 원본</span><span class="sxs-lookup"><span data-stu-id="97fb4-116">Data Source</span></span> | <span data-ttu-id="97fb4-117">로컬 컴퓨터를 사용하여</span><span class="sxs-lookup"><span data-stu-id="97fb4-117">Ingest it using</span></span> |
| --- | --- |
| <span data-ttu-id="97fb4-118">수집</span><span class="sxs-lookup"><span data-stu-id="97fb4-118">Local computer</span></span> |<ul> <li>[<span data-ttu-id="97fb4-119">Azure Portal</span><span class="sxs-lookup"><span data-stu-id="97fb4-119">Azure Portal</span></span>](/data-lake-store-get-started-portal.md)</li> <li>[<span data-ttu-id="97fb4-120">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="97fb4-120">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)</li> <li>[<span data-ttu-id="97fb4-121">Azure 플랫폼 간 CLI 2.0</span><span class="sxs-lookup"><span data-stu-id="97fb4-121">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)</li> <li>[<span data-ttu-id="97fb4-122">Visual Studio용 Data Lake 도구를 사용하여 U-SQL 스크립트 만들기</span><span class="sxs-lookup"><span data-stu-id="97fb4-122">Using Data Lake Tools for Visual Studio</span></span>](../data-lake-analytics/data-lake-analytics-data-lake-tools-get-started.md) </li></ul> |
| <span data-ttu-id="97fb4-123">Azure 저장소 Blob</span><span class="sxs-lookup"><span data-stu-id="97fb4-123">Azure Storage Blob</span></span> |<ul> <li>[<span data-ttu-id="97fb4-124">Azure 데이터 팩터리</span><span class="sxs-lookup"><span data-stu-id="97fb4-124">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)</li> <li>[<span data-ttu-id="97fb4-125">AdlCopy 도구</span><span class="sxs-lookup"><span data-stu-id="97fb4-125">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="97fb4-126">HDInsight 클러스터에서 실행되는 DistCp</span><span class="sxs-lookup"><span data-stu-id="97fb4-126">DistCp running on HDInsight cluster</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li> </ul> |

### <a name="streamed-data"></a><span data-ttu-id="97fb4-127">스트리밍된 데이터</span><span class="sxs-lookup"><span data-stu-id="97fb4-127">Streamed data</span></span>
<span data-ttu-id="97fb4-128">응용 프로그램, 장치, 센서 등 다양한 원본을 통해 생성할 수 있는 데이터를 나타냅니다. 이 데이터는 다양한 도구를 사용하여 Data Lake 저장소에 수집할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-128">This represents data that can be generated by various sources such as applications, devices, sensors, etc. This data can be ingested into a Data Lake Store by variety tools.</span></span> <span data-ttu-id="97fb4-129">이러한 도구는 일반적으로 캡처하고에서 이벤트에서 이벤트 별로 hello 데이터 처리 실시간으로 다음 hello 이벤트를에서 쓰는 일괄 처리 데이터 레이크 저장소에 추가로 처리 될 수 있도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-129">These tools will usually capture and process hello data on an event-by-event basis in real-time, and then write hello events in batches into Data Lake Store so that they can be further processed.</span></span>

<span data-ttu-id="97fb4-130">다음은 사용할 수 있는 도구입니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-130">Following are tools that you can use:</span></span>

* <span data-ttu-id="97fb4-131">[Azure 스트림 분석](../stream-analytics/stream-analytics-data-lake-output.md) -이벤트 수집 된 이벤트 허브로 쓸 수 있습니다 tooAzure 데이터 레이크 출력은 Azure 데이터 레이크 저장소를 사용 하 여 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-131">[Azure Stream Analytics](../stream-analytics/stream-analytics-data-lake-output.md) - Events ingested into Event Hubs can be written tooAzure Data Lake using an Azure Data Lake Store output.</span></span>
* <span data-ttu-id="97fb4-132">[Azure HDInsight 스톰](../hdinsight/hdinsight-storm-write-data-lake-store.md) -tooData Lake 저장소에서 Storm 클러스터 hello 직접 데이터를 쓸 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-132">[Azure HDInsight Storm](../hdinsight/hdinsight-storm-write-data-lake-store.md) - You can write data directly tooData Lake Store from hello Storm cluster.</span></span>
* <span data-ttu-id="97fb4-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) – 이벤트 허브에서 이벤트를 수신 하 고 다음 써야 tooData Lake 저장소 hello를 사용 하 여 [데이터 레이크 저장소.NET SDK](data-lake-store-get-started-net-sdk.md)합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-133">[EventProcessorHost](../event-hubs/event-hubs-dotnet-standard-getstarted-receive-eph.md) – You can receive events from Event Hubs and then write it tooData Lake Store using hello [Data Lake Store .NET SDK](data-lake-store-get-started-net-sdk.md).</span></span>

### <a name="relational-data"></a><span data-ttu-id="97fb4-134">관계형 데이터</span><span class="sxs-lookup"><span data-stu-id="97fb4-134">Relational data</span></span>
<span data-ttu-id="97fb4-135">관계형 데이터베이스의 데이터를 원본으로 사용할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-135">You can also source data from relational databases.</span></span> <span data-ttu-id="97fb4-136">관계형 데이터베이스는 일정 기간 동안 엄청난 양의 데이터를 수집합니다. 이 데이터를 빅 데이터 파이프라인을 통해 처리하면 중요한 정보를 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-136">Over a period of time, relational databases collect huge amounts of data which can provide key insights if processed through a big data pipeline.</span></span> <span data-ttu-id="97fb4-137">데이터 레이크 저장소로 hello 도구 toomove 다음 이러한 데이터를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-137">You can use hello following tools toomove such data into Data Lake Store.</span></span>

* [<span data-ttu-id="97fb4-138">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="97fb4-138">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="97fb4-139">Azure 데이터 팩터리</span><span class="sxs-lookup"><span data-stu-id="97fb4-139">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

### <a name="web-server-log-data-upload-using-custom-applications"></a><span data-ttu-id="97fb4-140">웹 서버 로그 데이터(사용자 지정 응용 프로그램을 사용하여 업로드)</span><span class="sxs-lookup"><span data-stu-id="97fb4-140">Web server log data (upload using custom applications)</span></span>
<span data-ttu-id="97fb4-141">웹 서버 로그 데이터의 분석 빅 데이터 응용 프로그램에 대 한 일반적인 사용 사례 이며 많은 양의 파일 toobe 로그 업로드 toohello 데이터 레이크 저장소가 필요 하기 때문에이 유형의 데이터 집합 특별히 호출 됩니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-141">This type of dataset is specifically called out because analysis of web server log data is a common use case for big data applications and requires large volumes of log files toobe uploaded toohello Data Lake Store.</span></span> <span data-ttu-id="97fb4-142">Hello 도구 toowrite 뒤의 모든 사용자 고유의 스크립트 또는 응용 프로그램 tooupload를 사용할 수 있습니다 이러한 데이터입니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-142">You can use any of hello following tools toowrite your own scripts or applications tooupload such data.</span></span>

* [<span data-ttu-id="97fb4-143">Azure 플랫폼 간 CLI 2.0</span><span class="sxs-lookup"><span data-stu-id="97fb4-143">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="97fb4-144">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="97fb4-144">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="97fb4-145">Azure Data Lake 저장소 .NET SDK</span><span class="sxs-lookup"><span data-stu-id="97fb4-145">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)
* [<span data-ttu-id="97fb4-146">Azure 데이터 팩터리</span><span class="sxs-lookup"><span data-stu-id="97fb4-146">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)

<span data-ttu-id="97fb4-147">웹 서버 로그 데이터를 업로드 하기 위한 또한 다른 종류의 데이터 (예: 소셜 표현의 데이터)를 업로드 하기 위한 것이 좋은 접근 toowrite 사용자 고유의 사용자 지정 스크립트/응용 프로그램 수 있기 때문에 hello 유연성 tooinclude 데이터 일부로 구성 요소를 업로드 하는 중 더 큰 빅 데이터 응용 프로그램입니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-147">For uploading web server log data, and also for uploading other kinds of data (e.g. social sentiments data), it is a good approach toowrite your own custom scripts/applications because it gives you hello flexibility tooinclude your data uploading component as part of your larger big data application.</span></span> <span data-ttu-id="97fb4-148">일부 경우에이 코드는 스크립트 또는 간단한 명령줄 유틸리티의 hello 양식을 걸릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-148">In some cases this code may take hello form of a script or simple command line utility.</span></span> <span data-ttu-id="97fb4-149">경우에 따라 hello 코드 비즈니스 응용 프로그램이 나 솔루션에 사용 되는 toointegrate 빅 데이터 처리를 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-149">In other cases, hello code may be used toointegrate big data processing into a business application or solution.</span></span>

### <a name="data-associated-with-azure-hdinsight-clusters"></a><span data-ttu-id="97fb4-150">Azure HDInsight 클러스터와 연결된 데이터</span><span class="sxs-lookup"><span data-stu-id="97fb4-150">Data associated with Azure HDInsight clusters</span></span>
<span data-ttu-id="97fb4-151">대부분의 HDInsight 클러스터 유형(Hadoop, HBase, Storm)은 데이터 저장소 리포지토리로 Data Lake 저장소를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-151">Most HDInsight cluster types (Hadoop, HBase, Storm) support Data Lake Store as a data storage repository.</span></span> <span data-ttu-id="97fb4-152">HDInsight 클러스터는 Azure 저장소 Blob(WASB)에서 데이터에 액세스합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-152">HDInsight clusters access data from Azure Storage Blobs (WASB).</span></span> <span data-ttu-id="97fb4-153">성능 향상을 위해 hello 클러스터와 연결 된 데이터 레이크 저장소 계정으로 WASB에서 hello 데이터를 복사할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-153">For better performance, you can copy hello data from WASB into a Data Lake Store account associated with hello cluster.</span></span> <span data-ttu-id="97fb4-154">다음 도구 toocopy hello 데이터 hello를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-154">You can use hello following tools toocopy hello data.</span></span>

* [<span data-ttu-id="97fb4-155">Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="97fb4-155">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)
* [<span data-ttu-id="97fb4-156">AdlCopy Service</span><span class="sxs-lookup"><span data-stu-id="97fb4-156">AdlCopy Service</span></span>](data-lake-store-copy-data-azure-storage-blob.md)
* [<span data-ttu-id="97fb4-157">Azure 데이터 팩터리</span><span class="sxs-lookup"><span data-stu-id="97fb4-157">Azure Data Factory</span></span>](../data-factory/data-factory-azure-datalake-connector.md)

### <a name="data-stored-in-on-premises-or-iaas-hadoop-clusters"></a><span data-ttu-id="97fb4-158">온-프레미스 또는 IaaS Hadoop 클러스터에 저장된 데이터</span><span class="sxs-lookup"><span data-stu-id="97fb4-158">Data stored in on-premises or IaaS Hadoop clusters</span></span>
<span data-ttu-id="97fb4-159">HDFS를 사용하여 로컬 컴퓨터의 기존 Hadoop 클러스터에 대량의 데이터를 저장할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-159">Large amounts of data may be stored in existing Hadoop clusters, locally on machines using HDFS.</span></span> <span data-ttu-id="97fb4-160">hello Hadoop 클러스터는 온-프레미스 배포에 있을 수 있습니다 또는 Azure에서는 IaaS 클러스터 내에서 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-160">hello Hadoop clusters may be in an on-premises deployment or may be within an IaaS cluster on Azure.</span></span> <span data-ttu-id="97fb4-161">이러한 데이터 tooAzure Data Lake 저장소에 적절 하 게 되풀이 또는 일회용 접근 방식에 대 한 요구 사항 toocopy 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-161">There could be requirements toocopy such data tooAzure Data Lake Store for a one-off approach or in a recurring fashion.</span></span> <span data-ttu-id="97fb4-162">사용할 수 있는 tooachieve이 다양 한 옵션이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-162">There are various options that you can use tooachieve this.</span></span> <span data-ttu-id="97fb4-163">다음은 대체 목록 및 hello 장점과 단점을 이해 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-163">Below is a list of alternatives and hello associated trade-offs.</span></span>

| <span data-ttu-id="97fb4-164">접근 방식</span><span class="sxs-lookup"><span data-stu-id="97fb4-164">Approach</span></span> | <span data-ttu-id="97fb4-165">세부 정보</span><span class="sxs-lookup"><span data-stu-id="97fb4-165">Details</span></span> | <span data-ttu-id="97fb4-166">장점</span><span class="sxs-lookup"><span data-stu-id="97fb4-166">Advantages</span></span> | <span data-ttu-id="97fb4-167">고려 사항</span><span class="sxs-lookup"><span data-stu-id="97fb4-167">Considerations</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="97fb4-168">Azure 데이터 팩터리 (ADF) toocopy 데이터를 사용 하 여 Hadoop 클러스터 tooAzure 데이터 레이크 저장소에서 직접</span><span class="sxs-lookup"><span data-stu-id="97fb4-168">Use Azure Data Factory (ADF) toocopy data directly from Hadoop clusters tooAzure Data Lake Store</span></span> |[<span data-ttu-id="97fb4-169">ADF는 데이터 원본으로 HDFS 지원</span><span class="sxs-lookup"><span data-stu-id="97fb4-169">ADF supports HDFS as a data source</span></span>](../data-factory/data-factory-hdfs-connector.md) |<span data-ttu-id="97fb4-170">ADF는 HDFS에 대한 기본 지원과 일등급 종단 간 관리 및 모니터링을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-170">ADF provides out-of-the-box support for HDFS and first class end-to-end management and monitoring</span></span> |<span data-ttu-id="97fb4-171">사용 하려면 데이터 관리 게이트웨이 toobe 온-프레미스를 배포 또는 hello IaaS 클러스터</span><span class="sxs-lookup"><span data-stu-id="97fb4-171">Requires Data Management Gateway toobe deployed on-premises or in hello IaaS cluster</span></span> |
| <span data-ttu-id="97fb4-172">Hadoop에서 데이터를 파일로 내보냅니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-172">Export data from Hadoop as files.</span></span> <span data-ttu-id="97fb4-173">그런 다음 적절 한 메커니즘을 사용 하 여 hello 파일 tooAzure 데이터 레이크 저장소를 복사 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-173">Then copy hello files tooAzure Data Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="97fb4-174">사용 하 여 파일 tooAzure Data Lake 저장소에 복사할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-174">You can copy files tooAzure Data Lake Store using:</span></span> <ul><li>[<span data-ttu-id="97fb4-175">Windows OS용 Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="97fb4-175">Azure PowerShell for Windows OS</span></span>](data-lake-store-get-started-powershell.md)</li><li>[<span data-ttu-id="97fb4-176">비Windows OS용 Azure 플랫폼 간 CLI 2.0</span><span class="sxs-lookup"><span data-stu-id="97fb4-176">Azure Cross-platform CLI 2.0 for non-Windows OS</span></span>](data-lake-store-get-started-cli-2.0.md)</li><li><span data-ttu-id="97fb4-177">Data Lake Store SDK를 사용하는 사용자 지정 앱</span><span class="sxs-lookup"><span data-stu-id="97fb4-177">Custom app using any Data Lake Store SDK</span></span></li></ul> |<span data-ttu-id="97fb4-178">빠른 tooget 시작 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-178">Quick tooget started.</span></span> <span data-ttu-id="97fb4-179">맞춤 업로드를 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-179">Can do customized uploads</span></span> |<span data-ttu-id="97fb4-180">여러 기술을 사용하는 다단계 절차입니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-180">Multi-step process that involves multiple technologies.</span></span> <span data-ttu-id="97fb4-181">관리 및 모니터링 증가 하는 것이 어려울 toobe hello 도구의 지정 된 시간이 hello 사용자 지정 특성</span><span class="sxs-lookup"><span data-stu-id="97fb4-181">Management and monitoring will grow toobe a challenge over time given hello customized nature of hello tools</span></span> |
| <span data-ttu-id="97fb4-182">Distcp toocopy 데이터 Hadoop tooAzure 저장소를에서 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-182">Use Distcp toocopy data from Hadoop tooAzure Storage.</span></span> <span data-ttu-id="97fb4-183">그런 다음 적절 한 메커니즘을 사용 하 여 Azure 저장소 tooData Lake 저장소에서 데이터를 복사 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-183">Then copy data from Azure Storage tooData Lake Store using appropriate mechanism.</span></span> |<span data-ttu-id="97fb4-184">사용 하 여 Azure 저장소 tooData Lake 저장소에서 데이터를 복사할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-184">You can copy data from Azure Storage tooData Lake Store using:</span></span> <ul><li>[<span data-ttu-id="97fb4-185">Azure 데이터 팩터리</span><span class="sxs-lookup"><span data-stu-id="97fb4-185">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)</li><li>[<span data-ttu-id="97fb4-186">AdlCopy 도구</span><span class="sxs-lookup"><span data-stu-id="97fb4-186">AdlCopy tool</span></span>](data-lake-store-copy-data-azure-storage-blob.md)</li><li>[<span data-ttu-id="97fb4-187">HDInsight 클러스터에서 실행되는 Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="97fb4-187">Apache DistCp running on HDInsight clusters</span></span>](data-lake-store-copy-data-wasb-distcp.md)</li></ul> |<span data-ttu-id="97fb4-188">오픈 소스 도구를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-188">You can use open-source tools.</span></span> |<span data-ttu-id="97fb4-189">여러 기술을 사용하는 다단계 절차입니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-189">Multi-step process that involves multiple technologies</span></span> |

### <a name="really-large-datasets"></a><span data-ttu-id="97fb4-190">매우 큰 데이터 집합</span><span class="sxs-lookup"><span data-stu-id="97fb4-190">Really large datasets</span></span>
<span data-ttu-id="97fb4-191">범위 테라바이트까지에 있는 데이터 집합을 업로드 하는 것에 대 한 위의 hello 방법을 사용 하 여 수 있습니다 느리고 비용이 많이 드는.</span><span class="sxs-lookup"><span data-stu-id="97fb4-191">For uploading datasets that range in several terabytes, using hello methods described above can sometimes be slow and costly.</span></span> <span data-ttu-id="97fb4-192">이 경우 아래 hello 옵션을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-192">In such cases, you can use hello options below.</span></span>

* <span data-ttu-id="97fb4-193">**Azure Express 경로 사용**.</span><span class="sxs-lookup"><span data-stu-id="97fb4-193">**Using Azure ExpressRoute**.</span></span> <span data-ttu-id="97fb4-194">Azure Express 경로를 사용하면 온-프레미스의 인프라와 Azure 데이터 센터 사이에 개인 연결을 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-194">Azure ExpressRoute lets you create private connections between Azure datacenters and infrastructure on your premises.</span></span> <span data-ttu-id="97fb4-195">이렇게 하면 대용량 데이터를 안전하게 전송할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-195">This provides a reliable option for transferring large amounts of data.</span></span> <span data-ttu-id="97fb4-196">자세한 내용은 [Azure Express 경로 설명서](../expressroute/expressroute-introduction.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="97fb4-196">For more information, see [Azure ExpressRoute documentation](../expressroute/expressroute-introduction.md).</span></span>
* <span data-ttu-id="97fb4-197">**데이터를 "오프라인"으로 업로드**.</span><span class="sxs-lookup"><span data-stu-id="97fb4-197">**"Offline" upload of data**.</span></span> <span data-ttu-id="97fb4-198">Azure ExpressRoute를 사용 하 여 적절 하지 않은 어떤 이유로 든 사용할 수 있습니다 [Azure 가져오기/내보내기 서비스](../storage/common/storage-import-export-service.md) 데이터 tooan Azure 데이터 센터에 있는 tooship 하드 디스크 드라이브입니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-198">If using Azure ExpressRoute is not feasible for any reason, you can use [Azure Import/Export service](../storage/common/storage-import-export-service.md) tooship hard disk drives with your data tooan Azure data center.</span></span> <span data-ttu-id="97fb4-199">데이터가 첫 번째 업로드 tooAzure 저장소 Blob 됩니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-199">Your data is first uploaded tooAzure Storage Blobs.</span></span> <span data-ttu-id="97fb4-200">사용할 수 있습니다 [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) 또는 [AdlCopy 도구](data-lake-store-copy-data-azure-storage-blob.md) toocopy 데이터를 Azure 저장소 Blob tooData Lake 저장소입니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-200">You can then use [Azure Data Factory](../data-factory/data-factory-azure-datalake-connector.md) or [AdlCopy tool](data-lake-store-copy-data-azure-storage-blob.md) toocopy data from Azure Storage Blobs tooData Lake Store.</span></span>

  > [!NOTE]
  > <span data-ttu-id="97fb4-201">가져오기/내보내기 서비스를 hello를 사용 하 여, 동안 hello 디스크 배송 tooAzure 데이터 센터에서 hello 파일 크기 195 g B 보다 크지 않아야 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-201">While using hello Import/Export service, hello file sizes on hello disks that you ship tooAzure data center should not be greater than 195 GB.</span></span>
  >
  >

## <a name="process-data-stored-in-data-lake-store"></a><span data-ttu-id="97fb4-202">Data Lake 저장소에 저장된 데이터 처리</span><span class="sxs-lookup"><span data-stu-id="97fb4-202">Process data stored in Data Lake Store</span></span>
<span data-ttu-id="97fb4-203">데이터 레이크 저장소의 hello 데이터를 사용할 수 있는 hello를 사용 하 여 데이터 빅 데이터 응용 프로그램을 지원 하는지 분석에서 실행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-203">Once hello data is available in Data Lake Store you can run analysis on that data using hello supported big data applications.</span></span> <span data-ttu-id="97fb4-204">현재 데이터 레이크 저장소에 저장 된 hello 데이터에서 Azure HDInsight 및 Azure 데이터 레이크 분석 toorun 데이터 분석 작업을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-204">Currently, you can use Azure HDInsight and Azure Data Lake Analytics toorun data analysis jobs on hello data stored in Data Lake Store.</span></span>

<span data-ttu-id="97fb4-205">![Data Lake Store의 데이터 분석](./media/data-lake-store-data-scenarios/analyze-data.png "Data Lake Store의 데이터 분석")</span><span class="sxs-lookup"><span data-stu-id="97fb4-205">![Analyze data in Data Lake Store](./media/data-lake-store-data-scenarios/analyze-data.png "Analyze data in Data Lake Store")</span></span>

<span data-ttu-id="97fb4-206">다음 예제는 hello 볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-206">You can look at hello following examples.</span></span>

* [<span data-ttu-id="97fb4-207">Data Lake 저장소를 저장소로 사용하여 HDInsight 클러스터 만들기</span><span class="sxs-lookup"><span data-stu-id="97fb4-207">Create an HDInsight cluster with Data Lake Store as storage</span></span>](data-lake-store-hdinsight-hadoop-use-portal.md)
* [<span data-ttu-id="97fb4-208">Azure 데이터 레이크 분석에 데이터 레이크 저장소 사용</span><span class="sxs-lookup"><span data-stu-id="97fb4-208">Use Azure Data Lake Analytics with Data Lake Store</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)

## <a name="download-data-from-data-lake-store"></a><span data-ttu-id="97fb4-209">Data Lake 저장소에서 데이터 다운로드</span><span class="sxs-lookup"><span data-stu-id="97fb4-209">Download data from Data Lake Store</span></span>
<span data-ttu-id="97fb4-210">또한 toodownload 원하는 또는에서 데이터를 이동할 Azure 데이터 레이크 저장소 시나리오와 같은 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-210">You might also want toodownload or move data from Azure Data Lake Store for scenarios such as:</span></span>

* <span data-ttu-id="97fb4-211">기존 데이터 처리 파이프라인으로 tooother 저장소 toointerface 데이터를 이동 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-211">Move data tooother repositories toointerface with your existing data processing pipelines.</span></span> <span data-ttu-id="97fb4-212">예를 들어 있습니다 데이터 레이크 저장소 tooAzure SQL 데이터베이스에서에서 데이터 toomove 하거나 온-프레미스 SQL Server.</span><span class="sxs-lookup"><span data-stu-id="97fb4-212">For example, you might want toomove data from Data Lake Store tooAzure SQL Database or on-premises SQL Server.</span></span>
* <span data-ttu-id="97fb4-213">IDE 환경에서 응용 프로그램 프로토타입을 빌드하는 동안 처리를 위해 데이터 tooyour 로컬 컴퓨터를 다운로드 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-213">Download data tooyour local computer for processing in IDE environments while building application prototypes.</span></span>

<span data-ttu-id="97fb4-214">![Data Lake Store에서 데이터 송신](./media/data-lake-store-data-scenarios/egress-data.png "Data Lake Store에서 데이터 송신")</span><span class="sxs-lookup"><span data-stu-id="97fb4-214">![Egress data from Data Lake Store](./media/data-lake-store-data-scenarios/egress-data.png "Egress data from Data Lake Store")</span></span>

<span data-ttu-id="97fb4-215">이러한 경우 hello 다음 옵션 중 하나를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-215">In such cases, you can use any of hello following options:</span></span>

* [<span data-ttu-id="97fb4-216">Apache Sqoop</span><span class="sxs-lookup"><span data-stu-id="97fb4-216">Apache Sqoop</span></span>](data-lake-store-data-transfer-sql-sqoop.md)
* [<span data-ttu-id="97fb4-217">Azure 데이터 팩터리</span><span class="sxs-lookup"><span data-stu-id="97fb4-217">Azure Data Factory</span></span>](../data-factory/data-factory-data-movement-activities.md)
* [<span data-ttu-id="97fb4-218">Apache DistCp</span><span class="sxs-lookup"><span data-stu-id="97fb4-218">Apache DistCp</span></span>](data-lake-store-copy-data-wasb-distcp.md)

<span data-ttu-id="97fb4-219">작업을 데이터 레이크 저장소에서 직접 스크립트/응용 프로그램 toodownload 데이터 hello toowrite 메서드 다음으로 사용할 수도 합니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-219">You can also use hello following methods toowrite your own script/application toodownload data from Data Lake Store.</span></span>

* [<span data-ttu-id="97fb4-220">Azure 플랫폼 간 CLI 2.0</span><span class="sxs-lookup"><span data-stu-id="97fb4-220">Azure Cross-platform CLI 2.0</span></span>](data-lake-store-get-started-cli-2.0.md)
* [<span data-ttu-id="97fb4-221">Azure PowerShell</span><span class="sxs-lookup"><span data-stu-id="97fb4-221">Azure PowerShell</span></span>](data-lake-store-get-started-powershell.md)
* [<span data-ttu-id="97fb4-222">Azure Data Lake 저장소 .NET SDK</span><span class="sxs-lookup"><span data-stu-id="97fb4-222">Azure Data Lake Store .NET SDK</span></span>](data-lake-store-get-started-net-sdk.md)

## <a name="visualize-data-in-data-lake-store"></a><span data-ttu-id="97fb4-223">Data Lake 저장소에서 데이터 시각화</span><span class="sxs-lookup"><span data-stu-id="97fb4-223">Visualize data in Data Lake Store</span></span>
<span data-ttu-id="97fb4-224">데이터 레이크 저장소에 저장 된 데이터 서비스 toocreate 시각적 표시를 혼합 하 여 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-224">You can use a mix of services toocreate visual representations of data stored in Data Lake Store.</span></span>

<span data-ttu-id="97fb4-225">![Data Lake Store에서 데이터 시각화](./media/data-lake-store-data-scenarios/visualize-data.png "Data Lake Store에서 데이터 시각화")</span><span class="sxs-lookup"><span data-stu-id="97fb4-225">![Visualize data in Data Lake Store](./media/data-lake-store-data-scenarios/visualize-data.png "Visualize data in Data Lake Store")</span></span>

* <span data-ttu-id="97fb4-226">사용 하 여 시작할 수 있습니다 [Azure Data Factory toomove 데이터로 데이터 레이크 저장소 tooAzure SQL 데이터 웨어하우스](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span><span class="sxs-lookup"><span data-stu-id="97fb4-226">You can start by using [Azure Data Factory toomove data from Data Lake Store tooAzure SQL Data Warehouse](../data-factory/data-factory-data-movement-activities.md#supported-data-stores-and-formats)</span></span>
* <span data-ttu-id="97fb4-227">그 후 수 [Azure SQL 데이터 웨어하우스와 Power BI 통합](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) toocreate hello 데이터의 시각적 표현입니다.</span><span class="sxs-lookup"><span data-stu-id="97fb4-227">After that, you can [integrate Power BI with Azure SQL Data Warehouse](../sql-data-warehouse/sql-data-warehouse-integrate-power-bi.md) toocreate visual representation of hello data.</span></span>
