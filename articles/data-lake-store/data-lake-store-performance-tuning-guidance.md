---
title: "데이터 레이크 저장소 성능 튜닝 지침 aaaAzure | Microsoft Docs"
description: "Azure Data Lake Store 성능 조정 지침"
services: data-lake-store
documentationcenter: 
author: stewu
manager: amitkul
editor: cgronlun
ms.assetid: ebde7b9f-2e51-4d43-b7ab-566417221335
ms.service: data-lake-store
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 06/30/2017
ms.author: stewu
ms.openlocfilehash: 939faa068c0f81d18d9533956f4d336bc4d0cbe3
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="tuning-azure-data-lake-store-for-performance"></a><span data-ttu-id="40fec-103">Azure Data Lake Store의 성능 조정</span><span class="sxs-lookup"><span data-stu-id="40fec-103">Tuning Azure Data Lake Store for performance</span></span>

<span data-ttu-id="40fec-104">Data Lake Store는 I/O 집약적 분석 및 데이터 이동에 대해 높은 처리량을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-104">Data Lake Store supports high-throughput for I/O intensive analytics and data movement.</span></span>  <span data-ttu-id="40fec-105">Azure 데이터 레이크 저장소 사용 가능한 모든 처리량 – 읽거나 초당 쓰기 수 있는 데이터의 양을 hello-를 사용 하 여는 중요 한 tooget hello 최상의 성능입니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-105">In Azure Data Lake Store, using all available throughput – hello amount of data that can be read or written per second – is important tooget hello best performance.</span></span>  <span data-ttu-id="40fec-106">이를 위해 최대한 많은 읽기와 쓰기를 병렬로 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-106">This is achieved by performing as many reads and writes in parallel as possible.</span></span>

![Data Lake Store 성능](./media/data-lake-store-performance-tuning-guidance/throughput.png)

<span data-ttu-id="40fec-108">Azure 데이터 레이크 저장소 tooprovide hello 모든 분석 시나리오에 대 한 필요한 처리량을 확장할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-108">Azure Data Lake Store can scale tooprovide hello necessary throughput for all analytics scenario.</span></span> <span data-ttu-id="40fec-109">기본적으로 Azure 데이터 레이크 저장소 계정 사용 사례는 광범위 한 범주 toomeet hello 요구 자동으로 충분 한 처리량을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-109">By default, an Azure Data Lake Store account provides automatically enough throughput toomeet hello needs of a broad category of use cases.</span></span> <span data-ttu-id="40fec-110">ADLS 계정 hello hello 경우 고객 hello 기본 한도를 실행 하는 위치에 대 한 Microsoft 지원에 문의 하 여 구성 된 tooprovide 처리량을 높일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-110">For hello cases where customers run into hello default limit, hello ADLS account can be configured tooprovide more throughput by contacting Microsoft support.</span></span>

## <a name="data-ingestion"></a><span data-ttu-id="40fec-111">데이터 수집</span><span class="sxs-lookup"><span data-stu-id="40fec-111">Data ingestion</span></span>

<span data-ttu-id="40fec-112">원본 시스템 tooADLS에서 데이터를 수집 하는 방법, 경우에 중요 한 원본 하드웨어, 원본 네트워크 하드웨어 및 네트워크 연결 tooADLS hello tooconsider hello 병목 지점이 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-112">When ingesting data from a source system tooADLS, it is important tooconsider that hello source hardware, source network hardware, and network connectivity tooADLS can be hello bottleneck.</span></span>  

![Data Lake Store 성능](./media/data-lake-store-performance-tuning-guidance/bottleneck.png)

<span data-ttu-id="40fec-114">데이터 이동 hello tooensure 이러한 요인에 의해 영향을 받지 않습니다 유용 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-114">It is important tooensure that hello data movement is not affected by these factors.</span></span>

### <a name="source-hardware"></a><span data-ttu-id="40fec-115">원본 하드웨어</span><span class="sxs-lookup"><span data-stu-id="40fec-115">Source Hardware</span></span>

<span data-ttu-id="40fec-116">사용 하 여 온-프레미스 컴퓨터 또는 Vm에 Azure를 hello 적절 한 하드웨어를 신중 하 게 선택 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-116">Whether you are using on-premises machines or VMs in Azure, you should carefully select hello appropriate hardware.</span></span> <span data-ttu-id="40fec-117">원본 디스크 하드웨어에 대 한 Ssd tooHDDs 선호 하 고 스핀 들이 더 빠른 디스크 하드웨어를 선택 하십시오.</span><span class="sxs-lookup"><span data-stu-id="40fec-117">For Source Disk Hardware, prefer SSDs tooHDDs and pick disk hardware with faster spindles.</span></span> <span data-ttu-id="40fec-118">원본 네트워크 하드웨어에 대 한 가장 빠른 Nic 가능한 hello를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-118">For Source Network Hardware, use hello fastest NICs possible.</span></span>  <span data-ttu-id="40fec-119">Azure에서 Azure D14 Vm hello 적절 하 게 강력한 디스크 및 네트워킹 하드웨어를 포함 하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-119">On Azure, we recommend Azure D14 VMs which have hello appropriately powerful disk and networking hardware.</span></span>

### <a name="network-connectivity-tooazure-data-lake-store"></a><span data-ttu-id="40fec-120">네트워크 연결 tooAzure 데이터 레이크 저장소</span><span class="sxs-lookup"><span data-stu-id="40fec-120">Network Connectivity tooAzure Data Lake Store</span></span>

<span data-ttu-id="40fec-121">원본 데이터와 Azure 데이터 레이크 저장소 간의 네트워크 연결 hello hello 병목 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-121">hello network connectivity between your source data and Azure Data Lake store can sometimes be hello bottleneck.</span></span> <span data-ttu-id="40fec-122">원본 데이터가 온-프레미스인 경우 [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/)와 함께 전용 링크를 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-122">When your source data is On-Premises, consider using a dedicated link with [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/) .</span></span> <span data-ttu-id="40fec-123">원본 데이터를 Azure에 있으면, hello 성능이 되 최상의 hello에 hello 데이터가 있으면 hello 데이터 레이크 저장소와 같은 Azure 지역입니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-123">If your source data is in Azure, hello performance will be best when hello data is in hello same Azure region as hello Data Lake Store.</span></span>

### <a name="configure-data-ingestion-tools-for-maximum-parallelization"></a><span data-ttu-id="40fec-124">최대 병렬 처리를 위해 데이터 수집 도구 구성</span><span class="sxs-lookup"><span data-stu-id="40fec-124">Configure Data Ingestion tools for maximum parallelization</span></span>

<span data-ttu-id="40fec-125">Hello 소스 하드웨어 처리 하 고 네트워크 연결 병목 현상을 위의 준비 tooconfigure 됩니다 수집 도구입니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-125">Once you have addressed hello source hardware and network connectivity bottlenecks above, you are ready tooconfigure your ingestion tools.</span></span> <span data-ttu-id="40fec-126">hello 다음 표에 요약 여러 인기 있는 수집 도구에 대 한 hello 키 설정 하 고 제공 심층 분석 문서를 위한 성능 튜닝에 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-126">hello following table summarizes hello key settings for several popular ingestion tools and provides in-depth performance tuning articles for them.</span></span>  <span data-ttu-id="40fec-127">이 toolearn toouse 시나리오에 대 한 도구에 대 한 내용은 방문 [문서](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios)합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-127">toolearn more about which tool toouse for your scenario, visit this [article](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-scenarios).</span></span>

| <span data-ttu-id="40fec-128">도구</span><span class="sxs-lookup"><span data-stu-id="40fec-128">Tool</span></span>               | <span data-ttu-id="40fec-129">설정</span><span class="sxs-lookup"><span data-stu-id="40fec-129">Settings</span></span>     | <span data-ttu-id="40fec-130">자세한 정보</span><span class="sxs-lookup"><span data-stu-id="40fec-130">More Details</span></span>                                                                 |
|--------------------|------------------------------------------------------|------------------------------|
| <span data-ttu-id="40fec-131">PowerShell</span><span class="sxs-lookup"><span data-stu-id="40fec-131">Powershell</span></span>       | <span data-ttu-id="40fec-132">PerFileThreadCount, ConcurrentFileCount</span><span class="sxs-lookup"><span data-stu-id="40fec-132">PerFileThreadCount, ConcurrentFileCount</span></span> |  [<span data-ttu-id="40fec-133">링크</span><span class="sxs-lookup"><span data-stu-id="40fec-133">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-get-started-powershell#performance-guidance-while-using-powershell)   |
| <span data-ttu-id="40fec-134">AdlCopy</span><span class="sxs-lookup"><span data-stu-id="40fec-134">AdlCopy</span></span>    | <span data-ttu-id="40fec-135">Azure Data Lake Analytics 단위</span><span class="sxs-lookup"><span data-stu-id="40fec-135">Azure Data Lake Analytics units</span></span>  |   [<span data-ttu-id="40fec-136">링크</span><span class="sxs-lookup"><span data-stu-id="40fec-136">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob#performance-considerations-for-using-adlcopy)         |
| <span data-ttu-id="40fec-137">DistCp</span><span class="sxs-lookup"><span data-stu-id="40fec-137">DistCp</span></span>            | <span data-ttu-id="40fec-138">-m(mapper)</span><span class="sxs-lookup"><span data-stu-id="40fec-138">-m (mapper)</span></span>   | [<span data-ttu-id="40fec-139">링크</span><span class="sxs-lookup"><span data-stu-id="40fec-139">Link</span></span>](https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-copy-data-wasb-distcp#performance-considerations-while-using-distcp)                             |
| <span data-ttu-id="40fec-140">Azure 데이터 팩터리</span><span class="sxs-lookup"><span data-stu-id="40fec-140">Azure Data Factory</span></span>| <span data-ttu-id="40fec-141">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="40fec-141">parallelCopies</span></span>    | [<span data-ttu-id="40fec-142">링크</span><span class="sxs-lookup"><span data-stu-id="40fec-142">Link</span></span>](../data-factory/data-factory-copy-activity-performance.md)                          |
| <span data-ttu-id="40fec-143">Sqoop</span><span class="sxs-lookup"><span data-stu-id="40fec-143">Sqoop</span></span>           | <span data-ttu-id="40fec-144">fs.azure.block.size, -m(mapper)</span><span class="sxs-lookup"><span data-stu-id="40fec-144">fs.azure.block.size, -m (mapper)</span></span>    |   [<span data-ttu-id="40fec-145">링크</span><span class="sxs-lookup"><span data-stu-id="40fec-145">Link</span></span>](https://blogs.msdn.microsoft.com/bigdatasupport/2015/02/17/sqoop-job-performance-tuning-in-hdinsight-hadoop/)        |

## <a name="structure-your-data-set"></a><span data-ttu-id="40fec-146">데이터 집합 구성</span><span class="sxs-lookup"><span data-stu-id="40fec-146">Structure your data set</span></span>

<span data-ttu-id="40fec-147">데이터 레이크 저장소 hello 파일 크기에에서 데이터가 저장 되 면 파일 및 폴더 구조 수 성능에 영향을 줄 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-147">When data is stored in Data Lake Store, hello file size, number of files, and folder structure have an impact on performance.</span></span>  <span data-ttu-id="40fec-148">hello 다음 섹션에서는 이러한 영역 모범 사례</span><span class="sxs-lookup"><span data-stu-id="40fec-148">hello following section describes best practices in these areas.</span></span>  

### <a name="file-size"></a><span data-ttu-id="40fec-149">파일 크기</span><span class="sxs-lookup"><span data-stu-id="40fec-149">File size</span></span>

<span data-ttu-id="40fec-150">일반적으로 HDInsight, Azure Data Lake Analytics 등의 분석 엔진에서는 파일당 오버헤드가 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-150">Typically, analytics engines such as HDInsight and Azure Data Lake Analytics have a per-file overhead.</span></span>  <span data-ttu-id="40fec-151">데이터를 많은 작은 파일로 저장하는 경우 성능이 저하될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-151">If you store your data as many small files, this can negatively affect performance.</span></span>  

<span data-ttu-id="40fec-152">일반적으로 성능을 향상하려면 데이터를 더 큰 파일로 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-152">In general, organize your data into larger sized files for better performance.</span></span>  <span data-ttu-id="40fec-153">경험상, 데이터 집합을 256MB 이상의 파일로 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-153">As a rule of thumb, organize data sets in files of 256MB or larger.</span></span> <span data-ttu-id="40fec-154">이미지 및 이진 데이터와 같은 일부 경우에 없는 가능한 tooprocess 동시에 해당 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-154">In some cases such as images and binary data, it is not possible tooprocess them in parallel.</span></span>  <span data-ttu-id="40fec-155">이러한 경우 tookeep 개별 파일 2GB 미만 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-155">In these cases, it is recommended tookeep individual files under 2GB.</span></span>

<span data-ttu-id="40fec-156">경우에 따라 데이터 파이프라인에 다 수의 작은 파일 hello 원시 데이터에 대 한 제어를 제한 됩니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-156">Sometimes, data pipelines have limited control over hello raw data which has lots of small files.</span></span>  <span data-ttu-id="40fec-157">Toohave 좋습니다 큰를 생성 하는 "요리" 프로세스 toouse 다운스트림 응용 프로그램에 대 한 파일입니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-157">It is recommended toohave a “cooking” process that generates larger files toouse for downstream applications.</span></span>  

### <a name="organizing-time-series-data-in-folders"></a><span data-ttu-id="40fec-158">시계열 데이터를 폴더로 구성</span><span class="sxs-lookup"><span data-stu-id="40fec-158">Organizing Time Series data in folders</span></span>

<span data-ttu-id="40fec-159">Hive 및 ADLA 작업에 대 한 시계열 데이터의 파티션 정리 일부 쿼리 성능을 향상 시키는 hello 데이터의 하위 집합만 읽을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-159">For Hive and ADLA workloads, partition pruning of time-series data can help some queries read only a subset of hello data which improves performance.</span></span>    

<span data-ttu-id="40fec-160">시계열 데이터를 수집하는 이러한 파이프라인은 파일 및 폴더에 대해 구조적 명명을 사용하여 파일을 배치하는 경우가 많습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-160">Those pipelines that ingest time-series data, often place their files with a very structured naming for files and folders.</span></span> <span data-ttu-id="40fec-161">다음은 날짜별로 구성된 데이터에서 매우 일반적으로 나타나는 예입니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-161">Below is a very common example we see for data that is structured by date:</span></span>

    \DataSet\YYYY\MM\DD\datafile_YYYY_MM_DD.tsv

<span data-ttu-id="40fec-162">Datetime 정보 hello 폴더 및 파일 이름 hello에에서 나타나는지 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-162">Notice that hello datetime information appears both as folders and in hello filename.</span></span>

<span data-ttu-id="40fec-163">날짜 및 시간에 대 한 hello 다음은 일반 패턴</span><span class="sxs-lookup"><span data-stu-id="40fec-163">For date and time, hello following is a common pattern</span></span>

    \DataSet\YYYY\MM\DD\HH\mm\datafile_YYYY_MM_DD_HH_mm.tsv

<span data-ttu-id="40fec-164">마찬가지로 한 hello 더 큰 파일 크기 및 각 폴더에 있는 파일의 수를 적절 한 hello 선택 hello 폴더 및 파일 조직과 최적화 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-164">Again, hello choice you make with hello folder and file organization should optimize for hello larger file sizes and a reasonable number of files in each folder.</span></span>

## <a name="optimizing-io-intensive-jobs-on-hadoop-and-spark-workloads-on-hdinsight"></a><span data-ttu-id="40fec-165">HDInsight의 Hadoop 및 Spark 워크로드에 대한 I/O 집약적 작업 최적화</span><span class="sxs-lookup"><span data-stu-id="40fec-165">Optimizing I/O intensive jobs on Hadoop and Spark workloads on HDInsight</span></span>

<span data-ttu-id="40fec-166">작업은 hello 다음 세 가지 범주 중 하나에 속합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-166">Jobs fall into one of hello following three categories:</span></span>

* <span data-ttu-id="40fec-167">**CPU 집약적.**</span><span class="sxs-lookup"><span data-stu-id="40fec-167">**CPU intensive.**</span></span>  <span data-ttu-id="40fec-168">이러한 작업은 최소한의 I/O 시간으로 계산 시간이 깁니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-168">These jobs have long computation times with minimal I/O times.</span></span>  <span data-ttu-id="40fec-169">기계 학습 및 자연어 처리 작업을 예로 들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-169">Examples include machine learning and natural language processing jobs.</span></span>  
* <span data-ttu-id="40fec-170">**메모리 집약적.**</span><span class="sxs-lookup"><span data-stu-id="40fec-170">**Memory intensive.**</span></span>  <span data-ttu-id="40fec-171">이러한 작업은 메모리를 많이 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-171">These jobs use lots of memory.</span></span>  <span data-ttu-id="40fec-172">PageRank 및 실시간 분석 작업을 예로 들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-172">Examples include PageRank and real-time analytics jobs.</span></span>  
* <span data-ttu-id="40fec-173">**I/O 집약적.**</span><span class="sxs-lookup"><span data-stu-id="40fec-173">**I/O intensive.**</span></span>  <span data-ttu-id="40fec-174">이러한 작업은 I/O를 수행하는 데 대부분의 시간을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-174">These jobs spend most of their time doing I/O.</span></span>  <span data-ttu-id="40fec-175">읽기 및 쓰기 작업만 수행하는 복사 작업이 일반적인 예입니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-175">A common example is a copy job which does only read and write operations.</span></span>  <span data-ttu-id="40fec-176">다른 예로 많은 데이터 읽기, 일부 데이터 변환을 수행 하는 데이터 준비 작업 하 고 쓰기 hello 데이터 백 toohello 저장소 키를 누릅니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-176">Other examples include data preparation jobs that read a lot of data, performs some data transformation, and then writes hello data back toohello store.</span></span>  

<span data-ttu-id="40fec-177">hello 지침은 적용 가능한 tooI/O 집약적 작업입니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-177">hello following guidance is only applicable tooI/O intensive jobs.</span></span>

### <a name="general-considerations-for-an-hdinsight-cluster"></a><span data-ttu-id="40fec-178">HDInsight 클러스터에 대한 일반적인 고려 사항</span><span class="sxs-lookup"><span data-stu-id="40fec-178">General Considerations for an HDInsight cluster</span></span>

* <span data-ttu-id="40fec-179">**HDInsight 버전.**</span><span class="sxs-lookup"><span data-stu-id="40fec-179">**HDInsight versions.**</span></span> <span data-ttu-id="40fec-180">최상의 성능을 위해 HDInsight의 최신 릴리스에 hello를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-180">For best performance, use hello latest release of HDInsight.</span></span>
* <span data-ttu-id="40fec-181">**지역.**</span><span class="sxs-lookup"><span data-stu-id="40fec-181">**Regions.**</span></span> <span data-ttu-id="40fec-182">데이터 레이크 저장소 hello hello에 배치 hello HDInsight 클러스터와 동일한 지역입니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-182">Place hello Data Lake Store in hello same region as hello HDInsight cluster.</span></span>  

<span data-ttu-id="40fec-183">HDInsight 클러스터는 헤드 노드 두 개와 일부 작업자 노드로 구성됩니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-183">An HDInsight cluster is composed of two head nodes and some worker nodes.</span></span> <span data-ttu-id="40fec-184">각 작업자 노드는 특정 코어 수와 hello VM 유형에 의해 결정 되는 메모리를 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-184">Each worker node provides a specific number of cores and memory, which is determined by hello VM-type.</span></span>  <span data-ttu-id="40fec-185">작업을 실행할 때 YARN hello 사용 가능한 메모리 및 코어 toocreate 컨테이너에서 할당 하는 hello 리소스 협상 자입니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-185">When running a job, YARN is hello resource negotiator that allocates hello available memory and cores toocreate containers.</span></span>  <span data-ttu-id="40fec-186">각 컨테이너는 hello 작업 필요한 toocomplete hello 작업을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-186">Each container runs hello tasks needed toocomplete hello job.</span></span>  <span data-ttu-id="40fec-187">컨테이너는 신속 하 게 병렬 tooprocess 작업에서 실행 됩니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-187">Containers run in parallel tooprocess tasks quickly.</span></span> <span data-ttu-id="40fec-188">따라서 최대한 많은 병렬 컨테이너를 실행하여 성능을 향상합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-188">Therefore, performance is improved by running as many parallel containers as possible.</span></span>

<span data-ttu-id="40fec-189">튜닝 된 tooincrease 일 수 있는 HDInsight 클러스터 내에서 3 계층 hello 컨테이너의 개수 및 사용 가능한 모든 처리량을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-189">There are three layers within an HDInsight cluster that can be tuned tooincrease hello number of containers and use all available throughput.</span></span>  

* <span data-ttu-id="40fec-190">**물리적 계층**</span><span class="sxs-lookup"><span data-stu-id="40fec-190">**Physical layer**</span></span>
* <span data-ttu-id="40fec-191">**YARN 계층**</span><span class="sxs-lookup"><span data-stu-id="40fec-191">**YARN layer**</span></span>
* <span data-ttu-id="40fec-192">**워크로드 계층**</span><span class="sxs-lookup"><span data-stu-id="40fec-192">**Workload layer**</span></span>

### <a name="physical-layer"></a><span data-ttu-id="40fec-193">물리적 계층</span><span class="sxs-lookup"><span data-stu-id="40fec-193">Physical Layer</span></span>

<span data-ttu-id="40fec-194">**더 많은 노드 및/또는 더 큰 VM으로 클러스터를 실행합니다.**</span><span class="sxs-lookup"><span data-stu-id="40fec-194">**Run cluster with more nodes and/or larger sized VMs.**</span></span>  <span data-ttu-id="40fec-195">대규모 클러스터를 사용 하면 toorun 아래 hello 그림에 표시 된 대로 YARN 컨테이너가 더 이상 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-195">A larger cluster will enable you toorun more YARN containers as shown in hello picture below.</span></span>

![Data Lake Store 성능](./media/data-lake-store-performance-tuning-guidance/VM.png)

<span data-ttu-id="40fec-197">**더 많은 네트워크 대역폭을 가진 VM을 사용합니다.**</span><span class="sxs-lookup"><span data-stu-id="40fec-197">**Use VMs with more network bandwidth.**</span></span>  <span data-ttu-id="40fec-198">데이터 레이크 저장소 처리량 보다 네트워크 대역폭을 덜는 네트워크 대역폭 양을 hello 병목 상태가 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-198">hello amount of network bandwidth can be a bottleneck if there is less network bandwidth than Data Lake Store throughput.</span></span>  <span data-ttu-id="40fec-199">VM마다 각기 다른 네트워크 대역폭 크기를 갖게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-199">Different VMs will have varying network bandwidth sizes.</span></span>  <span data-ttu-id="40fec-200">가장 큰 가능한 네트워크 대역폭이 hello VM 유형을 선택 하십시오.</span><span class="sxs-lookup"><span data-stu-id="40fec-200">Choose a VM-type that has hello largest possible network bandwidth.</span></span>

### <a name="yarn-layer"></a><span data-ttu-id="40fec-201">YARN 계층</span><span class="sxs-lookup"><span data-stu-id="40fec-201">YARN Layer</span></span>

<span data-ttu-id="40fec-202">**더 작은 YARN 컨테이너를 사용합니다.**</span><span class="sxs-lookup"><span data-stu-id="40fec-202">**Use smaller YARN containers.**</span></span>  <span data-ttu-id="40fec-203">Hello로 컨테이너가 더 이상 각 YARN 컨테이너 toocreate의 hello 크기를 줄이려면 같은 양의 리소스입니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-203">Reduce hello size of each YARN container toocreate more containers with hello same amount of resources.</span></span>

![Data Lake Store 성능](./media/data-lake-store-performance-tuning-guidance/small-containers.png)

<span data-ttu-id="40fec-205">워크로드에 따라 항상 필요한 최소 YARN 컨테이너 크기가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-205">Depending on your workload, there will always be a minimum YARN container size that is needed.</span></span> <span data-ttu-id="40fec-206">너무 작은 컨테이너를 선택하면 작업에서 메모리 부족 문제가 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-206">If you pick too small a container, your jobs will run into out-of-memory issues.</span></span> <span data-ttu-id="40fec-207">일반적으로 YARN 컨테이너는 1GB 이상이어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-207">Typically YARN containers should be no smaller than 1GB.</span></span> <span data-ttu-id="40fec-208">일반적인 toosee 3GB YARN 컨테이너 이며</span><span class="sxs-lookup"><span data-stu-id="40fec-208">It’s common toosee 3GB YARN containers.</span></span> <span data-ttu-id="40fec-209">일부 워크로드의 경우 더 큰 YARN 컨테이너가 필요할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-209">For some workloads, you may need larger YARN containers.</span></span>  

<span data-ttu-id="40fec-210">**YARN 컨테이너당 코어 수를 늘립니다.**</span><span class="sxs-lookup"><span data-stu-id="40fec-210">**Increase cores per YARN container.**</span></span>  <span data-ttu-id="40fec-211">Hello tooeach 컨테이너 tooincrease hello 개수의 병렬 작업이 각 컨테이너를 실행 하는 할당 된 코어 수를 증가 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-211">Increase hello number of cores allocated tooeach container tooincrease hello number of parallel tasks that run in each container.</span></span>  <span data-ttu-id="40fec-212">이 방법은 컨테이너당 여러 태스크를 실행하는 Spark 등의 응용 프로그램에 적합합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-212">This works for applications like Spark which run multiple tasks per container.</span></span>  <span data-ttu-id="40fec-213">응용 프로그램 Hive와 같은 각 컨테이너에는 단일 스레드 실행 하는 컨테이너 당 더 많은 코어를 사용 하지 않고 컨테이너가 더 이상 toohave 정보가 개선 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-213">For applications like Hive which run a single thread in each container, it is better toohave more containers rather than more cores per container.</span></span>   

### <a name="workload-layer"></a><span data-ttu-id="40fec-214">워크로드 계층</span><span class="sxs-lookup"><span data-stu-id="40fec-214">Workload Layer</span></span>

<span data-ttu-id="40fec-215">**사용 가능한 모든 컨테이너를 이용합니다.**</span><span class="sxs-lookup"><span data-stu-id="40fec-215">**Use all available containers.**</span></span>  <span data-ttu-id="40fec-216">모든 리소스 사용 되는지에 있도록 사용 가능한 컨테이너에서 hello 수보다 크거나 hello 수가 작업 toobe 설정 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-216">Set hello number of tasks toobe equal or larger than hello number of available containers so that all resources are utilized.</span></span>

![Data Lake Store 성능](./media/data-lake-store-performance-tuning-guidance/use-containers.png)

<span data-ttu-id="40fec-218">**실패한 태스크는 비용이 많이 듭니다.**</span><span class="sxs-lookup"><span data-stu-id="40fec-218">**Failed tasks are costly.**</span></span> <span data-ttu-id="40fec-219">각 작업에 많은 양의 데이터 tooprocess 작업의 실패는 비용이 많이 드는 다시 시도에서 발생 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-219">If each task has a large amount of data tooprocess, then failure of a task results in an expensive retry.</span></span>  <span data-ttu-id="40fec-220">따라서 것이 더 나은 toocreate 더 많은 작업을 각각 적은 양의 데이터를 처리 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-220">Therefore, it is better toocreate more tasks, each of which processes a small amount of data.</span></span>

<span data-ttu-id="40fec-221">또한 toohello 일반 위의 지침, 각 응용 프로그램에는 해당 특정 응용 프로그램에 대 한 다양 한 매개 변수의 사용 가능한 tootune 있습니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-221">In addition toohello general guidelines above, each application has different parameters available tootune for that specific application.</span></span> <span data-ttu-id="40fec-222">hello 아래 표에 일부 hello 매개 변수 및 링크 tooget 각 응용 프로그램에 대 한 성능 튜닝을 시작 합니다.</span><span class="sxs-lookup"><span data-stu-id="40fec-222">hello table below lists some of hello parameters and links tooget started with performance tuning for each application.</span></span>

| <span data-ttu-id="40fec-223">워크로드</span><span class="sxs-lookup"><span data-stu-id="40fec-223">Workload</span></span>               | <span data-ttu-id="40fec-224">매개 변수 tooset 작업</span><span class="sxs-lookup"><span data-stu-id="40fec-224">Parameter tooset tasks</span></span>                                                         |
|--------------------|-------------------------------------------------------------------------------------|
| [<span data-ttu-id="40fec-225">HDInisight의 Spark</span><span class="sxs-lookup"><span data-stu-id="40fec-225">Spark on HDInisight</span></span>](data-lake-store-performance-tuning-spark.md)       | <ul><li><span data-ttu-id="40fec-226">Num-executors</span><span class="sxs-lookup"><span data-stu-id="40fec-226">Num-executors</span></span></li><li><span data-ttu-id="40fec-227">Executor-memory</span><span class="sxs-lookup"><span data-stu-id="40fec-227">Executor-memory</span></span></li><li><span data-ttu-id="40fec-228">Executor-cores</span><span class="sxs-lookup"><span data-stu-id="40fec-228">Executor-cores</span></span></li></ul> |
| [<span data-ttu-id="40fec-229">HDInsight의 Hive</span><span class="sxs-lookup"><span data-stu-id="40fec-229">Hive on HDInsight</span></span>](data-lake-store-performance-tuning-hive.md)    | <ul><li><span data-ttu-id="40fec-230">hive.tez.container.size</span><span class="sxs-lookup"><span data-stu-id="40fec-230">hive.tez.container.size</span></span></li></ul>         |
| [<span data-ttu-id="40fec-231">HDInsight의 MapReduce</span><span class="sxs-lookup"><span data-stu-id="40fec-231">MapReduce on HDInsight</span></span>](data-lake-store-performance-tuning-mapreduce.md)            | <ul><li><span data-ttu-id="40fec-232">Mapreduce.map.memory</span><span class="sxs-lookup"><span data-stu-id="40fec-232">Mapreduce.map.memory</span></span></li><li><span data-ttu-id="40fec-233">Mapreduce.job.maps</span><span class="sxs-lookup"><span data-stu-id="40fec-233">Mapreduce.job.maps</span></span></li><li><span data-ttu-id="40fec-234">Mapreduce.reduce.memory</span><span class="sxs-lookup"><span data-stu-id="40fec-234">Mapreduce.reduce.memory</span></span></li><li><span data-ttu-id="40fec-235">Mapreduce.job.reduces</span><span class="sxs-lookup"><span data-stu-id="40fec-235">Mapreduce.job.reduces</span></span></li></ul> |
| [<span data-ttu-id="40fec-236">HDInsight의 Storm</span><span class="sxs-lookup"><span data-stu-id="40fec-236">Storm on HDInsight</span></span>](data-lake-store-performance-tuning-storm.md)| <ul><li><span data-ttu-id="40fec-237">작업자 프로세스 수</span><span class="sxs-lookup"><span data-stu-id="40fec-237">Number of worker processes</span></span></li><li><span data-ttu-id="40fec-238">Spout 실행자 인스턴스 수</span><span class="sxs-lookup"><span data-stu-id="40fec-238">Number of spout executor instances</span></span></li><li><span data-ttu-id="40fec-239">Bolt 실행자 인스턴스 수</span><span class="sxs-lookup"><span data-stu-id="40fec-239">Number of bolt executor instances</span></span> </li><li><span data-ttu-id="40fec-240">Spout 작업 수</span><span class="sxs-lookup"><span data-stu-id="40fec-240">Number of spout tasks</span></span></li><li><span data-ttu-id="40fec-241">Bolt 작업 수</span><span class="sxs-lookup"><span data-stu-id="40fec-241">Number of bolt tasks</span></span></li></ul>|

## <a name="see-also"></a><span data-ttu-id="40fec-242">참고 항목</span><span class="sxs-lookup"><span data-stu-id="40fec-242">See also</span></span>
* [<span data-ttu-id="40fec-243">Azure 데이터 레이크 저장소 개요</span><span class="sxs-lookup"><span data-stu-id="40fec-243">Overview of Azure Data Lake Store</span></span>](data-lake-store-overview.md)
* [<span data-ttu-id="40fec-244">Azure 데이터 레이크 분석 시작</span><span class="sxs-lookup"><span data-stu-id="40fec-244">Get Started with Azure Data Lake Analytics</span></span>](../data-lake-analytics/data-lake-analytics-get-started-portal.md)
