---
title: "복사 작업 성능 및 조정 가이드 | Microsoft 문서"
description: "복사 작업을 사용할 때 Azure Data Factory의 데이터 이동의 성능에 영향을 주는 주요 요소에 대해 알아봅니다."
services: data-factory
documentationcenter: 
author: linda33wj
manager: jhubbard
editor: monicar
ms.assetid: 4b9a6a4f-8cf5-4e0a-a06f-8133a2b7bc58
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/10/2017
ms.author: jingwang
ms.openlocfilehash: 2779655aee3af3a351b30f18b4c9d9918e9f2210
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 08/29/2017
---
# <a name="copy-activity-performance-and-tuning-guide"></a><span data-ttu-id="974d6-103">복사 작업 성능 및 조정 가이드</span><span class="sxs-lookup"><span data-stu-id="974d6-103">Copy Activity performance and tuning guide</span></span>
<span data-ttu-id="974d6-104">Azure Data Factory 복사 작업은 최고 수준의 보안, 안정성 및 고성능 데이터 로드 솔루션을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-104">Azure Data Factory Copy Activity delivers a first-class secure, reliable, and high-performance data loading solution.</span></span> <span data-ttu-id="974d6-105">풍부하게 다양한 클라우드 및 온-프레미스 데이터 저장소에서 매일 수십 테라바이트의 데이터를 복사할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-105">It enables you to copy tens of terabytes of data every day across a rich variety of cloud and on-premises data stores.</span></span> <span data-ttu-id="974d6-106">초고속 데이터 로드 성능은 핵심적인 "빅 데이터" 문제인 고급 분석 솔루션을 구축하고 모든 데이터에서 깊은 통찰을 얻는 데 집중할 수 있도록 하는 열쇠입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-106">Blazing-fast data loading performance is key to ensure you can focus on the core “big data” problem: building advanced analytics solutions and getting deep insights from all that data.</span></span>

<span data-ttu-id="974d6-107">Azure는 엔터프라이즈급 데이터 저장소 및 데이터 웨어하우스 솔루션 세트를 제공하고 복사 작업은 쉽게 구성 및 설정할 수 있는 고도로 최적화된 데이터 로드 환경을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-107">Azure provides a set of enterprise-grade data storage and data warehouse solutions, and Copy Activity offers a highly optimized data loading experience that is easy to configure and set up.</span></span> <span data-ttu-id="974d6-108">단일 복사 작업 만을 사용하여 다음을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-108">With just a single copy activity, you can achieve:</span></span>

* <span data-ttu-id="974d6-109">**1.2Gbps** 속도로 **Azure SQL Data Warehouse**에 데이터 로드 -</span><span class="sxs-lookup"><span data-stu-id="974d6-109">Loading data into **Azure SQL Data Warehouse** at **1.2 GBps**.</span></span> <span data-ttu-id="974d6-110">사용 사례가 있는 연습을 보려면 [Azure Data Factory를 통해 Azure SQL Data Warehouse에 15분 이내 1TB 로드](data-factory-load-sql-data-warehouse.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-110">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
* <span data-ttu-id="974d6-111">**1.0 Gbps** 속도로 **Azure Blob 저장소**에 데이터 로드</span><span class="sxs-lookup"><span data-stu-id="974d6-111">Loading data into **Azure Blob storage** at **1.0 GBps**</span></span>
* <span data-ttu-id="974d6-112">**1.0 Gbps** 속도로 **Azure Data Lake Store**에 데이터 로드</span><span class="sxs-lookup"><span data-stu-id="974d6-112">Loading data into **Azure Data Lake Store** at **1.0 GBps**</span></span>

<span data-ttu-id="974d6-113">이 문서에서는 다음을 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-113">This article describes:</span></span>

* <span data-ttu-id="974d6-114">[성능 참조 번호](#performance-reference)와 프로젝트를 계획하는 데 도움이 되는 싱크 데이터 저장소.</span><span class="sxs-lookup"><span data-stu-id="974d6-114">[Performance reference numbers](#performance-reference) for supported source and sink data stores to help you plan your project;</span></span>
* <span data-ttu-id="974d6-115">[클라우드 데이터 이동 단위](#cloud-data-movement-units), [병렬 복사](#parallel-copy), [준비된 복사](#staged-copy)를 포함한 다양한 시나리오에서 복사 처리량을 높일 수 있는 기능.</span><span class="sxs-lookup"><span data-stu-id="974d6-115">Features that can boost the copy throughput in different scenarios, including [cloud data movement units](#cloud-data-movement-units), [parallel copy](#parallel-copy), and [staged Copy](#staged-copy);</span></span>
* <span data-ttu-id="974d6-116">[성능 조정 지침](#performance-tuning-steps) .</span><span class="sxs-lookup"><span data-stu-id="974d6-116">[Performance tuning guidance](#performance-tuning-steps) on how to tune the performance and the key factors that can impact copy performance.</span></span>

> [!NOTE]
> <span data-ttu-id="974d6-117">복사 작업에 대해 전반적으로 잘 알지 못하는 경우, 이 문서를 읽기 전에 [복사 작업을 사용하여 데이터 이동](data-factory-data-movement-activities.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-117">If you are not familiar with Copy Activity in general, see [Move data by using Copy Activity](data-factory-data-movement-activities.md) before reading this article.</span></span>
>

## <a name="performance-reference"></a><span data-ttu-id="974d6-118">성능 참조</span><span class="sxs-lookup"><span data-stu-id="974d6-118">Performance reference</span></span>

<span data-ttu-id="974d6-119">참조로 아래 테이블에 사내 테스트에 따른 지정된 원본 및 싱크 쌍에 대한 복사 처리량(MBps)이 나와 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-119">As a reference, below table shows the copy throughput number in MBps for the given source and sink pairs based on in-house testing.</span></span> <span data-ttu-id="974d6-120">비교를 위해 [클라우드 데이터 이동 단위](#cloud-data-movement-units) 또는 [데이터 관리 게이트웨이 확장성](data-factory-data-management-gateway-high-availability-scalability.md)(여러 게이트웨이 노드)의 다른 설정이 어떻게 복사 성능에 도움이 되는지도 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-120">For comparison, it also demonstrates how different settings of [cloud data movement units](#cloud-data-movement-units) or [Data Management Gateway scalability](data-factory-data-management-gateway-high-availability-scalability.md) (multiple gateway nodes) can help on copy performance.</span></span>

![성능 매트릭스](./media/data-factory-copy-activity-performance/CopyPerfRef.png)


<span data-ttu-id="974d6-122">**주의할 사항:**</span><span class="sxs-lookup"><span data-stu-id="974d6-122">**Points to note:**</span></span>
* <span data-ttu-id="974d6-123">처리량은 다음 수식을 사용하여 계산됩니다. [원본에서 읽은 데이터의 크기]/[복사 작업 실행 기간]</span><span class="sxs-lookup"><span data-stu-id="974d6-123">Throughput is calculated by using the following formula: [size of data read from source]/[Copy Activity run duration].</span></span>
* <span data-ttu-id="974d6-124">테이블의 성능 참조 번호는 [TPC-H](http://www.tpc.org/tpch/) 데이터 집합을 사용하여 단일 복사 작업 실행을 통해 측정된 것입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-124">The performance reference numbers in the table were measured using [TPC-H](http://www.tpc.org/tpch/) data set in a single copy activity run.</span></span>
* <span data-ttu-id="974d6-125">Azure 데이터 저장소에서는 원본 및 싱크는 동일한 Azure 지역에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-125">In Azure data stores, the source and sink are in the same Azure region.</span></span>
* <span data-ttu-id="974d6-126">온-프레미스와 클라우드 데이터 저장소 간 하이브리드 복사의 경우 각 게이트웨이 노드는 아래 사양을 사용하는 온-프레미스 데이터 저장소에서 분리된 컴퓨터에서 실행되었습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-126">For hybrid copy between on-premises and cloud data stores, each gateway node was running on a machine that was separate from the on-premises data store with below specification.</span></span> <span data-ttu-id="974d6-127">게이트웨이에 단일 작업이 실행 중인 경우 복사 작업은 테스트 컴퓨터의 CPU, 메모리 또는 네트워크 대역폭의 작은 부분만 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-127">When a single activity was running on gateway, the copy operation consumed only a small portion of the test machine's CPU, memory, or network bandwidth.</span></span> <span data-ttu-id="974d6-128">[데이터 관리 게이트웨이에 대한 고려 사항](#considerations-for-data-management-gateway)에서 자세히 알아보세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-128">Learn more from [consideration for Data Management Gateway](#considerations-for-data-management-gateway).</span></span>
    <table>
    <tr>
        <td><span data-ttu-id="974d6-129">CPU</span><span class="sxs-lookup"><span data-stu-id="974d6-129">CPU</span></span></td>
        <td><span data-ttu-id="974d6-130">32 코어 2.20GHz Intel Xeon E5-2660 v2</span><span class="sxs-lookup"><span data-stu-id="974d6-130">32 cores 2.20 GHz Intel Xeon E5-2660 v2</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="974d6-131">메모리</span><span class="sxs-lookup"><span data-stu-id="974d6-131">Memory</span></span></td>
        <td><span data-ttu-id="974d6-132">128GB</span><span class="sxs-lookup"><span data-stu-id="974d6-132">128 GB</span></span></td>
    </tr>
    <tr>
        <td><span data-ttu-id="974d6-133">네트워크</span><span class="sxs-lookup"><span data-stu-id="974d6-133">Network</span></span></td>
        <td><span data-ttu-id="974d6-134">인터넷 인터페이스: 10Gbps. 인트라넷 인터페이스: 40Gbps</span><span class="sxs-lookup"><span data-stu-id="974d6-134">Internet interface: 10 Gbps; intranet interface: 40 Gbps</span></span></td>
    </tr>
    </table>


> [!TIP]
> <span data-ttu-id="974d6-135">기본 최대 DMU(데이터 이동 단위)보다 많은 DMU를 활용하여 더 많은 처리량을 획득할 수 있으며, 클라우드 간 복사 작업 실행의 경우 32입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-135">You can achieve higher throughput by leveraging more data movement units (DMUs) than the default maximum DMUs, which is 32 for a cloud-to-cloud copy activity run.</span></span> <span data-ttu-id="974d6-136">예를 들어 100개 DMU를 사용하면 **1.0GBps** 속도로 Azure Blob에서 Azure Data Lake Store로 데이터 복사를 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-136">For example, with 100 DMUs, you can achieve copying data from Azure Blob into Azure Data Lake Store at **1.0GBps**.</span></span> <span data-ttu-id="974d6-137">이 기능과 지원되는 시나리오에 대한 자세한 내용은 [클라우드 데이터 이동 단위](#cloud-data-movement-units) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-137">See the [Cloud data movement units](#cloud-data-movement-units) section for details about this feature and the supported scenario.</span></span> <span data-ttu-id="974d6-138">DMU를 더 많이 요청하려면 [Azure 지원](https://azure.microsoft.com/support/)에 문의하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-138">Contact [Azure support](https://azure.microsoft.com/support/) to request more DMUs.</span></span>

## <a name="parallel-copy"></a><span data-ttu-id="974d6-139">병렬 복사</span><span class="sxs-lookup"><span data-stu-id="974d6-139">Parallel copy</span></span>
<span data-ttu-id="974d6-140">**복사 작업 실행 내에서 병렬로** 원본에서 데이터를 읽어 오거나 대상에 데이터를 쓸 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-140">You can read data from the source or write data to the destination **in parallel within a Copy Activity run**.</span></span> <span data-ttu-id="974d6-141">이 기능을 통해 복사 작업의 처리량을 늘리고 데이터를 이동하는 데 소요되는 시간을 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-141">This feature enhances the throughput of a copy operation and reduces the time it takes to move data.</span></span>

<span data-ttu-id="974d6-142">이 설정은 작업 정의의 **concurrency** 속성과 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-142">This setting is different from the **concurrency** property in the activity definition.</span></span> <span data-ttu-id="974d6-143">**concurrency** 속성은 다양한 작업 기간(오전 1-2시, 오전 2-3시, 오전 3-4시 등)의 데이터를 처리하기 위해 **동시 복사 작업 실행**의 수를 결정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-143">The **concurrency** property determines the number of **concurrent Copy Activity runs** to process data from different activity windows (1 AM to 2 AM, 2 AM to 3 AM, 3 AM to 4 AM, and so on).</span></span> <span data-ttu-id="974d6-144">이 기능은 기록 로드를 수행하는 경우 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-144">This capability is helpful when you perform a historical load.</span></span> <span data-ttu-id="974d6-145">병렬 복사 기능은 **단일 작업 실행**에 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-145">The parallel copy capability applies to a **single activity run**.</span></span>

<span data-ttu-id="974d6-146">샘플 시나리오를 살펴 보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-146">Let's look at a sample scenario.</span></span> <span data-ttu-id="974d6-147">다음 예에서는 과거 여러 조각을 처리해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-147">In the following example, multiple slices from the past need to be processed.</span></span> <span data-ttu-id="974d6-148">Data Factory는 각 조각에 대한 복사 작업(작업 실행) 인스턴스를 하나 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-148">Data Factory runs an instance of Copy Activity (an activity run) for each slice:</span></span>

* <span data-ttu-id="974d6-149">첫 번째 작업 기간(오전 1시 - 오전 2시)의 데이터 조각 ==> 작업 실행 1</span><span class="sxs-lookup"><span data-stu-id="974d6-149">The data slice from the first activity window (1 AM to 2 AM) ==> Activity run 1</span></span>
* <span data-ttu-id="974d6-150">두 번째 작업 기간(오전 2시 - 오전 3시)의 데이터 조각 ==> 작업 실행 2</span><span class="sxs-lookup"><span data-stu-id="974d6-150">The data slice from the second activity window (2 AM to 3 AM) ==> Activity run 2</span></span>
* <span data-ttu-id="974d6-151">세 번째 작업 기간(오전 3시 - 오전 4시)의 데이터 조각 ==> 작업 실행 3</span><span class="sxs-lookup"><span data-stu-id="974d6-151">The data slice from the second activity window (3 AM to 4 AM) ==> Activity run 3</span></span>

<span data-ttu-id="974d6-152">방식으로 계속됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-152">And so on.</span></span>

<span data-ttu-id="974d6-153">이 예제의 **concurrency** 값이 2로 설정되면 **작업 실행 1** 및 **작업 실행 2**에서 두 작업 기간의 데이터를 **동시에** 복사하여 데이터 이동 성능을 향상시킬 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-153">In this example, when the **concurrency** value is set to 2, **Activity run 1** and **Activity run 2** copy data from two activity windows **concurrently** to improve data movement performance.</span></span> <span data-ttu-id="974d6-154">하지만, 작업 실행 1에 관련된 파일이 여러 개이면, 데이터 이동 서비스는 원본에서 대상으로 한 번에 하나의 파일을 복사합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-154">However, if multiple files are associated with Activity run 1, the data movement service copies files from the source to the destination one file at a time.</span></span>

### <a name="cloud-data-movement-units"></a><span data-ttu-id="974d6-155">클라우드 데이터 이동 단위</span><span class="sxs-lookup"><span data-stu-id="974d6-155">Cloud data movement units</span></span>
<span data-ttu-id="974d6-156">**클라우드 데이터 이동 단위(DMU)** 는 Data Factory 내 단일 단위의 힘(CPU, 메모리, 네트워크 자원 할당의 조합)을 나타내는 척도입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-156">A **cloud data movement unit (DMU)** is a measure that represents the power (a combination of CPU, memory, and network resource allocation) of a single unit in Data Factory.</span></span> <span data-ttu-id="974d6-157">클라우드-클라우드 복사 작업에 DMU를 사용할 수 있으며 하이브리드 복사에는 사용할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-157">A DMU might be used in a cloud-to-cloud copy operation, but not in a hybrid copy.</span></span>

<span data-ttu-id="974d6-158">기본적으로, Data Factory는 단일 클라우드 DMU를 사용하여 단일 복사 작업 실행을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-158">By default, Data Factory uses a single cloud DMU to perform a single Copy Activity run.</span></span> <span data-ttu-id="974d6-159">기본값을 재정의하려면 **cloudDataMovementUnits** 속성에 대한 값을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-159">To override this default, specify a value for the **cloudDataMovementUnits** property as follows.</span></span> <span data-ttu-id="974d6-160">특정 복사 원본 및 싱크에 대해 더 많은 단위를 구성할 때 얻을 수 있는 성능상 이점 수준에 대한 자세한 내용은 [성능 참조](#performance-reference)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-160">For information about the level of performance gain you might get when you configure more units for a specific copy source and sink, see the [performance reference](#performance-reference).</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "cloudDataMovementUnits": 32
        }
    }
]
```
<span data-ttu-id="974d6-161">**cloudDataMovementUnits** 속성에 **허용되는 값**은 1(기본값), 2, 4, 8, 16, 32입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-161">The **allowed values** for the **cloudDataMovementUnits** property are 1 (default), 2, 4, 8, 16, 32.</span></span> <span data-ttu-id="974d6-162">런타임 시 복사 작업에서 사용하는 **실제 클라우드 DMU 수**는 데이터 패턴에 따라 구성된 값 이하입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-162">The **actual number of cloud DMUs** that the copy operation uses at run time is equal to or less than the configured value, depending on your data pattern.</span></span>

> [!NOTE]
> <span data-ttu-id="974d6-163">더 높은 처리량을 위해 더 많은 클라우드 DMU가 필요하면 [Azure 지원](https://azure.microsoft.com/support/)에 문의하시기 바랍니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-163">If you need more cloud DMUs for a higher throughput, contact [Azure support](https://azure.microsoft.com/support/).</span></span> <span data-ttu-id="974d6-164">8 이상의 설정은 현재 **Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP에서 Blob storage/Data Lake Store/Azure SQL Database로 여러 파일을 복사**하는 경우에만 작동합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-164">Setting of 8 and above currently works only when you **copy multiple files from Blob storage/Data Lake Store/Amazon S3/cloud FTP/cloud SFTP to Blob storage/Data Lake Store/Azure SQL Database**.</span></span>
>

### <a name="parallelcopies"></a><span data-ttu-id="974d6-165">parallelCopies</span><span class="sxs-lookup"><span data-stu-id="974d6-165">parallelCopies</span></span>
<span data-ttu-id="974d6-166">**parallelCopies** 속성을 사용하여 복사 작업에 사용할 병렬 처리를 나타낼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-166">You can use the **parallelCopies** property to indicate the parallelism that you want Copy Activity to use.</span></span> <span data-ttu-id="974d6-167">이 속성을 병렬로 원본에서 읽어오거나 싱크 데이터 저장소에 쓰는 복사 작업 내 최대 스레드 수라고 생각할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-167">You can think of this property as the maximum number of threads within Copy Activity that can read from your source or write to your sink data stores in parallel.</span></span>

<span data-ttu-id="974d6-168">각각의 복사 작업 실행에 대해, Data Factory는 원본 데이터 저장소의 데이터를 대상 데이터 저장소에 복사하는 데 사용할 병렬 복사의 수를 결정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-168">For each Copy Activity run, Data Factory determines the number of parallel copies to use to copy data from the source data store and to the destination data store.</span></span> <span data-ttu-id="974d6-169">사용되는 병렬 복사의 기본 수는 사용 중인 원본 및 싱크의 유형에 따라 달라집니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-169">The default number of parallel copies that it uses depends on the type of source and sink that you are using.</span></span>  

| <span data-ttu-id="974d6-170">원본 및 싱크</span><span class="sxs-lookup"><span data-stu-id="974d6-170">Source and sink</span></span> | <span data-ttu-id="974d6-171">서비스에 의해 결정되는 기본 병렬 복사 개수</span><span class="sxs-lookup"><span data-stu-id="974d6-171">Default parallel copy count determined by service</span></span> |
| --- | --- |
| <span data-ttu-id="974d6-172">파일 기반 저장소 간에 데이터 복사(Blob 저장소, Data Lake Store, Amazon S3, 온-프레미스 파일 시스템, 온-프레미스 HDFS)</span><span class="sxs-lookup"><span data-stu-id="974d6-172">Copy data between file-based stores (Blob storage; Data Lake Store; Amazon S3; an on-premises file system; an on-premises HDFS)</span></span> |<span data-ttu-id="974d6-173">1에서 32 사이.</span><span class="sxs-lookup"><span data-stu-id="974d6-173">Between 1 and 32.</span></span> <span data-ttu-id="974d6-174">파일 크기 및 클라우드 데이터 이동 단위의 수(DMU)에 따라, 두 클라우드 데이터 저장소 간에 데이터를 복사하거나, 하이브리드 복사(온-프레미스 데이터 저장소 간에 데이터 복사)에 사용되는 게이트웨이 컴퓨터에 대한 물리적인 구성에 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-174">Depends on the size of the files and the number of cloud data movement units (DMUs) used to copy data between two cloud data stores, or the physical configuration of the Gateway machine used for a hybrid copy (to copy data to or from an on-premises data store).</span></span> |
| <span data-ttu-id="974d6-175">**원본 데이터 저장소의 데이터를 Azure 테이블 저장소에**</span><span class="sxs-lookup"><span data-stu-id="974d6-175">Copy data from **any source data store to Azure Table storage**</span></span> |<span data-ttu-id="974d6-176">4</span><span class="sxs-lookup"><span data-stu-id="974d6-176">4</span></span> |
| <span data-ttu-id="974d6-177">기타 모든 원본 및 싱크 쌍</span><span class="sxs-lookup"><span data-stu-id="974d6-177">All other source and sink pairs</span></span> |<span data-ttu-id="974d6-178">1</span><span class="sxs-lookup"><span data-stu-id="974d6-178">1</span></span> |

<span data-ttu-id="974d6-179">일반적으로 기본 동작이 최고의 처리량을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-179">Usually, the default behavior should give you the best throughput.</span></span> <span data-ttu-id="974d6-180">하지만, 데이터 저장소를 호스트하는 컴퓨터에서 로드를 제어하거나 복사 성능을 조정하기 위해 기본 값을 재정의하고 **parallelCopies** 속성의 값을 지정하도록 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-180">However, to control the load on machines that host your data stores, or to tune copy performance, you may choose to override the default value and specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="974d6-181">값은 1에서 32(두 숫자 모두 포함) 사이여야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-181">The value must be between 1 and 32 (both inclusive).</span></span> <span data-ttu-id="974d6-182">런타임 시, 최고의 성능을 위해 복사 작업은 설정된 값 이하의 값을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-182">At run time, for the best performance, Copy Activity uses a value that is less than or equal to the value that you set.</span></span>

```json
"activities":[  
    {
        "name": "Sample copy activity",
        "description": "",
        "type": "Copy",
        "inputs": [{ "name": "InputDataset" }],
        "outputs": [{ "name": "OutputDataset" }],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 8
        }
    }
]
```
<span data-ttu-id="974d6-183">주의할 사항:</span><span class="sxs-lookup"><span data-stu-id="974d6-183">Points to note:</span></span>

* <span data-ttu-id="974d6-184">파일 기반 저장소간에 데이터를 복사하면 **parallelCopies**에서 파일 수준 병렬 처리를 결정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-184">When you copy data between file-based stores, the **parallelCopies** determine the parallelism at the file level.</span></span> <span data-ttu-id="974d6-185">단일 파일에서 수행되는 청크는 자동으로 투명하게 발생하며, 주어진 원본 데이터 저장소 유형에 가장 적합한 청크 크기를 사용하여 parallelCopies에 대해 병렬 및 직각으로 데이터를 로드하도록 설계되었습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-185">The chunking within a single file would happen underneath automatically and transparently, and it's designed to use the best suitable chunk size for a given source data store type to load data in parallel and orthogonal to parallelCopies.</span></span> <span data-ttu-id="974d6-186">런타임 시 데이터 이동 서비스에서 복사 작업에 사용하는 병렬 복사의 실제 수는 사용자가 보유한 파일의 수를 넘지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-186">The actual number of parallel copies the data movement service uses for the copy operation at run time is no more than the number of files you have.</span></span> <span data-ttu-id="974d6-187">복사 동작이 **mergeFile**인 경우 복사 작업은 파일 수준 병렬 처리의 이점을 활용할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-187">If the copy behavior is **mergeFile**, Copy Activity cannot take advantage of file-level parallelism.</span></span>
* <span data-ttu-id="974d6-188">**parallelCopies** 속성에 대한 값을 지정할 때는 원본 및 싱크 데이터 저장소, 게이트웨이(하이브리드 복사인 경우)에 대한 로드 증가를 고려합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-188">When you specify a value for the **parallelCopies** property, consider the load increase on your source and sink data stores, and to gateway if it is a hybrid copy.</span></span> <span data-ttu-id="974d6-189">동일한 데이터 저장소에 대해 실행되는 여러 활동이 있거나 동일한 활동의 동시 실행이 있는 경우 특히 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-189">This happens especially when you have multiple activities or concurrent runs of the same activities that run against the same data store.</span></span> <span data-ttu-id="974d6-190">데이터 저장소나 게이트웨이가 로드로 인해 과부하가 걸리면, 로드가 감소되도록 **parallelCopies** 값을 줄이십시오.</span><span class="sxs-lookup"><span data-stu-id="974d6-190">If you notice that either the data store or Gateway is overwhelmed with the load, decrease the **parallelCopies** value to relieve the load.</span></span>
* <span data-ttu-id="974d6-191">파일 기반이 아닌 저장소에서 파일 기반인 저장소로 데이터를 이동할 경우 데이터 이동 서비스는 **parallelCopies** 속성을 무시합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-191">When you copy data from stores that are not file-based to stores that are file-based, the data movement service ignores the **parallelCopies** property.</span></span> <span data-ttu-id="974d6-192">병렬 처리를 지정하더라도 이 경우에는 적용되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-192">Even if parallelism is specified, it's not applied in this case.</span></span>

> [!NOTE]
> <span data-ttu-id="974d6-193">하이브리드 복사를 수행할 때 **parallelCopies** 기능을 사용하기 위해서는 1.11 버전 이상의 데이터 관리 게이트웨이를 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-193">You must use Data Management Gateway version 1.11 or later to use the **parallelCopies** feature when you do a hybrid copy.</span></span>
>
>

<span data-ttu-id="974d6-194">이러한 2가지 속성을 개선하고 데이터 이동 처리량을 향상시키려면 [샘플 사용 사례](#case-study-use-parallel-copy)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-194">To better use these two properties, and to enhance your data movement throughput, see the [sample use cases](#case-study-use-parallel-copy).</span></span> <span data-ttu-id="974d6-195">기본 동작을 활용하기 위해 **parallelCopies** 를 구성할 필요가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-195">You don't need to configure **parallelCopies** to take advantage of the default behavior.</span></span> <span data-ttu-id="974d6-196">구성을 수행하고 **parallelCopies**가 너무 작은 경우 여러 클라우드 DMU가 완전히 활용되지 않을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-196">If you do configure and **parallelCopies** is too small, multiple cloud DMUs might not be fully utilized.</span></span>  

### <a name="billing-impact"></a><span data-ttu-id="974d6-197">청구 영향</span><span class="sxs-lookup"><span data-stu-id="974d6-197">Billing impact</span></span>
<span data-ttu-id="974d6-198">복사 작업의 총 시간을 기준으로 요금이 청구된다는 점을 기억하는 것이 **중요**합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-198">It's **important** to remember that you are charged based on the total time of the copy operation.</span></span> <span data-ttu-id="974d6-199">클라우드 단위 1개로 1시간이 걸렸던 복사 작업이 이제 클라우드 단위 4개로 15분이 걸리는 경우 전체 청구 금액은 거의 동일한 상태로 유지됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-199">If a copy job used to take one hour with one cloud unit and now it takes 15 minutes with four cloud units, the overall bill remains almost the same.</span></span> <span data-ttu-id="974d6-200">예를 들어 4개의 클라우드 단위를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-200">For example, you use four cloud units.</span></span> <span data-ttu-id="974d6-201">첫 번째 클라우드 단위 10분, 두 번째 10분, 세 번째 5분, 네 번째 5분으로 모두 하나의 복사 작업 실행으로 수행됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-201">The first cloud unit spends 10 minutes, the second one, 10 minutes, the third one, 5 minutes, and the fourth one, 5 minutes, all in one Copy Activity run.</span></span> <span data-ttu-id="974d6-202">총 복사(데이터 이동) 시간(10 + 10 + 5 + 5 = 30분)에 대한 요금이 청구됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-202">You are charged for the total copy (data movement) time, which is 10 + 10 + 5 + 5 = 30 minutes.</span></span> <span data-ttu-id="974d6-203">**parallelCopies**의 사용은 청구에 영향을 주지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-203">Using **parallelCopies** does not affect billing.</span></span>

## <a name="staged-copy"></a><span data-ttu-id="974d6-204">준비된 복사</span><span class="sxs-lookup"><span data-stu-id="974d6-204">Staged copy</span></span>
<span data-ttu-id="974d6-205">원본 데이터 저장소에서 싱크 데이터 저장소에 데이터를 복사할 경우 중간 준비 저장소로 Blob 저장소를 사용하도록 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-205">When you copy data from a source data store to a sink data store, you might choose to use Blob storage as an interim staging store.</span></span> <span data-ttu-id="974d6-206">준비는 다음과 같은 경우에 특히 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-206">Staging is especially useful in the following cases:</span></span>

1. <span data-ttu-id="974d6-207">**PolyBase를 통해 다양한 데이터 저장소에서 SQL Data Warehouse에 데이터를 수집하고자 합니다.**</span><span class="sxs-lookup"><span data-stu-id="974d6-207">**You want to ingest data from various data stores into SQL Data Warehouse via PolyBase**.</span></span> <span data-ttu-id="974d6-208">SQL Data Warehouse는 많은 양의 데이터를 SQL Data Warehouse에 로드하는 처리량이 높은 메커니즘인 PolyBase를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-208">SQL Data Warehouse uses PolyBase as a high-throughput mechanism to load a large amount of data into SQL Data Warehouse.</span></span> <span data-ttu-id="974d6-209">단, 원본 데이터가 Blob 저장소에 있어야 하고 추가 조건을 충족해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-209">However, the source data must be in Blob storage, and it must meet additional criteria.</span></span> <span data-ttu-id="974d6-210">Blob 저장소가 아닌 데이터 저장소에서 데이터를 로드하는 경우 중간 준비 Blob 저장소를 통해 데이터 복사를 활성화할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-210">When you load data from a data store other than Blob storage, you can activate data copying via interim staging Blob storage.</span></span> <span data-ttu-id="974d6-211">이 경우 Data Factory는 PolyBase의 요구 사항을 충족하는지 확인하기 위해 필요한 데이터 변환을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-211">In that case, Data Factory performs the required data transformations to ensure that it meets the requirements of PolyBase.</span></span> <span data-ttu-id="974d6-212">그런 다음 PolyBase를 사용하여 데이터를 SQL Data Warehouse에 로드합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-212">Then it uses PolyBase to load data into SQL Data Warehouse.</span></span> <span data-ttu-id="974d6-213">자세한 내용은 [PolyBase를 사용하여 Azure SQL Data Warehouse에 데이터 로드](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-213">For more details, see [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).</span></span> <span data-ttu-id="974d6-214">사용 사례가 있는 연습을 보려면 [Azure Data Factory를 통해 Azure SQL Data Warehouse에 15분 이내 1TB 로드](data-factory-load-sql-data-warehouse.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-214">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>
2. <span data-ttu-id="974d6-215">**때로는 느린 네트워크 연결을 통해 하이브리드 데이터 이동(즉, 온-프레미스 데이터 저장소와 클라우드 데이터 저장소 간에 복사하려면)을 수행하는 데 오랜 시간이 걸립니다.**</span><span class="sxs-lookup"><span data-stu-id="974d6-215">**Sometimes it takes a while to perform a hybrid data movement (that is, to copy between an on-premises data store and a cloud data store) over a slow network connection**.</span></span> <span data-ttu-id="974d6-216">성능을 개선하기 위해 온-프레미스 데이터를 압축하면 데이터를 클라우드의 준비 데이터 저장소로 이동하는 데 소요되는 시간이 단축됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-216">To improve performance, you can compress the data on-premises so that it takes less time to move data to the staging data store in the cloud.</span></span> <span data-ttu-id="974d6-217">그런 다음 준비 저장소에서 데이터의 압축을 해제한 후 대상 데이터 저장소에 로드할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-217">Then you can decompress the data in the staging store before you load it into the destination data store.</span></span>
3. <span data-ttu-id="974d6-218">**기업 IT 정책 때문에 포트 80 및 포트 443 이외의 포트를 열지 않으려고 합니다**.</span><span class="sxs-lookup"><span data-stu-id="974d6-218">**You don't want to open ports other than port 80 and port 443 in your firewall, because of corporate IT policies**.</span></span> <span data-ttu-id="974d6-219">예를 들어 온-프레미스 데이터 저장소에서 Azure SQL Database 싱크 또는 Azure SQL Data Warehouse 싱크에 데이터를 복사할 경우 Windows 방화벽 및 회사 방화벽 모두에 대한 포트 1433에서 아웃바운드 TCP 통신을 활성화해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-219">For example, when you copy data from an on-premises data store to an Azure SQL Database sink or an Azure SQL Data Warehouse sink, you need to activate outbound TCP communication on port 1433 for both the Windows firewall and your corporate firewall.</span></span> <span data-ttu-id="974d6-220">이 시나리오에서는 게이트웨이를 활용하여 포트 443에서 HTTP 또는 HTTPS를 통해 데이터를 Blob 저장소 준비 인스턴스로 처음 복사합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-220">In this scenario, take advantage of the gateway to first copy data to a Blob storage staging instance over HTTP or HTTPS on port 443.</span></span> <span data-ttu-id="974d6-221">그런 다음 Blob 저장소 준비에서 데이터를 SQL Database 또는 SQL Data Warehouse로 로드합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-221">Then, load the data into SQL Database or SQL Data Warehouse from Blob storage staging.</span></span> <span data-ttu-id="974d6-222">이 흐름에서는 포트 1433을 사용하도록 설정하지 않아도 됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-222">In this flow, you don't need to enable port 1433.</span></span>

### <a name="how-staged-copy-works"></a><span data-ttu-id="974d6-223">준비 복사의 작동 방법</span><span class="sxs-lookup"><span data-stu-id="974d6-223">How staged copy works</span></span>
<span data-ttu-id="974d6-224">준비 기능을 활성화하면 먼저 데이터가 원본 데이터 저장소에서 준비 데이터 저장소(직접 준비)로 복사됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-224">When you activate the staging feature, first the data is copied from the source data store to the staging data store (bring your own).</span></span> <span data-ttu-id="974d6-225">그 다음, 데이터가 준비 데이터 저장소에서 싱크 데이터 저장소로 복사됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-225">Next, the data is copied from the staging data store to the sink data store.</span></span> <span data-ttu-id="974d6-226">Data Factory는 사용자에 대한 2단계 흐름을 자동으로 관리합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-226">Data Factory automatically manages the two-stage flow for you.</span></span> <span data-ttu-id="974d6-227">또한 Data Factory는 데이터 이동이 완료된 후에 준비 저장소에서 임시 데이터도 정리합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-227">Data Factory also cleans up temporary data from the staging storage after the data movement is complete.</span></span>

<span data-ttu-id="974d6-228">클라우드 복사 시나리오에서(원본 및 싱크 데이터 저장소는 모두 클라우드에 있음) 게이트웨이는 사용되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-228">In the cloud copy scenario (both source and sink data stores are in the cloud), gateway is not used.</span></span> <span data-ttu-id="974d6-229">Data Factory 서비스는 복사 작업을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-229">The Data Factory service performs the copy operations.</span></span>

![준비 복사: 클라우드 시나리오](media/data-factory-copy-activity-performance/staged-copy-cloud-scenario.png)

<span data-ttu-id="974d6-231">하이브리드 복사 시나리오에서(원본이 온-프레미스에 있고 싱크가 클라우드에 있음) 게이트웨이가 원본 데이터 저장소에서 준비 데이터 저장소로 데이터를 이동합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-231">In the hybrid copy scenario (source is on-premises and sink is in the cloud), the gateway moves data from the source data store to a staging data store.</span></span> <span data-ttu-id="974d6-232">Data Factory 서비스는 또한 준비 데이터 저장소에서 싱크 데이터 저장소로 데이터를 이동합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-232">Data Factory service moves data from the staging data store to the sink data store.</span></span> <span data-ttu-id="974d6-233">준비 단계를 통해 클라우드 데이터 저장소의 데이터를 온-프레미스 데이터 저장소로 복사하는 작업은 역방향 흐름으로도 지원됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-233">Copying data from a cloud data store to an on-premises data store via staging also is supported with the reversed flow.</span></span>

![준비 복사: 하이브리드 시나리오](media/data-factory-copy-activity-performance/staged-copy-hybrid-scenario.png)

<span data-ttu-id="974d6-235">준비 저장소를 사용한 데이터 이동을 활성화하면 원본 데이터 저장소에서 중간 또는 준비 데이터 저장소로 데이터를 이동하기 전에 데이터를 압축할지 및 중간 또는 준비 데이터 저장소에서 싱크 데이터 저장소로 데이터를 이동하기 전에 압축할지 여부를 지정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-235">When you activate data movement by using a staging store, you can specify whether you want the data to be compressed before moving data from the source data store to an interim or staging data store, and then decompressed before moving data from an interim or staging data store to the sink data store.</span></span>

<span data-ttu-id="974d6-236">현재는 준비 저장소를 사용하여 두 온-프레미스 데이터 저장소 간에 데이터를 복사할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-236">Currently, you can't copy data between two on-premises data stores by using a staging store.</span></span> <span data-ttu-id="974d6-237">이 옵션은 곧 제공될 예정입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-237">We expect this option to be available soon.</span></span>

### <a name="configuration"></a><span data-ttu-id="974d6-238">구성</span><span class="sxs-lookup"><span data-stu-id="974d6-238">Configuration</span></span>
<span data-ttu-id="974d6-239">복사 작업에 **enableStaging** 설정을 구성하여 데이터를 대상 데이터 저장소에 로드하기 전에 Blob 저장소에서 준비할지 여부를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-239">Configure the **enableStaging** setting in Copy Activity to specify whether you want the data to be staged in Blob storage before you load it into a destination data store.</span></span> <span data-ttu-id="974d6-240">**enableStaging** 을 TRUE로 설정한 경우 다음 표에 나열된 추가 속성을 지정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-240">When you set **enableStaging** to TRUE, specify the additional properties listed in the next table.</span></span> <span data-ttu-id="974d6-241">Azure Storage 또는 준비를 위한 Storage 공유 액세스 서명 연결된 서비스가 아직 없는 경우 만들어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-241">If you don’t have one, you also need to create an Azure Storage or Storage shared access signature-linked service for staging.</span></span>

| <span data-ttu-id="974d6-242">속성</span><span class="sxs-lookup"><span data-stu-id="974d6-242">Property</span></span> | <span data-ttu-id="974d6-243">설명</span><span class="sxs-lookup"><span data-stu-id="974d6-243">Description</span></span> | <span data-ttu-id="974d6-244">기본값</span><span class="sxs-lookup"><span data-stu-id="974d6-244">Default value</span></span> | <span data-ttu-id="974d6-245">필수</span><span class="sxs-lookup"><span data-stu-id="974d6-245">Required</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="974d6-246">**enableStaging**</span><span class="sxs-lookup"><span data-stu-id="974d6-246">**enableStaging**</span></span> |<span data-ttu-id="974d6-247">중간 준비 저장소를 통해 데이터를 복사할지 여부를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-247">Specify whether you want to copy data via an interim staging store.</span></span> |<span data-ttu-id="974d6-248">False</span><span class="sxs-lookup"><span data-stu-id="974d6-248">False</span></span> |<span data-ttu-id="974d6-249">아니요</span><span class="sxs-lookup"><span data-stu-id="974d6-249">No</span></span> |
| <span data-ttu-id="974d6-250">**linkedServiceName**</span><span class="sxs-lookup"><span data-stu-id="974d6-250">**linkedServiceName**</span></span> |<span data-ttu-id="974d6-251">중간 준비 저장소로 사용할 Storage 인스턴스를 참조하여 이름을 [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) 또는 [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) 연결된 서비스로 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-251">Specify the name of an [AzureStorage](data-factory-azure-blob-connector.md#azure-storage-linked-service) or [AzureStorageSas](data-factory-azure-blob-connector.md#azure-storage-sas-linked-service) linked service, which refers to the instance of Storage that you use as an interim staging store.</span></span> <br/><br/> <span data-ttu-id="974d6-252">PolyBase를 통해 SQL Data Warehouse로 데이터를 로드하는 데 공유 액세스 서명을 포함한 저장소를 사용할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-252">You cannot use Storage with a shared access signature to load data into SQL Data Warehouse via PolyBase.</span></span> <span data-ttu-id="974d6-253">다른 모든 시나리오에서는 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-253">You can use it in all other scenarios.</span></span> |<span data-ttu-id="974d6-254">해당 없음</span><span class="sxs-lookup"><span data-stu-id="974d6-254">N/A</span></span> |<span data-ttu-id="974d6-255">예, **enableStaging**이 TRUE로 설정된 경우입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-255">Yes, when **enableStaging** is set to TRUE</span></span> |
| <span data-ttu-id="974d6-256">**path**</span><span class="sxs-lookup"><span data-stu-id="974d6-256">**path**</span></span> |<span data-ttu-id="974d6-257">준비 데이터를 포함할 Blob 저장소 경로를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-257">Specify the Blob storage path that you want to contain the staged data.</span></span> <span data-ttu-id="974d6-258">경로를 제공하지 않으면 서비스는 임시 데이터를 저장하는 컨테이너를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-258">If you do not provide a path, the service creates a container to store temporary data.</span></span> <br/><br/> <span data-ttu-id="974d6-259">공유 액세스 서명을 포함한 저장소를 사용하거나 특정 위치에 임시 데이터가 필요한 경우에만 경로를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-259">Specify a path only if you use Storage with a shared access signature, or you require temporary data to be in a specific location.</span></span> |<span data-ttu-id="974d6-260">해당 없음</span><span class="sxs-lookup"><span data-stu-id="974d6-260">N/A</span></span> |<span data-ttu-id="974d6-261">아니요</span><span class="sxs-lookup"><span data-stu-id="974d6-261">No</span></span> |
| <span data-ttu-id="974d6-262">**enableCompression**</span><span class="sxs-lookup"><span data-stu-id="974d6-262">**enableCompression**</span></span> |<span data-ttu-id="974d6-263">대상에 복사하기 전에 데이터를 압축할지 여부를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-263">Specifies whether data should be compressed before it is copied to the destination.</span></span> <span data-ttu-id="974d6-264">이 설정은 전송되는 데이터 양을 줄입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-264">This setting reduces the volume of data being transferred.</span></span> |<span data-ttu-id="974d6-265">False</span><span class="sxs-lookup"><span data-stu-id="974d6-265">False</span></span> |<span data-ttu-id="974d6-266">아니요</span><span class="sxs-lookup"><span data-stu-id="974d6-266">No</span></span> |

<span data-ttu-id="974d6-267">앞의 표에 설명된 속성이 있는 복사 작업의 샘플 정의는 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-267">Here's a sample definition of Copy Activity with the properties that are described in the preceding table:</span></span>

```json
"activities":[  
{
    "name": "Sample copy activity",
    "type": "Copy",
    "inputs": [{ "name": "OnpremisesSQLServerInput" }],
    "outputs": [{ "name": "AzureSQLDBOutput" }],
    "typeProperties": {
        "source": {
            "type": "SqlSource",
        },
        "sink": {
            "type": "SqlSink"
        },
        "enableStaging": true,
        "stagingSettings": {
            "linkedServiceName": "MyStagingBlob",
            "path": "stagingcontainer/path",
            "enableCompression": true
        }
    }
}
]
```

### <a name="billing-impact"></a><span data-ttu-id="974d6-268">청구 영향</span><span class="sxs-lookup"><span data-stu-id="974d6-268">Billing impact</span></span>
<span data-ttu-id="974d6-269">복사 기간 및 복사 유형의 두 단계에 따라 요금이 청구됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-269">You are charged based on two steps: copy duration and copy type.</span></span>

* <span data-ttu-id="974d6-270">클라우드 복사 중에 준비 저장소를 사용할 경우 (클라우드 데이터 저장소에서 다른 클라우드 데이터 저장소에 데이터를 복사) [1단계 및 2단계 복사 기간의 합]x[클라우드 복사 단가]로 요금이 청구됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-270">When you use staging during a cloud copy (copying data from a cloud data store to another cloud data store), you are charged the [sum of copy duration for step 1 and step 2] x [cloud copy unit price].</span></span>
* <span data-ttu-id="974d6-271">하이브리드 복사 중에 준비를 사용하는 경우(온-프레미스 데이터 저장소에서 클라우드 데이터 저장소로 데이터를 복사) [하이브리드 복사 기간]x[하이브리드 복사 단가]+[클라우드 복사 기간]x[클라우드 복사 단가]로 요금이 청구됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-271">When you use staging during a hybrid copy (copying data from an on-premises data store to a cloud data store), you are charged for [hybrid copy duration] x [hybrid copy unit price] + [cloud copy duration] x [cloud copy unit price].</span></span>

## <a name="performance-tuning-steps"></a><span data-ttu-id="974d6-272">성능 튜닝 단계</span><span class="sxs-lookup"><span data-stu-id="974d6-272">Performance tuning steps</span></span>
<span data-ttu-id="974d6-273">다음 단계에 따라 복사 작업으로 Data Factory 서비스의 성능을 조정하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-273">We suggest that you take these steps to tune the performance of your Data Factory service with Copy Activity:</span></span>

1. <span data-ttu-id="974d6-274">**기초 설정**.</span><span class="sxs-lookup"><span data-stu-id="974d6-274">**Establish a baseline**.</span></span> <span data-ttu-id="974d6-275">개발 단계 중 대표적인 샘플 데이터에 대한 복사 작업을 사용하여 파이프라인을 테스트합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-275">During the development phase, test your pipeline by using Copy Activity against a representative data sample.</span></span> <span data-ttu-id="974d6-276">데이터 팩터리의 [모델 조각화](data-factory-scheduling-and-execution.md)를 사용하여 작업하는 데이터의 양을 제한할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-276">You can use the Data Factory [slicing model](data-factory-scheduling-and-execution.md) to limit the amount of data you work with.</span></span>

   <span data-ttu-id="974d6-277">**모니터링 및 관리 앱**을 사용하여 실행 시간 및 성능 특성을 수집합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-277">Collect execution time and performance characteristics by using the **Monitoring and Management App**.</span></span> <span data-ttu-id="974d6-278">Data Factory 홈페이지에서 **모니터 및 관리**를 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-278">Choose **Monitor & Manage** on your Data Factory home page.</span></span> <span data-ttu-id="974d6-279">트리 뷰에서 **출력 데이터 집합**을 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-279">In the tree view, choose the **output dataset**.</span></span> <span data-ttu-id="974d6-280">**작업 기간** 목록에서 복사 작업 실행을 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-280">In the **Activity Windows** list, choose the Copy Activity run.</span></span> <span data-ttu-id="974d6-281">**작업 기간**에는 복사 작업 기간 및 복사되는 데이터 크기가 나열됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-281">**Activity Windows** lists the Copy Activity duration and the size of the data that's copied.</span></span> <span data-ttu-id="974d6-282">처리량은 **작업 창 탐색기**에 나열됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-282">The throughput is listed in **Activity Window Explorer**.</span></span> <span data-ttu-id="974d6-283">앱에 대해 자세히 알아보려면 [모니터링 및 관리 앱을 사용하여 Azure Data Factory 파이프라인 모니터링 및 관리](data-factory-monitor-manage-app.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-283">To learn more about the app, see [Monitor and manage Azure Data Factory pipelines by using the Monitoring and Management App](data-factory-monitor-manage-app.md).</span></span>

   ![작업 실행 세부 정보](./media/data-factory-copy-activity-performance/mmapp-activity-run-details.png)

   <span data-ttu-id="974d6-285">문서의 뒷부분에서는 시나리오의 성능 및 구성을 테스트에서 복사 작업의 [성능 참조](#performance-reference)와 비교할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-285">Later in the article, you can compare the performance and configuration of your scenario to Copy Activity’s [performance reference](#performance-reference) from our tests.</span></span>
2. <span data-ttu-id="974d6-286">**성능 진단 및 최적화**.</span><span class="sxs-lookup"><span data-stu-id="974d6-286">**Diagnose and optimize performance**.</span></span> <span data-ttu-id="974d6-287">확인되는 성능이 기대에 미치지 못하는 경우 성능 병목 상태를 식별해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-287">If the performance you observe doesn't meet your expectations, you need to identify performance bottlenecks.</span></span> <span data-ttu-id="974d6-288">그런 다음 성능을 최적화하여 병목 현상의 효과를 제거하거나 줄입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-288">Then, optimize performance to remove or reduce the effect of bottlenecks.</span></span> <span data-ttu-id="974d6-289">성능 진단에 대한 자세한 내용은 이 문서의 범위를 벗어나지만 다음과 같이 몇 가지 일반적인 고려 사항이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-289">A full description of performance diagnosis is beyond the scope of this article, but here are some common considerations:</span></span>

   * <span data-ttu-id="974d6-290">성능 기능:</span><span class="sxs-lookup"><span data-stu-id="974d6-290">Performance features:</span></span>
     * [<span data-ttu-id="974d6-291">병렬 복사</span><span class="sxs-lookup"><span data-stu-id="974d6-291">Parallel copy</span></span>](#parallel-copy)
     * [<span data-ttu-id="974d6-292">클라우드 데이터 이동 단위</span><span class="sxs-lookup"><span data-stu-id="974d6-292">Cloud data movement units</span></span>](#cloud-data-movement-units)
     * [<span data-ttu-id="974d6-293">준비된 복사</span><span class="sxs-lookup"><span data-stu-id="974d6-293">Staged copy</span></span>](#staged-copy)
     * [<span data-ttu-id="974d6-294">데이터 관리 게이트웨이 확장성</span><span class="sxs-lookup"><span data-stu-id="974d6-294">Data Management Gateway scalability</span></span>](data-factory-data-management-gateway-high-availability-scalability.md)
   * [<span data-ttu-id="974d6-295">데이터 관리 게이트웨이</span><span class="sxs-lookup"><span data-stu-id="974d6-295">Data Management Gateway</span></span>](#considerations-for-data-management-gateway)
   * [<span data-ttu-id="974d6-296">원본</span><span class="sxs-lookup"><span data-stu-id="974d6-296">Source</span></span>](#considerations-for-the-source)
   * [<span data-ttu-id="974d6-297">싱크</span><span class="sxs-lookup"><span data-stu-id="974d6-297">Sink</span></span>](#considerations-for-the-sink)
   * [<span data-ttu-id="974d6-298">직렬화 및 역직렬화</span><span class="sxs-lookup"><span data-stu-id="974d6-298">Serialization and deserialization</span></span>](#considerations-for-serialization-and-deserialization)
   * [<span data-ttu-id="974d6-299">압축</span><span class="sxs-lookup"><span data-stu-id="974d6-299">Compression</span></span>](#considerations-for-compression)
   * [<span data-ttu-id="974d6-300">열 매핑</span><span class="sxs-lookup"><span data-stu-id="974d6-300">Column mapping</span></span>](#considerations-for-column-mapping)
   * [<span data-ttu-id="974d6-301">기타 고려 사항</span><span class="sxs-lookup"><span data-stu-id="974d6-301">Other considerations</span></span>](#other-considerations)
3. <span data-ttu-id="974d6-302">**전체 데이터 집합으로 구성 확장**.</span><span class="sxs-lookup"><span data-stu-id="974d6-302">**Expand the configuration to your entire data set**.</span></span> <span data-ttu-id="974d6-303">실행 결과 및 성능에 만족하면 정의 및 파이프라인 활성 기간을 확장하여 전체 데이터 집합을 포함할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-303">When you're satisfied with the execution results and performance, you can expand the definition and pipeline active period to cover your entire data set.</span></span>

## <a name="considerations-for-data-management-gateway"></a><span data-ttu-id="974d6-304">데이터 관리 게이트웨이에 대한 고려 사항</span><span class="sxs-lookup"><span data-stu-id="974d6-304">Considerations for Data Management Gateway</span></span>
<span data-ttu-id="974d6-305">**게이트웨이 설정**: 전용 컴퓨터를 사용하여 데이터 관리 게이트웨이를 호스팅하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-305">**Gateway setup**: We recommend that you use a dedicated machine to host Data Management Gateway.</span></span> <span data-ttu-id="974d6-306">[데이터 관리 게이트웨이에 대한 고려 사항](data-factory-data-management-gateway.md#considerations-for-using-gateway)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-306">See [Considerations for using Data Management Gateway](data-factory-data-management-gateway.md#considerations-for-using-gateway).</span></span>  

<span data-ttu-id="974d6-307">**게이트웨이 모니터링 및 강화/확장**: 하나 이상의 게이트웨이 노드를 사용하는 단일 논리 게이트웨이는 동시에 한 번에 여러 개의 복사 작업 실행을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-307">**Gateway monitoring and scale-up/out**: A single logical gateway with one or more gateway nodes can serve multiple Copy Activity runs at the same time concurrently.</span></span> <span data-ttu-id="974d6-308">Azure Portal에서 제한 대비 실행 중인 동시 작업 수뿐만 아니라, 게이트웨이 컴퓨터에서 리소스 사용률(CPU, 메모리, 네트워크(내부/외부) 등)의 스냅숏을 거의 실시간으로 확인할 수 있습니다. [포털에서 게이트웨이 모니터링](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-308">You can view near-real time snapshot of resource utilization (CPU, memory, network(in/out), etc.) on a gateway machine as well as the number of concurrent jobs running versus limit in the Azure portal, see [Monitor gateway in the portal](data-factory-data-management-gateway.md#monitor-gateway-in-the-portal).</span></span> <span data-ttu-id="974d6-309">동시 복사 작업 실행 수가 많거나 복사할 데이터 양이 많은 하이브리드 데이터 이동이 절실한 경우 리소스를 더 효율적으로 활용하거나, 복사를 지원하도록 더 많은 리소스를 프로비전할 수 있도록 [게이트웨이 강화 또는 확장](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations)을 고려해 보세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-309">If you have heavy need on hybrid data movement either with large number of concurrent copy activity runs or with large volume of data to copy, consider to [scale up or scale out gateway](data-factory-data-management-gateway-high-availability-scalability.md#scale-considerations) so as to better utilize your resource or to provision more resource to empower copy.</span></span> 

## <a name="considerations-for-the-source"></a><span data-ttu-id="974d6-310">원본에 대한 고려 사항</span><span class="sxs-lookup"><span data-stu-id="974d6-310">Considerations for the source</span></span>
### <a name="general"></a><span data-ttu-id="974d6-311">일반</span><span class="sxs-lookup"><span data-stu-id="974d6-311">General</span></span>
<span data-ttu-id="974d6-312">기본 데이터 저장소가 다른 실행 중인 워크로드에 의해 과부화되지 않도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-312">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="974d6-313">Microsoft 데이터 저장소의 경우 데이터 저장소 성능 특성을 이해하고 응답 시간을 최소화하며 처리량을 최대화할 수 있도록 하는 데이터 저장소 특정 [모니터링 및 튜닝 항목](#performance-reference)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-313">For Microsoft data stores, see [monitoring and tuning topics](#performance-reference) that are specific to data stores, and help you understand data store performance characteristics, minimize response times, and maximize throughput.</span></span>

<span data-ttu-id="974d6-314">Blob 저장소에서 SQL Data Warehouse로 데이터를 복사하는 경우에는, 성능을 높이기 위해 **PolyBase**를 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-314">If you copy data from Blob storage to SQL Data Warehouse, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="974d6-315">자세한 내용은 [PolyBase를 사용하여 Azure SQL 데이터 웨어하우스에 데이터 로드](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-315">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="974d6-316">사용 사례가 있는 연습을 보려면 [Azure Data Factory를 통해 Azure SQL Data Warehouse에 15분 이내 1TB 로드](data-factory-load-sql-data-warehouse.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-316">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="974d6-317">파일 기반 데이터 저장소</span><span class="sxs-lookup"><span data-stu-id="974d6-317">File-based data stores</span></span>
<span data-ttu-id="974d6-318">*(Blob 저장소, Data Lake Store, Amazon S3, 온-프레미스 파일 시스템, 온-프레미스 HDFS 포함)*</span><span class="sxs-lookup"><span data-stu-id="974d6-318">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="974d6-319">**평균 파일 크기 및 파일 개수**: 복사 작업은 데이터를 한 번에 하나씩 전송합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-319">**Average file size and file count**: Copy Activity transfers data one file at a time.</span></span> <span data-ttu-id="974d6-320">동일한 양의 데이터를 이동하는 경우 각 파일에 대한 부트스트랩 단계이기 때문에 적은 수의 큰 파일보다는 많은 수의 작은 파일로 데이터가 구성되는 경우 전체 처리량은 느려집니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-320">With the same amount of data to be moved, the overall throughput is lower if the data consists of many small files rather than a few large files due to the bootstrap phase for each file.</span></span> <span data-ttu-id="974d6-321">따라서 가능하면 작은 파일을 더 큰 파일에 결합하여 처리량을 높입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-321">Therefore, if possible, combine small files into larger files to gain higher throughput.</span></span>
* <span data-ttu-id="974d6-322">**파일 형식 및 압축**: 성능을 향상하는 다양한 방법은 [직렬화/역직렬화에 대한 고려 사항](#considerations-for-serialization-and-deserialization) 및 [압축에 대한 고려 사항](#considerations-for-compression) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-322">**File format and compression**: For more ways to improve performance, see the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections.</span></span>
* <span data-ttu-id="974d6-323">**데이터 관리 게이트웨이**가 필요한 **온-프레미스 파일 시스템** 시나리오는 [데이터 관리 게이트웨이에 대한 고려 사항](#considerations-for-data-management-gateway) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-323">For the **on-premises file system** scenario, in which **Data Management Gateway** is required, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="974d6-324">관계형 데이터 저장소</span><span class="sxs-lookup"><span data-stu-id="974d6-324">Relational data stores</span></span>
<span data-ttu-id="974d6-325">*(SQL Database, SQL Data Warehouse, Amazon Redshift, SQL Server 데이터베이스, Oracle, MySQL, DB2, Teradata, Sybase, PostgreSQL 데이터베이스 등 포함)*</span><span class="sxs-lookup"><span data-stu-id="974d6-325">*(Includes SQL Database; SQL Data Warehouse; Amazon Redshift; SQL Server databases; and Oracle, MySQL, DB2, Teradata, Sybase, and PostgreSQL databases, etc.)*</span></span>

* <span data-ttu-id="974d6-326">**데이터 패턴**: 테이블 스키마는 복사본 처리량에 영향을 줍니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-326">**Data pattern**: Your table schema affects copy throughput.</span></span> <span data-ttu-id="974d6-327">행 크기가 크면 동일한 양의 데이터를 복사하는 데 작은 행 크기보다 더 나은 성능을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-327">A large row size gives you a better performance than small row size, to copy the same amount of data.</span></span> <span data-ttu-id="974d6-328">원인은 데이터베이스가 적은 수의 행을 포함하는 더 적은 배치의 데이터보다 더욱 효율적으로 검색할 수 있기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-328">The reason is that the database can more efficiently retrieve fewer batches of data that contain fewer rows.</span></span>
* <span data-ttu-id="974d6-329">**쿼리 또는 저장 프로시저**: 데이터를 보다 효율적으로 가져오기 위해 복사 작업 원본에서 지정한 쿼리 또는 저장 프로시저의 논리를 최적화합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-329">**Query or stored procedure**: Optimize the logic of the query or stored procedure you specify in the Copy Activity source to fetch data more efficiently.</span></span>
* <span data-ttu-id="974d6-330">**데이터 관리 게이트웨이**를 사용해야 하는 SQL Server 및 Oracle과 같은 **온-프레미스 관계형 데이터베이스**는 [데이터 관리 게이트웨이에 대한 고려 사항](#considerations-on-data-management-gateway) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-330">For **on-premises relational databases**, such as SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-on-data-management-gateway) section.</span></span>

## <a name="considerations-for-the-sink"></a><span data-ttu-id="974d6-331">싱크에 대한 고려 사항</span><span class="sxs-lookup"><span data-stu-id="974d6-331">Considerations for the sink</span></span>
### <a name="general"></a><span data-ttu-id="974d6-332">일반</span><span class="sxs-lookup"><span data-stu-id="974d6-332">General</span></span>
<span data-ttu-id="974d6-333">기본 데이터 저장소가 다른 실행 중인 워크로드에 의해 과부화되지 않도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-333">Be sure that the underlying data store is not overwhelmed by other workloads that are running on or against it.</span></span>

<span data-ttu-id="974d6-334">Microsoft 데이터 저장소의 경우 데이터 저장소에 대한 [모니터링 및 튜닝 항목](#performance-reference)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-334">For Microsoft data stores, refer to [monitoring and tuning topics](#performance-reference) that are specific to data stores.</span></span> <span data-ttu-id="974d6-335">이러한 항목에서 데이터 저장소 성능 특성을 이해하고 응답 시간을 최소화하고 처리량을 최대화하는 방법을 파악할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-335">These topics can help you understand data store performance characteristics and how to minimize response times and maximize throughput.</span></span>

<span data-ttu-id="974d6-336">**Blob 저장소**에서 **SQL Data Warehouse**로 데이터를 복사하는 경우에는, 성능을 높이기 위해 **PolyBase**를 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-336">If you are copying data from **Blob storage** to **SQL Data Warehouse**, consider using **PolyBase** to boost performance.</span></span> <span data-ttu-id="974d6-337">자세한 내용은 [PolyBase를 사용하여 Azure SQL 데이터 웨어하우스에 데이터 로드](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-337">See [Use PolyBase to load data into Azure SQL Data Warehouse](data-factory-azure-sql-data-warehouse-connector.md#use-polybase-to-load-data-into-azure-sql-data-warehouse) for details.</span></span> <span data-ttu-id="974d6-338">사용 사례가 있는 연습을 보려면 [Azure Data Factory를 통해 Azure SQL Data Warehouse에 15분 이내 1TB 로드](data-factory-load-sql-data-warehouse.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-338">For a walkthrough with a use case, see [Load 1 TB into Azure SQL Data Warehouse under 15 minutes with Azure Data Factory](data-factory-load-sql-data-warehouse.md).</span></span>

### <a name="file-based-data-stores"></a><span data-ttu-id="974d6-339">파일 기반 데이터 저장소</span><span class="sxs-lookup"><span data-stu-id="974d6-339">File-based data stores</span></span>
<span data-ttu-id="974d6-340">*(Blob 저장소, Data Lake Store, Amazon S3, 온-프레미스 파일 시스템, 온-프레미스 HDFS 포함)*</span><span class="sxs-lookup"><span data-stu-id="974d6-340">*(Includes Blob storage, Data Lake Store, Amazon S3, on-premises file systems, and on-premises HDFS)*</span></span>

* <span data-ttu-id="974d6-341">**복사 동작**: 서로 다른 파일 기반 저장소에서 데이터를 복사하는 경우 복사 작업에는 **copyBehavior** 속성을 통해 3가지 옵션이 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-341">**Copy behavior**: If you copy data from a different file-based data store, Copy Activity has three options via the **copyBehavior** property.</span></span> <span data-ttu-id="974d6-342">계층 구조를 유지하고 평면화하며 파일을 병합합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-342">It preserves hierarchy, flattens hierarchy, or merges files.</span></span> <span data-ttu-id="974d6-343">계층 구조를 유지 또는 평면화하는 작업은 성능 오버 헤드가 거의 또는 전혀 발생하지 않는 반면 파일을 병합하는 작업은 성능 오버 헤드가 증가합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-343">Either preserving or flattening hierarchy has little or no performance overhead, but merging files causes performance overhead to increase.</span></span>
* <span data-ttu-id="974d6-344">**파일 형식 및 압축**: 성능을 개선하는 다양한 방법은 [직렬화/역직렬화에 대한 고려 사항](#considerations-for-serialization-and-deserialization) 및 [압축에 대한 고려 사항](#considerations-for-compression) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-344">**File format and compression**: See the [Considerations for serialization and deserialization](#considerations-for-serialization-and-deserialization) and [Considerations for compression](#considerations-for-compression) sections for more ways to improve performance.</span></span>
* <span data-ttu-id="974d6-345">**Blob 저장소**: 현재 Blob 저장소는 최적화된 데이터 전송 및 처리량에 대해서만 블록 Blob를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-345">**Blob storage**: Currently, Blob storage supports only block blobs for optimized data transfer and throughput.</span></span>
* <span data-ttu-id="974d6-346">**데이터 관리 게이트웨이**를 사용해야 하는 **온-프레미스 파일 시스템** 시나리오는 [데이터 관리 게이트웨이에 대한 고려 사항](#considerations-for-data-management-gateway) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-346">For **on-premises file systems** scenarios that require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="relational-data-stores"></a><span data-ttu-id="974d6-347">관계형 데이터 저장소</span><span class="sxs-lookup"><span data-stu-id="974d6-347">Relational data stores</span></span>
<span data-ttu-id="974d6-348">*(SQL Database, SQL Data Warehouse, SQL Server 데이터베이스 및 Oracle 데이터베이스 포함)*</span><span class="sxs-lookup"><span data-stu-id="974d6-348">*(Includes SQL Database, SQL Data Warehouse, SQL Server databases, and Oracle databases)*</span></span>

* <span data-ttu-id="974d6-349">**복사 동작**: **sqlSink**에 대해 설정된 속성에 따라 복사 작업은 대상 데이터베이스에 데이터를 다양한 방식으로 기록합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-349">**Copy behavior**: Depending on the properties you've set for **sqlSink**, Copy Activity writes data to the destination database in different ways.</span></span>
  * <span data-ttu-id="974d6-350">기본적으로 데이터 이동 서비스는 대량 복사 API를 사용하여 추가 모드에 데이터를 삽입하며 이는 최상의 성능을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-350">By default, the data movement service uses the Bulk Copy API to insert data in append mode, which provides the best performance.</span></span>
  * <span data-ttu-id="974d6-351">싱크에 저장 프로시저를 구성하는 경우 데이터베이스는 대량 로드가 아닌, 한 번에 한 행씩 데이터를 적용합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-351">If you configure a stored procedure in the sink, the database applies the data one row at a time instead of as a bulk load.</span></span> <span data-ttu-id="974d6-352">성능이 크게 저하됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-352">Performance drops significantly.</span></span> <span data-ttu-id="974d6-353">데이터 집합이 크면 적용할 수 있을 때 **sqlWriterCleanupScript** 속성(아래 참조)을 사용하도록 전환하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-353">If your data set is large, when applicable, consider switching to using the **sqlWriterCleanupScript** property.</span></span>
  * <span data-ttu-id="974d6-354">실행한 각 복사 작업에 **sqlWriterCleanupScript** 속성을 구성하는 경우 서비스는 스크립트를 트리거한 다음 대량 복사 API를 사용하여 데이터를 삽입합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-354">If you configure the **sqlWriterCleanupScript** property for each Copy Activity run, the service triggers the script, and then you use the Bulk Copy API to insert the data.</span></span> <span data-ttu-id="974d6-355">예를 들어 최신 데이터를 사용하여 전체 테이블을 덮어쓰려면 원본에서 새 데이터를 대량으로 로드하기 전에 먼저 스크립트를 지정하여 모든 레코드를 삭제할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-355">For example, to overwrite the entire table with the latest data, you can specify a script to first delete all records before bulk-loading the new data from the source.</span></span>
* <span data-ttu-id="974d6-356">**데이터 패턴 및 배치 크기**:</span><span class="sxs-lookup"><span data-stu-id="974d6-356">**Data pattern and batch size**:</span></span>
  * <span data-ttu-id="974d6-357">테이블 스키마는 복사본 처리량에 영향을 줍니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-357">Your table schema affects copy throughput.</span></span> <span data-ttu-id="974d6-358">동일한 양의 데이터를 복사하려면 데이터베이스가 데이터에서 적은 배치를 보다 효율적으로 커밋할 수 있기 때문에 행 크기가 크면 행 크기가 작은 경우 보다 더 성능이 나아집니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-358">To copy the same amount of data, a large row size gives you better performance than a small row size because the database can more efficiently commit fewer batches of data.</span></span>
  * <span data-ttu-id="974d6-359">복사 작업은 일련의 배치로 데이터를 삽입합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-359">Copy Activity inserts data in a series of batches.</span></span> <span data-ttu-id="974d6-360">**writeBatchSize** 속성을 사용하여 배치에서 행 수를 설정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-360">You can set the number of rows in a batch by using the **writeBatchSize** property.</span></span> <span data-ttu-id="974d6-361">데이터에 작은 크기의 행이 있으면 높은 값을 가진 **writeBatchSize** 속성을 설정하여 적은 수의 배치 오버헤드와 높은 처리량의 혜택을 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-361">If your data has small rows, you can set the **writeBatchSize** property with a higher value to benefit from lower batch overhead and higher throughput.</span></span> <span data-ttu-id="974d6-362">데이터의 행 크기가 큰 경우 **writeBatchSize**를 늘릴 때 주의하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-362">If the row size of your data is large, be careful when you increase **writeBatchSize**.</span></span> <span data-ttu-id="974d6-363">이 값이 높으면 데이터베이스에 오버로드가 발생하여 복사에 실패할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-363">A high value might lead to a copy failure caused by overloading the database.</span></span>
* <span data-ttu-id="974d6-364">**데이터 관리 게이트웨이**를 사용해야 하는 SQL Server 및 Oracle과 같은 **온-프레미스 관계형 데이터베이스**는 [데이터 관리 게이트웨이에 대한 고려 사항](#considerations-for-data-management-gateway) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-364">For **on-premises relational databases** like SQL Server and Oracle, which require the use of **Data Management Gateway**, see the [Considerations for Data Management Gateway](#considerations-for-data-management-gateway) section.</span></span>

### <a name="nosql-stores"></a><span data-ttu-id="974d6-365">NoSQL 저장소</span><span class="sxs-lookup"><span data-stu-id="974d6-365">NoSQL stores</span></span>
<span data-ttu-id="974d6-366">*(테이블 저장소 및 Azure Cosmos DB 포함)*</span><span class="sxs-lookup"><span data-stu-id="974d6-366">*(Includes Table storage and Azure Cosmos DB )*</span></span>

* <span data-ttu-id="974d6-367">**테이블 저장소**:</span><span class="sxs-lookup"><span data-stu-id="974d6-367">For **Table storage**:</span></span>
  * <span data-ttu-id="974d6-368">**파티션**: 인터리브 파티션에 데이터를 작성하면 성능이 크게 저하됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-368">**Partition**: Writing data to interleaved partitions dramatically degrades performance.</span></span> <span data-ttu-id="974d6-369">파티션 키로 원본 데이터를 정렬할 수 있으므로 데이터는 파티션에 차례로 효율적으로 삽입되거나 논리를 조정하여 단일 파티션에 데이터를 기록할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-369">Sort your source data by partition key so that the data is inserted efficiently into one partition after another, or adjust the logic to write the data to a single partition.</span></span>
* <span data-ttu-id="974d6-370">**Azure Cosmos DB**의 경우:</span><span class="sxs-lookup"><span data-stu-id="974d6-370">For **Azure Cosmos DB**:</span></span>
  * <span data-ttu-id="974d6-371">**배치 크기**: **writeBatchSize** 속성은 문서를 작성하는 Azure Cosmos DB 서비스에 대한 병렬 요청 수를 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-371">**Batch size**: The **writeBatchSize** property sets the number of parallel requests to the Azure Cosmos DB service to create documents.</span></span> <span data-ttu-id="974d6-372">Azure Cosmos DB에 더 많은 병렬 요청이 전송되기 때문에 **writeBatchSize**가 증가하는 경우 더 나은 성능을 기대할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-372">You can expect better performance when you increase **writeBatchSize** because more parallel requests are sent to Azure Cosmos DB.</span></span> <span data-ttu-id="974d6-373">그러나 Azure Cosmos DB에 작성할 때 제한을 확인하세요(오류 메시지 "요청 속도가 큽니다").</span><span class="sxs-lookup"><span data-stu-id="974d6-373">However, watch for throttling when you write to Azure Cosmos DB (the error message is "Request rate is large").</span></span> <span data-ttu-id="974d6-374">문서 크기, 문서에서 용어의 수 및 대상 컬렉션의 인덱싱 정책 등 여러 가지 요인으로 인해 제한이 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-374">Various factors can cause throttling, including document size, the number of terms in the documents, and the target collection's indexing policy.</span></span> <span data-ttu-id="974d6-375">복사 처리량을 더 높이려면 더 나은 컬렉션(예: S3)을 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-375">To achieve higher copy throughput, consider using a better collection, for example, S3.</span></span>

## <a name="considerations-for-serialization-and-deserialization"></a><span data-ttu-id="974d6-376">직렬화 및 역직렬화에 대한 고려 사항</span><span class="sxs-lookup"><span data-stu-id="974d6-376">Considerations for serialization and deserialization</span></span>
<span data-ttu-id="974d6-377">입력 데이터 집합 또는 출력 데이터 집합이 파일인 경우 직렬화 및 역직렬화가 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-377">Serialization and deserialization can occur when your input data set or output data set is a file.</span></span> <span data-ttu-id="974d6-378">복사 작업에서 지원하는 파일 형식에 대한 세부 정보는 [지원되는 파일 및 압축 형식](data-factory-supported-file-and-compression-formats.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-378">See [Supported file and compression formats](data-factory-supported-file-and-compression-formats.md) with details on supported file formats by Copy Activity.</span></span>

<span data-ttu-id="974d6-379">**복사 동작**:</span><span class="sxs-lookup"><span data-stu-id="974d6-379">**Copy behavior**:</span></span>

* <span data-ttu-id="974d6-380">파일 기반 데이터 저장소 간에 파일 복사:</span><span class="sxs-lookup"><span data-stu-id="974d6-380">Copying files between file-based data stores:</span></span>
  * <span data-ttu-id="974d6-381">입력 및 출력 데이터 집합 모두가 동일한 파일 형식이거나 파일 형식 설정이 없을 때 데이터 이동 서비스는 직렬화/역직렬화 없이 이진 복사를 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-381">When input and output data sets both have the same or no file format settings, the data movement service executes a binary copy without any serialization or deserialization.</span></span> <span data-ttu-id="974d6-382">원본 및 싱크 파일 형식 설정이 서로 다른 시나리오에 비해 더 나은 처리량이 나타납니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-382">You see a higher throughput compared to the scenario, in which the source and sink file format settings are different from each other.</span></span>
  * <span data-ttu-id="974d6-383">입력 및 출력 데이터 집합이 모두 텍스트 형식이고 인코딩 형식만 다른 경우 데이터 이동 서비스는 인코딩 변환만 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-383">When input and output data sets both are in text format and only the encoding type is different, the data movement service only does encoding conversion.</span></span> <span data-ttu-id="974d6-384">이진 복사에 비해 성능 오버헤드를 유발하는 어떠한 직렬화 및 역직렬화도 수행하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-384">It doesn't do any serialization and deserialization, which causes some performance overhead compared to a binary copy.</span></span>
  * <span data-ttu-id="974d6-385">입력 및 출력 데이터 집합이 파일 형식이 다르거나 구분 기호와 같이 구성이 다른 경우 데이터 이동 서비스는 원본 데이터를 deserialize하여 스트리밍, 변환한 다음 표시된 출력 형식으로 직렬화합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-385">When input and output data sets both have different file formats or different configurations, like delimiters, the data movement service deserializes source data to stream, transform, and then serialize it into the output format you indicated.</span></span> <span data-ttu-id="974d6-386">이 작업으로 다른 시나리오에 비해 훨씬 더 심각한 성능 오버헤드가 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-386">This operation results in a much more significant performance overhead compared to other scenarios.</span></span>
* <span data-ttu-id="974d6-387">파일 기반이 아닌 데이터 저장소 간에 파일을 복사하는 경우(예를 들어 파일 기반 저장소에서 관계형 저장소로) 직렬화 및 역직렬화 단계가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-387">When you copy files to/from a data store that is not file-based (for example, from a file-based store to a relational store), the serialization or deserialization step is required.</span></span> <span data-ttu-id="974d6-388">이 단계로 상당한 성능 오버헤드가 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-388">This step results in significant performance overhead.</span></span>

<span data-ttu-id="974d6-389">**파일 형식**: 선택한 파일 형식에 따라 복사 성능이 달라질 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-389">**File format**: The file format you choose might affect copy performance.</span></span> <span data-ttu-id="974d6-390">예를 들어 Avro는 데이터를 사용하여 메타데이터를 저장하는 간단한 이진 형식입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-390">For example, Avro is a compact binary format that stores metadata with data.</span></span> <span data-ttu-id="974d6-391">처리 및 쿼리에 대한 Hadoop 에코시스템을 광범위하게 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-391">It has broad support in the Hadoop ecosystem for processing and querying.</span></span> <span data-ttu-id="974d6-392">그러나 Avro는 텍스트 형식에 비해 복사 처리량이 더 낮은 직렬화 및 역직렬화의 경우 더 비쌉니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-392">However, Avro is more expensive for serialization and deserialization, which results in lower copy throughput compared to text format.</span></span> <span data-ttu-id="974d6-393">파일 형식의 선택은 처리 흐름 전체적으로 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-393">Make your choice of file format throughout the processing flow holistically.</span></span> <span data-ttu-id="974d6-394">원본 데이터 저장소에 저장하거나 외부 시스템에서 추출될 데이터 형식에서 시작하여 저장소로 가장 적절한 형식, 분석 처리 및 쿼리, 그리고 보고 및 시각화 도구에 대한 데이터 마트에 데이터를 내보낼 형식 등이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-394">Start with what form the data is stored in, source data stores or to be extracted from external systems; the best format for storage, analytical processing, and querying; and in what format the data should be exported into data marts for reporting and visualization tools.</span></span> <span data-ttu-id="974d6-395">경우에 따라 읽기 및 쓰기 성능에 대해 최적이 아닌 파일 형식은 전체 분석 프로세스를 고려할 때 적합한 선택일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-395">Sometimes a file format that is suboptimal for read and write performance might be a good choice when you consider the overall analytical process.</span></span>

## <a name="considerations-for-compression"></a><span data-ttu-id="974d6-396">압축에 대한 고려 사항</span><span class="sxs-lookup"><span data-stu-id="974d6-396">Considerations for compression</span></span>
<span data-ttu-id="974d6-397">입력 또는 출력 데이터 집합이 파일인 경우 대상에 데이터를 쓸 때 복사 작업을 설정하여 압축하거나 압축을 해제할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-397">When your input or output data set is a file, you can set Copy Activity to perform compression or decompression as it writes data to the destination.</span></span> <span data-ttu-id="974d6-398">압축을 선택할 때 입력/출력(I/O) 및 CPU 간에 균형을 유지합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-398">When you choose compression, you make a tradeoff between input/output (I/O) and CPU.</span></span> <span data-ttu-id="974d6-399">계산 리소스에서 데이터를 압축하는 데 추가 비용이 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-399">Compressing the data costs extra in compute resources.</span></span> <span data-ttu-id="974d6-400">대신에, 네트워크 I/O 및 저장소는 감소합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-400">But in return, it reduces network I/O and storage.</span></span> <span data-ttu-id="974d6-401">데이터에 따라 전체 복사 처리량이 향상되는 것을 볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-401">Depending on your data, you may see a boost in overall copy throughput.</span></span>

<span data-ttu-id="974d6-402">**코덱**: 복사 작업에서는 gzip, bzip2 및 Deflate 압축 형식을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-402">**Codec**: Copy Activity supports gzip, bzip2, and Deflate compression types.</span></span> <span data-ttu-id="974d6-403">Azure HDInsight에서는 처리를 위해 세 가지 형식을 모두 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-403">Azure HDInsight can consume all three types for processing.</span></span> <span data-ttu-id="974d6-404">압축 코덱에는 각각 장점이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-404">Each compression codec has advantages.</span></span> <span data-ttu-id="974d6-405">예를 들어 bzip2는 가장 낮은 복사 처리량을 갖지만 처리를 위해 분할될 수 있으므로 bzip2로 최상의 Hive 쿼리 성능을 얻게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-405">For example, bzip2 has the lowest copy throughput, but you get the best Hive query performance with bzip2 because you can split it for processing.</span></span> <span data-ttu-id="974d6-406">Gzip는 가장 균형 있는 옵션을 제공하고 가장 흔하게 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-406">Gzip is the most balanced option, and it is used the most often.</span></span> <span data-ttu-id="974d6-407">종단 간 시나리오에 가장 적합한 코덱을 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-407">Choose the codec that best suits your end-to-end scenario.</span></span>

<span data-ttu-id="974d6-408">**수준**: 각 압축 코덱의 경우 빠른 압축 및 최적 압축이라는 두 옵션 중에서 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-408">**Level**: You can choose from two options for each compression codec: fastest compressed and optimally compressed.</span></span> <span data-ttu-id="974d6-409">파일이 최적으로 압축되지 않은 경우에도 가장 빠르게 압축된 옵션은 데이터를 최대한 빨리 압축합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-409">The fastest compressed option compresses the data as quickly as possible, even if the resulting file is not optimally compressed.</span></span> <span data-ttu-id="974d6-410">최적으로 압축된 옵션은 압축에 더 많은 시간을 사용하고 최소한의 데이터를 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-410">The optimally compressed option spends more time on compression and yields a minimal amount of data.</span></span> <span data-ttu-id="974d6-411">두 옵션 모두 테스트하여 어떤 옵션이 사용자에게 더 나은 성능을 제공하는지 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-411">You can test both options to see which provides better overall performance in your case.</span></span>

<span data-ttu-id="974d6-412">**고려 사항**: 온-프레미스 저장소와 클라우드 간에 더 많은 데이터를 복사하려면 압축을 통해 임시 Blob 저장소를 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-412">**A consideration**: To copy a large amount of data between an on-premises store and the cloud, consider using interim blob storage with compression.</span></span> <span data-ttu-id="974d6-413">임시 저장소 사용은 회사 네트워크의 대역폭과 Azure 서비스가 제한하는 요소이고 입력 데이터 집합과 출력 데이터 집합이 모두 압축되지 않은 형식인 경우 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-413">Using interim storage is helpful when the bandwidth of your corporate network and your Azure services is the limiting factor, and you want the input data set and output data set both to be in uncompressed form.</span></span> <span data-ttu-id="974d6-414">보다 자세히, 단일 복사 작업을 두 개의 복사 작업으로 나눌 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-414">More specifically, you can break a single copy activity into two copy activities.</span></span> <span data-ttu-id="974d6-415">첫 번째 복사 작업은 압축된 형식으로 원본에서 임시 또는 준비 Blob로 복사합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-415">The first copy activity copies from the source to an interim or staging blob in compressed form.</span></span> <span data-ttu-id="974d6-416">두 번째 복사 작업은 준비에서 압축된 데이터를 복사한 후 싱크에 쓰면서 압축을 해제합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-416">The second copy activity copies the compressed data from staging, and then decompresses while it writes to the sink.</span></span>

## <a name="considerations-for-column-mapping"></a><span data-ttu-id="974d6-417">열 매핑에 대한 고려 사항</span><span class="sxs-lookup"><span data-stu-id="974d6-417">Considerations for column mapping</span></span>
<span data-ttu-id="974d6-418">복사 작업에서 **columnMappings** 속성을 설정하여 입력 열의 전체 또는 하위 집합을 출력 열에 매핑할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-418">You can set the **columnMappings** property in Copy Activity to map all or a subset of the input columns to the output columns.</span></span> <span data-ttu-id="974d6-419">데이터 이동 서비스는 원본에서 데이터를 읽은 후에 데이터를 싱크에 쓰기 전에 데이터에 열 매핑을 수행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-419">After the data movement service reads the data from the source, it needs to perform column mapping on the data before it writes the data to the sink.</span></span> <span data-ttu-id="974d6-420">이 추가 처리는 복사 처리량을 감소시킵니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-420">This extra processing reduces copy throughput.</span></span>

<span data-ttu-id="974d6-421">원본 데이터 저장소를 쿼리할 수 있는 경우 예를 들어 SQL Database 또는 SQL Server와 같은 관계형 저장소이거나 테이블 저장소 또는 Azure Cosmos DB와 같은 NoSQL 저장소인 경우 열 매핑을 사용하는 대신, 열 필터링 및 재정렬 논리를 **query** 속성에 푸시하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-421">If your source data store is queryable, for example, if it's a relational store like SQL Database or SQL Server, or if it's a NoSQL store like Table storage or Azure Cosmos DB, consider pushing the column filtering and reordering logic to the **query** property instead of using column mapping.</span></span> <span data-ttu-id="974d6-422">이러한 방식으로 데이터 이동 서비스가 원본 데이터 저장소에서 데이터를 읽는 동안 프로젝션이 발생하며 이는 훨씬 효율적입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-422">This way, the projection occurs while the data movement service reads data from the source data store, where it is much more efficient.</span></span>

## <a name="other-considerations"></a><span data-ttu-id="974d6-423">기타 고려 사항</span><span class="sxs-lookup"><span data-stu-id="974d6-423">Other considerations</span></span>
<span data-ttu-id="974d6-424">복사하려는 데이터 크기가 큰 경우 Data Factory에서 조각화 메커니즘을 사용하여 데이터를 추가 파티션하도록 비즈니스 논리를 조정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-424">If the size of data you want to copy is large, you can adjust your business logic to further partition the data using the slicing mechanism in Data Factory.</span></span> <span data-ttu-id="974d6-425">그런 다음 각 복사 작업 실행에 대해 데이터 크기를 줄이기 위해 더 자주 실행할 복사 작업을 예약합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-425">Then, schedule Copy Activity to run more frequently to reduce the data size for each Copy Activity run.</span></span>

<span data-ttu-id="974d6-426">Data Factory에서 동시에 동일한 데이터 저장소에 연결해야 하는 데이터 집합 및 복사 작업 수에 주의하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-426">Be cautious about the number of data sets and copy activities requiring Data Factory to connector to the same data store at the same time.</span></span> <span data-ttu-id="974d6-427">많은 동시 복사 작업은 데이터 저장소를 제한하고 성능 저하, 복사 작업 내부 재시도 및 일부 경우 실행 오류를 발생시킬 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-427">Many concurrent copy jobs might throttle a data store and lead to degraded performance, copy job internal retries, and in some cases, execution failures.</span></span>

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a><span data-ttu-id="974d6-428">샘플 시나리오: 온-프레미스 SQL Server에서 Blob 저장소로 복사</span><span class="sxs-lookup"><span data-stu-id="974d6-428">Sample scenario: Copy from an on-premises SQL Server to Blob storage</span></span>
<span data-ttu-id="974d6-429">**시나리오**: 파이프라인은 온-프레미스 SQL Server에서 Blob 저장소로 CSV 형식으로 데이터를 복사하도록 작성됩니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-429">**Scenario**: A pipeline is built to copy data from an on-premises SQL Server to Blob storage in CSV format.</span></span> <span data-ttu-id="974d6-430">복사 작업을 더 빠르게 하려면 CSV 파일이 bzip2 형식으로 압축되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-430">To make the copy job faster, the CSV files should be compressed into bzip2 format.</span></span>

<span data-ttu-id="974d6-431">**테스트 및 분석**: 복사 작업의 처리량이 2MBps보다 적고 성능 벤치마크보다 훨씬 더 느립니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-431">**Test and analysis**: The throughput of Copy Activity is less than 2 MBps, which is much slower than the performance benchmark.</span></span>

<span data-ttu-id="974d6-432">**성능 분석 및 튜닝**: 성능 문제를 해결하기 위해 데이터가 처리되고 이동되는 방법을 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-432">**Performance analysis and tuning**: To troubleshoot the performance issue, let’s look at how the data is processed and moved.</span></span>

1. <span data-ttu-id="974d6-433">**데이터 읽기**: 게이트웨이는 SQL Server에 연결을 열고 쿼리를 보냅니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-433">**Read data**: Gateway opens a connection to SQL Server and sends the query.</span></span> <span data-ttu-id="974d6-434">SQL Server는 데이터 스트림을 인트라넷을 통해 게이트웨이로 전송하여 응답합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-434">SQL Server responds by sending the data stream to Gateway via the intranet.</span></span>
2. <span data-ttu-id="974d6-435">**데이터 직렬화 및 압축**: 게이트웨이는 데이터 스트림을 CSV 형식으로 직렬화하고 데이터를 bzip2 스트림으로 압축합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-435">**Serialize and compress data**: Gateway serializes the data stream to CSV format, and compresses the data to a bzip2 stream.</span></span>
3. <span data-ttu-id="974d6-436">**데이터 쓰기**: 게이트웨이는 인터넷을 통해 Blob 저장소로 bzip2 스트림을 업로드합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-436">**Write data**: Gateway uploads the bzip2 stream to Blob storage via the Internet.</span></span>

<span data-ttu-id="974d6-437">보이는 대로 데이터를 처리하고 다음 스트리밍 순으로 이동합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-437">As you can see, the data is being processed and moved in a streaming sequential manner: SQL Server > LAN > Gateway > WAN > Blob storage.</span></span> <span data-ttu-id="974d6-438">SQL Server -> LAN -> 게이트웨이 -> WAN -> Blob 저장소 **전반적인 성능은 파이프라인을 통해 최소 처리량에서 제어됩니다**.</span><span class="sxs-lookup"><span data-stu-id="974d6-438">**The overall performance is gated by the minimum throughput across the pipeline**.</span></span>

![데이터 흐름](./media/data-factory-copy-activity-performance/case-study-pic-1.png)

<span data-ttu-id="974d6-440">다음 중 하나 이상의 요인으로 성능 병목 현상이 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-440">One or more of the following factors might cause the performance bottleneck:</span></span>

* <span data-ttu-id="974d6-441">**원본**: SQL Server 자체가 과도한 로드로 인해 처리량이 낮아집니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-441">**Source**: SQL Server itself has low throughput because of heavy loads.</span></span>
* <span data-ttu-id="974d6-442">**데이터 관리 게이트웨이**:</span><span class="sxs-lookup"><span data-stu-id="974d6-442">**Data Management Gateway**:</span></span>
  * <span data-ttu-id="974d6-443">**LAN**: 게이트웨이가 SQL Server 컴퓨터에서 멀리 떨어져 있고 낮은 대역폭 연결을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-443">**LAN**: Gateway is located far from the SQL Server machine and has a low-bandwidth connection.</span></span>
  * <span data-ttu-id="974d6-444">**게이트웨이**: 게이트웨이는 다음 작업을 수행하는 로드 제한에 도달했습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-444">**Gateway**: Gateway has reached its load limitations to perform the following operations:</span></span>
    * <span data-ttu-id="974d6-445">**직렬화**: CSV 형식에 대한 데이터 스트림을 직렬화하면 처리량이 느려집니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-445">**Serialization**: Serializing the data stream to CSV format has slow throughput.</span></span>
    * <span data-ttu-id="974d6-446">**압축**: 느린 압축 코덱을 선택했습니다(예: Core i7 2.8MBps의 bzip2).</span><span class="sxs-lookup"><span data-stu-id="974d6-446">**Compression**: You chose a slow compression codec (for example, bzip2, which is 2.8 MBps with Core i7).</span></span>
  * <span data-ttu-id="974d6-447">**WAN**: 회사 네트워크 및 Azure 서비스 간의 대역폭이 낮습니다(예: T1 = 1,544kbps, T2 = 6,312kbps).</span><span class="sxs-lookup"><span data-stu-id="974d6-447">**WAN**: The bandwidth between the corporate network and your Azure services is low (for example, T1 = 1,544 kbps; T2 = 6,312 kbps).</span></span>
* <span data-ttu-id="974d6-448">**싱크**: Blob 저장소의 처리량이 낮습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-448">**Sink**: Blob storage has low throughput.</span></span> <span data-ttu-id="974d6-449">(이 시나리오에서는 해당 SLA가 최소 60MBps를 보장하므로 가능성이 없습니다.)</span><span class="sxs-lookup"><span data-stu-id="974d6-449">(This scenario is unlikely because its SLA guarantees a minimum of 60 MBps.)</span></span>

<span data-ttu-id="974d6-450">이 경우 bzip2 데이터 압축은 전체 파이프라인을 느리게 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-450">In this case, bzip2 data compression might be slowing down the entire pipeline.</span></span> <span data-ttu-id="974d6-451">gzip 압축 코덱을 전환하면 병목 상태를 완화할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-451">Switching to a gzip compression codec might ease this bottleneck.</span></span>

## <a name="sample-scenarios-use-parallel-copy"></a><span data-ttu-id="974d6-452">샘플 시나리오: 병렬 복사본 사용</span><span class="sxs-lookup"><span data-stu-id="974d6-452">Sample scenarios: Use parallel copy</span></span>
<span data-ttu-id="974d6-453">**시나리오 I:** 1MB 파일 1,000개를 온-프레미스 파일 시스템에서 Blob 저장소로 복사하는 경우.</span><span class="sxs-lookup"><span data-stu-id="974d6-453">**Scenario I:** Copy 1,000 1-MB files from the on-premises file system to Blob storage.</span></span>

<span data-ttu-id="974d6-454">**분석 및 성능 튜닝**: 예를 들어 쿼드 코어 컴퓨터에 게이트웨이를 설치했다고 가정할 때, Data Factory는 16개의 병렬 복사를 사용하여 파일 시스템에서 Blob 저장소로 동시에 파일을 이동합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-454">**Analysis and performance tuning**: For an example, if you have installed gateway on a quad core machine, Data Factory uses 16 parallel copies to move files from the file system to Blob storage concurrently.</span></span> <span data-ttu-id="974d6-455">이 병렬 실행 결과, 높은 처리량이 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-455">This parallel execution should result in high throughput.</span></span> <span data-ttu-id="974d6-456">또한 병렬 복사 개수를 명시적으로 지정할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-456">You also can explicitly specify the parallel copies count.</span></span> <span data-ttu-id="974d6-457">다수의 작은 파일을 복사하는 경우, 병렬 복사는 리소스를 보다 효과적으로 활용하여 처리량을 급격히 향상시키는 데 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-457">When you copy many small files, parallel copies dramatically help throughput by using resources more effectively.</span></span>

![시나리오 1](./media/data-factory-copy-activity-performance/scenario-1.png)

<span data-ttu-id="974d6-459">**시나리오 II**: 크기가 500MB인 Blob 20개를 Blob 저장소에서 Data Lake Store 분석으로 복사한 후 성능을 조정하는 경우.</span><span class="sxs-lookup"><span data-stu-id="974d6-459">**Scenario II**: Copy 20 blobs of 500 MB each from Blob storage to Data Lake Store Analytics, and then tune performance.</span></span>

<span data-ttu-id="974d6-460">**분석 및 성능 튜닝**: 이 시나리오에서 Data Factory는 단일 복사(**parallelCopies**를 1로 설정)를 사용하고 단일 클라우드 데이터 이동 단위를 사용하여 Blob 저장소에서 Data Lake Store로 데이터를 복사합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-460">**Analysis and performance tuning**: In this scenario, Data Factory copies the data from Blob storage to Data Lake Store by using single-copy (**parallelCopies** set to 1) and single-cloud data movement units.</span></span> <span data-ttu-id="974d6-461">처리량을 관찰하면 [성능 참조 섹션](#performance-reference)에 설명된 것에 근접한 것을 볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-461">The throughput you observe will be close to that described in the [performance reference section](#performance-reference).</span></span>   

![시나리오 2](./media/data-factory-copy-activity-performance/scenario-2.png)

<span data-ttu-id="974d6-463">**시나리오 III**: 개별 파일 크기는 수십 MB를 초과하며 총 볼륨은 큽니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-463">**Scenario III**: Individual file size is greater than dozens of MBs and total volume is large.</span></span>

<span data-ttu-id="974d6-464">**분석 및 성능 튜닝**: **parallelCopies**를 늘린다고 해도 단일 클라우드 DMU의 리소스 제한으로 인해 복사 성능이 향상되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-464">**Analysis and performance turning**: Increasing **parallelCopies** doesn't result in better copy performance because of the resource limitations of a single-cloud DMU.</span></span> <span data-ttu-id="974d6-465">대신, 데이터 이동을 수행할 리소스를 더 확보하기 위해서 더 많은 클라우드 DMU를 지정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-465">Instead, you should specify more cloud DMUs to get more resources to perform the data movement.</span></span> <span data-ttu-id="974d6-466">**parallelCopies** 속성에 대한 값을 지정하지 마세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-466">Do not specify a value for the **parallelCopies** property.</span></span> <span data-ttu-id="974d6-467">Data Factory는 병렬 처리를 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-467">Data Factory handles the parallelism for you.</span></span> <span data-ttu-id="974d6-468">이 경우 **cloudDataMovementUnits**를 4로 설정하면 처리량은 약 4배 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-468">In this case, if you set **cloudDataMovementUnits** to 4, a throughput of about four times occurs.</span></span>

![시나리오 3](./media/data-factory-copy-activity-performance/scenario-3.png)

## <a name="reference"></a><span data-ttu-id="974d6-470">참조</span><span class="sxs-lookup"><span data-stu-id="974d6-470">Reference</span></span>
<span data-ttu-id="974d6-471">다음은 지원되는 데이터 저장소에 대한 몇 가지 성능 모니터링 및 튜닝 참조입니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-471">Here are performance monitoring and tuning references for some of the supported data stores:</span></span>

* <span data-ttu-id="974d6-472">Azure Storage(Blob 저장소 및 테이블 저장소 포함): [Azure Storage 확장성 목표](../storage/common/storage-scalability-targets.md) 및 [Azure Storage 성능 및 확장성 검사 목록](../storage/common/storage-performance-checklist.md)</span><span class="sxs-lookup"><span data-stu-id="974d6-472">Azure Storage (including Blob storage and Table storage): [Azure Storage scalability targets](../storage/common/storage-scalability-targets.md) and [Azure Storage performance and scalability checklist](../storage/common/storage-performance-checklist.md)</span></span>
* <span data-ttu-id="974d6-473">Azure SQL Database: [성능을 모니터링](../sql-database/sql-database-single-database-monitor.md)하고 DTU(데이터베이스 트랜잭션 단위) 비율을 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="974d6-473">Azure SQL Database: You can [monitor the performance](../sql-database/sql-database-single-database-monitor.md) and check the database transaction unit (DTU) percentage</span></span>
* <span data-ttu-id="974d6-474">Azure SQL Data Warehouse: 해당 기능은 DWU(데이터 웨어하우스 단위)로 측정됩니다. [Azure SQL Data Warehouse의 계산 능력 관리(개요)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="974d6-474">Azure SQL Data Warehouse: Its capability is measured in data warehouse units (DWUs); see [Manage compute power in Azure SQL Data Warehouse (Overview)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md)</span></span>
* <span data-ttu-id="974d6-475">Azure Cosmos DB: [Azure Cosmos DB의 성능 수준](../documentdb/documentdb-performance-levels.md)</span><span class="sxs-lookup"><span data-stu-id="974d6-475">Azure Cosmos DB: [Performance levels in Azure Cosmos DB](../documentdb/documentdb-performance-levels.md)</span></span>
* <span data-ttu-id="974d6-476">온-프레미스 SQL Server: [성능에 대한 모니터링 및 튜닝](https://msdn.microsoft.com/library/ms189081.aspx)</span><span class="sxs-lookup"><span data-stu-id="974d6-476">On-premises SQL Server: [Monitor and tune for performance](https://msdn.microsoft.com/library/ms189081.aspx)</span></span>
* <span data-ttu-id="974d6-477">온-프레미스 파일 서버: [파일 서버에 대한 성능 튜닝](https://msdn.microsoft.com/library/dn567661.aspx)</span><span class="sxs-lookup"><span data-stu-id="974d6-477">On-premises file server: [Performance tuning for file servers](https://msdn.microsoft.com/library/dn567661.aspx)</span></span>
