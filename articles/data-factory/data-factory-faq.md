---
title: "데이터 팩터리-aaaAzure 질문과 대답"
description: "Azure 데이터 팩터리에 대한 질문과 대답입니다."
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: 532dec5a-7261-4770-8f54-bfe527918058
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: 78289fb4b6e15d74772af6c71ec25c7d2ca1a0bd
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="azure-data-factory---frequently-asked-questions"></a><span data-ttu-id="5a125-103">Azure 데이터 팩터리 - 질문과 대답</span><span class="sxs-lookup"><span data-stu-id="5a125-103">Azure Data Factory - Frequently Asked Questions</span></span>
## <a name="general-questions"></a><span data-ttu-id="5a125-104">일반적인 질문</span><span class="sxs-lookup"><span data-stu-id="5a125-104">General questions</span></span>
### <a name="what-is-azure-data-factory"></a><span data-ttu-id="5a125-105">Azure 데이터 팩터리란 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="5a125-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="5a125-106">데이터 팩터리는 클라우드 기반 데이터를 통합 하는 서비스 **데이터의 hello 이동 및 변환을 자동화**합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-106">Data Factory is a cloud-based data integration service that **automates hello movement and transformation of data**.</span></span> <span data-ttu-id="5a125-107">데이터 팩터리 tootake 원자재 장비를 실행 하 고 완성 된 상품으로 변환 하는 팩터리와 마찬가지로 원시 데이터를 수집 하 고 사용 가능한 준비 정보로 변환 하는 기존 서비스를 조정 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-107">Just like a factory that runs equipment tootake raw materials and transform them into finished goods, Data Factory orchestrates existing services that collect raw data and transform it into ready-to-use information.</span></span>

<span data-ttu-id="5a125-108">데이터 팩터리에 온-프레미스 및 클라우드 데이터 저장소를 비롯해 Azure HDInsight Azure 데이터 레이크 분석 등의 계산 서비스를 사용 하 여 프로세스/변환 데이터 간에 toocreate 데이터 기반 워크플로 toomove 데이터 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-108">Data Factory allows you toocreate data-driven workflows toomove data between both on-premises and cloud data stores as well as process/transform data using compute services such as Azure HDInsight and Azure Data Lake Analytics.</span></span> <span data-ttu-id="5a125-109">필요한 hello 동작을 수행 하는 파이프라인을 만든 후 toorun 주기적으로 (매시간, 매일, 매주 등) 예약할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-109">After you create a pipeline that performs hello action that you need, you can schedule it toorun periodically (hourly, daily, weekly etc.).</span></span>   

<span data-ttu-id="5a125-110">자세한 내용은 [개요 및 주요 개념](data-factory-introduction.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-110">For more information, see [Overview & Key Concepts](data-factory-introduction.md).</span></span>

### <a name="where-can-i-find-pricing-details-for-azure-data-factory"></a><span data-ttu-id="5a125-111">Azure 데이터 팩터리에 대한 가격 정보는 어디서 찾을 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="5a125-111">Where can I find pricing details for Azure Data Factory?</span></span>
<span data-ttu-id="5a125-112">참조 [데이터 팩터리 가격 정보 페이지] [ adf-pricing-details] hello 가격 hello Azure Data Factory에 대 한 정보에 대 한 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-112">See [Data Factory Pricing Details page][adf-pricing-details] for hello pricing details for hello Azure Data Factory.</span></span>  

### <a name="how-do-i-get-started-with-azure-data-factory"></a><span data-ttu-id="5a125-113">Azure 데이터 팩터리를 시작하려면 어떻게 해야 하나요?</span><span class="sxs-lookup"><span data-stu-id="5a125-113">How do I get started with Azure Data Factory?</span></span>
* <span data-ttu-id="5a125-114">Azure Data Factory의 개요를 참조 하십시오. [소개 tooAzure Data Factory](data-factory-introduction.md)합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-114">For an overview of Azure Data Factory, see [Introduction tooAzure Data Factory](data-factory-introduction.md).</span></span>
* <span data-ttu-id="5a125-115">방법에 대 한 자습서에 대 한 너무**복사/이동 데이터** 복사 작업을 사용 하 여, 참조 [Azure Blob 저장소 tooAzure SQL 데이터베이스에서에서 데이터를 복사](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md)합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-115">For a tutorial on how too**copy/move data** using Copy Activity, see [Copy data from Azure Blob Storage tooAzure SQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>
* <span data-ttu-id="5a125-116">방법에 대 한 자습서에 대 한 너무**데이터 변환** HDInsight Hive 활동 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-116">For a tutorial on how too**transform data** using HDInsight Hive Activity.</span></span> <span data-ttu-id="5a125-117">[Process data by running Hive script on Hadoop cluster](data-factory-build-your-first-pipeline.md)(Hadoop 클러스터에서 Hive 스크립트를 실행하여 데이터 처리)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-117">See [Process data by running Hive script on Hadoop cluster](data-factory-build-your-first-pipeline.md)</span></span>

### <a name="what-is-hello-data-factorys-region-availability"></a><span data-ttu-id="5a125-118">Hello 데이터 팩토리 영역 가용성 란?</span><span class="sxs-lookup"><span data-stu-id="5a125-118">What is hello Data Factory’s region availability?</span></span>
<span data-ttu-id="5a125-119">Data Factory는 **미국 서부** 및 **북유럽**에서 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-119">Data Factory is available in **US West** and **North Europe**.</span></span> <span data-ttu-id="5a125-120">hello 계산 및 데이터 팩터리에서 사용 하는 저장소 서비스는 다른 지역 들에 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-120">hello compute and storage services used by data factories can be in other regions.</span></span> <span data-ttu-id="5a125-121">[지원되는 지역](data-factory-introduction.md#supported-regions)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-121">See [Supported regions](data-factory-introduction.md#supported-regions).</span></span>

### <a name="what-are-hello-limits-on-number-of-data-factoriespipelinesactivitiesdatasets"></a><span data-ttu-id="5a125-122">다양 한 데이터 팩터리/파이프라인/활동/datasets에 hello 제한 사항은 무엇입니까?</span><span class="sxs-lookup"><span data-stu-id="5a125-122">What are hello limits on number of data factories/pipelines/activities/datasets?</span></span>
<span data-ttu-id="5a125-123">참조 **Azure 데이터 팩터리 제한** hello 섹션 [Azure 구독 및 서비스 제한, 할당량 및 제약 조건](../azure-subscription-service-limits.md#data-factory-limits) 문서.</span><span class="sxs-lookup"><span data-stu-id="5a125-123">See **Azure Data Factory Limits** section of hello [Azure Subscription and Service Limits, Quotas, and Constraints](../azure-subscription-service-limits.md#data-factory-limits) article.</span></span>

### <a name="what-is-hello-authoringdeveloper-experience-with-azure-data-factory-service"></a><span data-ttu-id="5a125-124">Azure Data Factory 서비스와 hello 제작/개발자 환경 이란?</span><span class="sxs-lookup"><span data-stu-id="5a125-124">What is hello authoring/developer experience with Azure Data Factory service?</span></span>
<span data-ttu-id="5a125-125">작성자/만들면 hello 도구/Sdk를 다음 중 하나를 사용 하 여 데이터 팩터리 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-125">You can author/create data factories using one of hello following tools/SDKs:</span></span>

* <span data-ttu-id="5a125-126">**Azure 포털** hello Data Factory 블레이드 hello Azure 포털에서에서 다양 한 사용자 인터페이스를 제공할 toocreate 데이터 팩터리 ad 연결 된 서비스입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-126">**Azure portal** hello Data Factory blades in hello Azure portal provide rich user interface for you toocreate data factories ad linked services.</span></span> <span data-ttu-id="5a125-127">hello **데이터 팩터리 편집기**, hello 포털의 일부 이기도 하면 tooeasily 이러한 아티팩트에 대 한 JSON 정의 지정 하 여 연결 된 서비스, 테이블, 데이터 집합 및 파이프라인을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-127">hello **Data Factory Editor**, which is also part of hello portal, allows you tooeasily create linked services, tables, data sets, and pipelines by specifying JSON definitions for these artifacts.</span></span> <span data-ttu-id="5a125-128">참조 [Azure 포털을 사용 하 여 첫 번째 데이터 파이프라인을 빌드](data-factory-build-your-first-pipeline-using-editor.md) 사용 하는 예제 포털/편집기 toocreate hello 및 데이터 팩터리를 배포 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-128">See [Build your first data pipeline using Azure portal](data-factory-build-your-first-pipeline-using-editor.md) for an example of using hello portal/editor toocreate and deploy a data factory.</span></span>
* <span data-ttu-id="5a125-129">**Visual Studio** Visual Studio toocreate Azure 데이터 팩터리를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-129">**Visual Studio** You can use Visual Studio toocreate an Azure data factory.</span></span> <span data-ttu-id="5a125-130">자세한 내용은 [Build your first data pipeline using Visual Studio](data-factory-build-your-first-pipeline-using-vs.md) (Visual Studio를 사용하여 첫 번째 데이터 파이프라인 빌드)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-130">See [Build your first data pipeline using Visual Studio](data-factory-build-your-first-pipeline-using-vs.md) for details.</span></span>
* <span data-ttu-id="5a125-131">**Azure PowerShell** PowerShell을 사용하여 Data Factory를 만드는 자습서는 [Create and monitor Azure Data Factory using Azure PowerShell](data-factory-build-your-first-pipeline-using-powershell.md) (Azure PowerShell을 사용하여 Azure Data Factory 만들기 및 모니터링)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-131">**Azure PowerShell** See [Create and monitor Azure Data Factory using Azure PowerShell](data-factory-build-your-first-pipeline-using-powershell.md) for a tutorial/walkthrough for creating a data factory using PowerShell.</span></span> <span data-ttu-id="5a125-132">데이터 팩터리 cmdlet의 포괄적인 설명서는 MSDN 라이브러리의 [데이터 팩터리 Cmdlet 참조][adf-powershell-reference] 콘텐츠를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-132">See [Data Factory Cmdlet Reference][adf-powershell-reference] content on MSDN Library for a comprehensive documentation of Data Factory cmdlets.</span></span>
* <span data-ttu-id="5a125-133">**.NET 클래스 라이브러리** Data Factory .NET SDK를 사용하여 프로그래밍 방식으로 데이터 팩터리를 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-133">**.NET Class Library** You can programmatically create data factories by using Data Factory .NET SDK.</span></span> <span data-ttu-id="5a125-134">.NET SDK를 사용하여 데이터 팩터리를 만드는 연습은 [.NET SDK를 사용하여 데이터 팩터리 만들기, 모니터링 및 관리](data-factory-create-data-factories-programmatically.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-134">See [Create, monitor, and manage data factories using .NET SDK](data-factory-create-data-factories-programmatically.md) for a walkthrough of creating a data factory using .NET SDK.</span></span> <span data-ttu-id="5a125-135">데이터 팩터리 .NET SDK의 포괄적인 설명서는 [데이터 팩터리 클래스 라이브러리 참조][msdn-class-library-reference]를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-135">See [Data Factory Class Library Reference][msdn-class-library-reference] for a comprehensive documentation of Data Factory .NET SDK.</span></span>
* <span data-ttu-id="5a125-136">**REST API** hello hello Azure Data Factory 서비스 toocreate에 의해 노출 되는 REST API를 사용 하 고 데이터 팩터리를 배포할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-136">**REST API** You can also use hello REST API exposed by hello Azure Data Factory service toocreate and deploy data factories.</span></span> <span data-ttu-id="5a125-137">데이터 팩터리 REST API의 포괄적인 설명서는 [데이터 팩터리 REST API 참조][msdn-rest-api-reference]를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-137">See [Data Factory REST API Reference][msdn-rest-api-reference] for a comprehensive documentation of Data Factory REST API.</span></span>
* <span data-ttu-id="5a125-138">**Azure Resource Manager 템플릿** 자세한 내용은 [자습서: Azure Resource Manager 템플릿을 사용하여 첫 번째 Azure Data Factory 빌드](data-factory-build-your-first-pipeline-using-arm.md) 를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-138">**Azure Resource Manager Template** See [Tutorial: Build your first Azure data factory using Azure Resource Manager template](data-factory-build-your-first-pipeline-using-arm.md) fo details.</span></span>

### <a name="can-i-rename-a-data-factory"></a><span data-ttu-id="5a125-139">Data Factory의 이름을 바꿀 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="5a125-139">Can I rename a data factory?</span></span>
<span data-ttu-id="5a125-140">아니요.</span><span class="sxs-lookup"><span data-stu-id="5a125-140">No.</span></span> <span data-ttu-id="5a125-141">다른 Azure 리소스와 마찬가지로 Azure 데이터 팩터리에의 hello 이름을 변경할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-141">Like other Azure resources, hello name of an Azure data factory cannot be changed.</span></span>

### <a name="can-i-move-a-data-factory-from-one-azure-subscription-tooanother"></a><span data-ttu-id="5a125-142">하나의 Azure 구독 tooanother에서 데이터 팩터리를 이동할 수 있습니까?</span><span class="sxs-lookup"><span data-stu-id="5a125-142">Can I move a data factory from one Azure subscription tooanother?</span></span>
<span data-ttu-id="5a125-143">예.</span><span class="sxs-lookup"><span data-stu-id="5a125-143">Yes.</span></span> <span data-ttu-id="5a125-144">사용 하 여 hello **이동** hello 다음 다이어그램에에서 표시 된 대로 데이터 팩터리 블레이드에서 단추:</span><span class="sxs-lookup"><span data-stu-id="5a125-144">Use hello **Move** button on your data factory blade as shown in hello following diagram:</span></span>

![데이터 팩터리 이동](media/data-factory-faq/move-data-factory.png)

### <a name="what-are-hello-compute-environments-supported-by-data-factory"></a><span data-ttu-id="5a125-146">Data Factory에서 지 원하는 hello 계산 환경 이란?</span><span class="sxs-lookup"><span data-stu-id="5a125-146">What are hello compute environments supported by Data Factory?</span></span>
<span data-ttu-id="5a125-147">hello 다음 표에서 계산 환경에서 실행할 수 있는 Data Factory와 hello 활동에서 지 원하는 목록을.</span><span class="sxs-lookup"><span data-stu-id="5a125-147">hello following table provides a list of compute environments supported by Data Factory and hello activities that can run on them.</span></span>

| <span data-ttu-id="5a125-148">컴퓨팅 환경</span><span class="sxs-lookup"><span data-stu-id="5a125-148">Compute environment</span></span> | <span data-ttu-id="5a125-149">작업</span><span class="sxs-lookup"><span data-stu-id="5a125-149">activities</span></span> |
| --- | --- |
| <span data-ttu-id="5a125-150">[주문형 HDInsight 클러스터](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) 또는 [사용자 고유의 HDInsight 클러스터](data-factory-compute-linked-services.md#azure-hdinsight-linked-service)</span><span class="sxs-lookup"><span data-stu-id="5a125-150">[On-demand HDInsight cluster](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) or [your own HDInsight cluster](data-factory-compute-linked-services.md#azure-hdinsight-linked-service)</span></span> |<span data-ttu-id="5a125-151">[DotNet](data-factory-use-custom-activities.md), [Hive](data-factory-hive-activity.md), [Pig](data-factory-pig-activity.md), [MapReduce](data-factory-map-reduce.md), [Hadoop 스트리밍](data-factory-hadoop-streaming-activity.md)</span><span class="sxs-lookup"><span data-stu-id="5a125-151">[DotNet](data-factory-use-custom-activities.md), [Hive](data-factory-hive-activity.md), [Pig](data-factory-pig-activity.md), [MapReduce](data-factory-map-reduce.md), [Hadoop Streaming](data-factory-hadoop-streaming-activity.md)</span></span> |
| [<span data-ttu-id="5a125-152">Azure 배치</span><span class="sxs-lookup"><span data-stu-id="5a125-152">Azure Batch</span></span>](data-factory-compute-linked-services.md#azure-batch-linked-service) |[<span data-ttu-id="5a125-153">DotNet</span><span class="sxs-lookup"><span data-stu-id="5a125-153">DotNet</span></span>](data-factory-use-custom-activities.md) |
| [<span data-ttu-id="5a125-154">Azure 기계 학습</span><span class="sxs-lookup"><span data-stu-id="5a125-154">Azure Machine Learning</span></span>](data-factory-compute-linked-services.md#azure-machine-learning-linked-service) |[<span data-ttu-id="5a125-155">Machine Learning 작업: 배치 실행 및 업데이트 리소스</span><span class="sxs-lookup"><span data-stu-id="5a125-155">Machine Learning activities: Batch Execution and Update Resource</span></span>](data-factory-azure-ml-batch-execution-activity.md) |
| [<span data-ttu-id="5a125-156">Azure 데이터 레이크 분석</span><span class="sxs-lookup"><span data-stu-id="5a125-156">Azure Data Lake Analytics</span></span>](data-factory-compute-linked-services.md#azure-data-lake-analytics-linked-service) |[<span data-ttu-id="5a125-157">데이터 레이크 분석 U-SQL</span><span class="sxs-lookup"><span data-stu-id="5a125-157">Data Lake Analytics U-SQL</span></span>](data-factory-usql-activity.md) |
| <span data-ttu-id="5a125-158">[Azure SQL](data-factory-compute-linked-services.md#azure-sql-linked-service), [Azure SQL Data Warehouse](data-factory-compute-linked-services.md#azure-sql-data-warehouse-linked-service), [SQL Server](data-factory-compute-linked-services.md#sql-server-linked-service)</span><span class="sxs-lookup"><span data-stu-id="5a125-158">[Azure SQL](data-factory-compute-linked-services.md#azure-sql-linked-service), [Azure SQL Data Warehouse](data-factory-compute-linked-services.md#azure-sql-data-warehouse-linked-service), [SQL Server](data-factory-compute-linked-services.md#sql-server-linked-service)</span></span> |[<span data-ttu-id="5a125-159">저장 프로시저</span><span class="sxs-lookup"><span data-stu-id="5a125-159">Stored Procedure</span></span>](data-factory-stored-proc-activity.md) |

### <a name="how-does-azure-data-factory-compare-with-sql-server-integration-services-ssis"></a><span data-ttu-id="5a125-160">Azure Data Factory를 SSIS(SQL Server Integration Services)와 비교하면 어떻게 다른가요?</span><span class="sxs-lookup"><span data-stu-id="5a125-160">How does Azure Data Factory compare with SQL Server Integration Services (SSIS)?</span></span> 
<span data-ttu-id="5a125-161">Hello 참조 [Azure Data Factory vs. SSIS](http://www.sqlbits.com/Sessions/Event15/Azure_Data_Factory_vs_SSIS) 프레젠테이션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-161">See hello [Azure Data Factory vs. SSIS](http://www.sqlbits.com/Sessions/Event15/Azure_Data_Factory_vs_SSIS) presentation from one of our MVPs (Most Valued Professionals): Reza Rad.</span></span> <span data-ttu-id="5a125-162">데이터 팩터리 hello 최근 변경 사항 중 일부 hello 슬라이드 모음에 나열 되지 않을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-162">Some of hello recent changes in Data Factory may not be listed in hello slide deck.</span></span> <span data-ttu-id="5a125-163">더 많은 기능 tooAzure Data Factory 지속적으로 추가 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-163">We are continuously adding more capabilities tooAzure Data Factory.</span></span> <span data-ttu-id="5a125-164">더 많은 기능 tooAzure Data Factory 지속적으로 추가 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-164">We are continuously adding more capabilities tooAzure Data Factory.</span></span> <span data-ttu-id="5a125-165">우리는 이러한 업데이트에 통합 hello Microsoft의 데이터 통합 기술 비교 올해 후반 잠시 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-165">We will incorporate these updates into hello comparison of data integration technologies from Microsoft sometime later this year.</span></span>   

## <a name="activities---faq"></a><span data-ttu-id="5a125-166">작업 - FAQ</span><span class="sxs-lookup"><span data-stu-id="5a125-166">Activities - FAQ</span></span>
### <a name="what-are-hello-different-types-of-activities-you-can-use-in-a-data-factory-pipeline"></a><span data-ttu-id="5a125-167">데이터 팩터리 파이프라인에서 사용할 수는 활동의 hello 다른 유형은 무엇 인가요?</span><span class="sxs-lookup"><span data-stu-id="5a125-167">What are hello different types of activities you can use in a Data Factory pipeline?</span></span>
* <span data-ttu-id="5a125-168">[데이터 이동 작업](data-factory-data-movement-activities.md) toomove 데이터입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-168">[Data Movement Activities](data-factory-data-movement-activities.md) toomove data.</span></span>
* <span data-ttu-id="5a125-169">[데이터 변환 작업](data-factory-data-transformation-activities.md) tooprocess/변환 데이터입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-169">[Data Transformation Activities](data-factory-data-transformation-activities.md) tooprocess/transform data.</span></span>

### <a name="when-does-an-activity-run"></a><span data-ttu-id="5a125-170">작업은 언제 실행되나요?</span><span class="sxs-lookup"><span data-stu-id="5a125-170">When does an activity run?</span></span>
<span data-ttu-id="5a125-171">hello **가용성** hello 구성 설정을 출력 데이터 테이블 hello 활동 실행 되는 시기를 결정 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-171">hello **availability** configuration setting in hello output data table determines when hello activity is run.</span></span> <span data-ttu-id="5a125-172">입력된 데이터 집합을 지정 하는 경우 hello 활동 모든 hello 입력된 데이터 종속성을 충족 하는지 여부를 확인 (즉, **준비** 상태) 실행을 시작 하기 전에.</span><span class="sxs-lookup"><span data-stu-id="5a125-172">If input datasets are specified, hello activity checks whether all hello input data dependencies are satisfied (that is, **Ready** state) before it starts running.</span></span>

## <a name="copy-activity---faq"></a><span data-ttu-id="5a125-173">복사 작업 - FAQ</span><span class="sxs-lookup"><span data-stu-id="5a125-173">Copy Activity - FAQ</span></span>
### <a name="is-it-better-toohave-a-pipeline-with-multiple-activities-or-a-separate-pipeline-for-each-activity"></a><span data-ttu-id="5a125-174">여러 작업이 포함 된 파이프라인 또는 각 활동에 대해 별도 파이프라인 더 나은 toohave 입니까?</span><span class="sxs-lookup"><span data-stu-id="5a125-174">Is it better toohave a pipeline with multiple activities or a separate pipeline for each activity?</span></span>
<span data-ttu-id="5a125-175">파이프라인 되어야 하는 toobundle 관련 활동입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-175">Pipelines are supposed toobundle related activities.</span></span> <span data-ttu-id="5a125-176">Hello 데이터 집합을 연결 하는 hello 파이프라인의 외부에 있는 다른 모든 작업에 사용 되지 않는, 경우에 파이프라인 하나에 hello 활동을 유지할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-176">If hello datasets that connect them are not consumed by any other activity outside hello pipeline, you can keep hello activities in one pipeline.</span></span> <span data-ttu-id="5a125-177">이 이렇게 하지 해야 toochain 파이프라인 활성 기간 서로 배열 되도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-177">This way, you would not need toochain pipeline active periods so that they align with each other.</span></span> <span data-ttu-id="5a125-178">또한 hello 테이블 내부 toohello 파이프라인에서 데이터 무결성 hello hello 파이프라인을 업데이트할 때에 더 잘 유지 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-178">Also, hello data integrity in hello tables internal toohello pipeline is better preserved when updating hello pipeline.</span></span> <span data-ttu-id="5a125-179">파이프라인 업데이트 기본적으로 hello 파이프라인 내의 모든 hello 활동, 제거, 멈추고으로 다시 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-179">Pipeline update essentially stops all hello activities within hello pipeline, removes them, and creates them again.</span></span> <span data-ttu-id="5a125-180">큐브를 제작할 수도 있습니다 hello와 관련 된 내부 데이터의 toosee hello 흐름을 보다 쉽게 hello 파이프라인에 대 한 JSON의 작업 파일입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-180">From authoring perspective, it might also be easier toosee hello flow of data within hello related activities in one JSON file for hello pipeline.</span></span>

### <a name="what-are-hello-supported-data-stores"></a><span data-ttu-id="5a125-181">데이터 저장소를 지원 hello 이란?</span><span class="sxs-lookup"><span data-stu-id="5a125-181">What are hello supported data stores?</span></span>
<span data-ttu-id="5a125-182">복사 활동 Data Factory에는 원본 데이터 저장소 tooa 싱크 데이터 저장소에서 데이터를 복사합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-182">Copy Activity in Data Factory copies data from a source data store tooa sink data store.</span></span> <span data-ttu-id="5a125-183">데이터 팩터리 hello 다음 데이터 저장소를 지원 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-183">Data Factory supports hello following data stores.</span></span> <span data-ttu-id="5a125-184">데이터 소스에서 tooany 싱크를 작성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-184">Data from any source can be written tooany sink.</span></span> <span data-ttu-id="5a125-185">데이터 저장소 toolearn 방법을 클릭 해당 저장소에서 데이터 tooand toocopy 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-185">Click a data store toolearn how toocopy data tooand from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

> [!NOTE]
> <span data-ttu-id="5a125-186">데이터 저장소와 * 온-프레미스 될 수 있습니다 또는 Azure IaaS에서 고 tooinstall 있어야 하며 [데이터 관리 게이트웨이](data-factory-data-management-gateway.md) 에-프레미스/Azure IaaS 컴퓨터에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-186">Data stores with * can be on-premises or on Azure IaaS, and require you tooinstall [Data Management Gateway](data-factory-data-management-gateway.md) on an on-premises/Azure IaaS machine.</span></span>

### <a name="what-are-hello-supported-file-formats"></a><span data-ttu-id="5a125-187">파일 형식 지원 이란 hello?</span><span class="sxs-lookup"><span data-stu-id="5a125-187">What are hello supported file formats?</span></span>
[!INCLUDE [data-factory-file-format](../../includes/data-factory-file-format.md)]

### <a name="where-is-hello-copy-operation-performed"></a><span data-ttu-id="5a125-188">Hello 복사 작업을 수행 하는 위치</span><span class="sxs-lookup"><span data-stu-id="5a125-188">Where is hello copy operation performed?</span></span>
<span data-ttu-id="5a125-189">자세한 내용은 [전역적으로 사용 가능한 데이터 이동](data-factory-data-movement-activities.md#global) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-189">See [Globally available data movement](data-factory-data-movement-activities.md#global) section for details.</span></span> <span data-ttu-id="5a125-190">즉, 온-프레미스 데이터 저장소와 관련 되어 온-프레미스 환경에 데이터 관리 게이트웨이 hello 하 여 hello 복사 작업이 수행 됩니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-190">In short, when an on-premises data store is involved, hello copy operation is performed by hello Data Management Gateway in your on-premises environment.</span></span> <span data-ttu-id="5a125-191">Hello 지역 가장 가까운 toohello 싱크에서에서 위치에 있는 hello hello 복사 작업은 수행 hello 데이터 이동 클라우드 저장소 사이 있는 경우와 동일한 지리적 위치입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-191">And, when hello data movement is between two cloud stores, hello copy operation is performed in hello region closest toohello sink location in hello same geography.</span></span>

## <a name="hdinsight-activity---faq"></a><span data-ttu-id="5a125-192">HDInsight 작업 - FAQ</span><span class="sxs-lookup"><span data-stu-id="5a125-192">HDInsight Activity - FAQ</span></span>
### <a name="what-regions-are-supported-by-hdinsight"></a><span data-ttu-id="5a125-193">HDInsight에서 지원하는 지역은 어디인가요?</span><span class="sxs-lookup"><span data-stu-id="5a125-193">What regions are supported by HDInsight?</span></span>
<span data-ttu-id="5a125-194">참조 지리적 가용성 섹션에서 다음 문서는 hello hello: 또는 [HDInsight 가격 정보][hdinsight-supported-regions]합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-194">See hello Geographic Availability section in hello following article: or [HDInsight Pricing Details][hdinsight-supported-regions].</span></span>

### <a name="what-region-is-used-by-an-on-demand-hdinsight-cluster"></a><span data-ttu-id="5a125-195">주문형 HDInsight 클러스터가 사용되는 지역은 어디인가요?</span><span class="sxs-lookup"><span data-stu-id="5a125-195">What region is used by an on-demand HDInsight cluster?</span></span>
<span data-ttu-id="5a125-196">hello 주문형 HDInsight 클러스터를 만드는 hello에 동일한 toobe hello 클러스터와 사용을 지정 하는 hello 저장소가 있는 영역입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-196">hello on-demand HDInsight cluster is created in hello same region where hello storage you specified toobe used with hello cluster exists.</span></span>    

### <a name="how-tooassociate-additional-storage-accounts-tooyour-hdinsight-cluster"></a><span data-ttu-id="5a125-197">어떻게 tooassociate 추가 저장소 계정 tooyour HDInsight 클러스터?</span><span class="sxs-lookup"><span data-stu-id="5a125-197">How tooassociate additional storage accounts tooyour HDInsight cluster?</span></span>
<span data-ttu-id="5a125-198">사용자 고유의 HDInsight 클러스터 (BYOC-고유의 클러스터 가져오기)를 사용 하는 경우 hello 다음 항목을 참조 하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-198">If you are using your own HDInsight Cluster (BYOC - Bring Your Own Cluster), see hello following topics:</span></span>

* <span data-ttu-id="5a125-199">[대체 저장소 계정 및 메타스토어와 HDInsight 클러스터 사용][hdinsight-alternate-storage]</span><span class="sxs-lookup"><span data-stu-id="5a125-199">[Using an HDInsight Cluster with Alternate Storage Accounts and Metastores][hdinsight-alternate-storage]</span></span>
* <span data-ttu-id="5a125-200">[HDInsight Hive와 추가 저장소 계정 사용][hdinsight-alternate-storage-2]</span><span class="sxs-lookup"><span data-stu-id="5a125-200">[Use Additional Storage Accounts with HDInsight Hive][hdinsight-alternate-storage-2]</span></span>

<span data-ttu-id="5a125-201">Hello 데이터 팩터리 서비스에 의해 만들어진 주문형 클러스터를 사용 하는 경우에 hello 데이터 팩터리 서비스에서 사용자 대신 등록할 수 있도록 HDInsight hello에 대 한 추가 저장소 계정을 연결 된 서비스를 지정 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-201">If you are using an on-demand cluster that is created by hello Data Factory service, specify additional storage accounts for hello HDInsight linked service so that hello Data Factory service can register them on your behalf.</span></span> <span data-ttu-id="5a125-202">Hello hello 주문형 연결 된 서비스에 대 한 JSON 정의에서 사용 하 여 **additionalLinkedServiceNames** 다음 JSON 코드 조각은 hello와 같이 속성 toospecify 대체 저장소 계정:</span><span class="sxs-lookup"><span data-stu-id="5a125-202">In hello JSON definition for hello on-demand linked service, use **additionalLinkedServiceNames** property toospecify alternate storage accounts as shown in hello following JSON snippet:</span></span>

```JSON
{
    "name": "MyHDInsightOnDemandLinkedService",
    "properties":
    {
        "type": "HDInsightOnDemandLinkedService",
        "typeProperties": {
            "version": "3.5",
            "clusterSize": 1,
            "timeToLive": "00:05:00",
            "osType": "Linux",
            "linkedServiceName": "LinkedService-SampleData",
            "additionalLinkedServiceNames": [ "otherLinkedServiceName1", "otherLinkedServiceName2" ]
        }
    }
}
```
<span data-ttu-id="5a125-203">Hello 위의 예에서 otherLinkedServiceName1 및 otherLinkedServiceName2 정의가 hello HDInsight 클러스터 요구 tooaccess 대체 저장소 계정 자격 증명을 포함 하는 연결 된 서비스를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-203">In hello example above, otherLinkedServiceName1 and otherLinkedServiceName2 represent linked services whose definitions contain credentials that hello HDInsight cluster needs tooaccess alternate storage accounts.</span></span>

## <a name="slices---faq"></a><span data-ttu-id="5a125-204">조각 - FAQ</span><span class="sxs-lookup"><span data-stu-id="5a125-204">Slices - FAQ</span></span>
### <a name="why-are-my-input-slices-not-in-ready-state"></a><span data-ttu-id="5a125-205">내 입력 조각이 준비 상태가 아닌 이유는 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="5a125-205">Why are my input slices not in Ready state?</span></span>
<span data-ttu-id="5a125-206">일반적인 실수는 설정 하지 않으면 **외부** 속성 너무**true** hello에 hello 입력 데이터를 필터링 하는 경우 입력된 데이터 집합은 외부 toohello 데이터 팩터리의 (hello 데이터 팩터리에 의해 생성 되지 않은).</span><span class="sxs-lookup"><span data-stu-id="5a125-206">A common mistake is not setting **external** property too**true** on hello input dataset when hello input data is external toohello data factory (not produced by hello data factory).</span></span>

<span data-ttu-id="5a125-207">다음 예제는 hello, 데이터만 필요 tooset **외부** 에 tootrue **dataset1**합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-207">In hello following example, you only need tooset **external** tootrue on **dataset1**.</span></span>  

<span data-ttu-id="5a125-208">**DataFactory1** 파이프라인 1: dataset1 -> activity1 -> dataset2 -> activity2 -> dataset3 파이프라인 2: dataset3-> activity3 -> dataset4</span><span class="sxs-lookup"><span data-stu-id="5a125-208">**DataFactory1** Pipeline 1: dataset1 -> activity1 -> dataset2 -> activity2 -> dataset3 Pipeline 2: dataset3-> activity3 -> dataset4</span></span>

<span data-ttu-id="5a125-209">Dataset4 (데이터 팩터리 1에서에서 2 파이프라인에서 생성 된)를 사용 하는 파이프라인이 포함 된 다른 데이터 팩터리를 사용 하도록 설정한 경우는 hello 데이터 집합 (DataFactory1, 하지 DataFactory2) 다른 데이터 팩터리에서 생성 하기 때문에 외부 데이터 집합으로 dataset4를 표시 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-209">If you have another data factory with a pipeline that takes dataset4 (produced by pipeline 2 in data factory 1), mark dataset4 as an external dataset because hello dataset is produced by a different data factory (DataFactory1, not DataFactory2).</span></span>  

<span data-ttu-id="5a125-210">**DataFactory2**  </span><span class="sxs-lookup"><span data-stu-id="5a125-210">**DataFactory2**  </span></span>  
<span data-ttu-id="5a125-211">파이프라인 1: activity4->dataset4->dataset5</span><span class="sxs-lookup"><span data-stu-id="5a125-211">Pipeline 1: dataset4->activity4->dataset5</span></span>

<span data-ttu-id="5a125-212">Hello 외부 속성을 올바르게 설정 하는 경우 입력된 데이터 hello hello 입력된 데이터 집합 정의에 지정 된 hello 위치에 있는지 여부를 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-212">If hello external property is properly set, verify whether hello input data exists in hello location specified in hello input dataset definition.</span></span>

### <a name="how-toorun-a-slice-at-another-time-than-midnight-when-hello-slice-is-being-produced-daily"></a><span data-ttu-id="5a125-213">어떻게 toorun hello slice가 생성 될 때 되 고 매일 자정 보다 나중에 한 조각?</span><span class="sxs-lookup"><span data-stu-id="5a125-213">How toorun a slice at another time than midnight when hello slice is being produced daily?</span></span>
<span data-ttu-id="5a125-214">사용 하 여 hello **오프셋** hello 조각 toobe 원하는 속성 toospecify hello 시간 생성 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-214">Use hello **offset** property toospecify hello time at which you want hello slice toobe produced.</span></span> <span data-ttu-id="5a125-215">이 속성에 대한 자세한 내용은 [데이터 집합 가용성](data-factory-create-datasets.md#dataset-availability) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-215">See [Dataset availability](data-factory-create-datasets.md#dataset-availability) section for details about this property.</span></span> <span data-ttu-id="5a125-216">간단한 예제는 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-216">Here is a quick example:</span></span>

```json
"availability":
{
    "frequency": "Day",
    "interval": 1,
    "offset": "06:00:00"
}
```
<span data-ttu-id="5a125-217">일별 조각화가 시작 시 **오전 6 시** hello 기본 자정 대신 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-217">Daily slices start at **6 AM** instead of hello default midnight.</span></span>     

### <a name="how-can-i-rerun-a-slice"></a><span data-ttu-id="5a125-218">어떻게 조각을 다시 실행할 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="5a125-218">How can I rerun a slice?</span></span>
<span data-ttu-id="5a125-219">Hello 같은 방법으로 다음 중 하나에 있는 분할 영역을 다시 실행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-219">You can rerun a slice in one of hello following ways:</span></span>

* <span data-ttu-id="5a125-220">모니터 및 앱 관리 toorerun 활동 또는 분할 영역을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-220">Use Monitor and Manage App toorerun an activity window or slice.</span></span> <span data-ttu-id="5a125-221">지침에 대해서는 [선택한 작업 창 다시 실행](data-factory-monitor-manage-app.md#perform-batch-actions)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-221">See [Rerun selected activity windows](data-factory-monitor-manage-app.md#perform-batch-actions) for instructions.</span></span>   
* <span data-ttu-id="5a125-222">클릭 **실행** hello에 hello 명령 모음에서 **데이터 조각을** 블레이드 hello Azure 포털에서에서 hello 조각에 대 한 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-222">Click **Run** in hello command bar on hello **DATA SLICE** blade for hello slice in hello Azure portal.</span></span>
* <span data-ttu-id="5a125-223">실행 **집합 AzureRmDataFactorySliceStatus** 상태를 사용 하 여 cmdlet 너무 설정**대기** hello 조각에 대 한 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-223">Run **Set-AzureRmDataFactorySliceStatus** cmdlet with Status set too**Waiting** for hello slice.</span></span>   

    ```PowerShell
    Set-AzureRmDataFactorySliceStatus -Status Waiting -ResourceGroupName $ResourceGroup -DataFactoryName $df -TableName $table -StartDateTime "02/26/2015 19:00:00" -EndDateTime "02/26/2015 20:00:00"
    ```
<span data-ttu-id="5a125-224">참조 [집합 AzureRmDataFactorySliceStatus] [ set-azure-datafactory-slice-status] hello cmdlet에 대 한 세부 정보에 대 한 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-224">See [Set-AzureRmDataFactorySliceStatus][set-azure-datafactory-slice-status] for details about hello cmdlet.</span></span>

### <a name="how-long-did-it-take-tooprocess-a-slice"></a><span data-ttu-id="5a125-225">얼마나 오래 걸린 tooprocess 조각을?</span><span class="sxs-lookup"><span data-stu-id="5a125-225">How long did it take tooprocess a slice?</span></span>
<span data-ttu-id="5a125-226">활동 창 탐색기를 사용 하 여 모니터링 및 앱 관리 tooknow 걸린 tooprocess 데이터 조각에에서 있습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-226">Use Activity Window Explorer in Monitor & Manage App tooknow how long it took tooprocess a data slice.</span></span> <span data-ttu-id="5a125-227">자세한 내용은 [작업 창 탐색기](data-factory-monitor-manage-app.md#activity-window-explorer)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="5a125-227">See [Activity Window Explorer](data-factory-monitor-manage-app.md#activity-window-explorer) for details.</span></span>

<span data-ttu-id="5a125-228">수행할 수 있습니다 hello Azure 포털에서에서 다음 hello:</span><span class="sxs-lookup"><span data-stu-id="5a125-228">You can also do hello following in hello Azure portal:</span></span>  

1. <span data-ttu-id="5a125-229">클릭 **데이터 집합** hello 타일 **DATA FACTORY** 블레이드 데이터 팩토리에 대 한 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-229">Click **Datasets** tile on hello **DATA FACTORY** blade for your data factory.</span></span>
2. <span data-ttu-id="5a125-230">Hello에 특정 데이터 집합 hello 클릭 **데이터 집합** 블레이드입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-230">Click hello specific dataset on hello **Datasets** blade.</span></span>
3. <span data-ttu-id="5a125-231">Hello에 관심 있는 선택 hello 조각 **최근 조각** hello 목록 **테이블** 블레이드입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-231">Select hello slice that you are interested in from hello **Recent slices** list on hello **TABLE** blade.</span></span>
4. <span data-ttu-id="5a125-232">Hello에서를 실행 하는 hello 활동 클릭 **활동을 실행** hello 목록 **데이터 조각을** 블레이드입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-232">Click hello activity run from hello **Activity Runs** list on hello **DATA SLICE** blade.</span></span>
5. <span data-ttu-id="5a125-233">클릭 **속성** hello 타일 **작업 실행 세부 정보** 블레이드입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-233">Click **Properties** tile on hello **ACTIVITY RUN DETAILS** blade.</span></span>
6. <span data-ttu-id="5a125-234">Hello 표시 되어야 **기간** 값이 있는 필드입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-234">You should see hello **DURATION** field with a value.</span></span> <span data-ttu-id="5a125-235">이 값은 hello 시간이 tooprocess hello 조각화를 수행 합니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-235">This value is hello time taken tooprocess hello slice.</span></span>   

### <a name="how-toostop-a-running-slice"></a><span data-ttu-id="5a125-236">어떻게 toostop 실행 중인 조각?</span><span class="sxs-lookup"><span data-stu-id="5a125-236">How toostop a running slice?</span></span>
<span data-ttu-id="5a125-237">Toostop hello 파이프라인을 실행 해야 하는 경우 사용할 수 있습니다 [Suspend AzureRmDataFactoryPipeline](/powershell/module/azurerm.datafactories/suspend-azurermdatafactorypipeline) cmdlet.</span><span class="sxs-lookup"><span data-stu-id="5a125-237">If you need toostop hello pipeline from executing, you can use [Suspend-AzureRmDataFactoryPipeline](/powershell/module/azurerm.datafactories/suspend-azurermdatafactorypipeline) cmdlet.</span></span> <span data-ttu-id="5a125-238">현재 hello 파이프라인을 일시 중단 해도 진행 중인 hello 조각 실행 중지 되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-238">Currently, suspending hello pipeline does not stop hello slice executions that are in progress.</span></span> <span data-ttu-id="5a125-239">Hello 진행 중인 실행 될 때 완료 되 면 추가 슬라이스 선택 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-239">Once hello in-progress executions finish, no extra slice is picked up.</span></span>

<span data-ttu-id="5a125-240">원하는 경우 toostop 모든 hello 실행 즉시, hello만 방식으로 toodelete hello 파이프라인 하 고 다시 만드십시오.</span><span class="sxs-lookup"><span data-stu-id="5a125-240">If you really want toostop all hello executions immediately, hello only way would be toodelete hello pipeline and create it again.</span></span> <span data-ttu-id="5a125-241">Toodelete hello 파이프라인을 선택 하면 불필요 toodelete 테이블과 hello 파이프라인에서 사용 되는 연결 된 서비스입니다.</span><span class="sxs-lookup"><span data-stu-id="5a125-241">If you choose toodelete hello pipeline, you do NOT need toodelete tables and linked services used by hello pipeline.</span></span>

[create-factory-using-dotnet-sdk]: data-factory-create-data-factories-programmatically.md
[msdn-class-library-reference]: /dotnet/api/microsoft.azure.management.datafactories.models
[msdn-rest-api-reference]: /rest/api/datafactory/

[adf-powershell-reference]: /powershell/resourcemanager/azurerm.datafactories/v2.3.0/azurerm.datafactories
[azure-portal]: http://portal.azure.com
[set-azure-datafactory-slice-status]: /powershell/resourcemanager/azurerm.datafactories/v2.3.0/set-azurermdatafactoryslicestatus

[adf-pricing-details]: http://go.microsoft.com/fwlink/?LinkId=517777
[hdinsight-supported-regions]: http://azure.microsoft.com/pricing/details/hdinsight/
[hdinsight-alternate-storage]: http://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx
[hdinsight-alternate-storage-2]: http://blogs.msdn.com/b/cindygross/archive/2014/05/05/use-additional-storage-accounts-with-hdinsight-hive.aspx
