---
title: "Azure 데이터 팩터리 - 질문과 대답"
description: "Azure 데이터 팩터리에 대한 질문과 대답입니다."
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: 532dec5a-7261-4770-8f54-bfe527918058
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: 086e6b2fb9bd0ee8541401b6f0d65268926e45a5
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 08/18/2017
---
# <a name="azure-data-factory---frequently-asked-questions"></a><span data-ttu-id="743e7-103">Azure 데이터 팩터리 - 질문과 대답</span><span class="sxs-lookup"><span data-stu-id="743e7-103">Azure Data Factory - Frequently Asked Questions</span></span>
## <a name="general-questions"></a><span data-ttu-id="743e7-104">일반적인 질문</span><span class="sxs-lookup"><span data-stu-id="743e7-104">General questions</span></span>
### <a name="what-is-azure-data-factory"></a><span data-ttu-id="743e7-105">Azure 데이터 팩터리란 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="743e7-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="743e7-106">Data Factory는 **데이터의 이동과 변환을 자동화**하는 클라우드 기반 데이터 통합 서비스입니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-106">Data Factory is a cloud-based data integration service that **automates the movement and transformation of data**.</span></span> <span data-ttu-id="743e7-107">원자재를 가져다가 완제품으로 만들기 위해 장비를 작동하는 공장처럼 데이터 팩터리는 원시 데이터를 수집하여 바로 사용할 수 있는 정보로 변환하는 기존 서비스를 오케스트레이션합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-107">Just like a factory that runs equipment to take raw materials and transform them into finished goods, Data Factory orchestrates existing services that collect raw data and transform it into ready-to-use information.</span></span>

<span data-ttu-id="743e7-108">Data Factory를 사용하면 온-프레미스와 클라우드 데이터 저장소 간에 데이터를 이동하는 데이터 기반 워크플로를 만들 수 있을 뿐 아니라, Azure HDInsight 및 Azure Data Lake 분석과 같은 계산 서비스를 사용하여 데이터를 처리/변환할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-108">Data Factory allows you to create data-driven workflows to move data between both on-premises and cloud data stores as well as process/transform data using compute services such as Azure HDInsight and Azure Data Lake Analytics.</span></span> <span data-ttu-id="743e7-109">필요한 작업을 수행하는 파이프라인을 만든 후 정기적(매시간, 매일, 매주 등...)으로 실행되도록 예약할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-109">After you create a pipeline that performs the action that you need, you can schedule it to run periodically (hourly, daily, weekly etc.).</span></span>   

<span data-ttu-id="743e7-110">자세한 내용은 [개요 및 주요 개념](data-factory-introduction.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-110">For more information, see [Overview & Key Concepts](data-factory-introduction.md).</span></span>

### <a name="where-can-i-find-pricing-details-for-azure-data-factory"></a><span data-ttu-id="743e7-111">Azure 데이터 팩터리에 대한 가격 정보는 어디서 찾을 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-111">Where can I find pricing details for Azure Data Factory?</span></span>
<span data-ttu-id="743e7-112">Azure 데이터 팩터리에 대한 가격 정보는 [데이터 팩터리 가격 정보 페이지][adf-pricing-details]를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-112">See [Data Factory Pricing Details page][adf-pricing-details] for the pricing details for the Azure Data Factory.</span></span>  

### <a name="how-do-i-get-started-with-azure-data-factory"></a><span data-ttu-id="743e7-113">Azure 데이터 팩터리를 시작하려면 어떻게 해야 하나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-113">How do I get started with Azure Data Factory?</span></span>
* <span data-ttu-id="743e7-114">Azure 데이터 팩터리에 대한 개요는 [Azure 데이터 팩터리 소개](data-factory-introduction.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-114">For an overview of Azure Data Factory, see [Introduction to Azure Data Factory](data-factory-introduction.md).</span></span>
* <span data-ttu-id="743e7-115">복사 작업을 사용하여 **데이터를 이동/복사**하는 방법에 대한 자습서는 [Azure Blob 저장소에서 Azure SQL 데이터베이스로 데이터 복사](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-115">For a tutorial on how to **copy/move data** using Copy Activity, see [Copy data from Azure Blob Storage to Azure SQL Database](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md).</span></span>
* <span data-ttu-id="743e7-116">HDInsight Hive 작업을 사용하여 **데이터를 변환**하는 방법에 대한 자습서는</span><span class="sxs-lookup"><span data-stu-id="743e7-116">For a tutorial on how to **transform data** using HDInsight Hive Activity.</span></span> <span data-ttu-id="743e7-117">[Process data by running Hive script on Hadoop cluster](data-factory-build-your-first-pipeline.md)(Hadoop 클러스터에서 Hive 스크립트를 실행하여 데이터 처리)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-117">See [Process data by running Hive script on Hadoop cluster](data-factory-build-your-first-pipeline.md)</span></span>

### <a name="what-is-the-data-factorys-region-availability"></a><span data-ttu-id="743e7-118">데이터 팩터리의 지역 가용성은 얼마나 되나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-118">What is the Data Factory’s region availability?</span></span>
<span data-ttu-id="743e7-119">Data Factory는 **미국 서부** 및 **북유럽**에서 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-119">Data Factory is available in **US West** and **North Europe**.</span></span> <span data-ttu-id="743e7-120">데이터 팩터리에서 사용되는 계산 및 저장소 서비스는 다른 지역에 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-120">The compute and storage services used by data factories can be in other regions.</span></span> <span data-ttu-id="743e7-121">[지원되는 지역](data-factory-introduction.md#supported-regions)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-121">See [Supported regions](data-factory-introduction.md#supported-regions).</span></span>

### <a name="what-are-the-limits-on-number-of-data-factoriespipelinesactivitiesdatasets"></a><span data-ttu-id="743e7-122">데이터 팩터리/파이프라인/작업/데이터 집합의 수에 대한 제한은 어떻게 되나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-122">What are the limits on number of data factories/pipelines/activities/datasets?</span></span>
<span data-ttu-id="743e7-123">**Azure 구독 및 서비스 제한, 할당량 및 제약 조건** 문서의 [Azure Data Factory 제한](../azure-subscription-service-limits.md#data-factory-limits) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-123">See **Azure Data Factory Limits** section of the [Azure Subscription and Service Limits, Quotas, and Constraints](../azure-subscription-service-limits.md#data-factory-limits) article.</span></span>

### <a name="what-is-the-authoringdeveloper-experience-with-azure-data-factory-service"></a><span data-ttu-id="743e7-124">Azure Data Factory 서비스를 사용한 제작/개발자 환경이란 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="743e7-124">What is the authoring/developer experience with Azure Data Factory service?</span></span>
<span data-ttu-id="743e7-125">다음 도구/SDK 중 하나를 사용하여 데이터 팩터리를 작성/생성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-125">You can author/create data factories using one of the following tools/SDKs:</span></span>

* <span data-ttu-id="743e7-126">**Azure 포털** Azure 포털의 Data Factory 블레이드는 데이터 팩터리 AD 연결된 서비스를 만들기 위한 풍부한 사용자 인터페이스를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-126">**Azure portal** The Data Factory blades in the Azure portal provide rich user interface for you to create data factories ad linked services.</span></span> <span data-ttu-id="743e7-127">포털에 포함된 **데이터 팩터리 편집기**에서 이러한 아티팩트에 대한 JSON 정의를 지정하여 연결된 서비스, 테이블, 데이터 집합 및 파이프라인을 쉽게 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-127">The **Data Factory Editor**, which is also part of the portal, allows you to easily create linked services, tables, data sets, and pipelines by specifying JSON definitions for these artifacts.</span></span> <span data-ttu-id="743e7-128">포털/편집기를 사용하여 데이터 팩터리를 만들고 배포하는 예제는 [Build your first data pipeline using Azure Portal](data-factory-build-your-first-pipeline-using-editor.md) (Azure 포털을 사용하여 첫 번째 데이터 파이프라인 빌드)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-128">See [Build your first data pipeline using Azure portal](data-factory-build-your-first-pipeline-using-editor.md) for an example of using the portal/editor to create and deploy a data factory.</span></span>
* <span data-ttu-id="743e7-129">**Visual Studio** Visual Studio를 사용하여 Azure Data Factory를 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-129">**Visual Studio** You can use Visual Studio to create an Azure data factory.</span></span> <span data-ttu-id="743e7-130">자세한 내용은 [Build your first data pipeline using Visual Studio](data-factory-build-your-first-pipeline-using-vs.md) (Visual Studio를 사용하여 첫 번째 데이터 파이프라인 빌드)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-130">See [Build your first data pipeline using Visual Studio](data-factory-build-your-first-pipeline-using-vs.md) for details.</span></span>
* <span data-ttu-id="743e7-131">**Azure PowerShell** PowerShell을 사용하여 Data Factory를 만드는 자습서는 [Create and monitor Azure Data Factory using Azure PowerShell](data-factory-build-your-first-pipeline-using-powershell.md) (Azure PowerShell을 사용하여 Azure Data Factory 만들기 및 모니터링)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-131">**Azure PowerShell** See [Create and monitor Azure Data Factory using Azure PowerShell](data-factory-build-your-first-pipeline-using-powershell.md) for a tutorial/walkthrough for creating a data factory using PowerShell.</span></span> <span data-ttu-id="743e7-132">데이터 팩터리 cmdlet의 포괄적인 설명서는 MSDN 라이브러리의 [데이터 팩터리 Cmdlet 참조][adf-powershell-reference] 콘텐츠를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-132">See [Data Factory Cmdlet Reference][adf-powershell-reference] content on MSDN Library for a comprehensive documentation of Data Factory cmdlets.</span></span>
* <span data-ttu-id="743e7-133">**.NET 클래스 라이브러리** Data Factory .NET SDK를 사용하여 프로그래밍 방식으로 데이터 팩터리를 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-133">**.NET Class Library** You can programmatically create data factories by using Data Factory .NET SDK.</span></span> <span data-ttu-id="743e7-134">.NET SDK를 사용하여 데이터 팩터리를 만드는 연습은 [.NET SDK를 사용하여 데이터 팩터리 만들기, 모니터링 및 관리](data-factory-create-data-factories-programmatically.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-134">See [Create, monitor, and manage data factories using .NET SDK](data-factory-create-data-factories-programmatically.md) for a walkthrough of creating a data factory using .NET SDK.</span></span> <span data-ttu-id="743e7-135">데이터 팩터리 .NET SDK의 포괄적인 설명서는 [데이터 팩터리 클래스 라이브러리 참조][msdn-class-library-reference]를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-135">See [Data Factory Class Library Reference][msdn-class-library-reference] for a comprehensive documentation of Data Factory .NET SDK.</span></span>
* <span data-ttu-id="743e7-136">**REST API** Azure Data Factory 서비스에 의해 노출된 REST API를 사용하여 데이터 팩터리를 만들고 배포할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-136">**REST API** You can also use the REST API exposed by the Azure Data Factory service to create and deploy data factories.</span></span> <span data-ttu-id="743e7-137">데이터 팩터리 REST API의 포괄적인 설명서는 [데이터 팩터리 REST API 참조][msdn-rest-api-reference]를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-137">See [Data Factory REST API Reference][msdn-rest-api-reference] for a comprehensive documentation of Data Factory REST API.</span></span>
* <span data-ttu-id="743e7-138">**Azure Resource Manager 템플릿** 자세한 내용은 [자습서: Azure Resource Manager 템플릿을 사용하여 첫 번째 Azure Data Factory 빌드](data-factory-build-your-first-pipeline-using-arm.md) 를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-138">**Azure Resource Manager Template** See [Tutorial: Build your first Azure data factory using Azure Resource Manager template](data-factory-build-your-first-pipeline-using-arm.md) fo details.</span></span>

### <a name="can-i-rename-a-data-factory"></a><span data-ttu-id="743e7-139">Data Factory의 이름을 바꿀 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-139">Can I rename a data factory?</span></span>
<span data-ttu-id="743e7-140">아니요.</span><span class="sxs-lookup"><span data-stu-id="743e7-140">No.</span></span> <span data-ttu-id="743e7-141">다른 Azure 리소스와 마찬가지로 Azure 데이터 팩터리의 이름을 변경할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-141">Like other Azure resources, the name of an Azure data factory cannot be changed.</span></span>

### <a name="can-i-move-a-data-factory-from-one-azure-subscription-to-another"></a><span data-ttu-id="743e7-142">데이터 팩터리를 Azure 구독 간에 이동할 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-142">Can I move a data factory from one Azure subscription to another?</span></span>
<span data-ttu-id="743e7-143">예.</span><span class="sxs-lookup"><span data-stu-id="743e7-143">Yes.</span></span> <span data-ttu-id="743e7-144">다음 다이어그램과 같이 데이터 팩터리 블레이드의 **이동** 단추를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-144">Use the **Move** button on your data factory blade as shown in the following diagram:</span></span>

![데이터 팩터리 이동](media/data-factory-faq/move-data-factory.png)

### <a name="what-are-the-compute-environments-supported-by-data-factory"></a><span data-ttu-id="743e7-146">Data Factory에서 지원하는 컴퓨팅 환경은 무엇입니까?</span><span class="sxs-lookup"><span data-stu-id="743e7-146">What are the compute environments supported by Data Factory?</span></span>
<span data-ttu-id="743e7-147">다음 표는 Data Factory 및 실행할 수 있는 작업에서 지원하는 컴퓨팅 환경 목록을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-147">The following table provides a list of compute environments supported by Data Factory and the activities that can run on them.</span></span>

| <span data-ttu-id="743e7-148">컴퓨팅 환경</span><span class="sxs-lookup"><span data-stu-id="743e7-148">Compute environment</span></span> | <span data-ttu-id="743e7-149">작업</span><span class="sxs-lookup"><span data-stu-id="743e7-149">activities</span></span> |
| --- | --- |
| <span data-ttu-id="743e7-150">[주문형 HDInsight 클러스터](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) 또는 [사용자 고유의 HDInsight 클러스터](data-factory-compute-linked-services.md#azure-hdinsight-linked-service)</span><span class="sxs-lookup"><span data-stu-id="743e7-150">[On-demand HDInsight cluster](data-factory-compute-linked-services.md#azure-hdinsight-on-demand-linked-service) or [your own HDInsight cluster](data-factory-compute-linked-services.md#azure-hdinsight-linked-service)</span></span> |<span data-ttu-id="743e7-151">[DotNet](data-factory-use-custom-activities.md), [Hive](data-factory-hive-activity.md), [Pig](data-factory-pig-activity.md), [MapReduce](data-factory-map-reduce.md), [Hadoop 스트리밍](data-factory-hadoop-streaming-activity.md)</span><span class="sxs-lookup"><span data-stu-id="743e7-151">[DotNet](data-factory-use-custom-activities.md), [Hive](data-factory-hive-activity.md), [Pig](data-factory-pig-activity.md), [MapReduce](data-factory-map-reduce.md), [Hadoop Streaming](data-factory-hadoop-streaming-activity.md)</span></span> |
| [<span data-ttu-id="743e7-152">Azure 배치</span><span class="sxs-lookup"><span data-stu-id="743e7-152">Azure Batch</span></span>](data-factory-compute-linked-services.md#azure-batch-linked-service) |[<span data-ttu-id="743e7-153">DotNet</span><span class="sxs-lookup"><span data-stu-id="743e7-153">DotNet</span></span>](data-factory-use-custom-activities.md) |
| [<span data-ttu-id="743e7-154">Azure 기계 학습</span><span class="sxs-lookup"><span data-stu-id="743e7-154">Azure Machine Learning</span></span>](data-factory-compute-linked-services.md#azure-machine-learning-linked-service) |[<span data-ttu-id="743e7-155">Machine Learning 작업: 배치 실행 및 업데이트 리소스</span><span class="sxs-lookup"><span data-stu-id="743e7-155">Machine Learning activities: Batch Execution and Update Resource</span></span>](data-factory-azure-ml-batch-execution-activity.md) |
| [<span data-ttu-id="743e7-156">Azure 데이터 레이크 분석</span><span class="sxs-lookup"><span data-stu-id="743e7-156">Azure Data Lake Analytics</span></span>](data-factory-compute-linked-services.md#azure-data-lake-analytics-linked-service) |[<span data-ttu-id="743e7-157">데이터 레이크 분석 U-SQL</span><span class="sxs-lookup"><span data-stu-id="743e7-157">Data Lake Analytics U-SQL</span></span>](data-factory-usql-activity.md) |
| <span data-ttu-id="743e7-158">[Azure SQL](data-factory-compute-linked-services.md#azure-sql-linked-service), [Azure SQL Data Warehouse](data-factory-compute-linked-services.md#azure-sql-data-warehouse-linked-service), [SQL Server](data-factory-compute-linked-services.md#sql-server-linked-service)</span><span class="sxs-lookup"><span data-stu-id="743e7-158">[Azure SQL](data-factory-compute-linked-services.md#azure-sql-linked-service), [Azure SQL Data Warehouse](data-factory-compute-linked-services.md#azure-sql-data-warehouse-linked-service), [SQL Server](data-factory-compute-linked-services.md#sql-server-linked-service)</span></span> |[<span data-ttu-id="743e7-159">저장 프로시저</span><span class="sxs-lookup"><span data-stu-id="743e7-159">Stored Procedure</span></span>](data-factory-stored-proc-activity.md) |

### <a name="how-does-azure-data-factory-compare-with-sql-server-integration-services-ssis"></a><span data-ttu-id="743e7-160">Azure Data Factory를 SSIS(SQL Server Integration Services)와 비교하면 어떻게 다른가요?</span><span class="sxs-lookup"><span data-stu-id="743e7-160">How does Azure Data Factory compare with SQL Server Integration Services (SSIS)?</span></span> 
<span data-ttu-id="743e7-161">MVP(Most Valued Professionals) 중 한 명인 Reza Rad가 제공한 [Azure Data Factory 및 SSIS](http://www.sqlbits.com/Sessions/Event15/Azure_Data_Factory_vs_SSIS) 프레젠테이션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-161">See the [Azure Data Factory vs. SSIS](http://www.sqlbits.com/Sessions/Event15/Azure_Data_Factory_vs_SSIS) presentation from one of our MVPs (Most Valued Professionals): Reza Rad.</span></span> <span data-ttu-id="743e7-162">데이터 팩터리의 최근 변경 내용 중 일부는 슬라이드 모음에 표시되지 않을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-162">Some of the recent changes in Data Factory may not be listed in the slide deck.</span></span> <span data-ttu-id="743e7-163">지속적으로 Azure Data Factory에 기능을 추가할 예정입니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-163">We are continuously adding more capabilities to Azure Data Factory.</span></span> <span data-ttu-id="743e7-164">지속적으로 Azure Data Factory에 기능을 추가할 예정입니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-164">We are continuously adding more capabilities to Azure Data Factory.</span></span> <span data-ttu-id="743e7-165">이러한 업데이트는 올해 후반기에 Microsoft의 데이터 통합 기술 비교 자료에 포함될 예정입니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-165">We will incorporate these updates into the comparison of data integration technologies from Microsoft sometime later this year.</span></span>   

## <a name="activities---faq"></a><span data-ttu-id="743e7-166">작업 - FAQ</span><span class="sxs-lookup"><span data-stu-id="743e7-166">Activities - FAQ</span></span>
### <a name="what-are-the-different-types-of-activities-you-can-use-in-a-data-factory-pipeline"></a><span data-ttu-id="743e7-167">Data Factory 파이프라인에서 사용할 수 있는 다른 형식의 작업은 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="743e7-167">What are the different types of activities you can use in a Data Factory pipeline?</span></span>
* <span data-ttu-id="743e7-168">[데이터 이동 작업](data-factory-data-movement-activities.md) </span><span class="sxs-lookup"><span data-stu-id="743e7-168">[Data Movement Activities](data-factory-data-movement-activities.md) to move data.</span></span>
* <span data-ttu-id="743e7-169">[데이터 변환 작업](data-factory-data-transformation-activities.md) </span><span class="sxs-lookup"><span data-stu-id="743e7-169">[Data Transformation Activities](data-factory-data-transformation-activities.md) to process/transform data.</span></span>

### <a name="when-does-an-activity-run"></a><span data-ttu-id="743e7-170">작업은 언제 실행되나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-170">When does an activity run?</span></span>
<span data-ttu-id="743e7-171">출력 데이터 테이블의 **가용성** 구성 설정에 따라 작업 실행 시기가 결정됩니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-171">The **availability** configuration setting in the output data table determines when the activity is run.</span></span> <span data-ttu-id="743e7-172">입력 데이터 집합이 지정된 경우 작업은 실행을 시작하기 전에 모든 입력 데이터 종속성이 충족되었는지 (즉, **Ready** 상태) 검사합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-172">If input datasets are specified, the activity checks whether all the input data dependencies are satisfied (that is, **Ready** state) before it starts running.</span></span>

## <a name="copy-activity---faq"></a><span data-ttu-id="743e7-173">복사 작업 - FAQ</span><span class="sxs-lookup"><span data-stu-id="743e7-173">Copy Activity - FAQ</span></span>
### <a name="is-it-better-to-have-a-pipeline-with-multiple-activities-or-a-separate-pipeline-for-each-activity"></a><span data-ttu-id="743e7-174">여러 작업이 포함된 파이프라인 1개보다 각 작업에 개별 파이프라인을 사용하는 것이 더 효율적인가요?</span><span class="sxs-lookup"><span data-stu-id="743e7-174">Is it better to have a pipeline with multiple activities or a separate pipeline for each activity?</span></span>
<span data-ttu-id="743e7-175">파이프라인은 관련 작업의 번들로 간주됩니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-175">Pipelines are supposed to bundle related activities.</span></span> <span data-ttu-id="743e7-176">작업을 연결하는 데이터 집합이 파이프라인 외의 다른 작업에서 사용되지 않는 경우 파이프라인 하나에 작업을 유지할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-176">If the datasets that connect them are not consumed by any other activity outside the pipeline, you can keep the activities in one pipeline.</span></span> <span data-ttu-id="743e7-177">이 경우 서로 정렬되도록 파이프라인 활성 기간을 연결할 필요가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-177">This way, you would not need to chain pipeline active periods so that they align with each other.</span></span> <span data-ttu-id="743e7-178">또한 파이프라인을 업데이트할 때 파이프라인 내부 테이블의 데이터 무결성이 보다 완벽하게 유지됩니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-178">Also, the data integrity in the tables internal to the pipeline is better preserved when updating the pipeline.</span></span> <span data-ttu-id="743e7-179">파이프라인 업데이트는 기본적으로 파이프라인 내의 모든 작업을 중지하고 제거한 후 다시 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-179">Pipeline update essentially stops all the activities within the pipeline, removes them, and creates them again.</span></span> <span data-ttu-id="743e7-180">제작 관점에서는 파이프라인에 대한 하나의 JSON 파일에서 관련 작업 내의 데이터 흐름을 확인하는 것이 더 쉬울 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-180">From authoring perspective, it might also be easier to see the flow of data within the related activities in one JSON file for the pipeline.</span></span>

### <a name="what-are-the-supported-data-stores"></a><span data-ttu-id="743e7-181">지원되는 데이터 저장소는 무엇입니까?</span><span class="sxs-lookup"><span data-stu-id="743e7-181">What are the supported data stores?</span></span>
<span data-ttu-id="743e7-182">데이터 팩터리의 복사 활동은 원본 데이터 저장소의 데이터를 싱크 데이터 저장소로 복사합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-182">Copy Activity in Data Factory copies data from a source data store to a sink data store.</span></span> <span data-ttu-id="743e7-183">Data Factory는 다음과 같은 데이터 저장소를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-183">Data Factory supports the following data stores.</span></span> <span data-ttu-id="743e7-184">모든 소스의 데이터를 모든 싱크에 쓸 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-184">Data from any source can be written to any sink.</span></span> <span data-ttu-id="743e7-185">데이터 저장소를 클릭하면 해당 저장소에서/저장소로 데이터를 복사하는 방법을 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-185">Click a data store to learn how to copy data to and from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

> [!NOTE]
> <span data-ttu-id="743e7-186">*가 있는 데이터 저장소는 온-프레미스 또는 Azure IaaS에 있을 수 있으며 온-프레미스/Azure IaaS 컴퓨터에 [데이터 관리 게이트웨이](data-factory-data-management-gateway.md) 를 설치해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-186">Data stores with * can be on-premises or on Azure IaaS, and require you to install [Data Management Gateway](data-factory-data-management-gateway.md) on an on-premises/Azure IaaS machine.</span></span>

### <a name="what-are-the-supported-file-formats"></a><span data-ttu-id="743e7-187">지원되는 파일 형식은 무엇입니까?</span><span class="sxs-lookup"><span data-stu-id="743e7-187">What are the supported file formats?</span></span>
[!INCLUDE [data-factory-file-format](../../includes/data-factory-file-format.md)]

### <a name="where-is-the-copy-operation-performed"></a><span data-ttu-id="743e7-188">복사 작업을 어디서 수행하나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-188">Where is the copy operation performed?</span></span>
<span data-ttu-id="743e7-189">자세한 내용은 [전역적으로 사용 가능한 데이터 이동](data-factory-data-movement-activities.md#global) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-189">See [Globally available data movement](data-factory-data-movement-activities.md#global) section for details.</span></span> <span data-ttu-id="743e7-190">즉, 온-프레미스 데이터 저장소가 관련된 경우 온-프레미스 환경의 데이터 관리 게이트웨이에서 복사 작업을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-190">In short, when an on-premises data store is involved, the copy operation is performed by the Data Management Gateway in your on-premises environment.</span></span> <span data-ttu-id="743e7-191">그리고 두 클라우드 저장소 간에 데이터를 이동하는 경우 같은 지리의 싱크 위치에 가장 가까운 지역에서 복사 작업을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-191">And, when the data movement is between two cloud stores, the copy operation is performed in the region closest to the sink location in the same geography.</span></span>

## <a name="hdinsight-activity---faq"></a><span data-ttu-id="743e7-192">HDInsight 작업 - FAQ</span><span class="sxs-lookup"><span data-stu-id="743e7-192">HDInsight Activity - FAQ</span></span>
### <a name="what-regions-are-supported-by-hdinsight"></a><span data-ttu-id="743e7-193">HDInsight에서 지원하는 지역은 어디인가요?</span><span class="sxs-lookup"><span data-stu-id="743e7-193">What regions are supported by HDInsight?</span></span>
<span data-ttu-id="743e7-194">다음 문서의 지리적 가용성 섹션 또는 [HDInsight 가격 정보][hdinsight-supported-regions]를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-194">See the Geographic Availability section in the following article: or [HDInsight Pricing Details][hdinsight-supported-regions].</span></span>

### <a name="what-region-is-used-by-an-on-demand-hdinsight-cluster"></a><span data-ttu-id="743e7-195">주문형 HDInsight 클러스터가 사용되는 지역은 어디인가요?</span><span class="sxs-lookup"><span data-stu-id="743e7-195">What region is used by an on-demand HDInsight cluster?</span></span>
<span data-ttu-id="743e7-196">주문형 HDInsight 클러스터는 클러스터에서 사용하도록 지정한 저장소가 있는 지역과 동일한 지역에 생성됩니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-196">The on-demand HDInsight cluster is created in the same region where the storage you specified to be used with the cluster exists.</span></span>    

### <a name="how-to-associate-additional-storage-accounts-to-your-hdinsight-cluster"></a><span data-ttu-id="743e7-197">추가 저장소 계정을 HDInsight 클러스터에 연결하려면 어떻게 해야 하나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-197">How to associate additional storage accounts to your HDInsight cluster?</span></span>
<span data-ttu-id="743e7-198">사용자 고유의 HDInsight 클러스터를 사용하는 경우(BYOC - 자체 클러스터 가져오기) 다음 항목을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-198">If you are using your own HDInsight Cluster (BYOC - Bring Your Own Cluster), see the following topics:</span></span>

* <span data-ttu-id="743e7-199">[대체 저장소 계정 및 메타스토어와 HDInsight 클러스터 사용][hdinsight-alternate-storage]</span><span class="sxs-lookup"><span data-stu-id="743e7-199">[Using an HDInsight Cluster with Alternate Storage Accounts and Metastores][hdinsight-alternate-storage]</span></span>
* <span data-ttu-id="743e7-200">[HDInsight Hive와 추가 저장소 계정 사용][hdinsight-alternate-storage-2]</span><span class="sxs-lookup"><span data-stu-id="743e7-200">[Use Additional Storage Accounts with HDInsight Hive][hdinsight-alternate-storage-2]</span></span>

<span data-ttu-id="743e7-201">데이터 팩터리 서비스에서 만든 주문형 클러스터를 사용하는 경우 데이터 팩터리 서비스가 사용자를 대신해서 등록할 수 있도록 HDInsight 연결된 서비스에 대한 추가 저장소 계정을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-201">If you are using an on-demand cluster that is created by the Data Factory service, specify additional storage accounts for the HDInsight linked service so that the Data Factory service can register them on your behalf.</span></span> <span data-ttu-id="743e7-202">주문형 연결된 서비스에 대한 JSON 정의에서, 다음 JSON 조각과 같이 **additionalLinkedServiceNames** 속성을 사용하여 대체 저장소 계정을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-202">In the JSON definition for the on-demand linked service, use **additionalLinkedServiceNames** property to specify alternate storage accounts as shown in the following JSON snippet:</span></span>

```JSON
{
    "name": "MyHDInsightOnDemandLinkedService",
    "properties":
    {
        "type": "HDInsightOnDemandLinkedService",
        "typeProperties": {
            "version": "3.5",
            "clusterSize": 1,
            "timeToLive": "00:05:00",
            "osType": "Linux",
            "linkedServiceName": "LinkedService-SampleData",
            "additionalLinkedServiceNames": [ "otherLinkedServiceName1", "otherLinkedServiceName2" ]
        }
    }
}
```
<span data-ttu-id="743e7-203">위의 예제에서 otherLinkedServiceName1 및 otherLinkedServiceName2는 HDInsight 클러스터가 대체 저장소 계정에 액세스하는 데 필요한 자격 증명이 해당 정의에 포함된 연결된 서비스를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-203">In the example above, otherLinkedServiceName1 and otherLinkedServiceName2 represent linked services whose definitions contain credentials that the HDInsight cluster needs to access alternate storage accounts.</span></span>

## <a name="slices---faq"></a><span data-ttu-id="743e7-204">조각 - FAQ</span><span class="sxs-lookup"><span data-stu-id="743e7-204">Slices - FAQ</span></span>
### <a name="why-are-my-input-slices-not-in-ready-state"></a><span data-ttu-id="743e7-205">내 입력 조각이 준비 상태가 아닌 이유는 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="743e7-205">Why are my input slices not in Ready state?</span></span>
<span data-ttu-id="743e7-206">일반적인 실수는 입력 데이터가 데이터 팩터리 외부의 데이터일 때(데이터 팩터리에 의해 생성되지 않음) 입력 데이터 집합에 대해 **external** 속성을 **true**로 설정하지 않는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-206">A common mistake is not setting **external** property to **true** on the input dataset when the input data is external to the data factory (not produced by the data factory).</span></span>

<span data-ttu-id="743e7-207">다음 예제에서는 **dataset1**에 대해서만 **external**을 true로 설정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-207">In the following example, you only need to set **external** to true on **dataset1**.</span></span>  

<span data-ttu-id="743e7-208">**DataFactory1** 파이프라인 1: dataset1 -> activity1 -> dataset2 -> activity2 -> dataset3 파이프라인 2: dataset3-> activity3 -> dataset4</span><span class="sxs-lookup"><span data-stu-id="743e7-208">**DataFactory1** Pipeline 1: dataset1 -> activity1 -> dataset2 -> activity2 -> dataset3 Pipeline 2: dataset3-> activity3 -> dataset4</span></span>

<span data-ttu-id="743e7-209">dataset4(데이터 팩터리 1의 파이프라인 2에 의해 생성)를 사용하는 파이프라인을 포함하는 다른 데이터 팩터리가 있는 경우 데이터 집합이 다른 데이터 팩터리(DataFactory1, DataFactory2는 아님)에 의해 생성되므로 dataset4를 외부 데이터 집합으로 표시합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-209">If you have another data factory with a pipeline that takes dataset4 (produced by pipeline 2 in data factory 1), mark dataset4 as an external dataset because the dataset is produced by a different data factory (DataFactory1, not DataFactory2).</span></span>  

<span data-ttu-id="743e7-210">**DataFactory2**  </span><span class="sxs-lookup"><span data-stu-id="743e7-210">**DataFactory2**  </span></span>  
<span data-ttu-id="743e7-211">파이프라인 1: activity4->dataset4->dataset5</span><span class="sxs-lookup"><span data-stu-id="743e7-211">Pipeline 1: dataset4->activity4->dataset5</span></span>

<span data-ttu-id="743e7-212">외부 속성이 제대로 설정된 경우 입력 데이터가 입력 데이터 집합 정의에 지정된 위치에 있는지 여부를 확인합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-212">If the external property is properly set, verify whether the input data exists in the location specified in the input dataset definition.</span></span>

### <a name="how-to-run-a-slice-at-another-time-than-midnight-when-the-slice-is-being-produced-daily"></a><span data-ttu-id="743e7-213">조각이 매일 생성될 때 자정 이외의 다른 시간에 조각을 실행하는 방법은 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="743e7-213">How to run a slice at another time than midnight when the slice is being produced daily?</span></span>
<span data-ttu-id="743e7-214">**offset** 속성을 사용하여 조각을 생성할 시간을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-214">Use the **offset** property to specify the time at which you want the slice to be produced.</span></span> <span data-ttu-id="743e7-215">이 속성에 대한 자세한 내용은 [데이터 집합 가용성](data-factory-create-datasets.md#dataset-availability) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-215">See [Dataset availability](data-factory-create-datasets.md#dataset-availability) section for details about this property.</span></span> <span data-ttu-id="743e7-216">간단한 예제는 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-216">Here is a quick example:</span></span>

```json
"availability":
{
    "frequency": "Day",
    "interval": 1,
    "offset": "06:00:00"
}
```
<span data-ttu-id="743e7-217">기본값인 자정 대신 **오전 6시**에 시작하는 일별 조각입니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-217">Daily slices start at **6 AM** instead of the default midnight.</span></span>     

### <a name="how-can-i-rerun-a-slice"></a><span data-ttu-id="743e7-218">어떻게 조각을 다시 실행할 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-218">How can I rerun a slice?</span></span>
<span data-ttu-id="743e7-219">다음 방법 중 하나로 조각을 다시 실행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-219">You can rerun a slice in one of the following ways:</span></span>

* <span data-ttu-id="743e7-220">모니터링 및 관리 앱을 사용하여 작업 창 또는 조각을 다시 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-220">Use Monitor and Manage App to rerun an activity window or slice.</span></span> <span data-ttu-id="743e7-221">지침에 대해서는 [선택한 작업 창 다시 실행](data-factory-monitor-manage-app.md#perform-batch-actions)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-221">See [Rerun selected activity windows](data-factory-monitor-manage-app.md#perform-batch-actions) for instructions.</span></span>   
* <span data-ttu-id="743e7-222">Azure 포털에서 조각의 **데이터 조각** 블레이드에 대해 명령 모음의 **실행**을 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-222">Click **Run** in the command bar on the **DATA SLICE** blade for the slice in the Azure portal.</span></span>
* <span data-ttu-id="743e7-223">조각의 상태를 **Waiting**으로 설정하여 **Set-AzureRmDataFactorySliceStatus** cmdlet을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-223">Run **Set-AzureRmDataFactorySliceStatus** cmdlet with Status set to **Waiting** for the slice.</span></span>   

    ```PowerShell
    Set-AzureRmDataFactorySliceStatus -Status Waiting -ResourceGroupName $ResourceGroup -DataFactoryName $df -TableName $table -StartDateTime "02/26/2015 19:00:00" -EndDateTime "02/26/2015 20:00:00"
    ```
<span data-ttu-id="743e7-224">cmdlet에 대한 자세한 내용은 [Set-AzureRmDataFactorySliceStatus][set-azure-datafactory-slice-status]를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-224">See [Set-AzureRmDataFactorySliceStatus][set-azure-datafactory-slice-status] for details about the cmdlet.</span></span>

### <a name="how-long-did-it-take-to-process-a-slice"></a><span data-ttu-id="743e7-225">조각을 처리하는 데 얼마나 오래 걸렸나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-225">How long did it take to process a slice?</span></span>
<span data-ttu-id="743e7-226">모니터링 및 관리 앱에서 작업 창 탐색기를 사용하여 데이터 조각을 처리하는 데 걸린 시간을 확인합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-226">Use Activity Window Explorer in Monitor & Manage App to know how long it took to process a data slice.</span></span> <span data-ttu-id="743e7-227">자세한 내용은 [작업 창 탐색기](data-factory-monitor-manage-app.md#activity-window-explorer)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="743e7-227">See [Activity Window Explorer](data-factory-monitor-manage-app.md#activity-window-explorer) for details.</span></span>

<span data-ttu-id="743e7-228">Azure 포털에서 다음을 수행할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-228">You can also do the following in the Azure portal:</span></span>  

1. <span data-ttu-id="743e7-229">데이터 팩터리의 **데이터 팩터리** 블레이드에서 **데이터 집합** 타일을 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-229">Click **Datasets** tile on the **DATA FACTORY** blade for your data factory.</span></span>
2. <span data-ttu-id="743e7-230">**데이터 집합** 블레이드에서 특정 데이터 집합을 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-230">Click the specific dataset on the **Datasets** blade.</span></span>
3. <span data-ttu-id="743e7-231">**테이블** 블레이드의 **최근 조각** 목록에서 관심 있는 조각을 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-231">Select the slice that you are interested in from the **Recent slices** list on the **TABLE** blade.</span></span>
4. <span data-ttu-id="743e7-232">**데이터 조각** 블레이드의 **작업 실행** 목록에서 작업 실행을 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-232">Click the activity run from the **Activity Runs** list on the **DATA SLICE** blade.</span></span>
5. <span data-ttu-id="743e7-233">**작업 실행 세부 정보** 블레이드에서 **속성** 타일을 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-233">Click **Properties** tile on the **ACTIVITY RUN DETAILS** blade.</span></span>
6. <span data-ttu-id="743e7-234">**기간** 필드와 값이 표시됩니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-234">You should see the **DURATION** field with a value.</span></span> <span data-ttu-id="743e7-235">이 값은 조각을 처리하는 데 소요된 시간입니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-235">This value is the time taken to process the slice.</span></span>   

### <a name="how-to-stop-a-running-slice"></a><span data-ttu-id="743e7-236">실행 중인 조각을 중지하려면 어떻게 해야 하나요?</span><span class="sxs-lookup"><span data-stu-id="743e7-236">How to stop a running slice?</span></span>
<span data-ttu-id="743e7-237">파이프라인 실행을 중지해야 하는 경우 [Suspend-AzureRmDataFactoryPipeline](/powershell/module/azurerm.datafactories/suspend-azurermdatafactorypipeline) cmdlet을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-237">If you need to stop the pipeline from executing, you can use [Suspend-AzureRmDataFactoryPipeline](/powershell/module/azurerm.datafactories/suspend-azurermdatafactorypipeline) cmdlet.</span></span> <span data-ttu-id="743e7-238">현재, 파이프라인을 일시 중단해도 진행 중인 조각 실행은 중지되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-238">Currently, suspending the pipeline does not stop the slice executions that are in progress.</span></span> <span data-ttu-id="743e7-239">진행 중인 실행이 완료되면 추가 조각이 선택되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-239">Once the in-progress executions finish, no extra slice is picked up.</span></span>

<span data-ttu-id="743e7-240">모든 실행을 즉시 중지하려면 파이프라인을 삭제하고 다시 만들어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-240">If you really want to stop all the executions immediately, the only way would be to delete the pipeline and create it again.</span></span> <span data-ttu-id="743e7-241">파이프라인을 삭제하도록 선택하는 경우 파이프라인에서 사용되는 테이블 및 연결된 서비스를 삭제할 필요는 없습니다.</span><span class="sxs-lookup"><span data-stu-id="743e7-241">If you choose to delete the pipeline, you do NOT need to delete tables and linked services used by the pipeline.</span></span>

[create-factory-using-dotnet-sdk]: data-factory-create-data-factories-programmatically.md
[msdn-class-library-reference]: /dotnet/api/microsoft.azure.management.datafactories.models
[msdn-rest-api-reference]: /rest/api/datafactory/

[adf-powershell-reference]: /powershell/resourcemanager/azurerm.datafactories/v2.3.0/azurerm.datafactories
[azure-portal]: http://portal.azure.com
[set-azure-datafactory-slice-status]: /powershell/resourcemanager/azurerm.datafactories/v2.3.0/set-azurermdatafactoryslicestatus

[adf-pricing-details]: http://go.microsoft.com/fwlink/?LinkId=517777
[hdinsight-supported-regions]: http://azure.microsoft.com/pricing/details/hdinsight/
[hdinsight-alternate-storage]: http://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx
[hdinsight-alternate-storage-2]: http://blogs.msdn.com/b/cindygross/archive/2014/05/05/use-additional-storage-accounts-with-hdinsight-hive.aspx
