---
title: "데이터 변환: 데이터 처리 및 변환 | Microsoft Docs"
description: "Hadoop, Machine Learning 또는 Azure Data Lake Analytics를 사용하여 Azure Data Factory에서 데이터를 변환 또는 처리하는 방법에 대해 알아봅니다."
keywords: "데이터 변환, 데이터 처리, 데이터를 변환, 변환 작업"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: 39786731-1e4b-40a4-81b7-d06e127427aa
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/16/2017
ms.author: shlo
ms.openlocfilehash: 7fc30f32b5038467b3474d89311dc51e182c6e8a
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 07/11/2017
---
# <a name="transform-data-in-azure-data-factory"></a><span data-ttu-id="286ed-104">Azure Data Factory의 데이터 변환</span><span class="sxs-lookup"><span data-stu-id="286ed-104">Transform data in Azure Data Factory</span></span>
> [!div class="op_single_selector"]
> * [<span data-ttu-id="286ed-105">Hive</span><span class="sxs-lookup"><span data-stu-id="286ed-105">Hive</span></span>](data-factory-hive-activity.md)  
> * [<span data-ttu-id="286ed-106">Pig</span><span class="sxs-lookup"><span data-stu-id="286ed-106">Pig</span></span>](data-factory-pig-activity.md)  
> * [<span data-ttu-id="286ed-107">MapReduce</span><span class="sxs-lookup"><span data-stu-id="286ed-107">MapReduce</span></span>](data-factory-map-reduce.md)  
> * [<span data-ttu-id="286ed-108">Hadoop 스트리밍</span><span class="sxs-lookup"><span data-stu-id="286ed-108">Hadoop Streaming</span></span>](data-factory-hadoop-streaming-activity.md)
> * [<span data-ttu-id="286ed-109">기계 학습</span><span class="sxs-lookup"><span data-stu-id="286ed-109">Machine Learning</span></span>](data-factory-azure-ml-batch-execution-activity.md) 
> * [<span data-ttu-id="286ed-110">저장 프로시저</span><span class="sxs-lookup"><span data-stu-id="286ed-110">Stored Procedure</span></span>](data-factory-stored-proc-activity.md)
> * [<span data-ttu-id="286ed-111">데이터 레이크 분석 U-SQL</span><span class="sxs-lookup"><span data-stu-id="286ed-111">Data Lake Analytics U-SQL</span></span>](data-factory-usql-activity.md)
> * [<span data-ttu-id="286ed-112">.NET 사용자 지정</span><span class="sxs-lookup"><span data-stu-id="286ed-112">.NET custom</span></span>](data-factory-use-custom-activities.md)

## <a name="overview"></a><span data-ttu-id="286ed-113">개요</span><span class="sxs-lookup"><span data-stu-id="286ed-113">Overview</span></span>
<span data-ttu-id="286ed-114">이 문서에서는 원시 데이터를 예측 가능하고 통찰력 있는 정보로 변환하고 처리하는 데 사용할 수 있는 Azure Data Factory의 데이터 변환 작업을 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-114">This article explains data transformation activities in Azure Data Factory that you can use to transform and processes your raw data into predictions and insights.</span></span> <span data-ttu-id="286ed-115">변환 작업은 Azure HDInsight 클러스터나 Azure Batch와 같은 컴퓨팅 환경에서 실행됩니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-115">A transformation activity executes in a computing environment such as Azure HDInsight cluster or an Azure Batch.</span></span> <span data-ttu-id="286ed-116">각 변환 작업에 대한 자세한 정보가 있는 문서에 대한 링크를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-116">It provides links to articles with detailed information on each transformation activity.</span></span>

<span data-ttu-id="286ed-117">Data Factory는 개별적 또는 다른 작업과 연계하여 [파이프라인](data-factory-create-pipelines.md)에 추가할 수 있는 다음 데이터 변환 작업을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-117">Data Factory supports the following data transformation activities that can be added to [pipelines](data-factory-create-pipelines.md) either individually or chained with another activity.</span></span>

> [!NOTE]
> <span data-ttu-id="286ed-118">단계별 지침이 포함된 연습은 [Hive 변환으로 파이프라인 만들기](data-factory-build-your-first-pipeline.md) 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-118">For a walkthrough with step-by-step instructions, see [Create a pipeline with Hive transformation](data-factory-build-your-first-pipeline.md) article.</span></span>  
> 
> 

## <a name="hdinsight-hive-activity"></a><span data-ttu-id="286ed-119">HDInsight Hive 작업</span><span class="sxs-lookup"><span data-stu-id="286ed-119">HDInsight Hive activity</span></span>
<span data-ttu-id="286ed-120">Data Factory 파이프라인에서 HDInsight Hive 작업은 사용자 고유 또는 주문형 Windows/Linux 기반 HDInsight 클러스터의 Hive 쿼리를 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-120">The HDInsight Hive activity in a Data Factory pipeline executes Hive queries on your own or on-demand Windows/Linux-based HDInsight cluster.</span></span> <span data-ttu-id="286ed-121">이 작업에 대한 자세한 내용은 [Hive 작업](data-factory-hive-activity.md) 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-121">See [Hive Activity](data-factory-hive-activity.md) article for details about this activity.</span></span> 

## <a name="hdinsight-pig-activity"></a><span data-ttu-id="286ed-122">HDInsight Pig 작업</span><span class="sxs-lookup"><span data-stu-id="286ed-122">HDInsight Pig activity</span></span>
<span data-ttu-id="286ed-123">Data Factory 파이프라인에서 HDInsight Pig 작업은 사용자 고유 또는 주문형 Windows/Linux 기반 HDInsight 클러스터의 Pig 쿼리를 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-123">The HDInsight Pig activity in a Data Factory pipeline executes Pig queries on your own or on-demand Windows/Linux-based HDInsight cluster.</span></span> <span data-ttu-id="286ed-124">이 작업에 대한 자세한 내용은 [Pig 작업](data-factory-pig-activity.md) 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-124">See [Pig Activity](data-factory-pig-activity.md) article for details about this activity.</span></span> 

## <a name="hdinsight-mapreduce-activity"></a><span data-ttu-id="286ed-125">HDInsight MapReduce 작업</span><span class="sxs-lookup"><span data-stu-id="286ed-125">HDInsight MapReduce activity</span></span>
<span data-ttu-id="286ed-126">Data Factory 파이프라인의 HDInsight MapReduce 작업은 사용자 고유 또는 주문형 Windows/Linux 기반 HDInsight 클러스터에서 MapReduce 프로그램을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-126">The HDInsight MapReduce activity in a Data Factory pipeline executes MapReduce programs on your own or on-demand Windows/Linux-based HDInsight cluster.</span></span> <span data-ttu-id="286ed-127">이 작업에 대한 자세한 내용은 [MapReduce 작업](data-factory-map-reduce.md) 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-127">See [MapReduce Activity](data-factory-map-reduce.md) article for details about this activity.</span></span>

## <a name="hdinsight-streaming-activity"></a><span data-ttu-id="286ed-128">HDInsight 스트리밍 작업</span><span class="sxs-lookup"><span data-stu-id="286ed-128">HDInsight Streaming activity</span></span>
<span data-ttu-id="286ed-129">Data Factory 파이프라인의 HDInsight 스트리밍 작업은 사용자 고유 또는 주문형 Windows/Linux 기반 HDInsight 클러스터에서 Hadoop 스트리밍 프로그램을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-129">The HDInsight Streaming Activity in a Data Factory pipeline executes Hadoop Streaming programs on your own or on-demand Windows/Linux-based HDInsight cluster.</span></span> <span data-ttu-id="286ed-130">이 작업에 대한 자세한 내용은 [HDInsight 스트리밍 작업](data-factory-hadoop-streaming-activity.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-130">See [HDInsight Streaming activity](data-factory-hadoop-streaming-activity.md) for details about this activity.</span></span>

## <a name="hdinsight-spark-activity"></a><span data-ttu-id="286ed-131">HDInsight Spark 작업</span><span class="sxs-lookup"><span data-stu-id="286ed-131">HDInsight Spark Activity</span></span>
<span data-ttu-id="286ed-132">Data Factory 파이프라인에서 HDInsight Spark 작업은 사용자 고유 HDInsight 클러스터에서 Spark 프로그램을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-132">The HDInsight Spark activity in a Data Factory pipeline executes Spark programs on your own HDInsight cluster.</span></span> <span data-ttu-id="286ed-133">자세한 내용은 [Azure Data Factory에서 Spark 프로그램 호출](data-factory-spark.md) 을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-133">For details, see [Invoke Spark programs from Azure Data Factory](data-factory-spark.md).</span></span> 

## <a name="machine-learning-activities"></a><span data-ttu-id="286ed-134">Machine Learning 작업</span><span class="sxs-lookup"><span data-stu-id="286ed-134">Machine Learning activities</span></span>
<span data-ttu-id="286ed-135">Azure Data Factory를 사용하면 예측 분석을 위해 게시된 Azure Machine Learning 웹 서비스를 사용하는 파이프라인을 쉽게 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-135">Azure Data Factory enables you to easily create pipelines that use a published Azure Machine Learning web service for predictive analytics.</span></span> <span data-ttu-id="286ed-136">Azure Data Factory 파이프라인에서 [배치 실행 작업](data-factory-azure-ml-batch-execution-activity.md#invoking-a-web-service-using-batch-execution-activity)을 사용하여 Machine Learning 웹 서비스를 호출하고 배치에 있는 데이터에 대한 예측을 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-136">Using the [Batch Execution Activity](data-factory-azure-ml-batch-execution-activity.md#invoking-a-web-service-using-batch-execution-activity) in an Azure Data Factory pipeline, you can invoke a Machine Learning web service to make predictions on the data in batch.</span></span>

<span data-ttu-id="286ed-137">시간이 지남에 따라 Machine Learning 점수 매기기 실험의 예측 모델은 새 입력 데이터 집합을 사용하여 다시 학습되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-137">Over time, the predictive models in the Machine Learning scoring experiments need to be retrained using new input datasets.</span></span> <span data-ttu-id="286ed-138">재학습으로 완료한 후에는 재학습한 Machine Learning 모델로 점수 매기기 웹 서비스를 업데이트하려고 합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-138">After you are done with retraining, you want to update the scoring web service with the retrained Machine Learning model.</span></span> <span data-ttu-id="286ed-139">[업데이트 리소스 작업](data-factory-azure-ml-batch-execution-activity.md#updating-models-using-update-resource-activity)을 사용하여 새로 학습된 모델로 웹 서비스를 업데이트합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-139">You can use the [Update Resource Activity](data-factory-azure-ml-batch-execution-activity.md#updating-models-using-update-resource-activity) to update the web service with the newly trained model.</span></span>  

<span data-ttu-id="286ed-140">이러한 Machine Learning 작업에 대한 자세한 내용은 [Machine Learning 작업 사용](data-factory-azure-ml-batch-execution-activity.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-140">See [Use Machine Learning activities](data-factory-azure-ml-batch-execution-activity.md) for details about these Machine Learning activities.</span></span> 

## <a name="stored-procedure-activity"></a><span data-ttu-id="286ed-141">저장 프로시저 작업</span><span class="sxs-lookup"><span data-stu-id="286ed-141">Stored procedure activity</span></span>
<span data-ttu-id="286ed-142">Data Factory 파이프라인에서 SQL Server 저장 프로시저 작업을 사용하여 엔터프라이즈 또는 Azure VM의 Azure SQL Database, Azure SQL 데이터 웨어하우스, SQL Server Database의 데이터 저장소 중 하나에서 저장 프로시저를 호출할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-142">You can use the SQL Server Stored Procedure activity in a Data Factory pipeline to invoke a stored procedure in one of the following data stores: Azure SQL Database, Azure SQL Data Warehouse, SQL Server Database in your enterprise or an Azure VM.</span></span> <span data-ttu-id="286ed-143">자세한 내용은 [저장 프로시저 작업](data-factory-stored-proc-activity.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-143">See [Stored Procedure Activity](data-factory-stored-proc-activity.md) article for details.</span></span>  

## <a name="data-lake-analytics-u-sql-activity"></a><span data-ttu-id="286ed-144">Data Lake Analytics U-SQL 작업</span><span class="sxs-lookup"><span data-stu-id="286ed-144">Data Lake Analytics U-SQL activity</span></span>
<span data-ttu-id="286ed-145">Data Lake Analytics U-SQL 작업은 Azure Data Lake Analytics 클러스터에 대해 U-SQL 스크립트를 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-145">Data Lake Analytics U-SQL Activity runs a U-SQL script on an Azure Data Lake Analytics cluster.</span></span> <span data-ttu-id="286ed-146">자세한 내용은 [Data Analytics U-SQL 작업](data-factory-usql-activity.md) 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-146">See [Data Analytics U-SQL Activity](data-factory-usql-activity.md) article for details.</span></span> 

## <a name="net-custom-activity"></a><span data-ttu-id="286ed-147">.NET 사용자 지정 작업</span><span class="sxs-lookup"><span data-stu-id="286ed-147">.NET custom activity</span></span>
<span data-ttu-id="286ed-148">Data Factory에서 지원되지 않는 방식으로 데이터를 변환해야 하는 경우 고유의 데이터 이동 논리가 포함된 사용자 지정 작업을 만들어서 파이프라인에 해당 작업을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-148">If you need to transform data in a way that is not supported by Data Factory, you can create a custom activity with your own data processing logic and use the activity in the pipeline.</span></span> <span data-ttu-id="286ed-149">Azure 배치 서비스 또는 Azure HDInsight 클러스터를 사용하여 실행되도록 사용자 지정 .NET 작업을 구성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-149">You can configure the custom .NET activity to run using either an Azure Batch service or an Azure HDInsight cluster.</span></span> <span data-ttu-id="286ed-150">자세한 내용은 [사용자 지정 작업 사용](data-factory-use-custom-activities.md) 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-150">See [Use custom activities](data-factory-use-custom-activities.md) article for details.</span></span> 

<span data-ttu-id="286ed-151">R이 설치된 HDInsight 클러스터에서 R 스크립트를 실행하는 사용자 지정 작업을 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-151">You can create a custom activity to run R scripts on your HDInsight cluster with R installed.</span></span> <span data-ttu-id="286ed-152">[Azure Data Factory를 사용하여 R 스크립트 실행](https://github.com/Azure/Azure-DataFactory/tree/master/Samples/RunRScriptUsingADFSample)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-152">See [Run R Script using Azure Data Factory](https://github.com/Azure/Azure-DataFactory/tree/master/Samples/RunRScriptUsingADFSample).</span></span> 

## <a name="compute-environments"></a><span data-ttu-id="286ed-153">컴퓨팅 환경</span><span class="sxs-lookup"><span data-stu-id="286ed-153">Compute environments</span></span>
<span data-ttu-id="286ed-154">컴퓨팅 환경을 위한 연결된 서비스를 만들고 변환 작업을 정의할 때 이 연결된 서비스를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-154">You create a linked service for the compute environment and then use the linked service when defining a transformation activity.</span></span> <span data-ttu-id="286ed-155">데이터 팩터리에서 지원하는 컴퓨팅 환경은 두 가지 유형이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-155">There are two types of compute environments supported by Data Factory.</span></span> 

1. <span data-ttu-id="286ed-156">**주문형**: 이 경우 데이터 팩터리에서 완전히 컴퓨팅 환경을 관리합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-156">**On-Demand**:  In this case, the computing environment is fully managed by Data Factory.</span></span> <span data-ttu-id="286ed-157">데이터를 처리하기 위한 작업을 제출하기 전에 데이터 팩터리 서비스에서 자동으로 컴퓨팅 환경을 만들고 작업이 완료되면 제거합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-157">It is automatically created by the Data Factory service before a job is submitted to process data and removed when the job is completed.</span></span> <span data-ttu-id="286ed-158">작업 실행, 클러스터 관리, 부트스트래핑 작업에 대한 주문형 컴퓨팅 환경의 세부적인 설정을 구성 및 제어할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-158">You can configure and control granular settings of the on-demand compute environment for job execution, cluster management, and bootstrapping actions.</span></span> 
2. <span data-ttu-id="286ed-159">**자체 환경 사용**: 이 경우 사용자 고유의 컴퓨팅 환경(예: HDInsight 클러스터)을 데이터 팩터리에 연결된 서비스로 등록할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-159">**Bring Your Own**: In this case, you can register your own computing environment (for example HDInsight cluster) as a linked service in Data Factory.</span></span> <span data-ttu-id="286ed-160">컴퓨팅 환경은 이를 사용하여 작업을 실행하는 데이터 팩터리 서비스와 사용자에 의해 관리됩니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-160">The computing environment is managed by you and the Data Factory service uses it to execute the activities.</span></span> 

<span data-ttu-id="286ed-161">데이터 팩터리에서 지원하는 계산 서비스에 대한 자세한 내용은 [계산 연결된 서비스](data-factory-compute-linked-services.md) 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="286ed-161">See [Compute Linked Services](data-factory-compute-linked-services.md) article to learn about compute services supported by Data Factory.</span></span> 

## <a name="summary"></a><span data-ttu-id="286ed-162">요약</span><span class="sxs-lookup"><span data-stu-id="286ed-162">Summary</span></span>
<span data-ttu-id="286ed-163">Azure Data Factory는 작업에 대한 다음 데이터 변환 작업 및 컴퓨팅 환경을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-163">Azure Data Factory supports the following data transformation activities and the compute environments for the activities.</span></span> <span data-ttu-id="286ed-164">변환 작업은 개별적 또는 다른 작업과 연계하여 파이프라인에 추가될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="286ed-164">The transformation activities can be added to pipelines either individually or chained with another activity.</span></span>

| <span data-ttu-id="286ed-165">데이터 변환 작업</span><span class="sxs-lookup"><span data-stu-id="286ed-165">Data transformation activity</span></span> | <span data-ttu-id="286ed-166">컴퓨팅 환경</span><span class="sxs-lookup"><span data-stu-id="286ed-166">Compute environment</span></span> |
|:--- |:--- |
| [<span data-ttu-id="286ed-167">Hive</span><span class="sxs-lookup"><span data-stu-id="286ed-167">Hive</span></span>](data-factory-hive-activity.md) |<span data-ttu-id="286ed-168">HDInsight [Hadoop]</span><span class="sxs-lookup"><span data-stu-id="286ed-168">HDInsight [Hadoop]</span></span> |
| [<span data-ttu-id="286ed-169">Pig</span><span class="sxs-lookup"><span data-stu-id="286ed-169">Pig</span></span>](data-factory-pig-activity.md) |<span data-ttu-id="286ed-170">HDInsight [Hadoop]</span><span class="sxs-lookup"><span data-stu-id="286ed-170">HDInsight [Hadoop]</span></span> |
| [<span data-ttu-id="286ed-171">MapReduce</span><span class="sxs-lookup"><span data-stu-id="286ed-171">MapReduce</span></span>](data-factory-map-reduce.md) |<span data-ttu-id="286ed-172">HDInsight [Hadoop]</span><span class="sxs-lookup"><span data-stu-id="286ed-172">HDInsight [Hadoop]</span></span> |
| [<span data-ttu-id="286ed-173">Hadoop 스트리밍</span><span class="sxs-lookup"><span data-stu-id="286ed-173">Hadoop Streaming</span></span>](data-factory-hadoop-streaming-activity.md) |<span data-ttu-id="286ed-174">HDInsight [Hadoop]</span><span class="sxs-lookup"><span data-stu-id="286ed-174">HDInsight [Hadoop]</span></span> |
| [<span data-ttu-id="286ed-175">Machine Learning 작업: 배치 실행 및 업데이트 리소스</span><span class="sxs-lookup"><span data-stu-id="286ed-175">Machine Learning activities: Batch Execution and Update Resource</span></span>](data-factory-azure-ml-batch-execution-activity.md) |<span data-ttu-id="286ed-176">Azure VM</span><span class="sxs-lookup"><span data-stu-id="286ed-176">Azure VM</span></span> |
| [<span data-ttu-id="286ed-177">저장 프로시저</span><span class="sxs-lookup"><span data-stu-id="286ed-177">Stored Procedure</span></span>](data-factory-stored-proc-activity.md) |<span data-ttu-id="286ed-178">Azure SQL, Azure SQL 데이터 웨어하우스 또는 SQL Server</span><span class="sxs-lookup"><span data-stu-id="286ed-178">Azure SQL, Azure SQL Data Warehouse, or SQL Server</span></span> |
| [<span data-ttu-id="286ed-179">데이터 레이크 분석 U-SQL</span><span class="sxs-lookup"><span data-stu-id="286ed-179">Data Lake Analytics U-SQL</span></span>](data-factory-usql-activity.md) |<span data-ttu-id="286ed-180">Azure 데이터 레이크 분석</span><span class="sxs-lookup"><span data-stu-id="286ed-180">Azure Data Lake Analytics</span></span> |
| [<span data-ttu-id="286ed-181">DotNet</span><span class="sxs-lookup"><span data-stu-id="286ed-181">DotNet</span></span>](data-factory-use-custom-activities.md) |<span data-ttu-id="286ed-182">HDInsight [Hadoop] 또는 Azure Batch</span><span class="sxs-lookup"><span data-stu-id="286ed-182">HDInsight [Hadoop] or Azure Batch</span></span> |

