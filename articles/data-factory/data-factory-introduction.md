---
title: "aaaIntroduction tooData 팩터리를 데이터 통합 서비스 | Microsoft Docs"
description: "Azure Data Factory가 무엇인지 알아봅니다. 데이터의 이동과 변환을 조율하고 자동화하는 클라우드 데이터 통합 서비스입니다."
keywords: "데이터 통합, 클라우드 데이터 통합, Azure 데이터 팩터리란"
services: data-factory
documentationcenter: 
author: sharonlo101
manager: jhubbard
editor: monicar
ms.assetid: cec68cb5-ca0d-473b-8ae8-35de949a009e
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 08/14/2017
ms.author: shlo
ms.openlocfilehash: 4cc30515315efc938951057743ff8eb3701214ef
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="introduction-tooazure-data-factory"></a><span data-ttu-id="94ba0-104">소개 tooAzure 데이터 팩터리</span><span class="sxs-lookup"><span data-stu-id="94ba0-104">Introduction tooAzure Data Factory</span></span> 
## <a name="what-is-azure-data-factory"></a><span data-ttu-id="94ba0-105">Azure 데이터 팩터리란 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="94ba0-105">What is Azure Data Factory?</span></span>
<span data-ttu-id="94ba0-106">빅 데이터의 hello world에서 어떻게 기존 데이터에에서 사용 될 비즈니스?</span><span class="sxs-lookup"><span data-stu-id="94ba0-106">In hello world of big data, how is existing data leveraged in business?</span></span> <span data-ttu-id="94ba0-107">온-프레미스 데이터 원본 또는 기타 개별 데이터 원본에서 참조 데이터를 사용 하 여 hello 클라우드에서 생성 가능한 tooenrich 데이터 입니까?</span><span class="sxs-lookup"><span data-stu-id="94ba0-107">Is it possible tooenrich data generated in hello cloud by using reference data from on-premises data sources or other disparate data sources?</span></span> <span data-ttu-id="94ba0-108">예를 들어, 게임 회사 hello 클라우드에서 게임에서 생성 된 많은 로그를 수집 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-108">For example, a gaming company collects many logs produced by games in hello cloud.</span></span> <span data-ttu-id="94ba0-109">이러한 로그 toogain insights toocustomer 기본 설정, 인구 통계, 사용량 동작에서 원하는 tooanalyze 등 tooidentify 상향 판매 및 교차 판매 기회 새로운 기능 toodrive 비즈니스 성장 강력한 개발 하 고 더 나은 환경을 제공 합니다. toocustomers 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-109">It wants tooanalyze these logs toogain insights in toocustomer preferences, demographics, usage behavior etc. tooidentify up-sell and cross-sell opportunities, develop new compelling features toodrive business growth, and provide a better experience toocustomers.</span></span> 

<span data-ttu-id="94ba0-110">tooanalyze hello 회사 이러한 로그는 고객 정보, 게임 정보, 마케팅 캠페인 정보 온-프레미스 데이터 저장소에 있는 같은 toouse hello 참조 데이터를 필요 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-110">tooanalyze these logs, hello company needs toouse hello reference data such as customer information, game information, marketing campaign information that is in an on-premises data store.</span></span> <span data-ttu-id="94ba0-111">따라서 hello 회사 hello 클라우드 데이터 저장소에서 로그 데이터를 tooingest 및 hello 온-프레미스 데이터 저장소에서 참조 데이터를 원합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-111">Therefore, hello company wants tooingest log data from hello cloud data store and reference data from hello on-premises data store.</span></span> <span data-ttu-id="94ba0-112">그런 다음 hello Hadoop을 사용 하 여 hello 데이터 처리는 클라우드 (Azure HDInsight) 하 고 SQL Server와 같은 Azure SQL 데이터 웨어하우스 또는 온-프레미스 데이터와 같은 클라우드 데이터 웨어하우스로 데이터를 저장 하는 hello 결과 게시 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-112">Then, process hello data by using Hadoop in hello cloud (Azure HDInsight) and publish hello result data into a cloud data warehouse such as Azure SQL Data Warehouse or an on-premises data store such as SQL Server.</span></span> <span data-ttu-id="94ba0-113">브로드캐스트하며이 워크플로 toorun 매주 한 번입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-113">It wants this workflow toorun weekly once.</span></span> 

<span data-ttu-id="94ba0-114">Hello 회사 toocreate, Hadoop과 같은 기존 계산 서비스를 사용 하 여 온-프레미스와 클라우드 데이터 저장소 모두에서 데이터 및 변환 또는 프로세스 데이터를 수집 하 고 hello 결과 tooan 온-프레미스를 게시할 수 있는 워크플로 수 있는 플랫폼은 필요한 또는 응용 프로그램 tooconsume BI에 대 한 클라우드 데이터 저장소입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-114">What is needed is a platform that allows hello company toocreate a workflow that can ingest data from both on-premises and cloud data stores, and transform or process data by using existing compute services such as Hadoop, and publish hello results tooan on-premises or cloud data store for BI applications tooconsume.</span></span> 

![데이터 팩터리 개요](media/data-factory-introduction/what-is-azure-data-factory.png) 

<span data-ttu-id="94ba0-116">Azure Data Factory에는 이러한 종류의 시나리오에 대 한 hello 플랫폼입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-116">Azure Data Factory is hello platform for this kind of scenarios.</span></span> <span data-ttu-id="94ba0-117">한 **오케스트레이션 하 고 데이터 변환 및 데이터 이동 자동화에 대 한 hello 클라우드에서 데이터 기반 워크플로 toocreate 수 있는 클라우드 기반 데이터 통합 서비스**합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-117">It is a **cloud-based data integration service that allows you toocreate data-driven workflows in hello cloud for orchestrating and automating data movement and data transformation**.</span></span> <span data-ttu-id="94ba0-118">Azure 데이터 팩터리를 사용 하 여 만들 수 있으며 데이터 기반 워크플로 (파이프라인 라고 함), 수 있는 서로 다른 데이터 저장소에서 데이터 수집 프로세스/변환 hello 데이터 Azure HDInsight Hadoop, Spark, Azure 데이터 레이크 등 계산 서비스를 사용 하 여 예약 웹 로그 분석 및 Azure 기계 학습 및 business intelligence (BI) 응용 프로그램 tooconsume에 대 한 Azure SQL 데이터 웨어하우스 등 toodata 데이터를 저장 하는 출력을 게시 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-118">Using Azure Data Factory, you can create and schedule data-driven workflows (called pipelines) that can ingest data from disparate data stores, process/transform hello data by using compute services such as Azure HDInsight Hadoop, Spark, Azure Data Lake Analytics, and Azure Machine Learning, and publish output data toodata stores such as Azure SQL Data Warehouse for business intelligence (BI) applications tooconsume.</span></span>  

<span data-ttu-id="94ba0-119">기존의 ETL(추출 및 변환 및 로드) 플랫폼이 아닌 EL(추출 및 로드)한 다음 TL(변환 및 로드) 플랫폼이 지지를 얻고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-119">It's more of an Extract-and-Load (EL) and then Transform-and-Load (TL) platform rather than a traditional Extract-Transform-and-Load (ETL) platform.</span></span> <span data-ttu-id="94ba0-120">파생 열, 등 데이터를 정렬 하는 행의 수를 계산을 추가 하기 위한 hello 것과 같은 tooperform 변환 되지 않고 hello 변환을 수행 하는 계산 서비스를 사용 하 여 데이터 tootransform/처리 됩니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-120">hello transformations that are performed are tootransform/process data by using compute services rather than tooperform transformations like hello ones for adding derived columns, counting number of rows, sorting data, etc.</span></span> 

<span data-ttu-id="94ba0-121">현재, Azure 데이터 팩터리를 사용 하 고 워크플로 통해 생성 되는 있는 hello 데이터는 **시간 조각화 데이터** (매시간, 매일, 매주 등.).</span><span class="sxs-lookup"><span data-stu-id="94ba0-121">Currently, in Azure Data Factory, hello data that is consumed and produced by workflows is **time-sliced data** (hourly, daily, weekly, etc.).</span></span> <span data-ttu-id="94ba0-122">예를 들어 파이프라인은 하루에 한 번 입력 데이터를 읽고, 데이터를 처리하고 출력 데이터를 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-122">For example, a pipeline may read input data, process data, and produce output data once a day.</span></span> <span data-ttu-id="94ba0-123">또한 워크플로를 한 번만 실행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-123">You can also run a workflow just one time.</span></span>  
  

## <a name="how-does-it-work"></a><span data-ttu-id="94ba0-124">작동 원리</span><span class="sxs-lookup"><span data-stu-id="94ba0-124">How does it work?</span></span> 
<span data-ttu-id="94ba0-125">일반적으로 Azure 데이터 팩터리에서 hello 파이프라인 (데이터 기반 워크플로) hello 세 단계를 수행 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-125">hello pipelines (data-driven workflows) in Azure Data Factory typically perform hello following three steps:</span></span>

![Azure Data Factory의 세 단계](media/data-factory-introduction/three-information-production-stages.png)

### <a name="connect-and-collect"></a><span data-ttu-id="94ba0-127">연결 및 수집</span><span class="sxs-lookup"><span data-stu-id="94ba0-127">Connect and collect</span></span>
<span data-ttu-id="94ba0-128">기업에는 다양한 형식의 데이터가 서로 다른 원본에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-128">Enterprises have data of various types located in disparate sources.</span></span> <span data-ttu-id="94ba0-129">hello 정보 프로덕션 시스템을 작성 하는 첫 번째 단계는 tooconnect tooall hello 필요한 데이터 소스 및 처리, SaaS 서비스와 같은 파일 공유, FTP, 웹 서비스 hello 데이터 필요에 따라 tooa 중앙 위치에 대 한 이동 후속 처리 중입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-129">hello first step in building an information production system is tooconnect tooall hello required sources of data and processing, such as SaaS services, file shares, FTP, web services, and move hello data as-needed tooa centralized location for subsequent processing.</span></span>

<span data-ttu-id="94ba0-130">데이터 팩터리 없이 엔터프라이즈 사용자 지정 데이터 이동을 구성 요소를 만들 하거나 이러한 데이터 원본 및 처리 사용자 지정 서비스 toointegrate를 작성 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-130">Without Data Factory, enterprises must build custom data movement components or write custom services toointegrate these data sources and processing.</span></span> <span data-ttu-id="94ba0-131">비용이 많이 들고 하드 toointegrate 되 고 이러한 시스템을 유지 관리할 완벽 하 게 관리 되는 서비스를 제공할 수 있는 hello 컨트롤과 hello 엔터프라이즈급 모니터링 및 경고, 종종 부족 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-131">It is expensive and hard toointegrate and maintain such systems, and it often lacks hello enterprise grade monitoring and alerting, and hello controls that a fully managed service can offer.</span></span>

<span data-ttu-id="94ba0-132">데이터 팩터리에 온-프레미스에서 데이터 파이프라인 toomove 데이터에 hello 복사 작업을 사용할 수 있으며 클라우드 hello 클라우드 추가 분석을 위해 원본 데이터 저장소 tooa 중앙 집중식 데이터 저장소 키를 누릅니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-132">With Data Factory, you can use hello Copy Activity in a data pipeline toomove data from both on-premises and cloud source data stores tooa centralization data store in hello cloud for further analysis.</span></span> <span data-ttu-id="94ba0-133">예를 들어 Azure Data Lake 분석 계산 서비스를 사용 하 여 나중에 Azure 데이터 레이크 저장소 및 변환 hello 데이터의 데이터를 수집할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-133">For example, you can collect data in an Azure Data Lake Store and transform hello data later by using an Azure Data Lake Analytics compute service.</span></span> <span data-ttu-id="94ba0-134">또는 Azure HDInsight Hadoop 클러스터를 사용하여 Azure Blob Storage에서 데이터를 수집하고 나중에 변환할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-134">Or, collect data in an Azure Blob Storage and transform data later by using an Azure HDInsight Hadoop cluster.</span></span>

### <a name="transform-and-enrich"></a><span data-ttu-id="94ba0-135">변환 및 보강</span><span class="sxs-lookup"><span data-stu-id="94ba0-135">Transform and enrich</span></span>
<span data-ttu-id="94ba0-136">Hello 클라우드에서 중앙 집중식된 데이터 저장소에 있는 데이터를 원하는 hello 수집 된 데이터 toobe 처리 되거나 HDInsight Hadoop, Spark, Data Lake 분석 및 기계 학습 등의 계산 서비스를 사용 하 여 변환 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-136">Once data is present in a centralized data store in hello cloud, you want hello collected data toobe processed or transformed by using compute services such as HDInsight Hadoop, Spark, Data Lake Analytics, and Machine Learning.</span></span> <span data-ttu-id="94ba0-137">신뢰할 수 있는 데이터를 사용 하 여 관리 하 고 제어 된 일정 toofeed 프로덕션 환경에 tooreliably 변환 생성 데이터 사용 하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-137">You want tooreliably produce transformed data on a maintainable and controlled schedule toofeed production environments with trusted data.</span></span> 

### <a name="publish"></a><span data-ttu-id="94ba0-138">게시</span><span class="sxs-lookup"><span data-stu-id="94ba0-138">Publish</span></span> 
<span data-ttu-id="94ba0-139">Tooon 온-프레미스 원본 SQL Server와 같은 hello 클라우드에서 변환 된 데이터를 제공 하거나에 보관 클라우드 사용을 위한 저장소 원본 BI (비즈니스 인텔리전스) 및 분석 도구와 다른 응용 프로그램에서 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-139">Deliver transformed data from hello cloud tooon-premises sources like SQL Server, or keep it in your cloud storage sources for consumption by business intelligence (BI) and analytics tools and other applications.</span></span>

## <a name="key-components"></a><span data-ttu-id="94ba0-140">핵심 구성 요소</span><span class="sxs-lookup"><span data-stu-id="94ba0-140">Key components</span></span>
<span data-ttu-id="94ba0-141">Azure 구독에는 하나 이상의 Azure Data Factory 인스턴스(또는 데이터 팩터리)가 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-141">An Azure subscription may have one or more Azure Data Factory instances (or data factories).</span></span> <span data-ttu-id="94ba0-142">Azure Data Factory 단계 toomove 및 변환에 데이터가 있는 데이터 기반 워크플로 작성할 수 있는 tooprovide hello 플랫폼 함께 작동 하는 네 가지 주요 구성 요소가 구성 되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-142">Azure Data Factory is composed of four key components that work together tooprovide hello platform on which you can compose data-driven workflows with steps toomove and transform data.</span></span> 

### <a name="pipeline"></a><span data-ttu-id="94ba0-143">파이프라인</span><span class="sxs-lookup"><span data-stu-id="94ba0-143">Pipeline</span></span>
<span data-ttu-id="94ba0-144">데이터 팩터리에는 하나 이상의 파이프라인이 포함될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-144">A data factory may have one or more pipelines.</span></span> <span data-ttu-id="94ba0-145">파이프라인은 활동 그룹입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-145">A pipeline is a group of activities.</span></span> <span data-ttu-id="94ba0-146">함께 파이프라인의 hello 활동 작업을 수행 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-146">Together, hello activities in a pipeline perform a task.</span></span> <span data-ttu-id="94ba0-147">예를 들어 파이프라인 Azure blob에서 데이터를 수집 하는 활동 그룹을 포함 하 고는 HDInsight 클러스터 toopartition hello 데이터에서 하이브 쿼리를 실행 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-147">For example, a pipeline could contain a group of activities that ingests data from an Azure blob, and then run a Hive query on an HDInsight cluster toopartition hello data.</span></span> <span data-ttu-id="94ba0-148">이 hello 이점은 hello 파이프라인 있습니다 toomanage hello 활동 각각 대신 집합으로 개별적으로입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-148">hello benefit of this is that hello pipeline allows you toomanage hello activities as a set instead of each one individually.</span></span> <span data-ttu-id="94ba0-149">예를 들어, 배포 및 hello 활동 대신 hello 파이프라인을 독립적으로 예약할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-149">For example, you can deploy and schedule hello pipeline, instead of hello activities independently.</span></span> 

### <a name="activity"></a><span data-ttu-id="94ba0-150">작업</span><span class="sxs-lookup"><span data-stu-id="94ba0-150">Activity</span></span>
<span data-ttu-id="94ba0-151">파이프라인에는 하나 이상의 작업이 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-151">A pipeline may have one or more activities.</span></span> <span data-ttu-id="94ba0-152">활동은 데이터에 대해 작업 tooperform hello를 정의합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-152">Activities define hello actions tooperform on your data.</span></span> <span data-ttu-id="94ba0-153">예를 들어 하나의 데이터 저장소 tooanother 데이터 저장소에서 복사 작업 toocopy 데이터를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-153">For example, you may use a Copy activity toocopy data from one data store tooanother data store.</span></span> <span data-ttu-id="94ba0-154">마찬가지로, Azure HDInsight 클러스터 tootransform에서 하이브 쿼리를 실행 하는 하이브 활동을 사용 하 여 또는 데이터를 분석할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-154">Similarly, you may use a Hive activity, which runs a Hive query on an Azure HDInsight cluster tootransform or analyze your data.</span></span> <span data-ttu-id="94ba0-155">Data Factory는 데이터 이동 활동 및 데이터 변환 활동이라는 두 종류의 활동을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-155">Data Factory supports two types of activities: data movement activities and data transformation activities.</span></span>

### <a name="data-movement-activities"></a><span data-ttu-id="94ba0-156">데이터 이동 활동</span><span class="sxs-lookup"><span data-stu-id="94ba0-156">Data movement activities</span></span>
<span data-ttu-id="94ba0-157">복사 활동 Data Factory에는 원본 데이터 저장소 tooa 싱크 데이터 저장소에서 데이터를 복사합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-157">Copy Activity in Data Factory copies data from a source data store tooa sink data store.</span></span> <span data-ttu-id="94ba0-158">데이터 팩터리 hello 다음 데이터 저장소를 지원 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-158">Data Factory supports hello following data stores.</span></span> <span data-ttu-id="94ba0-159">데이터 소스에서 tooany 싱크를 작성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-159">Data from any source can be written tooany sink.</span></span> <span data-ttu-id="94ba0-160">데이터 저장소 toolearn 방법을 클릭 해당 저장소에서 데이터 tooand toocopy 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-160">Click a data store toolearn how toocopy data tooand from that store.</span></span>

[!INCLUDE [data-factory-supported-data-stores](../../includes/data-factory-supported-data-stores.md)]

<span data-ttu-id="94ba0-161">자세한 내용은 [데이터 이동 활동](data-factory-data-movement-activities.md) 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="94ba0-161">For more information, see [Data Movement Activities](data-factory-data-movement-activities.md) article.</span></span>

### <a name="data-transformation-activities"></a><span data-ttu-id="94ba0-162">데이터 변환 활동</span><span class="sxs-lookup"><span data-stu-id="94ba0-162">Data transformation activities</span></span>
[!INCLUDE [data-factory-transformation-activities](../../includes/data-factory-transformation-activities.md)]

<span data-ttu-id="94ba0-163">자세한 내용은 [데이터 변환 활동](data-factory-data-transformation-activities.md) 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="94ba0-163">For more information, see [Data Transformation Activities](data-factory-data-transformation-activities.md) article.</span></span>

### <a name="custom-net-activities"></a><span data-ttu-id="94ba0-164">사용자 지정 .NET 활동</span><span class="sxs-lookup"><span data-stu-id="94ba0-164">Custom .NET activities</span></span>
<span data-ttu-id="94ba0-165">데이터 저장소에서 복사 작업에 해당 하지 않는 지원, 또는 변환 하는 고유한 논리를 사용 하 여 데이터 만들기/toomove 데이터를 유지 해야 하는 경우는 **사용자 지정.NET 작업**합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-165">If you need toomove data to/from a data store that Copy Activity doesn't support, or transform data using your own logic, create a **custom .NET activity**.</span></span> <span data-ttu-id="94ba0-166">사용자 지정 활동을 만들고 사용하는 방법에 대한 자세한 내용은 [Azure Data Factory 파이프라인에서 사용자 지정 활동 사용](data-factory-use-custom-activities.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="94ba0-166">For details on creating and using a custom activity, see [Use custom activities in an Azure Data Factory pipeline](data-factory-use-custom-activities.md).</span></span>

### <a name="datasets"></a><span data-ttu-id="94ba0-167">데이터 집합</span><span class="sxs-lookup"><span data-stu-id="94ba0-167">Datasets</span></span>
<span data-ttu-id="94ba0-168">작업은 0개 이상의 데이터 집합을 입력으로 사용하고 하나 이상의 데이터 집합을 출력으로 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-168">An activity takes zero or more datasets as inputs and one or more datasets as outputs.</span></span> <span data-ttu-id="94ba0-169">데이터 집합 내 단순히 가리키거나 hello에에서 데이터를 toouse 활동 입력 또는 출력으로 참조 하는 hello 데이터 저장소에서 데이터 구조를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-169">Datasets represent data structures within hello data stores, which simply point or reference hello data you want toouse in your activities as inputs or outputs.</span></span> <span data-ttu-id="94ba0-170">예를 들어 된 Azure Blob 데이터 집합에서 어떤 hello 파이프라인 hello 데이터 읽어야 하는 hello Azure Blob 저장소에 hello blob 컨테이너 및 폴더를 지정 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-170">For example, an Azure Blob dataset specifies hello blob container and folder in hello Azure Blob Storage from which hello pipeline should read hello data.</span></span> <span data-ttu-id="94ba0-171">또는 hello 테이블 toowhich hello 출력 데이터가 hello 활동에 의해 기록 되는 Azure SQL 테이블 데이터 집합을 지정 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-171">Or, an Azure SQL Table dataset specifies hello table toowhich hello output data is written by hello activity.</span></span> 

### <a name="linked-services"></a><span data-ttu-id="94ba0-172">연결된 서비스</span><span class="sxs-lookup"><span data-stu-id="94ba0-172">Linked services</span></span>
<span data-ttu-id="94ba0-173">연결 된 서비스 데이터 팩터리의 tooconnect tooexternal 리소스에 대 한 필요한 hello 연결 정보를 정의 하는 연결 문자열 매우 비슷합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-173">Linked services are much like connection strings, which define hello connection information needed for Data Factory tooconnect tooexternal resources.</span></span> <span data-ttu-id="94ba0-174">이러한 방식으로 생각-hello 연결 toohello 데이터 소스를 정의 하는 연결된 된 서비스 및 데이터 집합 hello hello 데이터 구조를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-174">Think of it this way - a linked service defines hello connection toohello data source and a dataset represents hello structure of hello data.</span></span> <span data-ttu-id="94ba0-175">예를 들어 Azure 저장소 연결 된 서비스에는 연결 문자열 tooconnect toohello Azure 저장소 계정을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-175">For example, an Azure Storage linked service specifies connection string tooconnect toohello Azure Storage account.</span></span> <span data-ttu-id="94ba0-176">고 hello blob 컨테이너 및 hello 폴더 hello 데이터를 포함 하는 Azure Blob 데이터 집합을 지정 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-176">And, an Azure Blob dataset specifies hello blob container and hello folder that contains hello data.</span></span>   

<span data-ttu-id="94ba0-177">연결된 서비스는 데이터 팩터리 내에서 두 가지 용도로 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-177">Linked services are used for two purposes in Data Factory:</span></span>

* <span data-ttu-id="94ba0-178">toorepresent는 **데이터 저장소** 등 뿐만 아니라 온-프레미스 SQL Server, Oracle 데이터베이스, 파일 공유 또는 Azure Blob 저장소 계정입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-178">toorepresent a **data store** including, but not limited to, an on-premises SQL Server, Oracle database, file share, or an Azure Blob Storage account.</span></span> <span data-ttu-id="94ba0-179">Hello 참조 [데이터 이동 작업](#data-movement-activities) 목록은 지원 되는 데이터 저장소 섹션.</span><span class="sxs-lookup"><span data-stu-id="94ba0-179">See hello [Data movement activities](#data-movement-activities) section for a list of supported data stores.</span></span>
* <span data-ttu-id="94ba0-180">toorepresent는 **계산 리소스** hello는 활동 실행을 호스팅할 수입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-180">toorepresent a **compute resource** that can host hello execution of an activity.</span></span> <span data-ttu-id="94ba0-181">예를 들어 hello HDInsightHive 활동 HDInsight Hadoop 클러스터에서 실행 됩니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-181">For example, hello HDInsightHive activity runs on an HDInsight Hadoop cluster.</span></span> <span data-ttu-id="94ba0-182">지원되는 컴퓨팅 환경 목록은 [데이터 변환 활동](#data-transformation-activities) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="94ba0-182">See [Data transformation activities](#data-transformation-activities) section for a list of supported compute environments.</span></span>

### <a name="relationship-between-data-factory-entities"></a><span data-ttu-id="94ba0-183">Data Factory 엔터티 간의 관계</span><span class="sxs-lookup"><span data-stu-id="94ba0-183">Relationship between Data Factory entities</span></span>
<span data-ttu-id="94ba0-184">![다이어그램: Data Factory, 클라우드 데이터 통합 서비스 - 주요 개념](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**그림 2.**</span><span class="sxs-lookup"><span data-stu-id="94ba0-184">![Diagram: Data Factory, a cloud data integration service - Key Concepts](./media/data-factory-introduction/data-integration-service-key-concepts.png)
**Figure 2.**</span></span> <span data-ttu-id="94ba0-185">데이터 집합, 활동, 파이프라인 및 연결된 서비스 간의 관계</span><span class="sxs-lookup"><span data-stu-id="94ba0-185">Relationships between Dataset, Activity, Pipeline, and Linked service</span></span>

## <a name="supported-regions"></a><span data-ttu-id="94ba0-186">지원되는 지역</span><span class="sxs-lookup"><span data-stu-id="94ba0-186">Supported regions</span></span>
<span data-ttu-id="94ba0-187">Hello에서 데이터 팩터리를 만들 수는 현재 **West US**, **미국 동부**, 및 **유럽 북부** 영역입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-187">Currently, you can create data factories in hello **West US**, **East US**, and **North Europe** regions.</span></span> <span data-ttu-id="94ba0-188">그러나 데이터 팩터리 데이터 저장소에 액세스할 수 있습니다 및 계산 서비스에서 데이터 저장소 간의 다른 Azure 지역 toomove 데이터 또는 계산 서비스를 사용 하 여 데이터를 처리 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-188">However, a data factory can access data stores and compute services in other Azure regions toomove data between data stores or process data using compute services.</span></span>

<span data-ttu-id="94ba0-189">Azure 데이터 팩터리 자체는 데이터를 저장하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-189">Azure Data Factory itself does not store any data.</span></span> <span data-ttu-id="94ba0-190">Tooorchestrate 간의 데이터 이동을 데이터 기반 워크플로 만들 수 있습니다 [데이터 저장소를 지원](#data-movement-activities) 및 사용 하 여 데이터의 처리 [계산 서비스](#data-transformation-activities) 온-프레미스 또는 다른 지역 들에 환경입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-190">It lets you create data-driven workflows tooorchestrate movement of data between [supported data stores](#data-movement-activities) and processing of data using [compute services](#data-transformation-activities) in other regions or in an on-premises environment.</span></span> <span data-ttu-id="94ba0-191">또한 있습니다 너무[워크플로 모니터링 및 관리](data-factory-monitor-manage-pipelines.md) 프로그래밍 방식으로 모두 사용 하 여 및 UI 메커니즘입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-191">It also allows you too[monitor and manage workflows](data-factory-monitor-manage-pipelines.md) using both programmatic and UI mechanisms.</span></span>

<span data-ttu-id="94ba0-192">데이터 팩터리는에서 사용할 수 있는 경우에 **West US**, **미국 동부**, 및 **유럽 북부** 영역, Data Factory에서 데이터 이동을 hello 전원을 hello 서비스를 사용할 수 [전체적으로](data-factory-data-movement-activities.md#global) 여러 지역에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-192">Even though Data Factory is available in only **West US**, **East US**, and **North Europe** regions, hello service powering hello data movement in Data Factory is available [globally](data-factory-data-movement-activities.md#global) in several regions.</span></span> <span data-ttu-id="94ba0-193">데이터 저장소는 방화벽 뒤에 있는 경우는 [데이터 관리 게이트웨이](data-factory-move-data-between-onprem-and-cloud.md) 대신 온-프레미스 환경 이동 hello 데이터에 설치 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-193">If a data store is behind a firewall, then a [Data Management Gateway](data-factory-move-data-between-onprem-and-cloud.md) installed in your on-premises environment moves hello data instead.</span></span>

<span data-ttu-id="94ba0-194">예를 들어 Azure HDInsight 클러스터 및 Azure Machine Learning과 같은 계산 환경이 서유럽 지역 외부에서 실행되고 있다고 가정해보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-194">For an example, let us assume that your compute environments such as Azure HDInsight cluster and Azure Machine Learning are running out of West Europe region.</span></span> <span data-ttu-id="94ba0-195">수 및 유럽 북부에 있는 Azure 데이터 팩터리 인스턴스를 사용 하 여 만들고 서 부 유럽에서 하거나 계산 환경에서 tooschedule 작업을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-195">You can create and use an Azure Data Factory instance in North Europe and use it tooschedule jobs on your compute environments in West Europe.</span></span> <span data-ttu-id="94ba0-196">Data Factory tootrigger hello 작업에 대 한 몇 밀리초 계산 환경에 걸리는 하지만 hello 작업 컴퓨팅 환경에서 실행 하기 위한 hello 시간이 변경 되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-196">It takes a few milliseconds for Data Factory tootrigger hello job on your compute environment but hello time for running hello job on your computing environment does not change.</span></span>

## <a name="get-started-with-creating-a-pipeline"></a><span data-ttu-id="94ba0-197">파이프라인 만들기 시작</span><span class="sxs-lookup"><span data-stu-id="94ba0-197">Get started with creating a pipeline</span></span>
<span data-ttu-id="94ba0-198">Azure Data Factory에 이러한 도구 또는 Api toocreate 데이터 파이프라인 중 하나를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-198">You can use one of these tools or APIs toocreate data pipelines in Azure Data Factory:</span></span> 

- <span data-ttu-id="94ba0-199">Azure portal</span><span class="sxs-lookup"><span data-stu-id="94ba0-199">Azure portal</span></span>
- <span data-ttu-id="94ba0-200">Visual Studio</span><span class="sxs-lookup"><span data-stu-id="94ba0-200">Visual Studio</span></span>
- <span data-ttu-id="94ba0-201">PowerShell</span><span class="sxs-lookup"><span data-stu-id="94ba0-201">PowerShell</span></span>
- <span data-ttu-id="94ba0-202">.NET API</span><span class="sxs-lookup"><span data-stu-id="94ba0-202">.NET API</span></span>
- <span data-ttu-id="94ba0-203">REST API</span><span class="sxs-lookup"><span data-stu-id="94ba0-203">REST API</span></span>
- <span data-ttu-id="94ba0-204">Azure Resource Manager 템플릿</span><span class="sxs-lookup"><span data-stu-id="94ba0-204">Azure Resource Manager template.</span></span> 

<span data-ttu-id="94ba0-205">toolearn 어떻게 데이터로 toobuild 데이터 팩터리 파이프라인, hello 다음 자습서의에서 단계별 지침을 따르세요.</span><span class="sxs-lookup"><span data-stu-id="94ba0-205">toolearn how toobuild data factories with data pipelines, follow step-by-step instructions in hello following tutorials:</span></span>

| <span data-ttu-id="94ba0-206">자습서</span><span class="sxs-lookup"><span data-stu-id="94ba0-206">Tutorial</span></span> | <span data-ttu-id="94ba0-207">설명</span><span class="sxs-lookup"><span data-stu-id="94ba0-207">Description</span></span> |
| --- | --- |
| [<span data-ttu-id="94ba0-208">두 클라우드 데이터 저장소 간의 데이터 이동</span><span class="sxs-lookup"><span data-stu-id="94ba0-208">Move data between two cloud data stores</span></span>](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md) |<span data-ttu-id="94ba0-209">이 자습서에서는 데이터 팩터리 파이프라인 하 만들 **데이터 이동** Blob 저장소 tooSQL 데이터베이스에서 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-209">In this tutorial, you create a data factory with a pipeline that **moves data** from Blob storage tooSQL database.</span></span> |
| [<span data-ttu-id="94ba0-210">Hadoop 클러스터를 사용하여 데이터 변환</span><span class="sxs-lookup"><span data-stu-id="94ba0-210">Transform data using Hadoop cluster</span></span>](data-factory-build-your-first-pipeline.md) |<span data-ttu-id="94ba0-211">이 자습서에서는 Azure HDInsight(Hadoop) 클러스터에서 Hive 스크립트를 실행하여 **데이터를 처리** 하는 데이터 파이프라인으로 첫 번째 Azure 데이터 팩터리를 구축합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-211">In this tutorial, you build your first Azure data factory with a data pipeline that **processes data** by running Hive script on an Azure HDInsight (Hadoop) cluster.</span></span> |
| [<span data-ttu-id="94ba0-212">데이터 관리 게이트웨이를 사용하여 온-프레미스 데이터 저장소와 클라우드 데이터 저장소 간에 데이터 이동</span><span class="sxs-lookup"><span data-stu-id="94ba0-212">Move data between an on-premises data store and a cloud data store using Data Management Gateway</span></span>](data-factory-move-data-between-onprem-and-cloud.md) |<span data-ttu-id="94ba0-213">이 자습서에서는 데이터 팩터리 빌드할 파이프라인이 있는 **데이터 이동** 에서 **온-프레미스** SQL Server 데이터베이스 tooan Azure blob입니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-213">In this tutorial, you build a data factory with a pipeline that **moves data** from an **on-premises** SQL Server database tooan Azure blob.</span></span> <span data-ttu-id="94ba0-214">Hello 연습의 일부로 설치 하 고 컴퓨터에 hello 데이터 관리 게이트웨이 구성 합니다.</span><span class="sxs-lookup"><span data-stu-id="94ba0-214">As part of hello walkthrough, you install and configure hello Data Management Gateway on your machine.</span></span> |
