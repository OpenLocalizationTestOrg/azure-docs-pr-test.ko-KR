---
title: "Azure HDInsight Spark-를 사용 하 여 aaaAnalyze Application Insight 기록 | Microsoft Docs"
description: "Application Insight tooexport tooblob 저장소를 기록 하는 방법을 알아보고 HDInsight의 spark hello 로그를 분석 합니다."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: 883beae6-9839-45b5-94f7-7eb0f4534ad5
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 08/15/2017
ms.author: larryfr
ms.openlocfilehash: 11ed8cf68dba8d5f9d6e4a65eba0d2b5a950cd00
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="analyze-application-insights-telemetry-logs-with-spark-on-hdinsight"></a><span data-ttu-id="d7edc-103">HDInsight에서 Spark를 사용하여 Application Insights 원격 분석 로그 분석</span><span class="sxs-lookup"><span data-stu-id="d7edc-103">Analyze Application Insights telemetry logs with Spark on HDInsight</span></span>

<span data-ttu-id="d7edc-104">자세한 내용은 HDInsight tooanalyze Application Insight 원격 분석 데이터에 toouse 멤버 하는 방법입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-104">Learn how toouse Spark on HDInsight tooanalyze Application Insight telemetry data.</span></span>

<span data-ttu-id="d7edc-105">[Visual Studio Application Insights](../application-insights/app-insights-overview.md) 는 웹 응용 프로그램을 모니터링하는 분석 서비스입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-105">[Visual Studio Application Insights](../application-insights/app-insights-overview.md) is an analytics service that monitors your web applications.</span></span> <span data-ttu-id="d7edc-106">Application Insights에 의해 생성 된 원격 분석 데이터에는 내보낸된 tooAzure 저장 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-106">Telemetry data generated by Application Insights can be exported tooAzure Storage.</span></span> <span data-ttu-id="d7edc-107">HDInsight 사용된 tooanalyze 수 hello 데이터를 Azure 저장소에 해당 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-107">Once hello data is in Azure Storage, HDInsight can be used tooanalyze it.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="d7edc-108">필수 조건</span><span class="sxs-lookup"><span data-stu-id="d7edc-108">Prerequisites</span></span>

* <span data-ttu-id="d7edc-109">응용 프로그램을 toouse Application Insights를 구성 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-109">An application that is configured toouse Application Insights.</span></span>

* <span data-ttu-id="d7edc-110">Linux 기반 HDInsight 클러스터를 만드는 데 익숙해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-110">Familiarity with creating a Linux-based HDInsight cluster.</span></span> <span data-ttu-id="d7edc-111">자세한 내용은 [HDInsight에서 Spark 만들기](hdinsight-apache-spark-jupyter-spark-sql.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="d7edc-111">For more information, see [Create Spark on HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

  > [!IMPORTANT]
  > <span data-ttu-id="d7edc-112">이 문서의 단계 hello Linux를 사용 하는 HDInsight 클러스터를 필요 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-112">hello steps in this document require an HDInsight cluster that uses Linux.</span></span> <span data-ttu-id="d7edc-113">Linux는 hello 전용 운영 체제 HDInsight 버전 3.4 이상에서 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-113">Linux is hello only operating system used on HDInsight version 3.4 or greater.</span></span> <span data-ttu-id="d7edc-114">자세한 내용은 [Windows에서 HDInsight 사용 중지](hdinsight-component-versioning.md#hdinsight-windows-retirement)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="d7edc-114">For more information, see [HDInsight retirement on Windows](hdinsight-component-versioning.md#hdinsight-windows-retirement).</span></span>

* <span data-ttu-id="d7edc-115">웹 브라우저.</span><span class="sxs-lookup"><span data-stu-id="d7edc-115">A web browser.</span></span>

<span data-ttu-id="d7edc-116">hello 다음 리소스에 사용 된 개발 하 고이 문서를 테스트 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-116">hello following resources were used in developing and testing this document:</span></span>

* <span data-ttu-id="d7edc-117">응용 프로그램 Insights 원격 분석 데이터를 사용 하 여 생성 하는 [Node.js 웹 응용 프로그램 구성 toouse Application Insights](../application-insights/app-insights-nodejs.md)합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-117">Application Insights telemetry data was generated using a [Node.js web app configured toouse Application Insights](../application-insights/app-insights-nodejs.md).</span></span>

* <span data-ttu-id="d7edc-118">HDInsight 클러스터 버전 3.5에서 Linux 기반 Spark에 사용 되는 tooanalyze hello 데이터 했습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-118">A Linux-based Spark on HDInsight cluster version 3.5 was used tooanalyze hello data.</span></span>

## <a name="architecture-and-planning"></a><span data-ttu-id="d7edc-119">아키텍처 및 계획</span><span class="sxs-lookup"><span data-stu-id="d7edc-119">Architecture and planning</span></span>

<span data-ttu-id="d7edc-120">다이어그램을 다음 hello이 예제의 hello 서비스 아키텍처를 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-120">hello following diagram illustrates hello service architecture of this example:</span></span>

![HDInsight의 Spark에 의해 처리 되는 다음에 Application Insights tooblob 저장소에서 데이터를 보여 주는 다이어그램](./media/hdinsight-spark-analyze-application-insight-logs/appinsightshdinsight.png)

### <a name="azure-storage"></a><span data-ttu-id="d7edc-122">Azure 저장소</span><span class="sxs-lookup"><span data-stu-id="d7edc-122">Azure storage</span></span>

<span data-ttu-id="d7edc-123">Application Insights 구성된 toocontinuously 내보내기 원격 분석 정보 tooblobs 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-123">Application Insights can be configured toocontinuously export telemetry information tooblobs.</span></span> <span data-ttu-id="d7edc-124">HDInsight은 hello blob에 저장 된 데이터 읽을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-124">HDInsight can then read data stored in hello blobs.</span></span> <span data-ttu-id="d7edc-125">그러나 따라야 할 몇 가지 요구 사항이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-125">However, there are some requirements that you must follow:</span></span>

* <span data-ttu-id="d7edc-126">**위치**: hello 저장소 계정 및 HDInsight 서로 다른 위치에 있으면 대기 시간이 길어질 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-126">**Location**: If hello Storage Account and HDInsight are in different locations, it may increase latency.</span></span> <span data-ttu-id="d7edc-127">또한 전송 요금 적용된 toodata 지역 간 이동은 비용을 증가 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-127">It also increases cost, as egress charges are applied toodata moving between regions.</span></span>

    > [!WARNING]
    > <span data-ttu-id="d7edc-128">HDInsight와 다른 위치에서는 저장소 계정을 사용할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-128">Using a Storage Account in a different location than HDInsight is not supported.</span></span>

* <span data-ttu-id="d7edc-129">**Blob 유형**: HDInsight는 블록 Blob만을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-129">**Blob type**: HDInsight only supports block blobs.</span></span> <span data-ttu-id="d7edc-130">Application Insights toousing 블록 blob을 HDInsight 함께 기본적으로 작동 해야 하므로 기본값입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-130">Application Insights defaults toousing block blobs, so should work by default with HDInsight.</span></span>

<span data-ttu-id="d7edc-131">추가 저장소 tooan 기존 HDInsight 클러스터를 추가 하는 방법에 대 한 정보를 참조 hello [추가 저장소 계정을 추가](hdinsight-hadoop-add-storage.md) 문서.</span><span class="sxs-lookup"><span data-stu-id="d7edc-131">For information on adding additional storage tooan existing HDInsight cluster, see hello [Add additional storage accounts](hdinsight-hadoop-add-storage.md) document.</span></span>

### <a name="data-schema"></a><span data-ttu-id="d7edc-132">데이터 스키마</span><span class="sxs-lookup"><span data-stu-id="d7edc-132">Data schema</span></span>

<span data-ttu-id="d7edc-133">Application Insights는 [데이터 모델을 내보낼](../application-insights/app-insights-export-data-model.md) hello 원격 분석 데이터 형식에 대 한 정보 tooblobs로 내보냅니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-133">Application Insights provides [export data model](../application-insights/app-insights-export-data-model.md) information for hello telemetry data format exported tooblobs.</span></span> <span data-ttu-id="d7edc-134">이 문서의 단계 hello hello 데이터로 Spark SQL toowork를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-134">hello steps in this document use Spark SQL toowork with hello data.</span></span> <span data-ttu-id="d7edc-135">Spark SQL Application Insights에 의해 기록 된 hello JSON 데이터 구조에 대 한 스키마를 자동으로 생성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-135">Spark SQL can automatically generate a schema for hello JSON data structure logged by Application Insights.</span></span>

## <a name="export-telemetry-data"></a><span data-ttu-id="d7edc-136">원격 분석 데이터 내보내기</span><span class="sxs-lookup"><span data-stu-id="d7edc-136">Export telemetry data</span></span>

<span data-ttu-id="d7edc-137">Hello 단계에 따라 [연속 내보내기 구성](../application-insights/app-insights-export-telemetry.md) tooconfigure Application Insights tooexport 원격 분석 정보 tooan Azure 저장소 blob입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-137">Follow hello steps in [Configure Continuous Export](../application-insights/app-insights-export-telemetry.md) tooconfigure your Application Insights tooexport telemetry information tooan Azure storage blob.</span></span>

## <a name="configure-hdinsight-tooaccess-hello-data"></a><span data-ttu-id="d7edc-138">HDInsight tooaccess hello 데이터 구성</span><span class="sxs-lookup"><span data-stu-id="d7edc-138">Configure HDInsight tooaccess hello data</span></span>

<span data-ttu-id="d7edc-139">HDInsight 클러스터를 만드는 경우 클러스터를 만드는 동안 hello 저장소 계정을 추가 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-139">If you are creating an HDInsight cluster, add hello storage account during cluster creation.</span></span>

<span data-ttu-id="d7edc-140">Azure 저장소 계정 tooan 기존 클러스터 tooadd hello hello 정보를 사용 하 여 hello에 [다른 저장소 계정을 추가할](hdinsight-hadoop-add-storage.md) 문서.</span><span class="sxs-lookup"><span data-stu-id="d7edc-140">tooadd hello Azure Storage Account tooan existing cluster, use hello information in hello [Add additional Storage Accounts](hdinsight-hadoop-add-storage.md) document.</span></span>

## <a name="analyze-hello-data-pyspark"></a><span data-ttu-id="d7edc-141">Hello 데이터 분석: PySpark</span><span class="sxs-lookup"><span data-stu-id="d7edc-141">Analyze hello data: PySpark</span></span>

1. <span data-ttu-id="d7edc-142">Hello에서 [Azure 포털](https://portal.azure.com)를 HDInsight 클러스터에서 Spark를 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-142">From hello [Azure portal](https://portal.azure.com), select your Spark on HDInsight cluster.</span></span> <span data-ttu-id="d7edc-143">Hello에서 **빠른 링크** 섹션에서 **클러스터 대시보드**를 선택한 후 **Jupyter 노트북** hello 클러스터 Dashboard__ 블레이드에서 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-143">From hello **Quick Links** section, select **Cluster Dashboards**, and then select **Jupyter Notebook** from hello Cluster Dashboard__ blade.</span></span>

    ![hello 클러스터 대시보드](./media/hdinsight-spark-analyze-application-insight-logs/clusterdashboards.png)

2. <span data-ttu-id="d7edc-145">Hello 오른쪽 위 모서리로 hello Jupyter 페이지에서 선택 **새로**, 차례로 **PySpark**합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-145">In hello upper right corner of hello Jupyter page, select **New**, and then **PySpark**.</span></span> <span data-ttu-id="d7edc-146">Python 기반 Jupyter Notebook을 포함하는 새 브라우저 탭이 열립니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-146">A new browser tab containing a Python-based Jupyter Notebook opens.</span></span>

3. <span data-ttu-id="d7edc-147">Hello 첫 번째 필드에서 (호출을 **셀**) hello 페이지 hello 텍스트 다음 입력:</span><span class="sxs-lookup"><span data-stu-id="d7edc-147">In hello first field (called a **cell**) on hello page, enter hello following text:</span></span>

   ```python
   sc._jsc.hadoopConfiguration().set('mapreduce.input.fileinputformat.input.dir.recursive', 'true')
   ```

    <span data-ttu-id="d7edc-148">이 코드는 hello 입력된 데이터에 대 한 Spark toorecursively 액세스 hello 디렉터리 구조를 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-148">This code configures Spark toorecursively access hello directory structure for hello input data.</span></span> <span data-ttu-id="d7edc-149">Application Insights 원격 분석은 기록된 tooa 디렉터리 구조와 유사한 toohello `/{telemetry type}/YYYY-MM-DD/{##}/`합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-149">Application Insights telemetry is logged tooa directory structure similar toohello `/{telemetry type}/YYYY-MM-DD/{##}/`.</span></span>

4. <span data-ttu-id="d7edc-150">사용 하 여 **SHIFT + ENTER** toorun hello 코드입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-150">Use **SHIFT+ENTER** toorun hello code.</span></span> <span data-ttu-id="d7edc-151">Hello hello 셀의 왼쪽에 '\*' hello 코드가이 셀에 실행 되 고 있음을 hello 대괄호 tooindicate 사이 나타납니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-151">On hello left side of hello cell, an '\*' appears between hello brackets tooindicate that hello code in this cell is being executed.</span></span> <span data-ttu-id="d7edc-152">이 완료 되 면 hello '\*' tooa 번호 및 텍스트 다음 유사한 toohello hello 셀 아래에 표시 되어 출력을 변경 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-152">Once it completes, hello '\*' changes tooa number, and output similar toohello following text is displayed below hello cell:</span></span>

        Creating SparkContext as 'sc'

        ID    YARN Application ID    Kind    State    Spark UI    Driver log    Current session?
        3    application_1468969497124_0001    pyspark    idle    Link    Link    ✔

        Creating HiveContext as 'sqlContext'
        SparkContext and HiveContext created. Executing user code ...
5. <span data-ttu-id="d7edc-153">새로운 셀 hello 아래 만들어집니다. 첫 번째 항목이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-153">A new cell is created below hello first one.</span></span> <span data-ttu-id="d7edc-154">Hello 텍스트 hello 새로운 셀에서 다음을 입력 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-154">Enter hello following text in hello new cell.</span></span> <span data-ttu-id="d7edc-155">대체 `CONTAINER` 및 `STORAGEACCOUNT` hello Azure 저장소 계정 이름 및 Application Insights 데이터를 포함 하는 blob 컨테이너 이름을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-155">Replace `CONTAINER` and `STORAGEACCOUNT` with hello Azure storage account name and blob container name that contains Application Insights data.</span></span>

   ```python
   %%bash
   hdfs dfs -ls wasb://CONTAINER@STORAGEACCOUNT.blob.core.windows.net/
   ```

    <span data-ttu-id="d7edc-156">사용 하 여 **SHIFT + ENTER** tooexecute이이 셀입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-156">Use **SHIFT+ENTER** tooexecute this cell.</span></span> <span data-ttu-id="d7edc-157">텍스트 다음 결과 유사한 toohello를 표시 됩니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-157">You see a result similar toohello following text:</span></span>

        Found 1 items
        drwxrwxrwx   -          0 1970-01-01 00:00 wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_2bededa61bc741fbdee6b556571a4831

    <span data-ttu-id="d7edc-158">반환 된 hello wasb 경로 hello 위치 hello Application Insights 원격 분석 데이터입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-158">hello wasb path returned is hello location of hello Application Insights telemetry data.</span></span> <span data-ttu-id="d7edc-159">변경 hello `hdfs dfs -ls` 으로 hello 셀 toouse hello wasb 경로 반환 하 고 사용 하 여 **SHIFT + ENTER** toorun hello 셀 다시 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-159">Change hello `hdfs dfs -ls` line in hello cell toouse hello wasb path returned, and then use **SHIFT+ENTER** toorun hello cell again.</span></span> <span data-ttu-id="d7edc-160">이 시간 hello 결과는 원격 분석 데이터를 포함 하는 hello 디렉터리 표시 되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-160">This time, hello results should display hello directories that contain telemetry data.</span></span>

   > [!NOTE]
   > <span data-ttu-id="d7edc-161">이 섹션의 단계를 hello 나머지 hello hello `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` 디렉터리가 사용 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-161">For hello remainder of hello steps in this section, hello `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` directory was used.</span></span> <span data-ttu-id="d7edc-162">사용자의 디렉터리 구조는 다를 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-162">Your directory structure may be different.</span></span>

6. <span data-ttu-id="d7edc-163">Hello 다음 셀에 입력 코드 다음 hello: 대체 `WASB_PATH` hello 이전 단계의 hello 경로 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-163">In hello next cell, enter hello following code: Replace `WASB_PATH` with hello path from hello previous step.</span></span>

   ```python
   jsonFiles = sc.textFile('WASB_PATH')
   jsonData = sqlContext.read.json(jsonFiles)
   ```

    <span data-ttu-id="d7edc-164">이 코드는 hello 연속 내보내기 프로세스에서 내보내는 hello JSON 파일에서 데이터 프레임이 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-164">This code creates a dataframe from hello JSON files exported by hello continuous export process.</span></span> <span data-ttu-id="d7edc-165">사용 하 여 **SHIFT + ENTER** toorun이이 셀입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-165">Use **SHIFT+ENTER** toorun this cell.</span></span>
7. <span data-ttu-id="d7edc-166">Hello 다음 셀에 입력 하 고 hello tooview hello Spark에서 만든 스키마를 hello JSON 파일에 대 한 다음 실행:</span><span class="sxs-lookup"><span data-stu-id="d7edc-166">In hello next cell, enter and run hello following tooview hello schema that Spark created for hello JSON files:</span></span>

   ```python
   jsonData.printSchema()
   ```

    <span data-ttu-id="d7edc-167">각 유형의 원격 분석에 대 한 hello 스키마는 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-167">hello schema for each type of telemetry is different.</span></span> <span data-ttu-id="d7edc-168">hello 다음 예제는 웹 요청에 대해 생성 되는 hello 스키마 (hello에 저장 된 데이터 `Requests` 하위 디렉터리):</span><span class="sxs-lookup"><span data-stu-id="d7edc-168">hello following example is hello schema that is generated for web requests (data stored in hello `Requests` subdirectory):</span></span>

        root
        |-- context: struct (nullable = true)
        |    |-- application: struct (nullable = true)
        |    |    |-- version: string (nullable = true)
        |    |-- custom: struct (nullable = true)
        |    |    |-- dimensions: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |    |-- metrics: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- eventTime: string (nullable = true)
        |    |    |-- isSynthetic: boolean (nullable = true)
        |    |    |-- samplingRate: double (nullable = true)
        |    |    |-- syntheticSource: string (nullable = true)
        |    |-- device: struct (nullable = true)
        |    |    |-- browser: string (nullable = true)
        |    |    |-- browserVersion: string (nullable = true)
        |    |    |-- deviceModel: string (nullable = true)
        |    |    |-- deviceName: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- osVersion: string (nullable = true)
        |    |    |-- type: string (nullable = true)
        |    |-- location: struct (nullable = true)
        |    |    |-- city: string (nullable = true)
        |    |    |-- clientip: string (nullable = true)
        |    |    |-- continent: string (nullable = true)
        |    |    |-- country: string (nullable = true)
        |    |    |-- province: string (nullable = true)
        |    |-- operation: struct (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |-- session: struct (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- isFirst: boolean (nullable = true)
        |    |-- user: struct (nullable = true)
        |    |    |-- anonId: string (nullable = true)
        |    |    |-- isAuthenticated: boolean (nullable = true)
        |-- internal: struct (nullable = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- documentVersion: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |-- request: array (nullable = true)
        |    |-- element: struct (containsNull = true)
        |    |    |-- count: long (nullable = true)
        |    |    |-- durationMetric: struct (nullable = true)
        |    |    |    |-- count: double (nullable = true)
        |    |    |    |-- max: double (nullable = true)
        |    |    |    |-- min: double (nullable = true)
        |    |    |    |-- sampledValue: double (nullable = true)
        |    |    |    |-- stdDev: double (nullable = true)
        |    |    |    |-- value: double (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |    |-- responseCode: long (nullable = true)
        |    |    |-- success: boolean (nullable = true)
        |    |    |-- url: string (nullable = true)
        |    |    |-- urlData: struct (nullable = true)
        |    |    |    |-- base: string (nullable = true)
        |    |    |    |-- hashTag: string (nullable = true)
        |    |    |    |-- host: string (nullable = true)
        |    |    |    |-- protocol: string (nullable = true)
8. <span data-ttu-id="d7edc-169">임시 테이블과 tooregister hello 데이터 프레임을 따라 hello를 사용 하 여 하 고 hello 데이터에 대 한 쿼리를 실행 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-169">Use hello following tooregister hello dataframe as a temporary table and run a query against hello data:</span></span>

   ```python
   jsonData.registerTempTable("requests")
   df = sqlContext.sql("select context.location.city from requests where context.location.city is not null")
   df.show()
   ```

    <span data-ttu-id="d7edc-170">이 쿼리 context.location.city null이 hello 상위 20 개의 레코드에 대 한 hello 도시 정보를 반환 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-170">This query returns hello city information for hello top 20 records where context.location.city is not null.</span></span>

   > [!NOTE]
   > <span data-ttu-id="d7edc-171">hello 컨텍스트 구조는 Application Insights에 의해 기록 된 모든 원격 분석에 존재 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-171">hello context structure is present in all telemetry logged by Application Insights.</span></span> <span data-ttu-id="d7edc-172">로그에 hello 도시 요소를 채울 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-172">hello city element may not be populated in your logs.</span></span> <span data-ttu-id="d7edc-173">Hello 스키마 tooidentify 프로그램 로그에 대 한 데이터를 포함할 수 있는 쿼리할 수 있는 다른 요소를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-173">Use hello schema tooidentify other elements that you can query that may contain data for your logs.</span></span>

    <span data-ttu-id="d7edc-174">이 쿼리 정보 비슷한 toohello를 다음 텍스트를 반환 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-174">This query returns information similar toohello following text:</span></span>

        +---------+
        |     city|
        +---------+
        | Bellevue|
        |  Redmond|
        |  Seattle|
        |Charlotte|
        ...
        +---------+

## <a name="analyze-hello-data-scala"></a><span data-ttu-id="d7edc-175">Hello 데이터 분석: Scala</span><span class="sxs-lookup"><span data-stu-id="d7edc-175">Analyze hello data: Scala</span></span>

1. <span data-ttu-id="d7edc-176">Hello에서 [Azure 포털](https://portal.azure.com)를 HDInsight 클러스터에서 Spark를 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-176">From hello [Azure portal](https://portal.azure.com), select your Spark on HDInsight cluster.</span></span> <span data-ttu-id="d7edc-177">Hello에서 **빠른 링크** 섹션에서 **클러스터 대시보드**를 선택한 후 **Jupyter 노트북** hello 클러스터 Dashboard__ 블레이드에서 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-177">From hello **Quick Links** section, select **Cluster Dashboards**, and then select **Jupyter Notebook** from hello Cluster Dashboard__ blade.</span></span>

    ![hello 클러스터 대시보드](./media/hdinsight-spark-analyze-application-insight-logs/clusterdashboards.png)
2. <span data-ttu-id="d7edc-179">Hello 오른쪽 위 모서리로 hello Jupyter 페이지에서 선택 **새로**, 차례로 **Scala**합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-179">In hello upper right corner of hello Jupyter page, select **New**, and then **Scala**.</span></span> <span data-ttu-id="d7edc-180">Scala 기반 Jupyter Notebook을 포함하는 새 브라우저 탭이 나타납니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-180">A new browser tab containing a Scala-based Jupyter Notebook appears.</span></span>
3. <span data-ttu-id="d7edc-181">Hello 첫 번째 필드에서 (호출을 **셀**) hello 페이지 hello 텍스트 다음 입력:</span><span class="sxs-lookup"><span data-stu-id="d7edc-181">In hello first field (called a **cell**) on hello page, enter hello following text:</span></span>

   ```scala
   sc.hadoopConfiguration.set("mapreduce.input.fileinputformat.input.dir.recursive", "true")
   ```

    <span data-ttu-id="d7edc-182">이 코드는 hello 입력된 데이터에 대 한 Spark toorecursively 액세스 hello 디렉터리 구조를 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-182">This code configures Spark toorecursively access hello directory structure for hello input data.</span></span> <span data-ttu-id="d7edc-183">Application Insights 원격 분석은 유사한 tooa 디렉터리 구조를 너무 기록`/{telemetry type}/YYYY-MM-DD/{##}/`합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-183">Application Insights telemetry is logged tooa directory structure similar too`/{telemetry type}/YYYY-MM-DD/{##}/`.</span></span>

4. <span data-ttu-id="d7edc-184">사용 하 여 **SHIFT + ENTER** toorun hello 코드입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-184">Use **SHIFT+ENTER** toorun hello code.</span></span> <span data-ttu-id="d7edc-185">Hello hello 셀의 왼쪽에 '\*' hello 코드가이 셀에 실행 되 고 있음을 hello 대괄호 tooindicate 사이 나타납니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-185">On hello left side of hello cell, an '\*' appears between hello brackets tooindicate that hello code in this cell is being executed.</span></span> <span data-ttu-id="d7edc-186">이 완료 되 면 hello '\*' tooa 번호 및 텍스트 다음 유사한 toohello hello 셀 아래에 표시 되어 출력을 변경 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-186">Once it completes, hello '\*' changes tooa number, and output similar toohello following text is displayed below hello cell:</span></span>

        Creating SparkContext as 'sc'

        ID    YARN Application ID    Kind    State    Spark UI    Driver log    Current session?
        3    application_1468969497124_0001    spark    idle    Link    Link    ✔

        Creating HiveContext as 'sqlContext'
        SparkContext and HiveContext created. Executing user code ...
5. <span data-ttu-id="d7edc-187">새로운 셀 hello 아래 만들어집니다. 첫 번째 항목이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-187">A new cell is created below hello first one.</span></span> <span data-ttu-id="d7edc-188">Hello 텍스트 hello 새로운 셀에서 다음을 입력 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-188">Enter hello following text in hello new cell.</span></span> <span data-ttu-id="d7edc-189">대체 `CONTAINER` 및 `STORAGEACCOUNT` hello Azure 저장소 계정 이름 및 Application Insights 포함 된 blob 컨테이너 이름으로 기록 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-189">Replace `CONTAINER` and `STORAGEACCOUNT` with hello Azure storage account name and blob container name that contains Application Insights logs.</span></span>

   ```scala
   %%bash
   hdfs dfs -ls wasb://CONTAINER@STORAGEACCOUNT.blob.core.windows.net/
   ```

    <span data-ttu-id="d7edc-190">사용 하 여 **SHIFT + ENTER** tooexecute이이 셀입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-190">Use **SHIFT+ENTER** tooexecute this cell.</span></span> <span data-ttu-id="d7edc-191">텍스트 다음 결과 유사한 toohello를 표시 됩니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-191">You see a result similar toohello following text:</span></span>

        Found 1 items
        drwxrwxrwx   -          0 1970-01-01 00:00 wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_2bededa61bc741fbdee6b556571a4831

    <span data-ttu-id="d7edc-192">반환 된 hello wasb 경로 hello 위치 hello Application Insights 원격 분석 데이터입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-192">hello wasb path returned is hello location of hello Application Insights telemetry data.</span></span> <span data-ttu-id="d7edc-193">변경 hello `hdfs dfs -ls` 으로 hello 셀 toouse hello wasb 경로 반환 하 고 사용 하 여 **SHIFT + ENTER** toorun hello 셀 다시 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-193">Change hello `hdfs dfs -ls` line in hello cell toouse hello wasb path returned, and then use **SHIFT+ENTER** toorun hello cell again.</span></span> <span data-ttu-id="d7edc-194">이 시간 hello 결과는 원격 분석 데이터를 포함 하는 hello 디렉터리 표시 되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-194">This time, hello results should display hello directories that contain telemetry data.</span></span>

   > [!NOTE]
   > <span data-ttu-id="d7edc-195">이 섹션의 단계를 hello 나머지 hello hello `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` 디렉터리가 사용 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-195">For hello remainder of hello steps in this section, hello `wasb://appinsights@contosostore.blob.core.windows.net/contosoappinsights_{ID}/Requests` directory was used.</span></span> <span data-ttu-id="d7edc-196">원격 분석 데이터가 웹앱에 대한 것이 아니면 이 디렉터리는 없을 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-196">This directory may not exist unless your telemetry data is for a web app.</span></span>

6. <span data-ttu-id="d7edc-197">Hello 다음 셀에 입력 코드 다음 hello: 대체 `WASB\_PATH` hello 이전 단계의 hello 경로 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-197">In hello next cell, enter hello following code: Replace `WASB\_PATH` with hello path from hello previous step.</span></span>

   ```scala
   var jsonFiles = sc.textFile('WASB_PATH')
   val sqlContext = new org.apache.spark.sql.SQLContext(sc)
   var jsonData = sqlContext.read.json(jsonFiles)
   ```

    <span data-ttu-id="d7edc-198">이 코드는 hello 연속 내보내기 프로세스에서 내보내는 hello JSON 파일에서 데이터 프레임이 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-198">This code creates a dataframe from hello JSON files exported by hello continuous export process.</span></span> <span data-ttu-id="d7edc-199">사용 하 여 **SHIFT + ENTER** toorun이이 셀입니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-199">Use **SHIFT+ENTER** toorun this cell.</span></span>

7. <span data-ttu-id="d7edc-200">Hello 다음 셀에 입력 하 고 hello tooview hello Spark에서 만든 스키마를 hello JSON 파일에 대 한 다음 실행:</span><span class="sxs-lookup"><span data-stu-id="d7edc-200">In hello next cell, enter and run hello following tooview hello schema that Spark created for hello JSON files:</span></span>

   ```scala
   jsonData.printSchema
   ```

    <span data-ttu-id="d7edc-201">각 유형의 원격 분석에 대 한 hello 스키마는 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-201">hello schema for each type of telemetry is different.</span></span> <span data-ttu-id="d7edc-202">hello 다음 예제는 웹 요청에 대해 생성 되는 hello 스키마 (hello에 저장 된 데이터 `Requests` 하위 디렉터리):</span><span class="sxs-lookup"><span data-stu-id="d7edc-202">hello following example is hello schema that is generated for web requests (data stored in hello `Requests` subdirectory):</span></span>

        root
        |-- context: struct (nullable = true)
        |    |-- application: struct (nullable = true)
        |    |    |-- version: string (nullable = true)
        |    |-- custom: struct (nullable = true)
        |    |    |-- dimensions: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |    |-- metrics: array (nullable = true)
        |    |    |    |-- element: string (containsNull = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- eventTime: string (nullable = true)
        |    |    |-- isSynthetic: boolean (nullable = true)
        |    |    |-- samplingRate: double (nullable = true)
        |    |    |-- syntheticSource: string (nullable = true)
        |    |-- device: struct (nullable = true)
        |    |    |-- browser: string (nullable = true)
        |    |    |-- browserVersion: string (nullable = true)
        |    |    |-- deviceModel: string (nullable = true)
        |    |    |-- deviceName: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- osVersion: string (nullable = true)
        |    |    |-- type: string (nullable = true)
        |    |-- location: struct (nullable = true)
        |    |    |-- city: string (nullable = true)
        |    |    |-- clientip: string (nullable = true)
        |    |    |-- continent: string (nullable = true)
        |    |    |-- country: string (nullable = true)
        |    |    |-- province: string (nullable = true)
        |    |-- operation: struct (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |-- session: struct (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- isFirst: boolean (nullable = true)
        |    |-- user: struct (nullable = true)
        |    |    |-- anonId: string (nullable = true)
        |    |    |-- isAuthenticated: boolean (nullable = true)
        |-- internal: struct (nullable = true)
        |    |-- data: struct (nullable = true)
        |    |    |-- documentVersion: string (nullable = true)
        |    |    |-- id: string (nullable = true)
        |-- request: array (nullable = true)
        |    |-- element: struct (containsNull = true)
        |    |    |-- count: long (nullable = true)
        |    |    |-- durationMetric: struct (nullable = true)
        |    |    |    |-- count: double (nullable = true)
        |    |    |    |-- max: double (nullable = true)
        |    |    |    |-- min: double (nullable = true)
        |    |    |    |-- sampledValue: double (nullable = true)
        |    |    |    |-- stdDev: double (nullable = true)
        |    |    |    |-- value: double (nullable = true)
        |    |    |-- id: string (nullable = true)
        |    |    |-- name: string (nullable = true)
        |    |    |-- responseCode: long (nullable = true)
        |    |    |-- success: boolean (nullable = true)
        |    |    |-- url: string (nullable = true)
        |    |    |-- urlData: struct (nullable = true)
        |    |    |    |-- base: string (nullable = true)
        |    |    |    |-- hashTag: string (nullable = true)
        |    |    |    |-- host: string (nullable = true)
        |    |    |    |-- protocol: string (nullable = true)

8. <span data-ttu-id="d7edc-203">임시 테이블과 tooregister hello 데이터 프레임을 따라 hello를 사용 하 여 하 고 hello 데이터에 대 한 쿼리를 실행 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-203">Use hello following tooregister hello dataframe as a temporary table and run a query against hello data:</span></span>

   ```scala
   jsonData.registerTempTable("requests")
   var city = sqlContext.sql("select context.location.city from requests where context.location.city is not null limit 10").show()
   ```

    <span data-ttu-id="d7edc-204">이 쿼리 context.location.city null이 hello 상위 20 개의 레코드에 대 한 hello 도시 정보를 반환 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-204">This query returns hello city information for hello top 20 records where context.location.city is not null.</span></span>

   > [!NOTE]
   > <span data-ttu-id="d7edc-205">hello 컨텍스트 구조는 Application Insights에 의해 기록 된 모든 원격 분석에 존재 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-205">hello context structure is present in all telemetry logged by Application Insights.</span></span> <span data-ttu-id="d7edc-206">로그에 hello 도시 요소를 채울 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-206">hello city element may not be populated in your logs.</span></span> <span data-ttu-id="d7edc-207">Hello 스키마 tooidentify 프로그램 로그에 대 한 데이터를 포함할 수 있는 쿼리할 수 있는 다른 요소를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-207">Use hello schema tooidentify other elements that you can query that may contain data for your logs.</span></span>
   >
   >

    <span data-ttu-id="d7edc-208">이 쿼리 정보 비슷한 toohello를 다음 텍스트를 반환 합니다.</span><span class="sxs-lookup"><span data-stu-id="d7edc-208">This query returns information similar toohello following text:</span></span>

        +---------+
        |     city|
        +---------+
        | Bellevue|
        |  Redmond|
        |  Seattle|
        |Charlotte|
        ...
        +---------+

## <a name="next-steps"></a><span data-ttu-id="d7edc-209">다음 단계</span><span class="sxs-lookup"><span data-stu-id="d7edc-209">Next steps</span></span>

<span data-ttu-id="d7edc-210">Spark toowork를 사용 하 여 데이터와 Azure에서 서비스의 자세한 예 hello 다음 문서를 참조:</span><span class="sxs-lookup"><span data-stu-id="d7edc-210">For more examples of using Spark toowork with data and services in Azure, see hello following documents:</span></span>

* [<span data-ttu-id="d7edc-211">BI와 Spark: BI 도구와 함께 HDInsight에서 Spark를 사용하여 대화형 데이터 분석 수행</span><span class="sxs-lookup"><span data-stu-id="d7edc-211">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="d7edc-212">기계 학습과 Spark: HVAC 데이터를 사용하여 건물 온도를 분석하는 데 HDInsight의 Spark 사용</span><span class="sxs-lookup"><span data-stu-id="d7edc-212">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="d7edc-213">Spark와 기계 학습: HDInsight toopredict 음식 검사 결과에 사용 하 여 Spark</span><span class="sxs-lookup"><span data-stu-id="d7edc-213">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="d7edc-214">Spark 스트리밍: HDInsight에서 Spark를 사용하여 스트리밍 응용 프로그램 빌드</span><span class="sxs-lookup"><span data-stu-id="d7edc-214">Spark Streaming: Use Spark in HDInsight for building streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="d7edc-215">HDInsight의 Spark를 사용하여 웹 사이트 로그 분석</span><span class="sxs-lookup"><span data-stu-id="d7edc-215">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

<span data-ttu-id="d7edc-216">만들고 Spark 실행 중인 응용 프로그램에 대 한 자세한 내용은 다음 문서는 hello를 참조 하세요.</span><span class="sxs-lookup"><span data-stu-id="d7edc-216">For information on creating and running Spark applications, see hello following documents:</span></span>

* [<span data-ttu-id="d7edc-217">Scala를 사용하여 독립 실행형 응용 프로그램 만들기</span><span class="sxs-lookup"><span data-stu-id="d7edc-217">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="d7edc-218">Livy를 사용하여 Spark 클러스터에서 원격으로 작업 실행</span><span class="sxs-lookup"><span data-stu-id="d7edc-218">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)
