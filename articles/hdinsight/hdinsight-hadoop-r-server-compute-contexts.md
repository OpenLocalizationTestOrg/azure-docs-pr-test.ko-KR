---
title: "Azure HDInsight에 R Server에 대 한 상황에 맞는 aaaCompute 옵션 | Microsoft Docs"
description: "Hello 다른 계산 컨텍스트 옵션 사용 가능한 toousers HDInsight에 R server에 대 한 자세한 내용은"
services: HDInsight
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 0deb0b1c-4094-459b-94fc-ec9b774c1f8a
ms.service: HDInsight
ms.custom: hdinsightactive
ms.devlang: R
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 06/19/2017
ms.author: bradsev
ms.openlocfilehash: b3b0d0cc3caa390797dcff8c73d66cd3ad78bcaa
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="compute-context-options-for-r-server-on-hdinsight"></a><span data-ttu-id="86ab5-103">HDInsight에서 R 서버의 계산 컨텍스트 옵션</span><span class="sxs-lookup"><span data-stu-id="86ab5-103">Compute context options for R Server on HDInsight</span></span>

<span data-ttu-id="86ab5-104">Azure HDInsight의 Microsoft R Server는 hello 계산 컨텍스트를 설정 하 여 호출을 실행 하는 방법을 제어 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-104">Microsoft R Server on Azure HDInsight controls how calls are executed by setting hello compute context.</span></span> <span data-ttu-id="86ab5-105">이 문서에는 hello 있는 옵션을 사용할 수 있는 toospecify 여부 및 실행 hello 가장자리 노드 또는 HDInsight 클러스터의 코어에서 병렬 처리 방법을 간략하게 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-105">This article outlines hello options that are available toospecify whether and how execution is parallelized across cores of hello edge node or HDInsight cluster.</span></span>

<span data-ttu-id="86ab5-106">클러스터의 hello 가장자리 노드 R 스크립트 편리한 위치 tooconnect toohello 클러스터 및 toorun 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-106">hello edge node of a cluster provides a convenient place tooconnect toohello cluster and toorun your R scripts.</span></span> <span data-ttu-id="86ab5-107">가장자리 노드 ScaleR의 hello distributed 옵션을 실행 중인 hello 평행 화 함수 hello에 지 노드 서버의 hello 코어 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-107">With an edge node, you have hello option of running hello parallelized distributed functions of ScaleR across hello cores of hello edge node server.</span></span> <span data-ttu-id="86ab5-108">실행할 수도 있습니다 이러한 hello 클러스터의 hello 노드에서 ScaleR의 Hadoop 맵 감소 또는 Spark를 사용 하 여 계산 컨텍스트.</span><span class="sxs-lookup"><span data-stu-id="86ab5-108">You can also run them across hello nodes of hello cluster by using ScaleR’s Hadoop Map Reduce or Spark compute contexts.</span></span>

## <a name="microsoft-r-server-on-azure-hdinsight"></a><span data-ttu-id="86ab5-109">Azure HDInsight의 Microsoft R Server</span><span class="sxs-lookup"><span data-stu-id="86ab5-109">Microsoft R Server on Azure HDInsight</span></span>
<span data-ttu-id="86ab5-110">[Azure HDInsight의 Microsoft R Server](hdinsight-hadoop-r-server-overview.md) R 기반 분석에 대 한 hello 최신 기능을 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-110">[Microsoft R Server on Azure HDInsight](hdinsight-hadoop-r-server-overview.md) provides hello latest capabilities for R-based analytics.</span></span> <span data-ttu-id="86ab5-111">HDFS 컨테이너에 저장 된 데이터를 사용할 수 있습니다 프로그램 [Azure Blob](../storage/common/storage-introduction.md "Azure Blob 저장소") 저장소 계정, 데이터 레이크 저장소 또는 hello 로컬 Linux 파일 시스템입니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-111">It can use data that is stored in an HDFS container in your [Azure Blob](../storage/common/storage-introduction.md "Azure Blob storage") storage account, a Data Lake store, or hello local Linux file system.</span></span> <span data-ttu-id="86ab5-112">R Server는 오픈 소스 R 기술을 기반으로 한 이후 hello에 R 기반 응용 프로그램을 빌드할 hello 8000 + 오픈 소스 R 패키지를 적용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-112">Since R Server is built on open source R, hello R-based applications you build can apply any of hello 8000+ open source R packages.</span></span> <span data-ttu-id="86ab5-113">Hello 루틴을 사용할 수 있습니다 [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), R Server에 포함 되어 있는 Microsoft의 빅 데이터 분석 패키지 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-113">They can also use hello routines in [RevoScaleR](https://msdn.microsoft.com/microsoft-r/scaler/scaler), Microsoft’s big data analytics package that is included with R Server.</span></span>  

## <a name="compute-contexts-for-an-edge-node"></a><span data-ttu-id="86ab5-114">에지 노드에 대한 계산 컨텍스트</span><span class="sxs-lookup"><span data-stu-id="86ab5-114">Compute contexts for an edge node</span></span>
<span data-ttu-id="86ab5-115">일반적으로 R 서버 hello 가장자리 노드에서 실행 되는 R 스크립트를 해당 노드의 hello R 인터프리터 내에서 실행 됩니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-115">In general, an R script that's run in R Server on hello edge node runs within hello R interpreter on that node.</span></span> <span data-ttu-id="86ab5-116">hello 예외 ScaleR 함수를 호출 하는 단계입니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-116">hello exceptions are those steps that call a ScaleR function.</span></span> <span data-ttu-id="86ab5-117">hello ScaleR 호출 hello ScaleR 계산 컨텍스트를 설정 하는 방법에 따라 결정 되는 계산 환경에서 실행 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-117">hello ScaleR calls run in a compute environment that is determined by how you set hello ScaleR compute context.</span></span>  <span data-ttu-id="86ab5-118">가장자리 노드에서 R 스크립트를 실행 하는 경우 컨텍스트는 hello hello의 가능한 값 계산:</span><span class="sxs-lookup"><span data-stu-id="86ab5-118">When you run your R script from an edge node, hello possible values of hello compute context are:</span></span>

- <span data-ttu-id="86ab5-119">로컬 순차(*‘local’*)</span><span class="sxs-lookup"><span data-stu-id="86ab5-119">local sequential (*‘local’*)</span></span>
- <span data-ttu-id="86ab5-120">로컬 병렬(*‘localpar’*)</span><span class="sxs-lookup"><span data-stu-id="86ab5-120">local parallel (*‘localpar’*)</span></span>
- <span data-ttu-id="86ab5-121">Map Reduce</span><span class="sxs-lookup"><span data-stu-id="86ab5-121">Map Reduce</span></span>
- <span data-ttu-id="86ab5-122">Spark</span><span class="sxs-lookup"><span data-stu-id="86ab5-122">Spark</span></span>

<span data-ttu-id="86ab5-123">hello *'local'* 및 *'localpar'* 옵션 방법만 다릅니다 **rxExec** 호출이 실행 됩니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-123">hello *‘local’* and *‘localpar’* options differ only in how **rxExec** calls are executed.</span></span> <span data-ttu-id="86ab5-124">모두 실행 기타 rx 함수 호출 병렬 방식으로 모든 사용 가능한 코어 ScaleR hello 사용 하 여 달리 지정 되지 않은 **numCoresToUse** 옵션을 예를 들어 `rxOptions(numCoresToUse=6)`합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-124">They both execute other rx-function calls in a parallel manner across all available cores unless specified otherwise through use of hello ScaleR **numCoresToUse** option, for example `rxOptions(numCoresToUse=6)`.</span></span> <span data-ttu-id="86ab5-125">병렬 실행 옵션은 최적의 성능을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-125">Parallel execution options offer optimal performance.</span></span>

<span data-ttu-id="86ab5-126">다음 표에 hello를 hello를 다양 한 계산 컨텍스트 옵션 tooset는 호출을 실행 하는 방법을 요약 되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-126">hello following table summarizes hello various compute context options tooset how calls are executed:</span></span>

| <span data-ttu-id="86ab5-127">계산 컨텍스트</span><span class="sxs-lookup"><span data-stu-id="86ab5-127">Compute context</span></span>  | <span data-ttu-id="86ab5-128">어떻게 tooset</span><span class="sxs-lookup"><span data-stu-id="86ab5-128">How tooset</span></span>                      | <span data-ttu-id="86ab5-129">실행 컨텍스트</span><span class="sxs-lookup"><span data-stu-id="86ab5-129">Execution context</span></span>                        |
| ---------------- | ------------------------------- | ---------------------------------------- |
| <span data-ttu-id="86ab5-130">로컬 순차</span><span class="sxs-lookup"><span data-stu-id="86ab5-130">Local sequential</span></span> | <span data-ttu-id="86ab5-131">rxSetComputeContext('local')</span><span class="sxs-lookup"><span data-stu-id="86ab5-131">rxSetComputeContext(‘local’)</span></span>    | <span data-ttu-id="86ab5-132">직렬로 실행 됩니다 rxExec 호출을 제외 하 고 hello 지 노드 서버 hello 코어에서 병렬된 실행</span><span class="sxs-lookup"><span data-stu-id="86ab5-132">Parallelized execution across hello cores of hello edge node server, except for rxExec calls, which are executed serially</span></span> |
| <span data-ttu-id="86ab5-133">로컬 병렬</span><span class="sxs-lookup"><span data-stu-id="86ab5-133">Local parallel</span></span>   | <span data-ttu-id="86ab5-134">rxSetComputeContext('localpar')</span><span class="sxs-lookup"><span data-stu-id="86ab5-134">rxSetComputeContext(‘localpar’)</span></span> | <span data-ttu-id="86ab5-135">Hello 지 노드 서버 hello 코어에서 병렬된 실행</span><span class="sxs-lookup"><span data-stu-id="86ab5-135">Parallelized execution across hello cores of hello edge node server</span></span> |
| <span data-ttu-id="86ab5-136">Spark</span><span class="sxs-lookup"><span data-stu-id="86ab5-136">Spark</span></span>            | <span data-ttu-id="86ab5-137">RxSpark()</span><span class="sxs-lookup"><span data-stu-id="86ab5-137">RxSpark()</span></span>                       | <span data-ttu-id="86ab5-138">Hello HDI 클러스터의 hello 노드에서 Spark 통해 분산된 실행 평행 화</span><span class="sxs-lookup"><span data-stu-id="86ab5-138">Parallelized distributed execution via Spark across hello nodes of hello HDI cluster</span></span> |
| <span data-ttu-id="86ab5-139">Map Reduce</span><span class="sxs-lookup"><span data-stu-id="86ab5-139">Map Reduce</span></span>       | <span data-ttu-id="86ab5-140">RxHadoopMR()</span><span class="sxs-lookup"><span data-stu-id="86ab5-140">RxHadoopMR()</span></span>                    | <span data-ttu-id="86ab5-141">병렬 배포를 통해 실행 맵 감소 hello 노드에서 hello HDI 클러스터의</span><span class="sxs-lookup"><span data-stu-id="86ab5-141">Parallelized distributed execution via Map Reduce across hello nodes of hello HDI cluster</span></span> |

## <a name="guidelines-for-deciding-on-a-compute-context"></a><span data-ttu-id="86ab5-142">계산 컨텍스트를 결정하기 위한 지침</span><span class="sxs-lookup"><span data-stu-id="86ab5-142">Guidelines for deciding on a compute context</span></span>

<span data-ttu-id="86ab5-143">Hello 세 가지 옵션 중 선택 하면 병렬된 실행을 제공 하는 분석 작업, hello 크기 및 데이터의 hello 위치의 hello 특성에 따라 달라 집니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-143">Which of hello three options you choose that provide parallelized execution depends on hello nature of your analytics work, hello size, and hello location of your data.</span></span> <span data-ttu-id="86ab5-144">상황에 맞는 toouse 계산를 알려 주는 간단한 수식은 없습니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-144">There is no simple formula that tells you which compute context toouse.</span></span> <span data-ttu-id="86ab5-145">그러나 가지, hello 올바른 선택을 확인 하거나 적어도 벤치 마크를 실행 하기 전에 선택한 내용을 좁힐 하는 데 도움이 데 도움이 되는 몇 가지 원칙은 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-145">There are, however, some guiding principles that can help you make hello right choice, or, at least, help you narrow down your choices before you run a benchmark.</span></span> <span data-ttu-id="86ab5-146">기본 원칙은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-146">These guiding principles include:</span></span>

- <span data-ttu-id="86ab5-147">Linux 로컬 파일 시스템 hello HDFS 보다 빠릅니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-147">hello local Linux file system is faster than HDFS.</span></span>
- <span data-ttu-id="86ab5-148">Hello 데이터는 로컬, 및 XDF 중인 경우에 반복 된 분석 빠릅니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-148">Repeated analyses are faster if hello data is local, and if it's in XDF.</span></span>
- <span data-ttu-id="86ab5-149">되기 소량의 텍스트 데이터 원본에서 데이터를 toostream 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-149">It's preferable toostream small amounts of data from a text data source.</span></span> <span data-ttu-id="86ab5-150">데이터의 양을 hello 큰 경우 tooXDF 분석 하기 전에 변환 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-150">If hello amount of data is larger, convert it tooXDF before analysis.</span></span>
- <span data-ttu-id="86ab5-151">복사 하거나 분석을 위해 hello 데이터 toohello 가장자리 노드 스트리밍의 hello 오버 헤드가 매우 많은 양의 데이터에 대 한 어려워집니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-151">hello overhead of copying or streaming hello data toohello edge node for analysis becomes unmanageable for very large amounts of data.</span></span>
- <span data-ttu-id="86ab5-152">Hadoop의 분석의 경우 Spark가 Map Reduce보다 빠릅니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-152">Spark is faster than Map Reduce for analysis in Hadoop.</span></span>

<span data-ttu-id="86ab5-153">이러한 원칙은 들어 hello 다음 섹션에서는 제공 몇 가지 일반적인 규칙 경험에의 한 계산 컨텍스트를 선택 하기 위한 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-153">Given these principles, hello following sections offer some general rules of thumb for selecting a compute context.</span></span>

### <a name="local"></a><span data-ttu-id="86ab5-154">Local</span><span class="sxs-lookup"><span data-stu-id="86ab5-154">Local</span></span>
* <span data-ttu-id="86ab5-155">Hello 양의 데이터 tooanalyze 작고 경우 반복 되는 분석 하지 않아도, 다음 스트리밍되 hello 일상적인 사용 하 여 분석에 직접 *'local'* 또는 *'localpar'*합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-155">If hello amount of data tooanalyze is small and does not require repeated analysis, then stream it directly into hello analysis routine using *'local'* or *'localpar'*.</span></span>
* <span data-ttu-id="86ab5-156">Hello 양의 데이터 tooanalyze 작거나 중간 크기의 고 반복 되는 분석, 다음 toohello 로컬 파일 시스템 복사, tooXDF, 가져오기 및 분석을 통해 *'local'* 또는 *'localpar'*합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-156">If hello amount of data tooanalyze is small or medium-sized and requires repeated analysis, then copy it toohello local file system, import it tooXDF, and analyze it via *'local'* or *'localpar'*.</span></span>

### <a name="hadoop-spark"></a><span data-ttu-id="86ab5-157">Hadoop Spark</span><span class="sxs-lookup"><span data-stu-id="86ab5-157">Hadoop Spark</span></span>
* <span data-ttu-id="86ab5-158">Hello 양의 데이터 tooanalyze 크면 가져옵니다 tooa Spark 데이터 프레임을 사용 하 여 **RxHiveData** 또는 **RxParquetData**, 또는 HDFS에서 tooXDF (저장소 문제가 제외), Spark hello를 사용 하 여 분석 하 고 컨텍스트를 계산 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-158">If hello amount of data tooanalyze is large, then import it tooa Spark DataFrame using **RxHiveData** or **RxParquetData**, or tooXDF in HDFS (unless storage is an issue), and analyze it using hello Spark compute context.</span></span>

### <a name="hadoop-map-reduce"></a><span data-ttu-id="86ab5-159">Hadoop Map Reduce</span><span class="sxs-lookup"><span data-stu-id="86ab5-159">Hadoop Map Reduce</span></span>
* <span data-ttu-id="86ab5-160">일반적으로 느린 이므로 hello Spark 계산 컨텍스트는 극복할 수 문제가 발생 하는 경우에 hello 맵 감소 계산 컨텍스트를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-160">Use hello Map Reduce compute context only if you encounter an insurmountable problem with hello Spark compute context since it is generally slower.</span></span>  

## <a name="inline-help-on-rxsetcomputecontext"></a><span data-ttu-id="86ab5-161">rxSetComputeContext의 인라인 도움말</span><span class="sxs-lookup"><span data-stu-id="86ab5-161">Inline help on rxSetComputeContext</span></span>
<span data-ttu-id="86ab5-162">자세한 내용 및 ScaleR의 예제에 대 한 계산 컨텍스트 r에서에 대 한 도움말 hello rxSetComputeContext 메서드, 예를 들어 hello 인라인을 참조 하십시오.</span><span class="sxs-lookup"><span data-stu-id="86ab5-162">For more information and examples of ScaleR compute contexts, see hello inline help in R on hello rxSetComputeContext method, for example:</span></span>

    > ?rxSetComputeContext

<span data-ttu-id="86ab5-163">Toohello을 참조할 수 있습니다 "[ScaleR 분산 컴퓨팅 가이드](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)" hello에서 사용할 수 있는 것 [R 서버 MSDN](https://msdn.microsoft.com/library/mt674634.aspx "MSDN에 R Server") 라이브러리입니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-163">You can also refer toohello “[ScaleR Distributed Computing Guide](https://msdn.microsoft.com/microsoft-r/scaler-distributed-computing)” that's available from hello [R Server MSDN](https://msdn.microsoft.com/library/mt674634.aspx "R Server on MSDN") library.</span></span>

## <a name="next-steps"></a><span data-ttu-id="86ab5-164">다음 단계</span><span class="sxs-lookup"><span data-stu-id="86ab5-164">Next steps</span></span>
<span data-ttu-id="86ab5-165">이 문서에서는 배웠습니다 toospecify 사용할 수 있는 hello 옵션에 대 한 실행 hello 가장자리 노드 또는 HDInsight 클러스터의 코어에서 병렬 처리 여부 및 방법을 합니다.</span><span class="sxs-lookup"><span data-stu-id="86ab5-165">In this article, you learned about hello options that are available toospecify whether and how execution is parallelized across cores of hello edge node or HDInsight cluster.</span></span> <span data-ttu-id="86ab5-166">toolearn toouse HDInsight와 R 서버 클러스터에 대 한 자세한 hello 다음 항목을 참조 하세요.</span><span class="sxs-lookup"><span data-stu-id="86ab5-166">toolearn more about how toouse R Server with HDInsight clusters, see hello following topics:</span></span>

* [<span data-ttu-id="86ab5-167">Hadoop용 R 서버 개요</span><span class="sxs-lookup"><span data-stu-id="86ab5-167">Overview of R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-overview.md)
* [<span data-ttu-id="86ab5-168">Hadoop용 R Server 시작</span><span class="sxs-lookup"><span data-stu-id="86ab5-168">Get started with R Server for Hadoop</span></span>](hdinsight-hadoop-r-server-get-started.md)
* [<span data-ttu-id="86ab5-169">RStudio 서버 tooHDInsight 추가 (클러스터 생성 중에 추가 되지) 하는 경우</span><span class="sxs-lookup"><span data-stu-id="86ab5-169">Add RStudio Server tooHDInsight (if not added during cluster creation)</span></span>](hdinsight-hadoop-r-server-install-r-studio.md)
* [<span data-ttu-id="86ab5-170">HDInsight에서 R Server의 Azure Storage 옵션</span><span class="sxs-lookup"><span data-stu-id="86ab5-170">Azure Storage options for R Server on HDInsight</span></span>](hdinsight-hadoop-r-server-storage.md)

