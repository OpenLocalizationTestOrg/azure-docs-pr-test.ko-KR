---
title: "Azure HDInsight의 aaaIntroduction tooSpark | Microsoft Docs"
description: "이 문서는 HDInsight의 Spark 클러스터를 사용할 수 있는 HDInsight 및 hello 다른 시나리오에 소개 tooSpark를 제공 합니다."
keywords: "apache spark, spark 클러스터, 소개 toospark 이란 hdinsight의 spark"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 82334b9e-4629-4005-8147-19f875c8774e
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: get-started-article
ms.date: 05/12/2017
ms.author: nitinme
ms.openlocfilehash: 41996e733618b8534469fa239b980ac50161a535
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="introduction-toospark-on-hdinsight"></a><span data-ttu-id="4cad9-104">HDInsight의 tooSpark 소개</span><span class="sxs-lookup"><span data-stu-id="4cad9-104">Introduction tooSpark on HDInsight</span></span>

<span data-ttu-id="4cad9-105">이 문서는 소개 tooSpark HDInsight에 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-105">This article provides you with an introduction tooSpark on HDInsight.</span></span> <span data-ttu-id="4cad9-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> 빅 데이터 분석 응용 프로그램의 tooboost hello 성능을 처리에서 메모리를 지 원하는 오픈 소스 병렬 처리 프레임 워크입니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-106"><a href="http://spark.apache.org/" target="_blank">Apache Spark</a> is an open-source parallel processing framework that supports in-memory processing tooboost hello performance of big-data analytic applications.</span></span> <span data-ttu-id="4cad9-107">HDInsight의 Spark 클러스터는 Azure Storage(WASB) 및 Azure Data Lake Store와 호환되므로 Azure에 저장된 기존 데이터를 Spark 클러스터를 통해 쉽게 처리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-107">Spark cluster on HDInsight is compatible with Azure Storage (WASB) as well as Azure Data Lake Store so your existing data stored in Azure can easily be processed via a Spark cluster.</span></span>

<span data-ttu-id="4cad9-108">HDInsight의 Spark 클러스터를 만들면 Spark가 설치되고 구성된 Azure 계산 리소스를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-108">When you create a Spark cluster on HDInsight, you create Azure compute resources with Spark installed and configured.</span></span> <span data-ttu-id="4cad9-109">HDInsight의 Spark는 toocreate 클러스터는 약 10 분 걸리는.</span><span class="sxs-lookup"><span data-stu-id="4cad9-109">It only takes about ten minutes toocreate a Spark cluster in HDInsight.</span></span> <span data-ttu-id="4cad9-110">처리 하는 hello 데이터 toobe Azure 데이터 레이크 저장소 또는 Azure 저장소에 저장 됩니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-110">hello data toobe processed is stored in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="4cad9-111">[HDInsight에서 Azure Storage 사용](hdinsight-hadoop-use-blob-storage.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="4cad9-111">See [Use Azure Storage with HDInsight](hdinsight-hadoop-use-blob-storage.md).</span></span>

<span data-ttu-id="4cad9-112">**HDInsight의 Spark는 toocreate 클러스터**, 참조 [퀵 스타트: Jupyter를 사용 하 여 대화형 쿼리를 실행 하 고 HDInsight의 Spark 클러스터를 만듭니다](hdinsight-apache-spark-jupyter-spark-sql.md)합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-112">**toocreate a Spark cluster on HDInsight**, see [QuickStart: create a Spark cluster on HDInsight and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>


## <a name="what-is-apache-spark-on-azure-hdinsight"></a><span data-ttu-id="4cad9-113">Azure HDInsight의 Apache Spark란?</span><span class="sxs-lookup"><span data-stu-id="4cad9-113">What is Apache Spark on Azure HDInsight?</span></span>
<span data-ttu-id="4cad9-114">HDInsight의 Spark 클러스터는 완벽하게 관리되는 Spark 서비스를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-114">Spark clusters on HDInsight offer a fully managed Spark service.</span></span> <span data-ttu-id="4cad9-115">HDInsight의 Spark 클러스터를 만드는 이점은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-115">Benefits of creating a Spark cluster on HDInsight are listed here.</span></span>

| <span data-ttu-id="4cad9-116">기능</span><span class="sxs-lookup"><span data-stu-id="4cad9-116">Feature</span></span> | <span data-ttu-id="4cad9-117">설명</span><span class="sxs-lookup"><span data-stu-id="4cad9-117">Description</span></span> |
| --- | --- |
| <span data-ttu-id="4cad9-118">손쉬운 Spark 클러스터 만들기</span><span class="sxs-lookup"><span data-stu-id="4cad9-118">Ease of creating Spark clusters</span></span> |<span data-ttu-id="4cad9-119">Hello Azure 포털, Azure PowerShell 또는 hello HDInsight.NET SDK를 사용 하 여 분에 HDInsight의 Spark 클러스터를 새를 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-119">You can create a new Spark cluster on HDInsight in minutes using hello Azure Portal, Azure PowerShell, or hello HDInsight .NET SDK.</span></span> <span data-ttu-id="4cad9-120">[HDInsight에서 Spark 클러스터 시작](hdinsight-apache-spark-jupyter-spark-sql.md)</span><span class="sxs-lookup"><span data-stu-id="4cad9-120">See [Get started with Spark cluster in HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md)</span></span> |
| <span data-ttu-id="4cad9-121">사용 편의성</span><span class="sxs-lookup"><span data-stu-id="4cad9-121">Ease of use</span></span> |<span data-ttu-id="4cad9-122">HDInsight의 Spark 클러스터에는 Jupyter 및 Zeppelin 노트북이 포함되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-122">Spark cluster in HDInsight include Jupyter and Zeppelin notebooks.</span></span> <span data-ttu-id="4cad9-123">대화형 데이터 처리 및 시각화에 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-123">You can use these for interactive data processing and visualization.</span></span>|
| <span data-ttu-id="4cad9-124">REST API</span><span class="sxs-lookup"><span data-stu-id="4cad9-124">REST APIs</span></span> |<span data-ttu-id="4cad9-125">HDInsight의 Spark 클러스터 포함 [리비](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), REST API 기반 Spark 작업 서버 tooremotely 전송 및 모니터 작업 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-125">Spark clusters in HDInsight include [Livy](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server), a REST API-based Spark job server tooremotely submit and monitor jobs.</span></span> |
| <span data-ttu-id="4cad9-126">Azure Data Lake 저장소에 대한 지원</span><span class="sxs-lookup"><span data-stu-id="4cad9-126">Support for Azure Data Lake Store</span></span> | <span data-ttu-id="4cad9-127">HDInsight의 Spark 클러스터에는 추가 저장소는 물론 (3.5 HDInsight 클러스터)에 주 저장소로 구성 된 toouse Azure 데이터 레이크 저장소 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-127">Spark cluster on HDInsight can be configured toouse Azure Data Lake Store as an additional storage, as well as primary storage (only with HDInsight 3.5 clusters) .</span></span> <span data-ttu-id="4cad9-128">Data Lake 저장소에 대한 자세한 내용은 [Azure Data Lake 저장소 개요](../data-lake-store/data-lake-store-overview.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="4cad9-128">For more information on Data Lake Store, see [Overview of Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md).</span></span> |
| <span data-ttu-id="4cad9-129">Azure 서비스와의 통합</span><span class="sxs-lookup"><span data-stu-id="4cad9-129">Integration with Azure services</span></span> |<span data-ttu-id="4cad9-130">HDInsight의 Spark 클러스터 커넥터 tooAzure 이벤트 허브 함께 제공 됩니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-130">Spark cluster on HDInsight comes with a connector tooAzure Event Hubs.</span></span> <span data-ttu-id="4cad9-131">고객 또한 너무 hello 이벤트 허브를 사용 하는 스트리밍 응용 프로그램을 빌드할 수[Kafka](http://kafka.apache.org/)를 이미 사용 하지 않는 Spark의 일환으로 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-131">Customers can build streaming applications using hello Event Hubs, in addition too[Kafka](http://kafka.apache.org/), which is already available as part of Spark.</span></span> |
| <span data-ttu-id="4cad9-132">R 서버에 대한 지원</span><span class="sxs-lookup"><span data-stu-id="4cad9-132">Support for R Server</span></span> | <span data-ttu-id="4cad9-133">HDInsight Spark 클러스터 toorun hello 속도 약속 Spark 클러스터와 함께 R 계산 배포에서 R 서버를 설정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-133">You can set up a R Server on HDInsight Spark cluster toorun distributed R computations with hello speeds promised with a Spark cluster.</span></span> <span data-ttu-id="4cad9-134">자세한 내용은 [HDInsight에서 R 서버 시작](hdinsight-hadoop-r-server-get-started.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="4cad9-134">For more information, see [Get started using R Server on HDInsight](hdinsight-hadoop-r-server-get-started.md).</span></span> |
| <span data-ttu-id="4cad9-135">타사 IDE와의 통합</span><span class="sxs-lookup"><span data-stu-id="4cad9-135">Integration with third-party IDEs</span></span> | <span data-ttu-id="4cad9-136">HDInsight은 IntelliJ 아이디어 등 toocreate를 사용할 수 있으며 응용 프로그램 tooan HDInsight Spark 클러스터를 제출 Eclipse Ide에 대 한 플러그 인을 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-136">HDInsight provides plugins for IDEs like IntelliJ IDEA and Eclipse that you can use toocreate and submit applications tooan HDInsight Spark cluster.</span></span> <span data-ttu-id="4cad9-137">자세한 내용은 [IntelliJ IDEA용 Azure 도구 키트 사용](hdinsight-apache-spark-intellij-tool-plugin.md) 및 [Eclipse용 Azure 도구 키트 사용](hdinsight-apache-spark-eclipse-tool-plugin.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="4cad9-137">For more information see [Use Azure Toolkit for IntelliJ IDEA](hdinsight-apache-spark-intellij-tool-plugin.md) and [Use Azure Toolkit for Eclipse](hdinsight-apache-spark-eclipse-tool-plugin.md).</span></span>|
| <span data-ttu-id="4cad9-138">동시 쿼리</span><span class="sxs-lookup"><span data-stu-id="4cad9-138">Concurrent Queries</span></span> |<span data-ttu-id="4cad9-139">HDInsight의 Spark 클러스터는 동시 쿼리를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-139">Spark clusters in HDInsight support concurrent queries.</span></span> <span data-ttu-id="4cad9-140">이렇게 하면 한 사용자 또는 다양 한 사용자의 여러 쿼리를 여러 개의 쿼리 및 응용 프로그램 tooshare hello 같은 클러스터 리소스입니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-140">This enables multiple queries from one user or multiple queries from various users and applications tooshare hello same cluster resources.</span></span> |
| <span data-ttu-id="4cad9-141">SSD에서 캐시</span><span class="sxs-lookup"><span data-stu-id="4cad9-141">Caching on SSDs</span></span> |<span data-ttu-id="4cad9-142">Ssd toohello 클러스터 노드를 연결 하거나 하나를 선택할 수 toocache 데이터 메모리에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-142">You can choose toocache data either in memory or in SSDs attached toohello cluster nodes.</span></span> <span data-ttu-id="4cad9-143">메모리에 캐시 hello 최고의 쿼리 성능을 제공 하지만 비용이 많이 드는; 수 Ssd의 캐싱 hello 필요 toocreate 필요한 toofit hello 전체 데이터 집합을 메모리 크기의 클러스터 없이 쿼리 성능 향상을 위한 훌륭한 옵션을 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-143">Caching in memory provides hello best query performance but could be expensive; caching in SSDs provides a great option for improving query performance without hello need toocreate a cluster of a size that is required toofit hello entire dataset in memory.</span></span> |
| <span data-ttu-id="4cad9-144">BI 도구와의 통합</span><span class="sxs-lookup"><span data-stu-id="4cad9-144">Integration with BI Tools</span></span> |<span data-ttu-id="4cad9-145">HDInsight의 Spark 클러스터는 데이터 분석을 위해 [Power BI](http://www.powerbi.com/) 및 [Tableau](http://www.tableau.com/products/desktop)와 같은 BI 도구용 커넥터를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-145">Spark clusters on HDInsight provide connectors for  BI tools such as [Power BI](http://www.powerbi.com/) and [Tableau](http://www.tableau.com/products/desktop) for data analytics.</span></span> |
| <span data-ttu-id="4cad9-146">미리 로드된 Anaconda 라이브러리</span><span class="sxs-lookup"><span data-stu-id="4cad9-146">Pre-loaded Anaconda libraries</span></span> |<span data-ttu-id="4cad9-147">HDInsight에서 Spark 클러스터는 미리 설치된 Anaconda 라이브러리와 함께 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-147">Spark clusters on HDInsight come with Anaconda libraries pre-installed.</span></span> <span data-ttu-id="4cad9-148">[Anaconda](http://docs.continuum.io/anaconda/) 는 기계 학습, 데이터 분석, 시각화 등 닫기 too200 라이브러리를 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-148">[Anaconda](http://docs.continuum.io/anaconda/) provides close too200 libraries for machine learning, data analysis, visualization, etc.</span></span> |
| <span data-ttu-id="4cad9-149">확장성</span><span class="sxs-lookup"><span data-stu-id="4cad9-149">Scalability</span></span> |<span data-ttu-id="4cad9-150">만드는 동안 클러스터의 노드 수가 hello를 지정할 수, 있지만 toogrow 원하는 또는 hello 클러스터 toomatch 작업 축소 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-150">Although you can specify hello number of nodes in your cluster during creation, you may want toogrow or shrink hello cluster toomatch workload.</span></span> <span data-ttu-id="4cad9-151">모든 HDInsight 클러스터 hello 클러스터의 노드 toochange hello 수를 허용합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-151">All HDInsight clusters allow you toochange hello number of nodes in hello cluster.</span></span> <span data-ttu-id="4cad9-152">또한 Spark 클러스터 모든 hello 데이터는 Azure 저장소 서비스 또는 데이터 레이크 저장소에 저장 되므로 데이터의 손실 없이 삭제할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-152">Also, Spark clusters can be dropped with no loss of data since all hello data is stored in Azure Storage or Data Lake Store.</span></span> |
| <span data-ttu-id="4cad9-153">24/7 지원</span><span class="sxs-lookup"><span data-stu-id="4cad9-153">24/7 Support</span></span> |<span data-ttu-id="4cad9-154">HDInsight의 Spark 클러스터는 24/7 엔터프라이즈 수준 지원 및 99.9% 가동 시간 SLA와 함께 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-154">Spark clusters on HDInsight come with  enterprise-level 24/7 support and an SLA of 99.9% up-time.</span></span> |

## <a name="what-are-hello-use-cases-for-spark-on-hdinsight"></a><span data-ttu-id="4cad9-155">HDInsight의 Spark에 대 한 hello 사용 사례는 무엇입니까?</span><span class="sxs-lookup"><span data-stu-id="4cad9-155">What are hello use cases for Spark on HDInsight?</span></span>
<span data-ttu-id="4cad9-156">HDInsight의 Spark 클러스터 hello 다음 주요 시나리오를 사용 하도록 설정 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-156">Spark clusters in HDInsight enable hello following key scenarios.</span></span>

### <a name="interactive-data-analysis-and-bi"></a><span data-ttu-id="4cad9-157">대화형 데이터 분석 및 BI</span><span class="sxs-lookup"><span data-stu-id="4cad9-157">Interactive data analysis and BI</span></span>
[<span data-ttu-id="4cad9-158">자습서 살펴보기</span><span class="sxs-lookup"><span data-stu-id="4cad9-158">Look at a tutorial</span></span>](hdinsight-apache-spark-use-bi-tools.md)

<span data-ttu-id="4cad9-159">HDInsight의 Apache Spark는 Azure Storage 또는 Azure Data Lake Store에 데이터를 저장합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-159">Apache Spark in HDInsight stores data in Azure Storage or Azure Data Lake Store.</span></span> <span data-ttu-id="4cad9-160">비즈니스 전문가 주요 의사 결정권자 분석 및 해당 데이터에 대해 보고서를 작성 하 고 수 hello 분석 데이터에서 Microsoft Power BI toobuild 대화형 보고서를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-160">Business experts and key decision makers can analyze and build reports over that data and use Microsoft Power BI toobuild interactive reports from hello analyzed data.</span></span> <span data-ttu-id="4cad9-161">분석가는 클러스터 저장소의 구조화 되지 않은/반 구조화 된 데이터에서 시작 하 고 전자 필기장을 사용 하 여 hello 데이터에 대 한 스키마를 정의 하 고 Microsoft Power BI를 사용 하 여 데이터 모델을 작성할 수 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-161">Analysts can start from unstructured/semi structured data in cluster storage, define a schema for hello data using notebooks, and then build data models using Microsoft Power BI.</span></span> <span data-ttu-id="4cad9-162">또한 HDInsight의 Spark 클러스터는 데이터 분석자, 비즈니스 전문가 및 주요 의사 결정권자를 위한 이상적인 플랫폼을 만드는 Tableau와 같은 여러 타사 BI 도구를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-162">Spark clusters in HDInsight also support a number of third party BI tools such as Tableau making it an ideal platform for data analysts, business experts, and key decision makers.</span></span>

### <a name="spark-machine-learning"></a><span data-ttu-id="4cad9-163">Spark 기계 학습</span><span class="sxs-lookup"><span data-stu-id="4cad9-163">Spark Machine Learning</span></span>
[<span data-ttu-id="4cad9-164">자습서 살펴보기: HVAC 데이터를 사용하여 건물 온도 예측</span><span class="sxs-lookup"><span data-stu-id="4cad9-164">Look at a tutorial: Predict building temperatures uisng HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)

[<span data-ttu-id="4cad9-165">자습서 살펴보기: 음식 검사 결과 예측</span><span class="sxs-lookup"><span data-stu-id="4cad9-165">Look at a tutorial: Predict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)

<span data-ttu-id="4cad9-166">Apache Spark는 [MLlib](http://spark.apache.org/mllib/), 즉 Spark를 기반으로 하여 빌드되어 HDInsight의 Spark 클러스터에서 사용할 수 있는 기계 학습 라이브러리와 함께 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-166">Apache Spark comes with [MLlib](http://spark.apache.org/mllib/), a machine learning library built on top of Spark that you can use from a Spark cluster in HDInsight.</span></span> <span data-ttu-id="4cad9-167">HDInsight의 Spark 클러스터에는 기계 학습을 위한 다양한 패키지가 포함된 Python 배포인 Anaconda도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-167">Spark cluster on HDInsight also includes Anaconda, a Python distribution with a variety of packages for machine learning.</span></span> <span data-ttu-id="4cad9-168">Jupyter 및 Zeppelin 노트북이 기본 제공되는 지원 기능과 결합하고, 기계 학습 응용 프로그램을 만들기 위한 최고의 환경을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-168">Couple this with a built-in support for Jupyter and Zeppelin notebooks, and you have a top-of-the-line environment for creating machine learning applications.</span></span>

### <a name="spark-streaming-and-real-time-data-analysis"></a><span data-ttu-id="4cad9-169">Spark 스트리밍 및 실시간 데이터 분석</span><span class="sxs-lookup"><span data-stu-id="4cad9-169">Spark streaming and real-time data analysis</span></span>
[<span data-ttu-id="4cad9-170">자습서 살펴보기</span><span class="sxs-lookup"><span data-stu-id="4cad9-170">Look at a tutorial</span></span>](hdinsight-apache-spark-eventhub-streaming.md)

<span data-ttu-id="4cad9-171">HDInsight의 Spark 클러스터는 실시간 분석 솔루션을 빌드하기 위한 풍부한 지원을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-171">Spark clusters in HDInsight offer a rich support for building real-time analytics solutions.</span></span> <span data-ttu-id="4cad9-172">Spark 커넥터 tooingest 데이터 Kafka, Flume, Twitter, ZeroMQ, 또는 TCP 소켓 같은 여러 소스에서 이미, HDInsight의 Spark에는 Azure 이벤트 허브에서 데이터를 수집 하는 방법에 대 한 첫 번째 클래스 지원을 추가 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-172">While Spark already has connectors tooingest data from many sources like Kafka, Flume, Twitter, ZeroMQ, or TCP sockets, Spark in HDInsight adds first-class support for ingesting data from Azure Event Hubs.</span></span> <span data-ttu-id="4cad9-173">이벤트 허브는 hello azure 큐 서비스에 가장 많이 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-173">Event Hubs are hello most widely used queuing service on Azure.</span></span> <span data-ttu-id="4cad9-174">Event Hubs에 대한 즉각적인 지원을 통해 HDInsight의 Spark 클러스터는 실시간 분석 파이프라인을 빌드하기 위한 이상적인 플랫폼이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-174">Having an out-of-the-box support for Event Hubs makes Spark clusters in HDInsight an ideal platform for building real time analytics pipeline.</span></span>

## <span data-ttu-id="4cad9-175"><a name="next-steps"></a>Spark 클러스터의 일부로 포함된 구성 요소</span><span class="sxs-lookup"><span data-stu-id="4cad9-175"><a name="next-steps"></a>What components are included as part of a Spark cluster?</span></span>
<span data-ttu-id="4cad9-176">HDInsight의 Spark 클러스터에는 다음과 같은 구성 요소가 기본적으로 hello 클러스터에서 사용할 수 있는 hello를 포함 됩니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-176">Spark clusters in HDInsight include hello following components that are available on hello clusters by default.</span></span>

* <span data-ttu-id="4cad9-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span><span class="sxs-lookup"><span data-stu-id="4cad9-177">[Spark Core](https://spark.apache.org/docs/1.5.1/).</span></span> <span data-ttu-id="4cad9-178">Spark Core, Spark SQL, Spark 스트리밍 API, GraphX 및 MLlib가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-178">Includes Spark Core, Spark SQL, Spark streaming APIs, GraphX, and MLlib.</span></span>
* [<span data-ttu-id="4cad9-179">Anaconda</span><span class="sxs-lookup"><span data-stu-id="4cad9-179">Anaconda</span></span>](http://docs.continuum.io/anaconda/)
* [<span data-ttu-id="4cad9-180">Livy</span><span class="sxs-lookup"><span data-stu-id="4cad9-180">Livy</span></span>](https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server)
* [<span data-ttu-id="4cad9-181">Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="4cad9-181">Jupyter notebook</span></span>](https://jupyter.org)
* [<span data-ttu-id="4cad9-182">Zeppelin Notebook</span><span class="sxs-lookup"><span data-stu-id="4cad9-182">Zeppelin notebook</span></span>](http://zeppelin-project.org/)

<span data-ttu-id="4cad9-183">HDInsight의 Spark 클러스터 제공는 [ODBC 드라이버](http://go.microsoft.com/fwlink/?LinkId=616229) Microsoft Power BI 및 Tableau와 같은 BI 도구에서 HDInsight의 연결 tooSpark 클러스터에 대 한 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-183">Spark clusters on HDInsight also provide an [ODBC driver](http://go.microsoft.com/fwlink/?LinkId=616229) for connectivity tooSpark clusters in HDInsight from BI tools such as Microsoft Power BI and Tableau.</span></span>

## <a name="where-do-i-start"></a><span data-ttu-id="4cad9-184">시작 단계</span><span class="sxs-lookup"><span data-stu-id="4cad9-184">Where do I start?</span></span>
<span data-ttu-id="4cad9-185">HDInsight의 Spark 클러스터를 만드는 것으로 시작합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-185">Start with creating a Spark cluster on HDInsight.</span></span> <span data-ttu-id="4cad9-186">[빠른 시작: HDInsight Linux에서 Spark 클러스터 만들기 및 Jupyter를 사용하여 대화형 쿼리 실행](hdinsight-apache-spark-jupyter-spark-sql.md).을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="4cad9-186">See [QuickStart: create a Spark cluster on HDInsight Linux and run interactive query using Jupyter](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> 

## <a name="next-steps"></a><span data-ttu-id="4cad9-187">다음 단계</span><span class="sxs-lookup"><span data-stu-id="4cad9-187">Next Steps</span></span>
### <a name="scenarios"></a><span data-ttu-id="4cad9-188">시나리오</span><span class="sxs-lookup"><span data-stu-id="4cad9-188">Scenarios</span></span>
* [<span data-ttu-id="4cad9-189">BI와 Spark: BI 도구와 함께 HDInsight에서 Spark를 사용하여 대화형 데이터 분석 수행</span><span class="sxs-lookup"><span data-stu-id="4cad9-189">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="4cad9-190">기계 학습과 Spark: HVAC 데이터를 사용하여 건물 온도를 분석하는 데 HDInsight의 Spark 사용</span><span class="sxs-lookup"><span data-stu-id="4cad9-190">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="4cad9-191">Spark와 기계 학습: HDInsight toopredict 음식 검사 결과에 사용 하 여 Spark</span><span class="sxs-lookup"><span data-stu-id="4cad9-191">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="4cad9-192">Spark 스트리밍: HDInsight에서 Spark를 사용하여 실시간 스트리밍 응용 프로그램 빌드</span><span class="sxs-lookup"><span data-stu-id="4cad9-192">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="4cad9-193">HDInsight의 Spark를 사용하여 웹 사이트 로그 분석</span><span class="sxs-lookup"><span data-stu-id="4cad9-193">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="4cad9-194">응용 프로그램 만들기 및 실행</span><span class="sxs-lookup"><span data-stu-id="4cad9-194">Create and run applications</span></span>
* [<span data-ttu-id="4cad9-195">Scala를 사용하여 독립 실행형 응용 프로그램 만들기</span><span class="sxs-lookup"><span data-stu-id="4cad9-195">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="4cad9-196">Livy를 사용하여 Spark 클러스터에서 원격으로 작업 실행</span><span class="sxs-lookup"><span data-stu-id="4cad9-196">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="4cad9-197">도구 및 확장</span><span class="sxs-lookup"><span data-stu-id="4cad9-197">Tools and extensions</span></span>
* [<span data-ttu-id="4cad9-198">IntelliJ 아이디어 toocreate에 대 한 HDInsight 도구 플러그 인을 사용 하 고 스파크 Scala 개 제출</span><span class="sxs-lookup"><span data-stu-id="4cad9-198">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applicatons</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="4cad9-199">IntelliJ 아이디어 toodebug Spark 응용 프로그램에 대 한 HDInsight 도구 플러그 인을 원격으로 사용</span><span class="sxs-lookup"><span data-stu-id="4cad9-199">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="4cad9-200">HDInsight에서 Spark 클러스터와 함께 Zeppelin Notebook 사용</span><span class="sxs-lookup"><span data-stu-id="4cad9-200">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="4cad9-201">HDInsight의 Spark 클러스터에서 Jupyter Notebook에 사용할 수 있는 커널</span><span class="sxs-lookup"><span data-stu-id="4cad9-201">Kernels available for Jupyter notebook in Spark cluster for HDInsight</span></span>](hdinsight-apache-spark-jupyter-notebook-kernels.md)
* [<span data-ttu-id="4cad9-202">Jupyter 노트북에서 외부 패키지 사용</span><span class="sxs-lookup"><span data-stu-id="4cad9-202">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="4cad9-203">Jupyter 사용자 컴퓨터에 설치 하 고 tooan HDInsight Spark 클러스터를 연결 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-203">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="4cad9-204">리소스 관리</span><span class="sxs-lookup"><span data-stu-id="4cad9-204">Manage resources</span></span>
* [<span data-ttu-id="4cad9-205">Azure HDInsight의 Apache Spark 클러스터 hello에 대 한 리소스를 관리 합니다.</span><span class="sxs-lookup"><span data-stu-id="4cad9-205">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="4cad9-206">HDInsight의 Apache Spark 클러스터에서 실행되는 작업 추적 및 디버그</span><span class="sxs-lookup"><span data-stu-id="4cad9-206">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
* <span data-ttu-id="4cad9-207">[Azure HDInsight의 Apache Spark에 대해 알려진 문제](hdinsight-apache-spark-known-issues.md)</span><span class="sxs-lookup"><span data-stu-id="4cad9-207">[Known issues of Apache Spark in Azure HDInsight](hdinsight-apache-spark-known-issues.md).</span></span>
