---
title: "Microsoft Azure Service Fabric에 대한 일반적인 질문 | Microsoft Docs"
description: "다음은 Service Fabric에 대해 자주 묻는 몇 가지 질문과 그에 대한 답변입니다."
services: service-fabric
documentationcenter: .net
author: chackdan
manager: timlt
editor: 
ms.assetid: 5a179703-ff0c-4b8e-98cd-377253295d12
ms.service: service-fabric
ms.devlang: dotnet
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: na
ms.date: 08/18/2017
ms.author: chackdan
ms.openlocfilehash: ee1fe4e83ce796fd50b779c0880701b9dfcefff7
ms.sourcegitcommit: 50e23e8d3b1148ae2d36dad3167936b4e52c8a23
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 08/18/2017
---
# <a name="commonly-asked-service-fabric-questions"></a><span data-ttu-id="53144-103">Service Fabric에 대해 자주 묻는 질문</span><span class="sxs-lookup"><span data-stu-id="53144-103">Commonly asked Service Fabric questions</span></span>

<span data-ttu-id="53144-104">Service Fabric으로 수행할 수 있는 작업 및 사용 방법에 대한 여러 가지 자주 묻는 질문이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-104">There are many commonly asked questions about what Service Fabric can do and how it should be used.</span></span> <span data-ttu-id="53144-105">이 문서에서는 자주 묻는 질문 및 그에 대한 답변을 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-105">This document covers many of those common questions and their answers.</span></span>

## <a name="cluster-setup-and-management"></a><span data-ttu-id="53144-106">클러스터 설정 및 관리</span><span class="sxs-lookup"><span data-stu-id="53144-106">Cluster setup and management</span></span>

### <a name="can-i-create-a-cluster-that-spans-multiple-azure-regions-or-my-own-datacenters"></a><span data-ttu-id="53144-107">여러 Azure 지역 또는 나만의 데이터 센터에 걸쳐서 클러스터를 만들 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="53144-107">Can I create a cluster that spans multiple Azure regions or my own datacenters?</span></span>

<span data-ttu-id="53144-108">예.</span><span class="sxs-lookup"><span data-stu-id="53144-108">Yes.</span></span> 

<span data-ttu-id="53144-109">코어 Service Fabric 클러스터링 기술은 서로 네트워크로 연결되어 있기만 한다면 전 세계 어디서나 실행되는 컴퓨터를 결합하는 데 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-109">The core Service Fabric clustering technology can be used to combine machines running anywhere in the world, so long as they have network connectivity to each other.</span></span> <span data-ttu-id="53144-110">그러나 이러한 클러스터를 구축하고 실행하는 것은 복잡할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-110">However, building and running such a cluster can be complicated.</span></span>

<span data-ttu-id="53144-111">이 시나리오에 관심이 있는 경우 [Service Fabric Github 문제 목록](https://github.com/azure/service-fabric-issues)을 확인하거나 지원 담당자를 통해 추가 지침을 얻는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-111">If you are interested in this scenario, we encourage you to get in contact either through the [Service Fabric Github Issues List](https://github.com/azure/service-fabric-issues) or through your support representative in order to obtain additional guidance.</span></span> <span data-ttu-id="53144-112">Service Fabric 팀은 이 시나리오에 대해 추가적인 설명, 지침 및 권장 사항을 제공하기 위해 작업 중입니다.</span><span class="sxs-lookup"><span data-stu-id="53144-112">The Service Fabric team is working to provide additional clarity, guidance, and recommendations for this scenario.</span></span> 

<span data-ttu-id="53144-113">고려할 사항은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-113">Some things to consider:</span></span> 

1. <span data-ttu-id="53144-114">현재 Azure에서 Service Fabric 클러스터 리소스는 클러스터가 작성된 가상 컴퓨터 크기 집합이므로 지역에 국한됩니다.</span><span class="sxs-lookup"><span data-stu-id="53144-114">The Service Fabric cluster resource in Azure is regional today, as are the virtual machine scale sets that the cluster is built on.</span></span> <span data-ttu-id="53144-115">즉, 하위 지역에서 오류가 발생할 때 Azure Resource Manager 또는 Azure Portal을 통해 클러스터를 관리하지 못하게 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-115">This means that in the event of a regional failure you may lose the ability to manage the cluster via the Azure Resource Manager or the Azure Portal.</span></span> <span data-ttu-id="53144-116">클러스터는 계속 실행되는데도 이러한 문제가 발생할 수도 있으며, 이 경우 직접 개입하는 것이 나을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-116">This can happen even though the cluster remains running and you'd be able to interact with it directly.</span></span> <span data-ttu-id="53144-117">또한 현재 Azure에서는 하위 지역에 걸쳐 사용할 수 있는 단일 가상 네트워크를 유지하는 기능을 제공하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-117">In addition, Azure today does not offer the ability to have a single virtual network that is usable across regions.</span></span> <span data-ttu-id="53144-118">즉, Azure의 다중 지역 클러스터에는 [VM Scale Sets의 각 VM에 대한 공용 IP 주소](../virtual-machine-scale-sets/virtual-machine-scale-sets-networking.md#public-ipv4-per-virtual-machine) 또는 [Azure VPN Gateway](../vpn-gateway/vpn-gateway-about-vpngateways.md)가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-118">This means that a multi-region cluster in Azure requires either [Public IP Addresses for each VM in the VM Scale Sets](../virtual-machine-scale-sets/virtual-machine-scale-sets-networking.md#public-ipv4-per-virtual-machine) or [Azure VPN Gateways](../vpn-gateway/vpn-gateway-about-vpngateways.md).</span></span> <span data-ttu-id="53144-119">이러한 네트워킹 선택 항목은 비용, 성능 및 응용 프로그램 디자인에 어느 정도 다르게 영향을 미치므로 이러한 환경을 구성하기 전에 신중하게 분석하고 계획해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-119">These networking choices have different impacts on costs, performance, and to some degree application design, so careful analysis and planning is required before standing up such an environment.</span></span>
2. <span data-ttu-id="53144-120">이러한 컴퓨터의 유지 관리, 관리, 모니터링은 복잡할 수 있으며 다른 클라우드 공급자 간 또는 온-프레미스 리소스와 Azure 간 등, 여러 환경 _유형_ 간에 걸쳐 있는 경우에는 특히 복잡할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-120">The maintenance, management, and monitoring of these machines can become complicated, especially when spanned across _types_ of environments, such as between different cloud providers or between on-premises resources and Azure.</span></span> <span data-ttu-id="53144-121">이러한 환경에서 프로덕션 워크로드를 실행하기 전에 클러스터 및 응용 프로그램 둘 다에 대해 업그레이드, 모니터링, 관리 및 진단을 파악하도록 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-121">Care must be taken to ensure that upgrades, monitoring, management, and diagnostics are understood for both the cluster and the applications before running production workloads in such an environment.</span></span> <span data-ttu-id="53144-122">Azure에서 또는 자체 데이터 센터 내에서 이러한 문제를 여러 번 해결해본 적이 있으면 Service Fabric 클러스터를 구축하거나 실행할 때도 이러한 동일한 해결 방법을 적용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-122">If you already have lots of experience solving these problems in Azure or within your own datacenters, then it is likely that those same solutions can be applied when building out or running your Service Fabric cluster.</span></span> 

### <a name="do-service-fabric-nodes-automatically-receive-os-updates"></a><span data-ttu-id="53144-123">Service Fabric 노드에서 OS 업데이트를 자동으로 수신하나요?</span><span class="sxs-lookup"><span data-stu-id="53144-123">Do Service Fabric nodes automatically receive OS updates?</span></span>

<span data-ttu-id="53144-124">당장은 아니지만, 이것 역시 Azure에서 제공하고자 하는 일반적인 요청입니다.</span><span class="sxs-lookup"><span data-stu-id="53144-124">Not today, but this is also a common request that Azure intends to deliver.</span></span>

<span data-ttu-id="53144-125">일단 Service Fabric 노드 아래의 운영 체제를 패치하고 최신 상태로 유지하는 [응용 프로그램을 제공](service-fabric-patch-orchestration-application.md)하고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-125">In the interim, we have [provided an application](service-fabric-patch-orchestration-application.md) that the operating systems underneath your Service Fabric nodes stay patched and up to date.</span></span>

<span data-ttu-id="53144-126">OS 업데이트 문제는 일반적으로 컴퓨터를 재부팅해야 하며 이로 인해 일시적인 가용성 손실이 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-126">The challenge with OS updates is that they typically require a reboot of the machine, which results in temporary availability loss.</span></span> <span data-ttu-id="53144-127">Service Fabric에서 해당 서비스에 대한 트래픽을 다른 노드로 리디렉션하므로 이것 자체는 문제가 아닙니다.</span><span class="sxs-lookup"><span data-stu-id="53144-127">By itself, that is not a problem, since Service Fabric will automatically redirect traffic for those services to other nodes.</span></span> <span data-ttu-id="53144-128">하지만 OS 업데이트가 클러스터 간에 조정되지 않는다면 많은 노드가 한 번에 다운될 가능성이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-128">However, if OS updates are not coordinated across the cluster, there is the potential that many nodes go down at once.</span></span> <span data-ttu-id="53144-129">이러한 동시 재부팅은 서비스 또는 적어도 특정 파티션(상태 저장 서비스)에 대한 총체적인 가용성 손실을 유도할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-129">Such simultaneous reboots can cause complete availability loss for a service, or at least for a specific partition (for a stateful service).</span></span>

<span data-ttu-id="53144-130">향후에는 완전 자동화되고 업데이트 도메인 간에 조정되는 OS 업데이트 정책을 지원하여 재부팅하거나 다른 예기치 않은 오류가 발생해도 가용성이 유지되도록 할 것입니다.</span><span class="sxs-lookup"><span data-stu-id="53144-130">In the future, we plan to support an OS update policy that is fully automated and coordinated across update domains, ensuring that availability is maintained despite reboots and other unexpected failures.</span></span>

### <a name="can-i-use-large-virtual-machine-scale-sets-in-my-sf-cluster"></a><span data-ttu-id="53144-131">SF 클러스터 내에서 큰 가상 컴퓨터 크기 집합을 사용할 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="53144-131">Can I use Large Virtual Machine Scale Sets in my SF cluster?</span></span> 

<span data-ttu-id="53144-132">**간단한 대답** - 아니요</span><span class="sxs-lookup"><span data-stu-id="53144-132">**Short answer** - No.</span></span> 

<span data-ttu-id="53144-133">**자세한 대답** - 큰 가상 컴퓨터 크기 집합은 최대 1000개 VM 인스턴스까지 가상 컴퓨터 크기 집합을 확장하도록 허용하지만 PG(배치 그룹)을 사용하여 이 작업을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-133">**Long Answer** - Although the Large Virtual Machine Scale Sets allow you to scale a virtual machine scale set upto 1000 VM instances, it does so by the use of Placement Groups (PGs).</span></span> <span data-ttu-id="53144-134">FD(장애 도메인) 및 UD(업그레이드 도메인)는 Service Fabric이 서비스 복제본/서비스 인스턴스의 배치 결정을 내리는 데 사용하는 배치 그룹 내에서만 일관됩니다.</span><span class="sxs-lookup"><span data-stu-id="53144-134">Fault domains (FDs) and upgrade domains (UDs) are only consistent within a placement group Service fabric uses FDs and UDs to make placement decisions of your service replicas/Service instances.</span></span> <span data-ttu-id="53144-135">FD 및 UD는 배치 그룹 내에서만 호환되므로 SF에서 사용할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-135">Since the FDs  and UDs are comparable only within a placement group SF cannot use it.</span></span> <span data-ttu-id="53144-136">예를 들어 PG1의 VM1이 토폴로지 FD=0을 갖고 PG2의 VM9가 토폴로지 FD=4를 갖는 경우 VM1 및 VM2가 2개의 다른 하드웨어 랙에 있다는 것을 의미하지는 않으므로 SF는 이 경우 FD 값을 사용하여 배치 결정을 내릴 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-136">For example, If VM1 in PG1 has a topology of FD=0 and VM9 in PG2 has a topology of FD=4 , it does not mean that VM1 and VM2 are on two different Hardware Racks, hence SF cannot use the FD values in this case to make placement decisions.</span></span>

<span data-ttu-id="53144-137">현재 큰 가상 컴퓨터 크기 집합에서는 수준 4 부하 분산 지원 부족과 같은 기타 문제가 나타납니다.</span><span class="sxs-lookup"><span data-stu-id="53144-137">There are other issues with Large virtual machine scale sets currently, like the lack of level-4 Load balancing support.</span></span> <span data-ttu-id="53144-138">[큰 크기 집합에 대한 세부 정보](../virtual-machine-scale-sets/virtual-machine-scale-sets-placement-groups.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="53144-138">Refer to for [details on Large scale sets](../virtual-machine-scale-sets/virtual-machine-scale-sets-placement-groups.md)</span></span>



### <a name="what-is-the-minimum-size-of-a-service-fabric-cluster-why-cant-it-be-smaller"></a><span data-ttu-id="53144-139">Service Fabric 클러스터의 최소 크기는 어떻게 되나요?</span><span class="sxs-lookup"><span data-stu-id="53144-139">What is the minimum size of a Service Fabric cluster?</span></span> <span data-ttu-id="53144-140">작으면 안되는 이유는 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="53144-140">Why can't it be smaller?</span></span>

<span data-ttu-id="53144-141">프로덕션 워크로드를 시행하는 Service Fabric 클러스터에 지원되는 최소 크기는 5개 노드입니다.</span><span class="sxs-lookup"><span data-stu-id="53144-141">The minimum supported size for a Service Fabric cluster running production workloads is five nodes.</span></span> <span data-ttu-id="53144-142">개발/테스트 시나리오에 대해 3개의 노드 클러스터를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-142">For dev/test scenarios, we support three node clusters.</span></span>

<span data-ttu-id="53144-143">Service Fabric 클러스터는 이름 지정 서비스 및 장애 조치(Failover) 관리자를 포함한 일련의 상태 저장 시스템 서비스를 실행하므로 이러한 최소 크기가 존재합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-143">These minimums exist because the Service Fabric cluster runs a set of stateful system services, including the naming service and the failover manager.</span></span> <span data-ttu-id="53144-144">이러한 클러스터에 어떤 서비스가 배포되었고 현재 호스트되는 위치를 추적하며 강력한 일관성을 따릅니다.</span><span class="sxs-lookup"><span data-stu-id="53144-144">These services, which track what services have been deployed to the cluster and where they're currently hosted, depend on strong consistency.</span></span> <span data-ttu-id="53144-145">한편 강력한 일관성은 해당 서비스 상태로 특정 업데이트를 위해 *쿼럼*을 획득하는 기능에 의존하는데, 여기서 쿼럼은 지정된 서비스에 대한 복제본(N/2 +1)의 엄격한 다수성을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="53144-145">That strong consistency, in turn, depends on the ability to acquire a *quorum* for any given update to the state of those services, where a quorum represents a strict majority of the replicas (N/2 +1) for a given service.</span></span>

<span data-ttu-id="53144-146">배경 정보로 몇 가지 가능한 클러스터 구성을 살펴보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-146">With that background, let's examine some possible cluster configurations:</span></span>

<span data-ttu-id="53144-147">**한 개 노드**: 이 옵션에서는 어떤 이유로든 단일 노드 손실이 전체 클러스터의 손실을 의미하므로 고가용성을 제공하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-147">**One node**: this option does not provide high availability since the loss of the single node for any reason means the loss of the entire cluster.</span></span>

<span data-ttu-id="53144-148">**두 개 노드**: 두 노드(N = 2) 간에 배포된 서비스의 쿼럼은 2(2/2 + 1 = 2)입니다.</span><span class="sxs-lookup"><span data-stu-id="53144-148">**Two nodes**: a quorum for a service deployed across two nodes (N = 2) is 2 (2/2 + 1 = 2).</span></span> <span data-ttu-id="53144-149">단일 복제본이 손실되면 쿼럼을 만들 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-149">When a single replica is lost, it is impossible to create a quorum.</span></span> <span data-ttu-id="53144-150">서비스 업그레이드를 수행하려면 복제본을 일시적으로 종료해야 하므로 유용한 구성이 아닙니다.</span><span class="sxs-lookup"><span data-stu-id="53144-150">Since performing a service upgrade requires temporarily taking down a replica, this is not a useful configuration.</span></span>

<span data-ttu-id="53144-151">**세 개 노드**: 세 개 노드(N=3)를 사용하며 쿼럼을 만들기 위한 요건은 계속해서 두 개 노드입니다(3/2 + 1 = 2).</span><span class="sxs-lookup"><span data-stu-id="53144-151">**Three nodes**: with three nodes (N=3), the requirement to create a quorum is still two nodes (3/2 + 1 = 2).</span></span> <span data-ttu-id="53144-152">따라서 개별 노드를 손실하고 쿼럼을 계속 유지할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-152">This means that you can lose an individual node and still maintain quorum.</span></span>

<span data-ttu-id="53144-153">업그레이드를 안전하게 수행하고 개별 노드 오류에도 대응 가능하므로(동시에 발생하지만 않는다면) 개발/테스트에 대해 세 개 노드 클러스터 구성이 지원됩니다.</span><span class="sxs-lookup"><span data-stu-id="53144-153">The three node cluster configuration is supported for dev/test because you can safely perform upgrades and survive individual node failures, as long as they don't happen simultaneously.</span></span> <span data-ttu-id="53144-154">프로덕션 워크로드를 위해 이러한 동시 오류에 대해 복원력이 있어야 하므로 5개의 노드가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-154">For production workloads, you must be resilient to such a simultaneous failure, so five nodes are required.</span></span>

### <a name="can-i-turn-off-my-cluster-at-nightweekends-to-save-costs"></a><span data-ttu-id="53144-155">비용 절감을 위해 야간/주말에 내 클러스터를 해제할 수 있나요?</span><span class="sxs-lookup"><span data-stu-id="53144-155">Can I turn off my cluster at night/weekends to save costs?</span></span>

<span data-ttu-id="53144-156">일반적으로 그렇지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-156">In general, no.</span></span> <span data-ttu-id="53144-157">Service Fabric은 임시 로컬 디스크에 상태를 저장하므로 가상 컴퓨터가 다른 호스트로 이동하는 경우 데이터가 이동하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-157">Service Fabric stores state on local, ephemeral disks, meaning that if the virtual machine is moved to a different host, the data does not move with it.</span></span> <span data-ttu-id="53144-158">정상 작동 시에는 새 노드는 다른 노드에 의해 최신 상태가 되므로 문제가 되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-158">In normal operation, that is not a problem as the new node is brought up to date by other nodes.</span></span> <span data-ttu-id="53144-159">그러나 모든 노드를 중지하고 나중에 다시 시작하는 경우 대부분의 노드가 새 호스트에서 실행되고 시스템을 복구할 수 없을 가능성이 높습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-159">However, if you stop all nodes and restart them later, there is a significant possibility that most of the nodes start on new hosts and make the system unable to recover.</span></span>

<span data-ttu-id="53144-160">배포하기 전 응용 프로그램 테스트를 위해 클러스트를 만드는 경우 해당 클러스터를 [연속 통합/연속 배포 파이프라인](service-fabric-set-up-continuous-integration.md)의 일부로 동적으로 만드는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-160">If you would like to create clusters for testing your application before it is deployed, we recommend that you dynamically create those clusters as part of your [continuous integration/continuous deployment pipeline](service-fabric-set-up-continuous-integration.md).</span></span>


### <a name="how-do-i-upgrade-my-operating-system-for-example-from-windows-server-2012-to-windows-server-2016"></a><span data-ttu-id="53144-161">운영 체제를 업그레이드(예: Windows Server 2012를 Windows Server 2016으로)하려면 어떻게 해야 하나요?</span><span class="sxs-lookup"><span data-stu-id="53144-161">How do I upgrade my Operating System (for example from Windows Server 2012 to Windows Server 2016)?</span></span>

<span data-ttu-id="53144-162">Microsoft는 환경 개선을 위해 노력하고 있지만 업그레이드에 대한 책임은 귀하에게 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-162">While we're working on an improved experience, today, you are responsible for the upgrade.</span></span> <span data-ttu-id="53144-163">클러스터의 가상 컴퓨터에서 OS 이미지를 업그레이드하고 한 번에 하나의 VM에서 수행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-163">You must upgrade the OS image on the virtual machines of the cluster one VM at a time.</span></span> 

## <a name="container-support"></a><span data-ttu-id="53144-164">컨테이너 지원</span><span class="sxs-lookup"><span data-stu-id="53144-164">Container Support</span></span>

### <a name="why-are-my-containers-that-are-deployed-to-sf-unable-to-resolve-dns-addresses"></a><span data-ttu-id="53144-165">SF에 배포된 내 컨테이너에서 DNS 주소를 확인할 수 없는 이유는 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="53144-165">Why are my containers that are deployed to SF unable to resolve DNS addresses?</span></span>

<span data-ttu-id="53144-166">이 문제는 5.6.204.9494 버전의 클러스터에 대해 보고되었습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-166">This issue has been reported on clusters that are on 5.6.204.9494 version</span></span> 

<span data-ttu-id="53144-167">**완화** : [이 문서](service-fabric-dnsservice.md)에 따라 클러스터의 DNS Service Fabric 서비스를 사용하도록 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-167">**Mitigation** :  Follow [this document](service-fabric-dnsservice.md) to enable the DNS service fabric service in your cluster.</span></span>

<span data-ttu-id="53144-168">**수정**: 사용 가능한 경우 5.6.204.9494보다 높은 지원되는 클러스터 버전으로 업그레이드합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-168">**Fix** :  Upgrade to a supported cluster version that is higher than 5.6.204.9494, when it is available.</span></span> <span data-ttu-id="53144-169">클러스터가 자동 업그레이드로 설정되면 클러스터는 이 문제가 수정된 버전으로 자동으로 업그레이드됩니다.</span><span class="sxs-lookup"><span data-stu-id="53144-169">If your cluster is set to automatic upgrades, then the cluster will automatically upgrade to the version that has this issue fixed.</span></span>

  
## <a name="application-design"></a><span data-ttu-id="53144-170">응용 프로그램 설계</span><span class="sxs-lookup"><span data-stu-id="53144-170">Application Design</span></span>

### <a name="whats-the-best-way-to-query-data-across-partitions-of-a-reliable-collection"></a><span data-ttu-id="53144-171">Reliable Collection의 파티션에 대해 데이터를 쿼리하는 가장 좋은 방법은 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="53144-171">What's the best way to query data across partitions of a Reliable Collection?</span></span>

<span data-ttu-id="53144-172">일반적으로 Reliable Collection은 더 나은 성능 및 처리량을 달성하도록 규모 확장하기 위해 [분할](service-fabric-concepts-partitioning.md)됩니다.</span><span class="sxs-lookup"><span data-stu-id="53144-172">Reliable collections are typically [partitioned](service-fabric-concepts-partitioning.md) to enable scale out for greater performance and throughput.</span></span> <span data-ttu-id="53144-173">즉, 지정된 서비스에 대한 상태가 수십 또는 수백 대의 컴퓨터 간에 분산될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-173">That means that the state for a given service may be spread across 10s or 100s of machines.</span></span> <span data-ttu-id="53144-174">전체 데이터 집합에 대한 작업을 수행하기 위한 몇 가지 옵션이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-174">To perform operations over that full data set, you have a few options:</span></span>

- <span data-ttu-id="53144-175">다른 서비스의 모든 파티션을 쿼리하는 서비스를 만들어 필요한 데이터를 가져옵니다.</span><span class="sxs-lookup"><span data-stu-id="53144-175">Create a service that queries all partitions of another service to pull in the required data.</span></span>
- <span data-ttu-id="53144-176">다른 서비스의 모든 파티션에서 데이터를 수신할 수 있는 서비스를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="53144-176">Create a service that can receive data from all partitions of another service.</span></span>
- <span data-ttu-id="53144-177">각 서비스에서 외부 저장소로 주기적으로 데이터를 푸시합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-177">Periodically push data from each service to an external store.</span></span> <span data-ttu-id="53144-178">이 방법은 수행하는 쿼리가 핵심 비즈니스 논리에 포함되지 않는 경우에만 적절합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-178">This approach is only appropriate if the queries you're performing are not part of your core business logic.</span></span>


### <a name="whats-the-best-way-to-query-data-across-my-actors"></a><span data-ttu-id="53144-179">내 행위자에 대해 데이터를 쿼리하는 가장 좋은 방법은 무엇인가요?</span><span class="sxs-lookup"><span data-stu-id="53144-179">What's the best way to query data across my actors?</span></span>

<span data-ttu-id="53144-180">행위자는 독립적인 상태 및 계산 단위로 설계되므로 런타임에는 행위자 상태에 대한 광범위한 쿼리를 수행하지 않는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-180">Actors are designed to be independent units of state and compute, so it is not recommended to perform broad queries of actor state at runtime.</span></span> <span data-ttu-id="53144-181">전체 행위자 상태 집합에 대해 쿼리를 해야 하는 경우 다음을 고려합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-181">If you have a need to query across the full set of actor state, you should consider either:</span></span>

- <span data-ttu-id="53144-182">행위자 서비스를 상태 저장 Reliable Services로 바꿔서 많은 네트워크 요청으로 여러 행위자의 모든 데이터를 서비스의 여러 파티션으로 수집하도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-182">Replacing your actor services with stateful reliable services, such that the number of network requests to gather all data from the number of actors to the number of partitions in your service.</span></span>
- <span data-ttu-id="53144-183">상태를 외부 저장소로 주기적으로 푸시하도록 행위자를 설계하여 간편하게 쿼리할 수 있도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-183">Designing your actors to periodically push their state to an external store for easier querying.</span></span> <span data-ttu-id="53144-184">위에서처럼 이 방법은 수행 중인 쿼리가 런타임 동작에 대해 필요하지 않은 경우에만 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-184">As above, this approach is only viable if the queries you're performing are not required for your runtime behavior.</span></span>

### <a name="how-much-data-can-i-store-in-a-reliable-collection"></a><span data-ttu-id="53144-185">Reliable Collection에 저장할 수 있는 데이터는 얼마나 되나요?</span><span class="sxs-lookup"><span data-stu-id="53144-185">How much data can I store in a Reliable Collection?</span></span>

<span data-ttu-id="53144-186">Reliable Services는 일반적으로 분할되므로 저장할 수 있는 양은 클러스터에 있는 컴퓨터 수와 해당 컴퓨터에서 사용할 수 있는 메모리 양에 의해서만 제한됩니다.</span><span class="sxs-lookup"><span data-stu-id="53144-186">Reliable services are typically partitioned, so the amount you can store is only limited by the number of machines you have in the cluster, and the amount of memory available on those machines.</span></span>

<span data-ttu-id="53144-187">예를 들어, 평균 1kb 크기의 개체를 저장하는 100개 파티션과 3개 복제본이 있는 서비스에 Reliable Collection이 있다고 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-187">As an example, suppose that you have a reliable collection in a service with 100 partitions and 3 replicas, storing objects that average 1kb in size.</span></span> <span data-ttu-id="53144-188">이제 컴퓨터당 16gb의 메모리가 있는 10개의 컴퓨터 클러스터가 있다고 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-188">Now suppose that you have a 10 machine cluster with 16gb of memory per machine.</span></span> <span data-ttu-id="53144-189">간단하고 무난한 작업을 위해 운영 체제 및 시스템 서비스, Service Fabric 런타임 및 사용자 서비스가 이중 6gb를 사용하고 나머지 10gb는 컴퓨터당 사용 가능(클러스터인 경우 100gb)하다고 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-189">For simplicity and to be very conservative, assume that the operating system and system services, the Service Fabric runtime, and your services consume 6gb of that, leaving 10gb available per machine, or 100gb for the cluster.</span></span>

<span data-ttu-id="53144-190">각 개체는 세 번(주에서 1번, 복제본에서 2번) 저장되어야 하며 전체 용량으로 작동할 때 컬렉션에서 약 3천 500만 개체에 대해 충분한 메모리를 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-190">Keeping in mind that each object must be stored three times (one primary and two replicas), you would have sufficient memory for approximately 35 million objects in your collection when operating at full capacity.</span></span> <span data-ttu-id="53144-191">하지만 오류 도메인 및 업그레이드 도메인의 동시 손실에 복원력을 갖추는 것이 좋습니다. 동시 손실의 경우 용량의 약 1/3을 나타내므로 약 2천 300만 개체로 감소합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-191">However, we recommend being resilient to the simultaneous loss of a failure domain and an upgrade domain, which represents about 1/3 of capacity, and would reduce the number to roughly 23 million.</span></span>

<span data-ttu-id="53144-192">이 계산에서는 다음 사항도 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-192">Note that this calculation also assumes:</span></span>

- <span data-ttu-id="53144-193">파티션 간 데이터 분포는 대략적으로 균일하거나 부하 메트릭을 Cluster Resource Manager에 보고합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-193">That the distribution of data across the partitions is roughly uniform or that you're reporting load metrics to the Cluster Resource Manager.</span></span> <span data-ttu-id="53144-194">기본적으로 Service Fabric은 복제본 수에 따라 부하 분산을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-194">By default, Service Fabric will load balance based on replica count.</span></span> <span data-ttu-id="53144-195">위의 예에서는 클러스터의 각 노드에 주 복제본 10개와 보조 복제본 20개를 배치합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-195">In our example above, that would put 10 primary replicas and 20 secondary replicas on each node in the cluster.</span></span> <span data-ttu-id="53144-196">파티션 간에 부하가 고르게 분포된 경우에는 원활하게 작동합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-196">That works well for load that is evenly distributed across the partitions.</span></span> <span data-ttu-id="53144-197">부하가 고르게 분포되지 않은 경우 로드를 보고하여 Resource Manager에서 작은 크기의 복제본을 함께 패킹하여 큰 복제본이 개별 노드에서 더 많은 메모리를 사용하도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-197">If load is not even, you must report load so that the Resource Manager can pack smaller replicas together and allow larger replicas to consume more memory on an individual node.</span></span>

- <span data-ttu-id="53144-198">문제가 되는 Reliable Services는 클러스터에서 유일한 저장 상태입니다.</span><span class="sxs-lookup"><span data-stu-id="53144-198">That the reliable service in question is the only one storing state in the cluster.</span></span> <span data-ttu-id="53144-199">여러 서비스를 클러스터에 배포할 수 있으므로 각각 해당 상태를 실행 및 관리해야 하는 리소스에 유념해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-199">Since you can deploy multiple services to a cluster, you need to be mindful of the resources that each will need to run and manage its state.</span></span>

- <span data-ttu-id="53144-200">클러스터 자체는 증가 또는 감소하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-200">That the cluster itself is not growing or shrinking.</span></span> <span data-ttu-id="53144-201">더 많은 컴퓨터를 추가하는 경우 개별 복제본은 컴퓨터 간에 걸쳐 있을 수 없으므로 컴퓨터 수가 서비스의 파티션 수를 초과할 때까지 Service Fabric은 복제본의 부하를 다시 조정하여 추가 용량을 활용합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-201">If you add more machines, Service Fabric will rebalance your replicas to leverage the additional capacity until the number of machines surpasses the number of partitions in your service, since an individual replica cannot span machines.</span></span> <span data-ttu-id="53144-202">이와 반대로 컴퓨터를 제거하여 클러스터 크기를 줄이는 경우 복제본을 보다 조밀하게 패킹하면 전체 용량이 감소합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-202">By contrast, if you reduce the size of the cluster by removing machines, your replicas will be packed more tightly and have less overall capacity.</span></span>

### <a name="how-much-data-can-i-store-in-an-actor"></a><span data-ttu-id="53144-203">행위자에 저장할 수 있는 데이터는 얼마나 되나요?</span><span class="sxs-lookup"><span data-stu-id="53144-203">How much data can I store in an actor?</span></span>

<span data-ttu-id="53144-204">Reliable Services와 마찬가지로 행위자 서비스에 저장할 수 있는 데이터 양은 클러스터에 있는 노드 간에 사용 가능한 총 디스크 공간 및 메모리 양에 의해서만 제한됩니다.</span><span class="sxs-lookup"><span data-stu-id="53144-204">As with reliable services, the amount of data that you can store in an actor service is only limited by the total disk space and memory available across the nodes in your cluster.</span></span> <span data-ttu-id="53144-205">하지만 개별 행위자는 적은 양의 상태 및 관련 비즈니스 논리를 캡슐화하는 데 사용할 경우 가장 효과적입니다.</span><span class="sxs-lookup"><span data-stu-id="53144-205">However, individual actors are most effective when they are used to encapsulate a small amount of state and associated business logic.</span></span> <span data-ttu-id="53144-206">일반적으로 개별 행위자는 킬로바이트 단위로 측정되는 상태를 포함하게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="53144-206">As a general rule, an individual actor should have state that is measured in kilobytes.</span></span>

## <a name="other-questions"></a><span data-ttu-id="53144-207">기타 질문</span><span class="sxs-lookup"><span data-stu-id="53144-207">Other questions</span></span>

### <a name="how-does-service-fabric-relate-to-containers"></a><span data-ttu-id="53144-208">Service Fabric은 컨테이너와 어떻게 연결되나요?</span><span class="sxs-lookup"><span data-stu-id="53144-208">How does Service Fabric relate to containers?</span></span>

<span data-ttu-id="53144-209">컨테이너는 서비스와 해당 종속성을 패키지하는 간단한 방법을 제공하여 모든 환경에서 일관성 있게 실행되고 단일 컴퓨터에서 격리된 방식으로 작동할 수 있도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-209">Containers offer a simple way to package services and their dependencies such that they run consistently in all environments and can operate in an isolated fashion on a single machine.</span></span> <span data-ttu-id="53144-210">Service Fabric은 [컨테이너에 패키지된 서비스](service-fabric-containers-overview.md)를 비롯하여 서비스를 배포 및 관리하는 방법을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-210">Service Fabric offers a way to deploy and manage services, including [services that have been packaged in a container](service-fabric-containers-overview.md).</span></span>

### <a name="are-you-planning-to-open-source-service-fabric"></a><span data-ttu-id="53144-211">Service Fabric의 오픈 소스 계획이 있나요?</span><span class="sxs-lookup"><span data-stu-id="53144-211">Are you planning to open source Service Fabric?</span></span>

<span data-ttu-id="53144-212">GitHub에서 Reliable Services 및 Reliable Actors 프레임워크에 대한 오픈 소스를 계획 중이며 해당 프로젝트에 대한 참여를 허용합니다.</span><span class="sxs-lookup"><span data-stu-id="53144-212">We intend to open source the reliable services and reliable actors frameworks on GitHub and will accept community contributions to those projects.</span></span> <span data-ttu-id="53144-213">공지되면 [Service Fabric 블로그](https://blogs.msdn.microsoft.com/azureservicefabric/)에서 자세한 내용을 확인하세요.</span><span class="sxs-lookup"><span data-stu-id="53144-213">Please follow the [Service Fabric blog](https://blogs.msdn.microsoft.com/azureservicefabric/) for more details as they're announced.</span></span>

<span data-ttu-id="53144-214">현재는 Service Fabric 런타임에 대한 오픈 소스 계획은 없습니다.</span><span class="sxs-lookup"><span data-stu-id="53144-214">The are currently no plans to open source the Service Fabric runtime.</span></span>

## <a name="next-steps"></a><span data-ttu-id="53144-215">다음 단계</span><span class="sxs-lookup"><span data-stu-id="53144-215">Next steps</span></span>

- [<span data-ttu-id="53144-216">핵심 Service Fabric 개념 및 모범 사례에 대해 알아보기</span><span class="sxs-lookup"><span data-stu-id="53144-216">Learn about core Service Fabric concepts and best practices</span></span>](https://mva.microsoft.com/en-us/training-courses/building-microservices-applications-on-azure-service-fabric-16747?l=tbuZM46yC_5206218965)
