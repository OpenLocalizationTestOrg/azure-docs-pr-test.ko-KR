---
title: "aaaService 패브릭 클러스터 리소스 관리자-관리 통합 | Microsoft Docs"
description: "Hello 클러스터 리소스 관리자 및 서비스 패브릭 관리 사이의 hello 통합 지점의 개요."
services: service-fabric
documentationcenter: .net
author: masnider
manager: timlt
editor: 
ms.assetid: 956cd0b8-b6e3-4436-a224-8766320e8cd7
ms.service: Service-Fabric
ms.devlang: dotnet
ms.topic: article
ms.tgt_pltfrm: NA
ms.workload: NA
ms.date: 08/18/2017
ms.author: masnider
ms.openlocfilehash: 9a24c9de121fbe2e8e5e8e4d117e64686918936a
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="cluster-resource-manager-integration-with-service-fabric-cluster-management"></a><span data-ttu-id="af828-103">클러스터 리소스 관리자와 서비스 패브릭 클러스터 관리 통합</span><span class="sxs-lookup"><span data-stu-id="af828-103">Cluster resource manager integration with Service Fabric cluster management</span></span>
<span data-ttu-id="af828-104">hello 서비스 패브릭 클러스터 리소스 관리자 서비스 패브릭의 업그레이드를 드라이브 하지 않습니다 되지만 관련 되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-104">hello Service Fabric Cluster Resource Manager doesn't drive upgrades in Service Fabric, but it is involved.</span></span> <span data-ttu-id="af828-105">hello hello 추적 된 경우 관리 hello 클러스터 리소스 관리자를 사용 하는 첫 번째 방법은 원하는 hello 클러스터 및 그 안에 hello 서비스의 상태입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-105">hello first way that hello Cluster Resource Manager helps with management is by tracking hello desired state of hello cluster and hello services inside it.</span></span> <span data-ttu-id="af828-106">클러스터 리소스 관리자 hello hello 클러스터 hello 원하는 구성에 배치 수 없는 경우 상태 보고서를 보냅니다.</span><span class="sxs-lookup"><span data-stu-id="af828-106">hello Cluster Resource Manager sends out health reports when it cannot put hello cluster into hello desired configuration.</span></span> <span data-ttu-id="af828-107">예를 들어 부족 용량 hello 클러스터 리소스 관리자 상태 경고 및 오류 hello 문제를 나타내는 보냅니다.</span><span class="sxs-lookup"><span data-stu-id="af828-107">For example, if there is insufficient capacity hello Cluster Resource Manager sends out health warnings and errors indicating hello problem.</span></span> <span data-ttu-id="af828-108">통합의 다른 부분에는 업그레이드 작동 방법으로 toodo 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-108">Another piece of integration has toodo with how upgrades work.</span></span> <span data-ttu-id="af828-109">클러스터 리소스 관리자 hello 업그레이드 하는 동안 약간의 동작을 변경합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-109">hello Cluster Resource Manager alters its behavior slightly during upgrades.</span></span>  

## <a name="health-integration"></a><span data-ttu-id="af828-110">상태 통합</span><span class="sxs-lookup"><span data-stu-id="af828-110">Health integration</span></span>
<span data-ttu-id="af828-111">hello 클러스터 리소스 관리자는 지속적으로 서비스를 배치에 대해 정의한 hello 규칙을 추적 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-111">hello Cluster Resource Manager constantly tracks hello rules you have defined for placing your services.</span></span> <span data-ttu-id="af828-112">또한 전체 용량 hello 노드에서 hello 클러스터 및 hello 클러스터의 각 메트릭에 대 한 남은 hello를 추적 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-112">It also tracks hello remaining capacity for each metric on hello nodes and in hello cluster and in hello cluster as a whole.</span></span> <span data-ttu-id="af828-113">해당 규칙을 충족할 수 없거나 용량이 부족한 경우 상태 경고 및 오류를 내보냅니다.</span><span class="sxs-lookup"><span data-stu-id="af828-113">If it can't satisfy those rules or if there is insufficient capacity, health warnings and errors are emitted.</span></span> <span data-ttu-id="af828-114">예를 들어, 노드 용량 및 hello 위에 있으면 클러스터 리소스 관리자는 서비스를 이동 하 여 toofix hello 상황을 시도 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-114">For example, if a node is over capacity and hello Cluster Resource Manager will try toofix hello situation by moving services.</span></span> <span data-ttu-id="af828-115">Hello 상황을 수정할 수 없는 경우에 노드가 나타내는 용량 초과 및 메트릭을 대 한 상태 경고를 내보냅니다.</span><span class="sxs-lookup"><span data-stu-id="af828-115">If it can't correct hello situation it emits a health warning indicating which node is over capacity, and for which metrics.</span></span>

<span data-ttu-id="af828-116">Hello 리소스 관리자의 상태는 경고의 또 다른 예로 배치 제약 조건 위반입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-116">Another example of hello Resource Manager's health warnings is violations of placement constraints.</span></span> <span data-ttu-id="af828-117">예를 들어, 배치 제약 조건을 정의한 경우 (같은 `“NodeColor == Blue”`) 및 해당 제약 조건 위반을 검색 하는 hello 리소스 관리자, 상태 경고를 생성 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-117">For example, if you have defined a placement constraint (such as `“NodeColor == Blue”`) and hello Resource Manager detects a violation of that constraint, it emits a health warning.</span></span> <span data-ttu-id="af828-118">이 사용자 지정 제약 조건 및 hello 기본 제약 조건 (예: hello 오류 도메인과 업그레이드 도메인 제약 조건)에 적용 됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-118">This is true for custom constraints and hello default constraints (like hello Fault Domain and Upgrade Domain constraints).</span></span>

<span data-ttu-id="af828-119">이러한 상태 보고서의 예를 들면 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-119">Here’s an example of one such health report.</span></span> <span data-ttu-id="af828-120">이 경우 hello 상태 보고서는 hello 시스템 서비스 파티션 중 하나입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-120">In this case, hello health report is for one of hello system service’s partitions.</span></span> <span data-ttu-id="af828-121">hello 상태 메시지는 너무 적은 업그레이드 도메인에 일시적으로 압축 되는 해당 파티션의 복제본 hello를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="af828-121">hello health message indicates hello replicas of that partition are temporarily packed into too few Upgrade Domains.</span></span>

```posh
PS C:\Users\User > Get-WindowsFabricPartitionHealth -PartitionId '00000000-0000-0000-0000-000000000001'


PartitionId           : 00000000-0000-0000-0000-000000000001
AggregatedHealthState : Warning
UnhealthyEvaluations  :
                        Unhealthy event: SourceId='System.PLB', Property='ReplicaConstraintViolation_UpgradeDomain', HealthState='Warning', ConsiderWarningAsError=false.

ReplicaHealthStates   :
                        ReplicaId             : 130766528804733380
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528804577821
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528854889931
                        AggregatedHealthState : Ok

                        ReplicaId             : 130766528804577822
                        AggregatedHealthState : Ok

                        ReplicaId             : 130837073190680024
                        AggregatedHealthState : Ok

HealthEvents          :
                        SourceId              : System.PLB
                        Property              : ReplicaConstraintViolation_UpgradeDomain
                        HealthState           : Warning
                        SequenceNumber        : 130837100116930204
                        SentAt                : 8/10/2015 7:53:31 PM
                        ReceivedAt            : 8/10/2015 7:53:33 PM
                        TTL                   : 00:01:05
                        Description           : hello Load Balancer has detected a Constraint Violation for this Replica: fabric:/System/FailoverManagerService Secondary Partition 00000000-0000-0000-0000-000000000001 is
                        violating hello Constraint: UpgradeDomain Details: UpgradeDomain ID -- 4, Replica on NodeName -- Node.8 Currently Upgrading -- false Distribution Policy -- Packing
                        RemoveWhenExpired     : True
                        IsExpired             : False
                        Transitions           : Ok->Warning = 8/10/2015 7:13:02 PM, LastError = 1/1/0001 12:00:00 AM
```

<span data-ttu-id="af828-122">상태 메시지는 다음과 같은 사항을 알려줍니다.</span><span class="sxs-lookup"><span data-stu-id="af828-122">Here's what this health message is telling us is:</span></span>

1. <span data-ttu-id="af828-123">자체 모든 hello 복제본이 정상: 각에 AggregatedHealthState: 확인</span><span class="sxs-lookup"><span data-stu-id="af828-123">All hello replicas themselves are healthy: Each has AggregatedHealthState : Ok</span></span>
2. <span data-ttu-id="af828-124">hello 업그레이드 도메인 배포 제약 조건에 위반 되 고 현재 됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-124">hello Upgrade Domain distribution constraint is currently being violated.</span></span> <span data-ttu-id="af828-125">이는 특정 업그레이드 도메인에 이 파티션보다 더 많은 복제본이 있음을 의미합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-125">This means a particular Upgrade Domain has more replicas from this partition than it should.</span></span>
3. <span data-ttu-id="af828-126">노드는 hello 복제본 바꾸지 hello 위반을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-126">Which node contains hello replica causing hello violation.</span></span> <span data-ttu-id="af828-127">이 경우 노드인지 hello "Node.8" hello 이름의</span><span class="sxs-lookup"><span data-stu-id="af828-127">In this case it's hello node with hello name "Node.8"</span></span>
4. <span data-ttu-id="af828-128">이 파티션에서 현재 업그레이드가 진행 중인지 여부("현재 업그레이드 중 - false")</span><span class="sxs-lookup"><span data-stu-id="af828-128">Whether an upgrade is currently happening for this partition ("Currently Upgrading -- false")</span></span>
5. <span data-ttu-id="af828-129">이 서비스에 대 한 배포 정책을 hello: "배포 정책--압축"입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-129">hello distribution policy for this service: "Distribution Policy -- Packing".</span></span> <span data-ttu-id="af828-130">이 hello 준하여 `RequireDomainDistribution` [배치 정책](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md#requiring-replica-distribution-and-disallowing-packing)합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-130">This is governed by hello `RequireDomainDistribution` [placement policy](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md#requiring-replica-distribution-and-disallowing-packing).</span></span> <span data-ttu-id="af828-131">"압축 중"은 이 경우 DomainDistribution이 필요하지 _않음_을 나타냅니다. 따라서 이 서비스에 대해 배치 정책이 지정되지 않았습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-131">"Packing" indicates that in this case DomainDistribution was _not_ required, so we know that placement policy was not specified for this service.</span></span> 
6. <span data-ttu-id="af828-132">Hello 보고서 발생 한 시기-2015 년 8 월 10 일 오후 7시 13분: 02</span><span class="sxs-lookup"><span data-stu-id="af828-132">When hello report happened - 8/10/2015 7:13:02 PM</span></span>

<span data-ttu-id="af828-133">Toodetect을 사용 하는 문제가 발생 했는지와 알아야 프로덕션 toolet 실행이 powers 경고 및 잘못 된 업그레이드를 중단 정보.</span><span class="sxs-lookup"><span data-stu-id="af828-133">Information like this powers alerts that fire in production toolet you know something has gone wrong and is also used toodetect and halt bad upgrades.</span></span> <span data-ttu-id="af828-134">이 경우 리소스 관리자 hello hello 업그레이드 도메인으로 toopack hello 복제본 시도가 이유 알아낼 수 있는 경우 toosee를 하려고 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-134">In this case, we’d want toosee if we can figure out why hello Resource Manager had toopack hello replicas into hello Upgrade Domain.</span></span> <span data-ttu-id="af828-135">일반적으로 압축 된 hello hello에 다른 업그레이드 도메인에 있던 노드에 다운 예를 들어 이므로 일시적입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-135">Usually packing is transient because hello nodes in hello other Upgrade Domains were down, for example.</span></span>

<span data-ttu-id="af828-136">클러스터 리소스 관리자 hello 시도 tooplace 일부 서비스 아닌 작동 하는 모든 솔루션 고 가정해 봅니다.</span><span class="sxs-lookup"><span data-stu-id="af828-136">Let’s say hello Cluster Resource Manager is trying tooplace some services, but there aren't any solutions that work.</span></span> <span data-ttu-id="af828-137">서비스를 배치할 수 없는 경우에 일반적으로 hello 다음 이유 중 하나에 대해:</span><span class="sxs-lookup"><span data-stu-id="af828-137">When services can't be placed, it is usually for one of hello following reasons:</span></span>

1. <span data-ttu-id="af828-138">일시적인 상태의 경우 일부가 아무런 상관이 불가능 한 tooplace 서비스 인스턴스나 복제본이 제대로</span><span class="sxs-lookup"><span data-stu-id="af828-138">Some transient condition has made it impossible tooplace this service instance or replica correctly</span></span>
2. <span data-ttu-id="af828-139">hello 서비스의 배치 요구 사항이 충족 시킬 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-139">hello service’s placement requirements are unsatisfiable.</span></span>

<span data-ttu-id="af828-140">이러한 경우에 상태 보고서 hello 클러스터 리소스 관리자에서에서 데 hello 서비스 있을 수 없습니다 이유를 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-140">In these cases, health reports from hello Cluster Resource Manager help you determine why hello service can’t be placed.</span></span> <span data-ttu-id="af828-141">이 프로세스 hello 제약 조건 제거 순서를 라고합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-141">We call this process hello constraint elimination sequence.</span></span> <span data-ttu-id="af828-142">Hello 시스템, 하는 동안 구성 된 hello 제약 조건에 영향을 주는 hello 서비스 및 레코드 제거 무엇 안내 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-142">During it, hello system walks through hello configured constraints affecting hello service and records what they eliminate.</span></span> <span data-ttu-id="af828-143">이러한 방식으로 서비스를 배치 하는 수 toobe 장치가 없는 경우에 노드 제거 된을 볼 수 있습니다 및 이유입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-143">This way when services aren’t able toobe placed, you can see which nodes were eliminated and why.</span></span>

## <a name="constraint-types"></a><span data-ttu-id="af828-144">제약 조건 형식</span><span class="sxs-lookup"><span data-stu-id="af828-144">Constraint types</span></span>
<span data-ttu-id="af828-145">이러한 상태 보고서에 각기 다른 제약 조건을 hello 알아보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-145">Let’s talk about each of hello different constraints in these health reports.</span></span> <span data-ttu-id="af828-146">복제본 있을 수 없습니다 상태 메시지 관련된 toothese 제약 조건 나타납니다 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-146">You will see health messages related toothese constraints when replicas can't be placed.</span></span>

* <span data-ttu-id="af828-147">**ReplicaExclusionStatic** 및 **ReplicaExclusionDynamic**: 이러한 제약 조건에서 두 서비스 개체 hello 같은 파티션에 toobe를 배치한 hello에 동일 하기 때문에 솔루션을 거부 했습니다 나타냅니다 노드.</span><span class="sxs-lookup"><span data-stu-id="af828-147">**ReplicaExclusionStatic** and **ReplicaExclusionDynamic**: These constraints indicates that a solution was rejected because two service objects from hello same partition would have toobe placed on hello same node.</span></span> <span data-ttu-id="af828-148">이는 해당 노드의 실패가 해당 파티션에 지나치게 영향을 줄 수 있으므로 허용되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-148">This isn’t allowed because then failure of that node would overly impact that partition.</span></span> <span data-ttu-id="af828-149">ReplicaExclusionStatic 및 ReplicaExclusionDynamic 동일한 규칙과 hello 차이점은 문제가 되지 않을 hello 거의 됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-149">ReplicaExclusionStatic and ReplicaExclusionDynamic are almost hello same rule and hello differences don't really matter.</span></span> <span data-ttu-id="af828-150">하는 경우 어느 hello ReplicaExclusionStatic 또는 ReplicaExclusionDynamic 제약 조건, hello 클러스터 리소스 관리자를 포함 하는 제약 조건 제거 시퀀스 생각 되지 않게 노드가 충분 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-150">If you are seeing a constraint elimination sequence containing either hello ReplicaExclusionStatic or ReplicaExclusionDynamic constraint, hello Cluster Resource Manager thinks that there aren’t enough nodes.</span></span> <span data-ttu-id="af828-151">이 허용 되지 않는 이러한 잘못 된 배치 솔루션 toouse 남은 필요 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-151">This requires remaining solutions toouse these invalid placements which are disallowed.</span></span> <span data-ttu-id="af828-152">hello hello 시퀀스에서 다른 제약 조건과 일반적으로 알려주세요 hello 첫 번째 위치에서 노드 제거 되는 이유.</span><span class="sxs-lookup"><span data-stu-id="af828-152">hello other constraints in hello sequence will usually tell us why nodes are being eliminated in hello first place.</span></span>
* <span data-ttu-id="af828-153">**PlacementConstraint**:이 메시지가 나타나는 경우 hello 서비스의 배치 제약 조건에 일치 하지 않는 때문에 일부 노드를 제거 했습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-153">**PlacementConstraint**: If you see this message, it means that we eliminated some nodes because they didn’t match hello service’s placement constraints.</span></span> <span data-ttu-id="af828-154">이 메시지의 일부로 현재 구성 된 hello 배치 제약 조건으로 추적 했습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-154">We trace out hello currently configured placement constraints as a part of this message.</span></span> <span data-ttu-id="af828-155">배치 제약 조건이 정의되어 있는 경우 이는 정상입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-155">This is normal if you have a placement constraint defined.</span></span> <span data-ttu-id="af828-156">그러나 배치 제약 조건을 올바르게 일으키는지 하지 제거 너무 많은 노드가 toobe 어떻게를 확인할 수입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-156">However, if placement constraint is incorrectly causing too many nodes toobe eliminated this is how you would notice.</span></span>
* <span data-ttu-id="af828-157">**NodeCapacity**:이 제약 조건은 의미 클러스터 리소스 관리자에 hello 복제본을 배치할 수 없습니다. 해당 hello hello 조치용 배치 하는 것 때문에 노드를 표시 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-157">**NodeCapacity**: This constraint means that hello Cluster Resource Manager couldn’t place hello replicas on hello indicated nodes because that would put them over capacity.</span></span>
* <span data-ttu-id="af828-158">**선호도**: 없습니다 배치 했었습니다 hello 복제본 hello 영향을 받는 노드에서 hello 선호도 제약 조건 위반 발생 시키기 때문이 제약 조건을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="af828-158">**Affinity**: This constraint indicates that we couldn’t place hello replica on hello affected nodes since it would cause a violation of hello affinity constraint.</span></span> <span data-ttu-id="af828-159">선호도에 대한 자세한 내용은 [이 문서](service-fabric-cluster-resource-manager-advanced-placement-rules-affinity.md)에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-159">More information on affinity is in [this article](service-fabric-cluster-resource-manager-advanced-placement-rules-affinity.md)</span></span>
* <span data-ttu-id="af828-160">**FaultDomain** 및 **UpgradeDomain**: hello에 배치 hello 복제본 노드는 특정 오류 또는 업그레이드 도메인에 포장로 인해 지정 된 경우이 제약 조건 노드를 제거 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-160">**FaultDomain** and **UpgradeDomain**: This constraint eliminates nodes if placing hello replica on hello indicated nodes would cause packing in a particular fault or upgrade domain.</span></span> <span data-ttu-id="af828-161">에이 제약 조건에 논의 하는 몇 가지 예는 hello 항목에 제시 된 [오류 및 업그레이드 도메인 제약 조건 및 결과 동작](service-fabric-cluster-resource-manager-cluster-description.md)</span><span class="sxs-lookup"><span data-stu-id="af828-161">Several examples discussing this constraint are presented in hello topic on [fault and upgrade domain constraints and resulting behavior](service-fabric-cluster-resource-manager-cluster-description.md)</span></span>
* <span data-ttu-id="af828-162">**PreferredLocation**: 기본적으로 최적화 방법으로 실행 되므로 hello 솔루션에서 노드를 제거 하면이 제약 조건은 정상적으로 표시 되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-162">**PreferredLocation**: You shouldn’t normally see this constraint removing nodes from hello solution since it runs as an optimization by default.</span></span> <span data-ttu-id="af828-163">hello 위치 제약 조건이 업그레이드 하는 동안 제공 됩니다. 기본 설정입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-163">hello preferred location constraint is also present during upgrades.</span></span> <span data-ttu-id="af828-164">업그레이드 하는 동안 hello 업그레이드를 시작할 때 사용 되는 toomove 서비스 백 toowhere 것 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-164">During upgrade it is used toomove services back toowhere they were when hello upgrade started.</span></span>

## <a name="blocklisting-nodes"></a><span data-ttu-id="af828-165">노드 차단 목록 작성</span><span class="sxs-lookup"><span data-stu-id="af828-165">Blocklisting Nodes</span></span>
<span data-ttu-id="af828-166">노드는 blocklisted 때 다른 상태 메시지 hello 클러스터 리소스 관리자 보고서 표시 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-166">Another health message hello Cluster Resource Manager reports is when nodes are blocklisted.</span></span> <span data-ttu-id="af828-167">차단 목록은 자동으로 적용되는 임시 제약 조건으로 간주할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-167">You can think of blocklisting as a temporary constraint that is automatically applied for you.</span></span> <span data-ttu-id="af828-168">해당 서비스 유형의 인스턴스를 시작할 때 반복적인 오류가 발생하면 노드가 차단 목록에 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-168">Nodes get blocklisted when they experience repeated failures when launching instances of that service type.</span></span> <span data-ttu-id="af828-169">노드는 서비스 유형별로 차단 목록에 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-169">Nodes are blocklisted on a per-service-type basis.</span></span> <span data-ttu-id="af828-170">하나의 서비스 유형에 대한 노드가 차단 목록에 포함되지만 다른 유형에 대해서는 차단 목록에 포함될 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-170">A node may be blocklisted for one service type but not another.</span></span> 

<span data-ttu-id="af828-171">개발 하는 동안에 자주 조정이 시작 blocklisting 표시 됩니다: 몇 가지 버그 서비스 호스트 toocrash를 시작할 때 발생 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-171">You'll see blocklisting kick in often during development: some bug causes your service host toocrash on startup.</span></span> <span data-ttu-id="af828-172">서비스 패브릭 toocreate hello 서비스 호스트를 여러 번 시도 및 hello 오류가 계속 발생 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-172">Service Fabric tries toocreate hello service host a few times, and hello failure keeps occurring.</span></span> <span data-ttu-id="af828-173">몇 번의 시도 후 hello 노드 blocklisted를 가져오고 hello 클러스터 리소스 관리자는 다른 곳에서 toocreate hello 서비스를 시도 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-173">After a few attempts, hello node gets blocklisted, and hello Cluster Resource Manager will try toocreate hello service elsewhere.</span></span> <span data-ttu-id="af828-174">여러 노드에 대해 해당 오류가 계속 발생 하는 경우 차단의 모든 hello 클러스터 결국 hello 유효한 노드 수입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-174">If that failure keeps happening on multiple nodes, it's possible that all of hello valid nodes in hello cluster end up blocked.</span></span> <span data-ttu-id="af828-175">Blocklisting은 hello 서비스 toomeet 원하는 hello 눈금 시작 성공적으로 충분 하지 않습니다. 너무 많은 노드를 제거할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-175">Blocklisting cna also remove so many nodes that not enough can successfully launch hello service toomeet hello desired scale.</span></span> <span data-ttu-id="af828-176">추가 오류 일반적으로 확인할 수 없거나 hello 클러스터 리소스 관리자 중임을 나타내는 hello 서비스 아래 hello 원하는 복제본 또는 인스턴스 수 뿐만 아니라 어떤 hello 실패를 나타내는 상태 메시지에서 발생 한 경고 toohello 선행 되는 hello 먼저에서 blocklisting 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-176">You'll typically see additional errors or warnings from hello Cluster Resource Manager indicating that hello service is below hello desired replica or instance count, as well as health messages indicating what hello failure is that's leading toohello blocklisting in hello first place.</span></span>

<span data-ttu-id="af828-177">차단 목록은 영구적인 조건이 아닙니다.</span><span class="sxs-lookup"><span data-stu-id="af828-177">Blocklisting is not a permanent condition.</span></span> <span data-ttu-id="af828-178">몇 분 후 hello 노드가 hello 차단 목록에서 제거 되 고 서비스 패브릭 해당 노드에서 hello 서비스를 다시 활성화 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-178">After a few minutes, hello node is removed from hello blocklist and Service Fabric may activate hello services on that node again.</span></span> <span data-ttu-id="af828-179">서비스 계속 toofail hello 노드를 해당 서비스 유형에 대 한 blocklisted 다시 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-179">If services continue toofail, hello node is blocklisted for that service type again.</span></span> 

### <a name="constraint-priorities"></a><span data-ttu-id="af828-180">제약 조건 우선 순위</span><span class="sxs-lookup"><span data-stu-id="af828-180">Constraint priorities</span></span>

> [!WARNING]
> <span data-ttu-id="af828-181">제약 조건 우선 순위를 변경하는 것은 권장되지 않으며 클러스터에 심각하게 부정적인 영향을 미칠 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-181">Changing constraint priorities is not recommended and may have significant adverse effects on your cluster.</span></span> <span data-ttu-id="af828-182">아래 정보는 hello hello 기본 제약 조건 우선 순위 및 해당 동작의 참조를 위해 제공 됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-182">hello below information is provided for reference of hello default constraint priorities and their behavior.</span></span> 
>

<span data-ttu-id="af828-183">이러한 제약 조건의 모든, 수 있는 되었습니다 혼동 있습니다 "Hey – 생각 오류 도메인 제약 조건 내 시스템에 가장 중요 한 사항은 hello 인지 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-183">With all of these constraints, you may have been thinking “Hey – I think that fault domain constraints are hello most important thing in my system.</span></span> <span data-ttu-id="af828-184">순서 tooensure hello 오류 도메인 제약 조건이 없는 위반, 저는 의향이 tooviolate 다른 제약 조건입니다. "</span><span class="sxs-lookup"><span data-stu-id="af828-184">In order tooensure hello fault domain constraint isn't violated, I’m willing tooviolate other constraints.”</span></span>

<span data-ttu-id="af828-185">제약 조건은 서로 다른 우선 순위 수준으로 구성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-185">Constraints can be configured with different priority levels.</span></span> <span data-ttu-id="af828-186">다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-186">These are:</span></span>

   - <span data-ttu-id="af828-187">"하드" (0)</span><span class="sxs-lookup"><span data-stu-id="af828-187">“hard” (0)</span></span>
   - <span data-ttu-id="af828-188">"소프트" (1)</span><span class="sxs-lookup"><span data-stu-id="af828-188">“soft” (1)</span></span>
   - <span data-ttu-id="af828-189">"최적화" (2)</span><span class="sxs-lookup"><span data-stu-id="af828-189">“optimization” (2)</span></span>
   - <span data-ttu-id="af828-190">"해제" (-1)</span><span class="sxs-lookup"><span data-stu-id="af828-190">“off” (-1).</span></span> 
   
<span data-ttu-id="af828-191">Hello 제약 조건 대부분에 기본적으로 하드 제약 조건으로 구성 됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-191">Most of hello constraints are configured as hard constraints by default.</span></span>

<span data-ttu-id="af828-192">제약 조건의 hello 우선 순위를 변경 흔하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-192">Changing hello priority of constraints is uncommon.</span></span> <span data-ttu-id="af828-193">내용이 시간 제약 조건이 우선 순위 toochange, 일반적으로 다른 몇 가지 버그 또는 hello 환경에 영향을 주지 된 동작 주위 toowork 가져야 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-193">There have been times where constraint priorities needed toochange, usually toowork around some other bug or behavior that was impacting hello environment.</span></span> <span data-ttu-id="af828-194">일반적으로 hello 제약 조건이 우선 순위 인프라의 유연성이 hello 한 적이 상태일 때 잘, 하지만 자주 필요 하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-194">Generally hello flexibility of hello constraint priority infrastructure has worked very well, but it isn't needed often.</span></span> <span data-ttu-id="af828-195">대부분의 hello 모든 기본 우선 순위에 위치합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-195">Most of hello time everything sits at their default priorities.</span></span> 

<span data-ttu-id="af828-196">hello 우선 순위 수준을 하지 않는다는 것을 의미에서 지정한 제약 조건 _됩니다_ 위반 수 나 충족 항상 됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-196">hello priority levels don't mean that a given constraint _will_ be violated, nor that it will always be met.</span></span> <span data-ttu-id="af828-197">제약 조건 우선 순위는 제약 조건이 적용되는 순서를 정의합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-197">Constraint priorities define an order in which constraints are enforced.</span></span> <span data-ttu-id="af828-198">우선 순위 hello 장단점 불가능 한 toosatisfy 되었을 때 모든 제약 조건을 정의 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-198">Priorities define hello tradeoffs when it is impossible toosatisfy all constraints.</span></span> <span data-ttu-id="af828-199">일반적으로 hello 환경에서 다른 진행 리 하지 않는 한 hello 제약 조건은 모두 충족 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-199">Usually all hello constraints can be satisfied unless there's something else going on in hello environment.</span></span> <span data-ttu-id="af828-200">Tooconstraint 위반 사항이 시나리오의 예로 충돌 하는 제약 조건 또는 많은 수의 동시 실패 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-200">Some examples of scenarios that will lead tooconstraint violations are conflicting constraints, or large numbers of concurrent failures.</span></span>

<span data-ttu-id="af828-201">고급 시나리오에서는 hello 제약 조건이 우선 순위를 변경할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-201">In advanced situations, you can change hello constraint priorities.</span></span> <span data-ttu-id="af828-202">예를 들어, tooensure 한다고 필요한 toosolve 노드 용량을 발급 하는 경우 선호도 위반 항상 것입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-202">For example, say you wanted tooensure that affinity would always be violated when necessary toosolve node capacity issues.</span></span> <span data-ttu-id="af828-203">tooachieve이 hello 선호도 제약 조건 "소프트" 너무 (1)의 hello 우선 순위를 설정 및 hello 용량 제한이 너무 "하드" 설정 (0) 나갈 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-203">tooachieve this, you could set hello priority of hello affinity constraint too“soft” (1) and leave hello capacity constraint set too“hard” (0).</span></span>

<span data-ttu-id="af828-204">제약 조건이 서로 다른 hello에 대 한 기본 우선 순위 값 hello hello 구성 뒤에 지정 됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-204">hello default priority values for hello different constraints are specified in hello following config:</span></span>

<span data-ttu-id="af828-205">ClusterManifest.xml</span><span class="sxs-lookup"><span data-stu-id="af828-205">ClusterManifest.xml</span></span>

```xml
        <Section Name="PlacementAndLoadBalancing">
            <Parameter Name="PlacementConstraintPriority" Value="0" />
            <Parameter Name="CapacityConstraintPriority" Value="0" />
            <Parameter Name="AffinityConstraintPriority" Value="0" />
            <Parameter Name="FaultDomainConstraintPriority" Value="0" />
            <Parameter Name="UpgradeDomainConstraintPriority" Value="1" />
            <Parameter Name="PreferredLocationConstraintPriority" Value="2" />
        </Section>
```

<span data-ttu-id="af828-206">독립 실행형 배포의 경우 ClusterConfig.json 또는 Azure 호스티드 클러스터의 경우 Template.json를 통해 수행됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-206">via ClusterConfig.json for Standalone deployments or Template.json for Azure hosted clusters:</span></span>

```json
"fabricSettings": [
  {
    "name": "PlacementAndLoadBalancing",
    "parameters": [
      {
          "name": "PlacementConstraintPriority",
          "value": "0"
      },
      {
          "name": "CapacityConstraintPriority",
          "value": "0"
      },
      {
          "name": "AffinityConstraintPriority",
          "value": "0"
      },
      {
          "name": "FaultDomainConstraintPriority",
          "value": "0"
      },
      {
          "name": "UpgradeDomainConstraintPriority",
          "value": "1"
      },
      {
          "name": "PreferredLocationConstraintPriority",
          "value": "2"
      }
    ]
  }
]
```

## <a name="fault-domain-and-upgrade-domain-constraints"></a><span data-ttu-id="af828-207">장애 도메인 및 업그레이드 도메인 제약 조건</span><span class="sxs-lookup"><span data-stu-id="af828-207">Fault domain and upgrade domain constraints</span></span>
<span data-ttu-id="af828-208">hello 클러스터 리소스 관리자가 오류 및 업그레이드 도메인 간에 분산 된 tookeep 서비스입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-208">hello Cluster Resource Manager wants tookeep services spread out among fault and upgrade domains.</span></span> <span data-ttu-id="af828-209">Hello 클러스터 리소스 관리자의 엔진 내 제약 조건으로 모델링합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-209">It models this as a constraint inside hello Cluster Resource Manager’s engine.</span></span> <span data-ttu-id="af828-210">사용 되는 방법에 대 한 자세한 내용 및 특정 동작에 대 한 체크 아웃 hello 문서에 [클러스터 구성](service-fabric-cluster-resource-manager-cluster-description.md#fault-and-upgrade-domain-constraints-and-resulting-behavior)합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-210">For more information on how they are used and their specific behavior, check out hello article on [cluster configuration](service-fabric-cluster-resource-manager-cluster-description.md#fault-and-upgrade-domain-constraints-and-resulting-behavior).</span></span>

<span data-ttu-id="af828-211">hello 클러스터 리소스 관리자 순서 toodeal 업그레이드 성공, 실패 또는 기타 제약 조건 위반으로의 업그레이드 도메인으로 toopack 복제본 두 개를 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-211">hello Cluster Resource Manager may need toopack a couple replicas into an upgrade domain in order toodeal with upgrades, failures, or other constraint violations.</span></span> <span data-ttu-id="af828-212">일반적으로 오류 또는 업그레이드 도메인으로 압축 몇 번의 실패 또는 다른 변동을 올바른 배치를 방지 하는 hello 시스템에 있는 경우에 발생 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-212">Packing into fault or upgrade domains normally happens only when there are several failures or other churn in hello system preventing correct placement.</span></span> <span data-ttu-id="af828-213">Hello를 활용할 수 있습니다 이러한 상황 중에 압축 tooprevent 원할 경우 `RequireDomainDistribution` [배치 정책](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md#requiring-replica-distribution-and-disallowing-packing)합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-213">If you wish tooprevent packing even during these situations, you can utilize hello `RequireDomainDistribution` [placement policy](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md#requiring-replica-distribution-and-disallowing-packing).</span></span> <span data-ttu-id="af828-214">이 경우 서비스 가용성 및 안정성에 부작용을 미칠 수 있으므로 신중하게 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-214">Note that this may affect service availability and reliability as a side effect, so consider it carefully.</span></span>

<span data-ttu-id="af828-215">Hello 환경이 올바르게 구성 하는 경우 모든 제약 조건이 완전히 고려, 업그레이드 중에 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-215">If hello environment is configured correctly, all constraints are fully respected, even during upgrades.</span></span> <span data-ttu-id="af828-216">hello 점을 클러스터 리소스 관리자 제약 조건이 배포 지역과 해당 hello입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-216">hello key thing is that hello Cluster Resource Manager is watching out for your constraints.</span></span> <span data-ttu-id="af828-217">위반을 검색 하는 경우 즉시 보고 하 고 toocorrect hello 문제를 시도 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-217">When it detects a violation it immediately reports it and tries toocorrect hello issue.</span></span>

## <a name="hello-preferred-location-constraint"></a><span data-ttu-id="af828-218">기본 설정 hello 위치 제약 조건</span><span class="sxs-lookup"><span data-stu-id="af828-218">hello preferred location constraint</span></span>
<span data-ttu-id="af828-219">hello PreferredLocation 제약 조건을 두 개의 서로 다른 사용이 약간 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="af828-219">hello PreferredLocation constraint is a little different, as it has two different uses.</span></span> <span data-ttu-id="af828-220">이 제약 조건의 한 가지 용도는 응용 프로그램 업그레이드 중에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-220">One use of this constraint is during application upgrades.</span></span> <span data-ttu-id="af828-221">hello 클러스터 리소스 관리자는 자동으로 업그레이드 하는 동안이 제약 조건은 관리합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-221">hello Cluster Resource Manager automatically manages this constraint during upgrades.</span></span> <span data-ttu-id="af828-222">사용 되는 tooensure는 복제본 반환 초기 위치 tootheir 함을 완료 되는 경우 업그레이드 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-222">It is used tooensure that when upgrades are complete that replicas return tootheir initial locations.</span></span> <span data-ttu-id="af828-223">hello hello PreferredLocation 제약 조건의 다른 용도 hello에 대 한 [ `PreferredPrimaryDomain` 배치 정책](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md)합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-223">hello other use of hello PreferredLocation constraint is for hello [`PreferredPrimaryDomain` placement policy](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md).</span></span> <span data-ttu-id="af828-224">두 가지 최적화 되며 따라서 hello PreferredLocation 제약 조건 hello만 제약 조건을 설정 너무 기본적으로 "최적화"입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-224">Both of these are optimizations, and hence hello PreferredLocation constraint is hello only constraint set too"Optimization" by default.</span></span>

## <a name="upgrades"></a><span data-ttu-id="af828-225">업그레이드</span><span class="sxs-lookup"><span data-stu-id="af828-225">Upgrades</span></span>
<span data-ttu-id="af828-226">hello 클러스터 리소스 관리자 응용 프로그램 및 두 개의 작업에는 클러스터 업그레이드 하는 동안 하기도 쉽습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-226">hello Cluster Resource Manager also helps during application and cluster upgrades, during which it has two jobs:</span></span>

* <span data-ttu-id="af828-227">hello 클러스터의 hello 규칙 손상 되지 않도록</span><span class="sxs-lookup"><span data-stu-id="af828-227">ensure that hello rules of hello cluster are not compromised</span></span>
* <span data-ttu-id="af828-228">toohelp hello 업그레이드 go를 원활 하 게 시도</span><span class="sxs-lookup"><span data-stu-id="af828-228">try toohelp hello upgrade go smoothly</span></span>

### <a name="keep-enforcing-hello-rules"></a><span data-ttu-id="af828-229">Hello 규칙을 적용할 유지</span><span class="sxs-lookup"><span data-stu-id="af828-229">Keep enforcing hello rules</span></span>
<span data-ttu-id="af828-230">hello 것이 중요 toobe 인식는 hello 규칙 – hello 엄격한 제약 조건 배치 제약 조건 및 특성과 같은-업그레이드 하는 동안 계속 적용 됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-230">hello main thing toobe aware of is that hello rules – hello strict constraints like placement constraints and capacities - are still enforced during upgrades.</span></span> <span data-ttu-id="af828-231">배치 제약 조건을 통해 업그레이드 중에도 허용된 작업을 실행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-231">Placement constraints ensure that your workloads only run where they are allowed to, even during upgrades.</span></span> <span data-ttu-id="af828-232">서비스에 대한 제약이 심하면 업그레이드가 오래 걸릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-232">When services are highly constrained, upgrades can take longer.</span></span> <span data-ttu-id="af828-233">이동할 수 있는 위치에 대 한 몇 가지 옵션 있을 수 있습니다는 업데이트에 대 한 종료 hello 서비스나 hello 노드에서 실행 되는 경우.</span><span class="sxs-lookup"><span data-stu-id="af828-233">When hello service or hello node it is running on is brought down for an update there may be few options for where it can go.</span></span>

### <a name="smart-replacements"></a><span data-ttu-id="af828-234">스마트 대체</span><span class="sxs-lookup"><span data-stu-id="af828-234">Smart replacements</span></span>
<span data-ttu-id="af828-235">업그레이드를 시작할 때 hello 리소스 관리자는 hello 현재 배열 hello 클러스터의 스냅숏을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="af828-235">When an upgrade starts, hello Resource Manager takes a snapshot of hello current arrangement of hello cluster.</span></span> <span data-ttu-id="af828-236">각 업그레이드 도메인 완료 tooreturn hello 서비스 해당 도메인 업그레이드 tootheir 원래 배열에서를 시도 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-236">As each Upgrade Domain completes, it attempts tooreturn hello services that were in that Upgrade Domain tootheir original arrangement.</span></span> <span data-ttu-id="af828-237">이러한 방식으로 최대 두 개의 전환이 있을 서비스에 대 한 hello 업그레이드 중입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-237">This way there are at most two transitions for a service during hello upgrade.</span></span> <span data-ttu-id="af828-238">영향을 받는 hello 노드의 아웃 하나의 이동 되며 하나 뒤로 이동 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-238">There is one move out of hello affected node and one move back in.</span></span> <span data-ttu-id="af828-239">Hello 업그레이드 갖는지도 hello 업그레이드 전의 hello 클러스터 또는 서비스 toohow 반환 hello 레이아웃 hello 클러스터의 영향을 주지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-239">Returning hello cluster or service toohow it was before hello upgrade also ensures hello upgrade doesn’t impact hello layout of hello cluster.</span></span> 

### <a name="reduced-churn"></a><span data-ttu-id="af828-240">이탈 감소</span><span class="sxs-lookup"><span data-stu-id="af828-240">Reduced churn</span></span>
<span data-ttu-id="af828-241">업그레이드 하는 동안 발생 하는 다른 항목은 균형 조정 클러스터 리소스 관리자를 해제 하는 hello입니다.</span><span class="sxs-lookup"><span data-stu-id="af828-241">Another thing that happens during upgrades is that hello Cluster Resource Manager turns off balancing.</span></span> <span data-ttu-id="af828-242">균형 조정 방지 서비스 hello 업그레이드에 대 한 비운 노드로 이동 하는 같은 자체를 불필요 한 반응과 toohello 업그레이드가 되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-242">Preventing balancing prevents unnecessary reactions toohello upgrade itself, like moving services into nodes that were emptied for hello upgrade.</span></span> <span data-ttu-id="af828-243">클러스터 업그레이드는 hello 업그레이드 문제의 이면 hello 전체 클러스터는 hello 업그레이드 하는 동안 균형이 맞지 않으면 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-243">If hello upgrade in question is a Cluster upgrade, then hello entire cluster is not balanced during hello upgrade.</span></span> <span data-ttu-id="af828-244">제약 조건 검사를 활성 상태로 유지, 메트릭 사전 분산 hello에 따라 유일한 움직임을 사용할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-244">Constraint checks stay active, only movement based on hello proactive balancing of metrics is disabled.</span></span>

### <a name="buffered-capacity--upgrade"></a><span data-ttu-id="af828-245">버퍼링된 용량 및 업그레이드</span><span class="sxs-lookup"><span data-stu-id="af828-245">Buffered Capacity & Upgrade</span></span>
<span data-ttu-id="af828-246">일반적으로 원하는 hello 업그레이드 toocomplete hello 클러스터는 제한 된 또는 닫기 toofull 하는 경우에 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-246">Generally you want hello upgrade toocomplete even if hello cluster is constrained or close toofull.</span></span> <span data-ttu-id="af828-247">Hello 클러스터의 hello 용량 관리 훨씬 더 중요할 경우 업그레이드 하는 동안 평소 보다</span><span class="sxs-lookup"><span data-stu-id="af828-247">Managing hello capacity of hello cluster is even more important during upgrades than usual.</span></span> <span data-ttu-id="af828-248">Hello에 따라 hello 업그레이드 롤업 hello 클러스터 통해으로 5-20% 용량의 업그레이드 도메인 수 마이그레이션해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-248">Depending on hello number of upgrade domains, between 5 and 20 percent of capacity must be migrated as hello upgrade rolls through hello cluster.</span></span> <span data-ttu-id="af828-249">해당 작업 toogo를 특정 위치에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-249">That work has toogo somewhere.</span></span> <span data-ttu-id="af828-250">개념을 여기서 hello은이 [용량 버퍼링](service-fabric-cluster-resource-manager-cluster-description.md#buffered-capacity) 유용 합니다.</span><span class="sxs-lookup"><span data-stu-id="af828-250">This is where hello notion of [buffered capacities](service-fabric-cluster-resource-manager-cluster-description.md#buffered-capacity) is useful.</span></span> <span data-ttu-id="af828-251">버퍼링된 용량은 정상 작업 중에 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="af828-251">Buffered capacity is respected during normal operation.</span></span> <span data-ttu-id="af828-252">hello 클러스터 리소스 관리자는 필요한 경우 업그레이드 하는 동안 tootheir 총 용량 (사용 hello 버퍼) 노드 채워질 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="af828-252">hello Cluster Resource Manager may fill nodes up tootheir total capacity (consuming hello buffer) during upgrades if necessary.</span></span>

## <a name="next-steps"></a><span data-ttu-id="af828-253">다음 단계</span><span class="sxs-lookup"><span data-stu-id="af828-253">Next steps</span></span>
* <span data-ttu-id="af828-254">Hello 처음부터 시작 하 고 [소개 toohello 서비스 패브릭 클러스터 리소스 관리자 가져오기](service-fabric-cluster-resource-manager-introduction.md)</span><span class="sxs-lookup"><span data-stu-id="af828-254">Start from hello beginning and [get an Introduction toohello Service Fabric Cluster Resource Manager](service-fabric-cluster-resource-manager-introduction.md)</span></span>
