---
title: "Azure에서 Linux로 Cassandra 실행 | Microsoft Docs"
description: "Node.js 앱에서 Azure 가상 컴퓨터의 Linux에서 Cassandra 클러스터를 실행하는 방법에 대해 알아봅니다."
services: virtual-machines-linux
documentationcenter: nodejs
author: tomarcher
manager: routlaw
editor: 
tags: azure-service-management
ms.assetid: 30de1f29-e97d-492f-ae34-41ec83488de0
ms.service: virtual-machines-linux
ms.workload: infrastructure-services
ms.tgt_pltfrm: vm-linux
ms.devlang: na
ms.topic: article
ms.date: 08/17/2017
ms.author: tarcher
ms.openlocfilehash: 1ff3d77ced6c9d90029b251490c05e52d9b43515
ms.sourcegitcommit: 18ad9bc049589c8e44ed277f8f43dcaa483f3339
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 08/29/2017
---
# <a name="running-cassandra-with-linux-on-azure-and-accessing-it-from-nodejs"></a><span data-ttu-id="63331-103">Azure에서 Linux 환경의 Cassandra 실행 및 Node.js에서 Cassandra에 액세스</span><span class="sxs-lookup"><span data-stu-id="63331-103">Running Cassandra with Linux on Azure and Accessing it from Node.js</span></span>
> [!IMPORTANT] 
> <span data-ttu-id="63331-104">Azure에는 리소스를 만들고 작업하기 위한 [리소스 관리자 및 클래식](../../../resource-manager-deployment-model.md)라는 두 가지 배포 모델이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-104">Azure has two different deployment models for creating and working with resources: [Resource Manager and Classic](../../../resource-manager-deployment-model.md).</span></span> <span data-ttu-id="63331-105">이 문서에서는 클래식 배포 모델 사용에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-105">This article covers using the Classic deployment model.</span></span> <span data-ttu-id="63331-106">새로운 배포는 대부분 리소스 관리자 모델을 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-106">Microsoft recommends that most new deployments use the Resource Manager model.</span></span> <span data-ttu-id="63331-107">[Datastax Enterprise](https://azure.microsoft.com/documentation/templates/datastax) 및 [CentOS의 Spark 클러스터 및 Cassandra](https://azure.microsoft.com/documentation/templates/spark-and-cassandra-on-centos/)는 Resource Manager 템플릿을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-107">See Resource Manager templates for [Datastax Enterprise](https://azure.microsoft.com/documentation/templates/datastax) and [Spark cluster and Cassandra on CentOS](https://azure.microsoft.com/documentation/templates/spark-and-cassandra-on-centos/).</span></span>

## <a name="overview"></a><span data-ttu-id="63331-108">개요</span><span class="sxs-lookup"><span data-stu-id="63331-108">Overview</span></span>
<span data-ttu-id="63331-109">Microsoft Azure는 운영 체제, 응용 프로그램 서버, 메시징 미들웨어뿐 아니라 상용 및 오픈 소스 모델의 SQL 및 NoSQL 데이터베이스를 포함하는 Microsoft 및 타사 소프트웨어를 실행하는 개방형 클라우드 플랫폼입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-109">Microsoft Azure is an open cloud platform that runs both Microsoft as well as non-Microsoft software which  includes operating systems, application servers, messaging middleware as well as SQL and NoSQL databases from both commercial and open source models.</span></span> <span data-ttu-id="63331-110">Azure를 비롯한 공용 클라우드에 복원 서비스를 빌드하려면 응용 프로그램 서버 및 저장소 계층 둘 다의 신중한 계획과 세밀한 아키텍처가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-110">Building resilient services on public clouds including Azure requires careful planning and deliberate architecture for both applications servers as well storage layers.</span></span> <span data-ttu-id="63331-111">Cassandra의 분산 저장소 아키텍처는 클러스터 오류에 대한 내결함성이 있는 고가용성 시스템 빌드에 도움이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-111">Cassandra’s distributed storage architecture naturally helps in building highly available systems that are fault tolerant for cluster failures.</span></span> <span data-ttu-id="63331-112">Cassandra는 cassandra.apache.org에서 Apache Software Foundation에 의해 유지 관리되는 클라우드 규모의 NoSQL 데이터베이스입니다. Cassandra는 Java로 작성되었으므로 Windows 및 Linux 플랫폼에서 모두 실행됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-112">Cassandra is a cloud scale NoSQL database maintained by Apache Software Foundation at cassandra.apache.org; Cassandra is written in Java and hence runs on both on Windows as well as Linux platforms.</span></span>

<span data-ttu-id="63331-113">이 문서는 Microsoft Azure 가상 컴퓨터 및 가상 네트워크를 활용하여 Cassandra를 단일 및 다중 데이터 센터로 Ubuntu에 배포하는 과정을 보여 주는 데 중점을 둡니다.</span><span class="sxs-lookup"><span data-stu-id="63331-113">The focus of this article is to show Cassandra deployment on Ubuntu as a single and multi-data center cluster leveraging Microsoft Azure Virtual Machines and Virtual Networks.</span></span> <span data-ttu-id="63331-114">프로덕션에 최적화된 작업을 위한 클러스터 배포는 필요한 복제, 데이터 일관성, 처리량 및 고가용성 요구 사항을 충족하기 위해 다중 디스크 노드 구성, 적절한 링 토폴로지 디자인 및 데이터 모델링이 필요하므로 이 문서의 범위를 벗어납니다.</span><span class="sxs-lookup"><span data-stu-id="63331-114">The cluster deployment for production optimized workloads is out of scope of this article as it requires multi-disk node configuration, appropriate ring topology design and data modeling to support the needed replication, data consistency, throughput and high availability requirements.</span></span>

<span data-ttu-id="63331-115">이 문서에서는 인프라 배포를 훨씬 용이하게 하는 Cassandra 클러스터 비교 Docker, Chef 또는 Puppet 빌드와 관련된 작업을 보여 주는 기본적인 접근 방법을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-115">This article takes a fundamental approach to show what is involved in building the Cassandra cluster compared Docker, Chef or Puppet which can make the infrastructure deployment a lot easier.</span></span>  

## <a name="the-deployment-models"></a><span data-ttu-id="63331-116">배포 모델</span><span class="sxs-lookup"><span data-stu-id="63331-116">The Deployment Models</span></span>
<span data-ttu-id="63331-117">Microsoft Azure 네트워킹을 사용하면 미세 조정된 네트워크 보안을 위해 액세스를 제한할 수 있는 격리된 개인 클러스터를 배포할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-117">Microsoft Azure networking allows the deployment of isolated private clusters, the access of which can be restricted to attain fine grained network security.</span></span>  <span data-ttu-id="63331-118">이 문서에서는 기본 수준의 Cassandra 배포를 보여 줄 것이므로 일관성 수준 및 처리량에 최적화된 저장소 디자인에는 중점을 두지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-118">Since this article is about showing the Cassandra deployment at a fundamental level, we will not focus on the consistency level and the optimal storage design for throughput.</span></span> <span data-ttu-id="63331-119">다음은 가상 클러스터에 대한 네트워킹 요구 사항 목록입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-119">Here is the list of networking requirements for our hypothetical cluster:</span></span>

* <span data-ttu-id="63331-120">외부 시스템은 Azure 내부나 외부에서 Cassandra 데이터베이스에 액세스할 수 없어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-120">External systems can’t access Cassandra database from within or outside Azure</span></span>
* <span data-ttu-id="63331-121">Cassandra 클러스터는 쓰리프트 트래픽에 대한 부하 분산 장치 뒤에 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-121">Cassandra cluster has to be behind a load balancer for thrift traffic</span></span>
* <span data-ttu-id="63331-122">클러스터 가용성 향상을 위해 각 데이터 센터의 두 그룹에 Cassandra 노드를 배포해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-122">Deploy Cassandra nodes in two groups in each data center for an enhanced cluster availability</span></span>
* <span data-ttu-id="63331-123">응용 프로그램 서버 팜만 데이터베이스에 직접 액세스할 수 있도록 클러스터를 잠가야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-123">Lock down the cluster so that only application server farm has access to the database directly</span></span>
* <span data-ttu-id="63331-124">SSH 이외의 공용 네트워킹 끝점이 없어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-124">No public networking endpoints other than SSH</span></span>
* <span data-ttu-id="63331-125">각 Cassandra 노드에 고정된 내부 IP 주소가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-125">Each Cassandra node needs a fixed internal IP address</span></span>

<span data-ttu-id="63331-126">Cassandra는 작업의 분산 특성에 따라 단일 Azure 지역이나 여러 지역에 배포할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-126">Cassandra can be deployed to a single Azure region or to multiple regions based on the distributed nature of the workload.</span></span> <span data-ttu-id="63331-127">다중 지역 배포 모델을 활용하면 동일한 Cassandra 인프라를 통해 특정 지역에 더 가까운 곳에서 최종 사용자에게 서비스를 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-127">Multi-region deployment model can be leveraged to serve end users closer to a particular geography through the same Cassandra infrastructure.</span></span> <span data-ttu-id="63331-128">Cassandra의 기본 제공 노드 복제는 여러 데이터 센터에서 발생한 다중 마스터 쓰기를 동기화하고 일관된 데이터 뷰를 응용 프로그램에 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-128">Cassandra’s built-in node replication takes care of the synchronization of multi-master writes originating from multiple data centers and presents a consistent view of the data to applications.</span></span> <span data-ttu-id="63331-129">또한 다중 지역 배포는 광범위한 Azure 서비스 중단 위험의 완화에도 도움이 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-129">Multi-region deployment can also help with the risk mitigation of the broader Azure service outages.</span></span> <span data-ttu-id="63331-130">Cassandra의 조정 가능한 일관성 및 복제 토폴로지는 응용 프로그램의 다양한 RPO 요구를 충족하는 데 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-130">Cassandra’s tunable consistency and replication topology will help in meeting diverse RPO needs of applications.</span></span>

### <a name="single-region-deployment"></a><span data-ttu-id="63331-131">단일 지역 배포</span><span class="sxs-lookup"><span data-stu-id="63331-131">Single Region Deployment</span></span>
<span data-ttu-id="63331-132">단일 지역 배포로 시작하여 다중 지역 모델을 만드는 방법을 알아보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-132">We will start with a single region deployment and harvest the learnings in creating a multi-region model.</span></span> <span data-ttu-id="63331-133">Azure 가상 네트워킹은 위에서 언급한 네트워크 보안 요구 사항을 충족할 수 있도록 격리된 서브넷을 만드는 데 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-133">Azure virtual networking will be used to create isolated subnets so that the network security requirements mentioned above can be met.</span></span>  <span data-ttu-id="63331-134">단일 지역 배포를 만드는 방법에서 설명된 프로세스는 Ubuntu 14.04 LTS 및 Cassandra 2.08을 사용하지만 다른 Linux 변형에도 쉽게 이 프로세스를 채택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-134">The process described in creating the single region deployment uses Ubuntu 14.04 LTS and Cassandra 2.08; however, the process can easily be adopted to the other Linux variants.</span></span> <span data-ttu-id="63331-135">다음은 단일 지역 배포의 몇 가지 시스템 특성입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-135">The following are some of the systemic characteristics of the single region deployment.</span></span>  

<span data-ttu-id="63331-136">**고가용성:** 노드가 고가용성을 위해 여러 오류 도메인 간에 분산되도록 Cassandra 노드는 그림 1에서처럼 두 가용성 집합에 배포됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-136">**High Availability:** The Cassandra nodes shown in the Figure 1 are deployed to two availability sets so that the nodes are spread between multiple fault domains for high availability.</span></span> <span data-ttu-id="63331-137">각 가용성 집합은 주석이 추가된 VM이 2개의 오류 도메인에 매핑됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-137">VMs annotated with each availability set is mapped to 2 fault domains.</span></span>  <span data-ttu-id="63331-138">Microsoft Azure는 계획되지 않은 작동 중지 시간(예: 하드웨어 또는 소프트웨어 오류)을 관리하는 데 장애 도메인의 개념을 사용하지만, 예정된 작동 중지 시간 관리에는 업그레이드 도메인(예: 호스트 또는 게스트 OS 패치/업그레이드, 응용 프로그램 업그레이드)의 개념을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-138">Microsoft Azure uses the concept of fault domain to manage unplanned down time (e.g. hardware or software failures) while the concept of upgrade domain (e.g. host or guest OS patching/upgrades, application upgrades) is used for managing scheduled down time.</span></span> <span data-ttu-id="63331-139">높은 가용성 확보에 있어 오류 및 업그레이드 도메인의 역할은 [Azure 응용 프로그램에 대한 고가용성 및 재해 복구](http://msdn.microsoft.com/library/dn251004.aspx) 를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-139">Please see [Disaster Recovery and High Availability for Azure Applications](http://msdn.microsoft.com/library/dn251004.aspx) for the role of fault and upgrade domains in attaining high availability.</span></span>

![단일 지역 배포](./media/cassandra-nodejs/cassandra-linux1.png)

<span data-ttu-id="63331-141">그림 1: 단일 지역 배포</span><span class="sxs-lookup"><span data-stu-id="63331-141">Figure 1: Single region deployment</span></span>

<span data-ttu-id="63331-142">이 문서를 작성할 당시, Azure는 특정 장애 도메인에 대한 VM 그룹의 명시적 매핑을 허용하지 않습니다. 따라서 그림 1에 표시된 배포 모델에서도 통계상 모든 가상 컴퓨터가 4개가 아닌 2개의 장애 도메인에 매핑될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-142">Note that at the time of this writing, Azure doesn’t allow the explicit mapping of a group of VMs to a specific fault domain; consequently, even with the deployment model shown in Figure 1, it is statistically probable that all the virtual machines may be mapped to two fault domains instead of four.</span></span>

<span data-ttu-id="63331-143">**로드 균형 조정 Thrift 트래픽:** 웹 서버 내부의 Thrift 클라이언트 라이브러리는 내부 부하 분산 장치를 통해 클러스터에 연결합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-143">**Load Balancing Thrift Traffic:** Thrift client libraries inside the web server connect to the cluster through an internal load balancer.</span></span> <span data-ttu-id="63331-144">이렇게 하려면 Cassandra 클러스터를 호스팅하는 클라우드 서비스의 컨텍스트에서 "데이터" 서브넷에 내부 부하 분산 장치를 추가하는 프로세스가 필요합니다(그림 1 참조).</span><span class="sxs-lookup"><span data-stu-id="63331-144">This requires the process of adding the internal load balancer to the “data” subnet (refer Figure 1) in the context of the cloud service hosting the Cassandra cluster.</span></span> <span data-ttu-id="63331-145">내부 부하 분산을 정의한 후, 각 노드에서 부하 분산된 끝점이 이전에 정의된 부하 분산 장치 이름을 포함하는 부하 분산된 집합의 주석으로 추가되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-145">Once the internal load balancer is defined, each node requires the load balanced endpoint to be added with the annotations of a load balanced set with previously defined load balancer name.</span></span> <span data-ttu-id="63331-146">자세한 내용은 [Azure 내부 부하 분산 ](../../../load-balancer/load-balancer-internal-overview.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-146">See [Azure Internal Load Balancing ](../../../load-balancer/load-balancer-internal-overview.md)for more details.</span></span>

<span data-ttu-id="63331-147">**클러스터 시드:** 새 노드는 시드 노드와 통신하여 클러스터의 토폴로지를 검색하므로 가장 가용성이 큰 노드를 시드에 대해 선택하는 것이 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-147">**Cluster Seeds:** It is important to select the most highly available nodes for seeds as the new nodes will communicate with seed nodes to discover the topology of the cluster.</span></span> <span data-ttu-id="63331-148">단일 실패 지점을 방지하기 위해 각 가용성 집합에서 하나의 노드가 시드 노드로 지정됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-148">One node from each availability set is designated as seed nodes to avoid single point of failure.</span></span>

<span data-ttu-id="63331-149">**복제 요소 및 일관성 수준:** Cassandra의 기본 제공 고가용성 및 데이터 지속성의 특징은 복제 계수(RF-클러스터에 저장된 각 행의 복사본 매수) 및 일관성 수준(호출자에게 결과를 반환하기 전에 읽기/쓰기를 수행할 복제본의 수)입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-149">**Replication Factor and Consistency Level:** Cassandra’s build-in high-availability and data durability is characterized by the Replication Factor (RF - number of copies of each row stored on the cluster) and Consistency Level (number of replicas to be read/written before returning the result to the caller).</span></span> <span data-ttu-id="63331-150">복제 요소는 CRUD 쿼리 실행 중 일관성 수준을 지정하는 반면 KEYSPACE(관계형 데이터베이스와 유사)를 만드는 동안 지정됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-150">Replication factor is specified during the KEYSPACE (similar to a relational database) creation whereas the consistency level is specified while issuing the CRUD query.</span></span> <span data-ttu-id="63331-151">일관성 세부 정보 및 쿼럼 계산에 대한 수식은 [일관성을 위해 구성](http://www.datastax.com/documentation/cassandra/2.0/cassandra/dml/dml_config_consistency_c.html) 의 Cassandra 설명서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-151">See Cassandra documentation at [Configuring for Consistency](http://www.datastax.com/documentation/cassandra/2.0/cassandra/dml/dml_config_consistency_c.html) for consistency details and the formula for quorum computation.</span></span>

<span data-ttu-id="63331-152">Cassandra는 두 가지 유형의 데이터 무결성 모델, 즉 일관성과 최종 일관성을 지원합니다. 복제 계수 및 일관성 수준이 결합되어 쓰기 작업이 완료되는 즉시 데이터가 일치하는지 또는 최종적으로 일치하는지를 결정합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-152">Cassandra supports two types of data integrity models – Consistency and Eventual Consistency; the Replication Factor and Consistency Level will together determine if the data will be consistent as soon as a write operation is complete or it will be eventually consistent.</span></span> <span data-ttu-id="63331-153">예를 들어 QUORUM을 일관성 수준으로 지정하면 항상 데이터 일관성이 유지되는 반면 QUORUM 실현에 필요한 쓸 복제본 수보다 낮은 일관성 수준(예: ONE)에서는 데이터가 최종적으로 일치합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-153">For example, specifying QUORUM as the Consistency Level will always ensures data Consistency while any consistency level, below the number of replicas to be written as needed to attain QUORUM (e.g. ONE) results in data being eventually consistent.</span></span>

<span data-ttu-id="63331-154">복제 계수가 3이고 읽기/쓰기 일관성 수준이 QUORUM(일관성을 위해 2개 노드를 읽거나 씀)인 위에 표시된 8 노드 클러스터는 응용 프로그램에서 실패를 감지하기 전에 복제 그룹당 최대 1개 노드의 이론적 손실을 감당할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-154">The 8-node cluster shown above, with a replication factor of 3 and QUORUM (2 nodes are read or written for consistency) read/write consistency level, can survive the theoretical loss of at the most 1 node per replication group before the application start noticing the failure.</span></span> <span data-ttu-id="63331-155">이 경우 모든 주요 공간에서 읽기/쓰기 요청의 균형이 잘 조정되어 있다고 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-155">This assumes that all the key spaces have well balanced read/write requests.</span></span>  <span data-ttu-id="63331-156">다음은 배포된 클러스터에 사용할 매개 변수입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-156">The following are the parameters we will use for the deployed cluster:</span></span>

<span data-ttu-id="63331-157">단일 지역 Cassandra 클러스터 구성:</span><span class="sxs-lookup"><span data-stu-id="63331-157">Single region Cassandra cluster configuration:</span></span>

| <span data-ttu-id="63331-158">클러스터 매개 변수</span><span class="sxs-lookup"><span data-stu-id="63331-158">Cluster Parameter</span></span> | <span data-ttu-id="63331-159">값</span><span class="sxs-lookup"><span data-stu-id="63331-159">Value</span></span> | <span data-ttu-id="63331-160">설명</span><span class="sxs-lookup"><span data-stu-id="63331-160">Remarks</span></span> |
| --- | --- | --- |
| <span data-ttu-id="63331-161">노드 수(N)</span><span class="sxs-lookup"><span data-stu-id="63331-161">Number of Nodes (N)</span></span> |<span data-ttu-id="63331-162">8</span><span class="sxs-lookup"><span data-stu-id="63331-162">8</span></span> |<span data-ttu-id="63331-163">클러스터의 총 노드 수</span><span class="sxs-lookup"><span data-stu-id="63331-163">Total number of nodes in the cluster</span></span> |
| <span data-ttu-id="63331-164">복제 계수(RF)</span><span class="sxs-lookup"><span data-stu-id="63331-164">Replication Factor (RF)</span></span> |<span data-ttu-id="63331-165">3</span><span class="sxs-lookup"><span data-stu-id="63331-165">3</span></span> |<span data-ttu-id="63331-166">지정된 행의 복제본 수</span><span class="sxs-lookup"><span data-stu-id="63331-166">Number of replicas of a given row</span></span> |
| <span data-ttu-id="63331-167">일관성 수준(쓰기)</span><span class="sxs-lookup"><span data-stu-id="63331-167">Consistency Level (Write)</span></span> |<span data-ttu-id="63331-168">QUORUM [(RF/2) +1= 2] 공식 결과는 버림됨</span><span class="sxs-lookup"><span data-stu-id="63331-168">QUORUM[(RF/2) +1) = 2] The result of the formula is rounded down</span></span> |<span data-ttu-id="63331-169">응답이 호출자에게 전송되기 전에 최대 2개의 복제본에 씁니다. 세 번째 복제본은 최종 일관성 방식으로 작성됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-169">Writes at the most 2 replicas before the response is sent to the caller; 3rd replica is written in an eventually consistent manner.</span></span> |
| <span data-ttu-id="63331-170">일관성 수준(읽기)</span><span class="sxs-lookup"><span data-stu-id="63331-170">Consistency Level (Read)</span></span> |<span data-ttu-id="63331-171">QUORUM [(RF/2) +1= 2] 공식 결과는 버림됨</span><span class="sxs-lookup"><span data-stu-id="63331-171">QUORUM [(RF/2) +1= 2] The result of the formula is rounded down</span></span> |<span data-ttu-id="63331-172">호출자에게 응답을 보내기 전에 2개의 복제본을 읽습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-172">Reads 2 replicas before sending response to the caller.</span></span> |
| <span data-ttu-id="63331-173">복제 전략</span><span class="sxs-lookup"><span data-stu-id="63331-173">Replication Strategy</span></span> |<span data-ttu-id="63331-174">NetworkTopologyStrategy자세한 내용은 Cassandra 설명서의 [데이터 복제](http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureDataDistributeReplication_c.html) 참조</span><span class="sxs-lookup"><span data-stu-id="63331-174">NetworkTopologyStrategy see [Data Replication](http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureDataDistributeReplication_c.html) in Cassandra documentation for more information</span></span> |<span data-ttu-id="63331-175">배포 토폴로지를 이해하고 모든 복제본이 동일한 랙에 배포되지 않도록 노드에 복제본을 배치합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-175">Understands the deployment topology and places replicas on nodes so that all the replicas don’t end up on the same rack</span></span> |
| <span data-ttu-id="63331-176">Snitch</span><span class="sxs-lookup"><span data-stu-id="63331-176">Snitch</span></span> |<span data-ttu-id="63331-177">GossipingPropertyFileSnitch 자세한 내용은 Cassandra 설명서의 [Snitches](http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureSnitchesAbout_c.html) 를 참조</span><span class="sxs-lookup"><span data-stu-id="63331-177">GossipingPropertyFileSnitch see [Snitches](http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureSnitchesAbout_c.html) in Cassandra documentation for more information</span></span> |<span data-ttu-id="63331-178">NetworkTopologyStrategy는 snitch 개념을 사용하여 토폴로지를 파악합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-178">NetworkTopologyStrategy uses a concept of snitch to understand the topology.</span></span> <span data-ttu-id="63331-179">GossipingPropertyFileSnitch를 사용하면 데이터 센터 및 랙에 대한 각 노드의 매핑을 보다 잘 제어할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-179">GossipingPropertyFileSnitch gives better control in mapping each node to data center and rack.</span></span> <span data-ttu-id="63331-180">클러스터는 가십을 사용하여 이 정보를 전파합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-180">The cluster then uses gossip to propagate this information.</span></span> <span data-ttu-id="63331-181">PropertyFileSnitch에 비해 동적 IP 설정이 훨씬 간단합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-181">This is much simpler in dynamic IP setting relative to PropertyFileSnitch</span></span> |

<span data-ttu-id="63331-182">**Cassandra 클러스터에 대한 Azure 고려 사항:** Microsoft Azure Virtual Machines 기능은 디스크 지속성을 위해 Azure Blob Storage를 사용합니다. Azure Storage는 높은 내구성을 위해 각 디스크의 복제본을 3개 저장합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-182">**Azure Considerations for Cassandra Cluster:** Microsoft Azure Virtual Machines capability uses Azure Blob storage for disk persistence; Azure Storage saves 3 replicas of each disk for high durability.</span></span> <span data-ttu-id="63331-183">즉, Cassandra 테이블에 삽입된 데이터의 각 행은 3개의 복제본에 이미 저장되어 있으므로 복제 계수(RF)가 1이더라도 데이터 일관성이 처리됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-183">That means each row of data inserted into a Cassandra table is already stored in 3 replicas and hence data consistency is already taken care of even if the Replication Factor (RF) is 1.</span></span> <span data-ttu-id="63331-184">복제 요소가 1인 가장 큰 문제는 단일 Cassandra 노드가 실패하는 경우더라도 응용 프로그램에서 작동 중단이 발생한다는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-184">The main problem with Replication Factor being 1 is that the application will experience downtime even if a single Cassandra node fails.</span></span> <span data-ttu-id="63331-185">그러나 Azure 패브릭 컨트롤러에서 인식된 문제(예: 하드웨어, 시스템 소프트웨어 오류)에 대한 노드가 다운되는 경우, 동일한 저장소 드라이브를 사용하여 해당 위치에 새 노드를 프로비전합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-185">However, if a node is down for the problems (e.g. hardware, system software failures) recognized by Azure Fabric Controller, it will provision a new node in its place using the same storage drives.</span></span> <span data-ttu-id="63331-186">새 노드를 프로비전하여 이전 노드로 바꾸려면 몇 분 정도 걸릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-186">Provisioning a new node to replace the old one may take a few minutes.</span></span>  <span data-ttu-id="63331-187">게스트 OS 변경 같이 계획된 유지 관리 작업과 마찬가지로, Cassandra가 업그레이드되고 응용 프로그램이 변경되어 Azure Fabric Controller는 클러스터에서 노드의 롤링 업그레이드를 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-187">Similarly for planned maintenance activities like guest OS changes, Cassandra upgrades and application changes Azure Fabric Controller performs rolling upgrades of the nodes in the cluster.</span></span>  <span data-ttu-id="63331-188">롤링 업그레이드도 한번에 몇 노드를 분해하므로 클러스터는 몇 파티션에 대해 간단한 가동 중지가 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-188">Rolling upgrades also may take down a few nodes at a time and hence the cluster may experience brief downtime for a few partitions.</span></span> <span data-ttu-id="63331-189">그러나 데이터는 기본 제공 Azure 저장소 중복으로 손실되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-189">However, the data will not be lost due to the built-in Azure Storage redundancy.</span></span>  

<span data-ttu-id="63331-190">Azure에 배포된 시스템에 고가용성(예: 8.76시간/년과 동등한 약 99.9, 자세한 내용은 [고가용성](http://en.wikipedia.org/wiki/High_availability) 참조)이 필요하지 않은 경우 RF=1 및 일관성 수준=ONE으로 실행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-190">For systems deployed to Azure that doesn’t require high availability (e.g. around 99.9 which is equivalent to 8.76 hrs/year; see [High Availability](http://en.wikipedia.org/wiki/High_availability) for details) you may be able to run with RF=1 and Consistency Level=ONE.</span></span>  <span data-ttu-id="63331-191">고가용성 요구 사항이 있는 응용 프로그램의 경우 RF=3 및 일관성 수준=QUORUM은 복제본 한 개당 노드 한 개의 가동 중지 시간을 감당합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-191">For applications with high availability requirements, RF=3 and Consistency Level=QUORUM will tolerate the down time of one of the nodes one of the replicas.</span></span> <span data-ttu-id="63331-192">기존 배포(예: 온-프레미스)의 RF=1은 디스크 오류 등의 문제로 인한 데이터 손실 때문에 사용할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-192">RF=1 in traditional deployments (e.g. on-premises) can’t be used due to the possible data loss resulting from problems like disk failures.</span></span>   

## <a name="multi-region-deployment"></a><span data-ttu-id="63331-193">다중 지역 배포</span><span class="sxs-lookup"><span data-stu-id="63331-193">Multi-region Deployment</span></span>
<span data-ttu-id="63331-194">위에서 설명한 Cassandra의 데이터 센터 인식 복제 및 일관성 모델은 외부 도구를 사용할 필요 없이 바로 다중 지역 배포를 도와줍니다.</span><span class="sxs-lookup"><span data-stu-id="63331-194">Cassandra’s data-center-aware replication and consistency model described above helps with the multi-region deployment out of the box without the need for any external tooling.</span></span> <span data-ttu-id="63331-195">이것이 다중 마스터 쓰기를 위한 데이터베이스 미러링 설정이 매우 복잡할 수 있는 기존 관계형 데이터베이스와의 차이점입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-195">This is quite different from the traditional relational databases where the setup for database mirroring for multi-master writes can be quite complex.</span></span> <span data-ttu-id="63331-196">다중 지역 설정의 Cassandra는 다음을 비롯한 사용 시나리오에서 유용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-196">Cassandra in a multi-region set up can help with the usage scenarios including the following:</span></span>

<span data-ttu-id="63331-197">**근접 기반 배포:** 테넌트 사용자를 명확하게 지역으로 매핑한 다중 테넌트 응용 프로그램은 다중 지역 클러스터의 낮은 대기 시간의 이점이 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-197">**Proximity based deployment:** Multi-tenant applications, with clear mapping of tenant users -to-region, can be benefited by the multi-region cluster’s low latencies.</span></span> <span data-ttu-id="63331-198">예를 들어, 교육 기관에 대한 학습 관리 시스템은 미국 동부 및 미국 서부 지역에 분산된 클러스터를 배포하여 트랜잭션 및 분석을 위해 각 캠퍼스를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-198">For example a learning management systems for educational institutions can deploy a distributed cluster in East US and West US regions to serve the respective campuses for transactional as well as analytics.</span></span> <span data-ttu-id="63331-199">데이터는 시간 읽기 및 쓰기에 로컬로 일관되어 두 영역에서 일관성이 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-199">The data can be locally consistent at the time reads and writes and can be eventually consistent across both the regions.</span></span> <span data-ttu-id="63331-200">미디어 배포, 전자 상거래와 같은 다른 예제는 없으며, 지역 관련 사용자 기반을 제공하는 모든 것이 이 배포 모델에 대한 좋은 사용 사례입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-200">There are other examples like media distribution, e-commerce and anything and everything that serves geo concentrated user base is a good use case for this deployment model.</span></span>

<span data-ttu-id="63331-201">**고가용성:** 중복성은 소프트웨어 및 하드웨어의 높은 가용성을 계산하는 핵심 요소이며 자세한 내용은 Microsoft Azure에서 신뢰할 수 있는 클라우드 시스템 구축을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-201">**High Availability:** Redundancy is a key factor in attaining high availability of software and hardware; see Building Reliable Cloud Systems on Microsoft Azure for details.</span></span> <span data-ttu-id="63331-202">Microsoft Azure에서 진정한 중복성을 달성하는 신뢰할 수 있는 유일한 방법은 다중 지역 클러스터를 배포하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-202">On Microsoft Azure, the only reliable way of achieving true redundancy is by deploying a multi-region cluster.</span></span> <span data-ttu-id="63331-203">액티브-패시브 또는 액티브-액티브 모드로 응용 프로그램을 배포할 수 있으며, 지역 중 하나가 다운되는 경우 Azure 트래픽 관리자는 활성 영역에 트래픽을 리디렉션할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-203">Applications can be deployed in an active-active or active-passive mode and if one of the regions is down, Azure Traffic Manager can redirect traffic to the active region.</span></span>  <span data-ttu-id="63331-204">단일 지역 배포로 가용성이 99.9인 경우, 두 지역 배포는 공식 (1-(1-0.999) * (1-0.999))*100)으로 계산된 99.9999의 가용성을 얻을 수 있습니다. 자세한 내용은 위 문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-204">With the single region deployment, if the availability is 99.9, a two-region deployment can attain an availability of 99.9999 computed by the formula: (1-(1-0.999) * (1-0.999))*100); see the above paper for details.</span></span>

<span data-ttu-id="63331-205">**재해 복구:** 제대로 설계된 경우 다중 지역 Cassandra 클러스터는 치명적인 데이터 센터 중단을 견딜 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-205">**Disaster Recovery:** Multi-region Cassandra cluster, if properly designed, can withstand catastrophic data center outages.</span></span> <span data-ttu-id="63331-206">한 지역이 다운된 경우, 다른 지역에 배포된 응용 프로그램이 최종 사용자를 제공하기 시작할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-206">If one region is down, the application deployed to other regions can start serving the end users.</span></span> <span data-ttu-id="63331-207">다른 모든 비즈니스 연속성 구현과 마찬가지로, 응용 프로그램은 비동기 파이프라인의 데이터에서 일부 데이터 손실을 허용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-207">Like any other business continuity implementations, the application has to be tolerant for some data loss resulting from the data in the asynchronous pipeline.</span></span> <span data-ttu-id="63331-208">그러나 Cassandra는 기존의 데이터베이스 복구 프로세스에서 소요된 시간 보다 훨씬 빠르게 복구를 작성합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-208">However, Cassandra makes the recovery much swifter than the time taken by traditional database recovery processes.</span></span> <span data-ttu-id="63331-209">그림 2는 각 지역에 8개의 노드가 있는 일반적인 다중 지역 배포 모델을 보여줍니다.</span><span class="sxs-lookup"><span data-stu-id="63331-209">Figure 2 shows the typical multi-region deployment model with eight nodes in each region.</span></span> <span data-ttu-id="63331-210">두 지역은 같은 대칭에 대한 서로 다른 미러 이미지입니다. 실제는 작업 유형(예: 트랜잭션 또는 분석), RPO, RTO, 데이터 일관성 및 가용성 요구 사항에 따라 디자인됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-210">Both regions are mirror images of each other for the same of symmetry; real world designs depend on the workload type (e.g. transactional or analytical), RPO, RTO, data consistency and availability requirements.</span></span>

![다중 지역 배포](./media/cassandra-nodejs/cassandra-linux2.png)

<span data-ttu-id="63331-212">그림 2: 다중 지역 Cassandra 배포</span><span class="sxs-lookup"><span data-stu-id="63331-212">Figure 2: Multi-region Cassandra deployment</span></span>

### <a name="network-integration"></a><span data-ttu-id="63331-213">네트워크 통합</span><span class="sxs-lookup"><span data-stu-id="63331-213">Network Integration</span></span>
<span data-ttu-id="63331-214">두 지역에 있는 개인 네트워크에 배포된 가상 컴퓨터 집합은 VPN 터널을 사용하여 서로 통신합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-214">Sets of virtual machines deployed to private networks located on two regions communicates with each other using a VPN tunnel.</span></span> <span data-ttu-id="63331-215">VPN 터널은 네트워크 배포 프로세스 중 프로비전된 두 개의 소프트웨어 게이트웨이를 연결합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-215">The VPN tunnel connects two software gateways provisioned during the network deployment process.</span></span> <span data-ttu-id="63331-216">두 지역은 "web" 및 "data" 서브넷 측면에서 네트워크 아키텍처가 유사합니다. Azure 네트워킹을 사용하면 필요한 개수만큼 서브넷을 만들고 네트워크 보안에 필요한 경우 ACL을 적용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-216">Both regions have similar network architecture in terms of “web” and “data” subnets; Azure networking allows the creation of as many subnets as needed and apply ACLs as needed by network security.</span></span> <span data-ttu-id="63331-217">디자인하는 동안 클러스터 토폴로지 데이터 센터 간 통신 대기 시간과 네트워크 트래픽의 경제적 영향을 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-217">While designing the cluster topology inter data center communication latency and the economic impact of the network traffic need to be considered.</span></span>

### <a name="data-consistency-for-multi-data-center-deployment"></a><span data-ttu-id="63331-218">다중 데이터 센터 배포에 대한 데이터 일관성</span><span class="sxs-lookup"><span data-stu-id="63331-218">Data Consistency for Multi-Data Center Deployment</span></span>
<span data-ttu-id="63331-219">분산 배포에서는 클러스터 토폴로지가 처리량 및 고가용성에 미치는 영향에 주의해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-219">Distributed deployments need to be aware of the cluster topology impact on throughput and high availability.</span></span> <span data-ttu-id="63331-220">할당량이 모든 데이터 센터의 가용성에 의존하지 않도록 RF 및 일관성 수준을 선택해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-220">The RF and Consistency Level need to be selected in such way that the quorum doesn’t depend on the availability of all the data centers.</span></span>
<span data-ttu-id="63331-221">높은 일관성이 필요한 시스템의 경우 일관성 수준(읽기 및 쓰기)을 LOCAL_QUORUM으로 설정하면 데이터가 원격 데이터 센터에 비동기적으로 복제되는 동안 로컬 읽기 및 쓰기가 로컬 노드에서 충족됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-221">For a system that needs high consistency, a LOCAL_QUORUM for consistency level (for reads and writes) will make sure that the local reads and writes are satisfied from the local nodes while data is replicated asynchronously to the remote data centers.</span></span>  <span data-ttu-id="63331-222">표 2에는 문서의 뒷부분에서 설명하는 다중 지역 클러스터의 구성 세부 정보가 요약되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-222">Table 2 summarizes the configuration details for the multi-region cluster outlined later in the write up.</span></span>

<span data-ttu-id="63331-223">**두 지역 Cassandra 클러스터 구성**</span><span class="sxs-lookup"><span data-stu-id="63331-223">**Two-region Cassandra cluster configuration**</span></span>

| <span data-ttu-id="63331-224">클러스터 매개 변수</span><span class="sxs-lookup"><span data-stu-id="63331-224">Cluster Parameter</span></span> | <span data-ttu-id="63331-225">값</span><span class="sxs-lookup"><span data-stu-id="63331-225">Value</span></span> | <span data-ttu-id="63331-226">설명</span><span class="sxs-lookup"><span data-stu-id="63331-226">Remarks</span></span> |
| --- | --- | --- |
| <span data-ttu-id="63331-227">노드 수(N)</span><span class="sxs-lookup"><span data-stu-id="63331-227">Number of Nodes (N)</span></span> |<span data-ttu-id="63331-228">8 + 8</span><span class="sxs-lookup"><span data-stu-id="63331-228">8 + 8</span></span> |<span data-ttu-id="63331-229">클러스터의 총 노드 수</span><span class="sxs-lookup"><span data-stu-id="63331-229">Total number of nodes in the cluster</span></span> |
| <span data-ttu-id="63331-230">복제 계수(RF)</span><span class="sxs-lookup"><span data-stu-id="63331-230">Replication Factor (RF)</span></span> |<span data-ttu-id="63331-231">3</span><span class="sxs-lookup"><span data-stu-id="63331-231">3</span></span> |<span data-ttu-id="63331-232">지정된 행의 복제본 수</span><span class="sxs-lookup"><span data-stu-id="63331-232">Number of replicas of a given row</span></span> |
| <span data-ttu-id="63331-233">일관성 수준(쓰기)</span><span class="sxs-lookup"><span data-stu-id="63331-233">Consistency Level (Write)</span></span> |<span data-ttu-id="63331-234">LOCAL_QUORUM [(sum(RF)/2) +1) = 4] 수식의 결과는 버림됨</span><span class="sxs-lookup"><span data-stu-id="63331-234">LOCAL_QUORUM [(sum(RF)/2) +1) = 4] The result of the formula is rounded down</span></span> |<span data-ttu-id="63331-235">2개 노드는 첫 번째 데이터 센터에 동기적으로 기록됩니다. 할당량에 필요한 추가 2개 노드는 두 번째 데이터 센터에 비동기적으로 기록됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-235">2 nodes will be written to the first data center synchronously; the additional 2 nodes needed for quorum will be written asynchronously to the 2nd data center.</span></span> |
| <span data-ttu-id="63331-236">일관성 수준(읽기)</span><span class="sxs-lookup"><span data-stu-id="63331-236">Consistency Level (Read)</span></span> |<span data-ttu-id="63331-237">LOCAL_QUORUM ((RF/2) +1) = 2 공식 결과는 버림됨</span><span class="sxs-lookup"><span data-stu-id="63331-237">LOCAL_QUORUM ((RF/2) +1) = 2 The result of the formula is rounded down</span></span> |<span data-ttu-id="63331-238">읽기 요청은 한 지역에서만 충족됩니다. 응답이 클라이언트로 다시 전송되기 전에 2개 노드를 읽습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-238">Read requests are satisfied from only one region; 2 nodes are read before the response is sent back to the client.</span></span> |
| <span data-ttu-id="63331-239">복제 전략</span><span class="sxs-lookup"><span data-stu-id="63331-239">Replication Strategy</span></span> |<span data-ttu-id="63331-240">NetworkTopologyStrategy자세한 내용은 Cassandra 설명서의 [데이터 복제](http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureDataDistributeReplication_c.html) 참조</span><span class="sxs-lookup"><span data-stu-id="63331-240">NetworkTopologyStrategy see [Data Replication](http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureDataDistributeReplication_c.html) in Cassandra documentation for more information</span></span> |<span data-ttu-id="63331-241">배포 토폴로지를 이해하고 모든 복제본이 동일한 랙에 배포되지 않도록 노드에 복제본을 배치합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-241">Understands the deployment topology and places replicas on nodes so that all the replicas don’t end up on the same rack</span></span> |
| <span data-ttu-id="63331-242">Snitch</span><span class="sxs-lookup"><span data-stu-id="63331-242">Snitch</span></span> |<span data-ttu-id="63331-243">GossipingPropertyFileSnitch 자세한 내용은 Cassandra 설명서의 [Snitches](http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureSnitchesAbout_c.html) 를 참조</span><span class="sxs-lookup"><span data-stu-id="63331-243">GossipingPropertyFileSnitch see [Snitches](http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureSnitchesAbout_c.html) in Cassandra documentation for more information</span></span> |<span data-ttu-id="63331-244">NetworkTopologyStrategy는 snitch 개념을 사용하여 토폴로지를 파악합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-244">NetworkTopologyStrategy uses a concept of snitch to understand the topology.</span></span> <span data-ttu-id="63331-245">GossipingPropertyFileSnitch를 사용하면 데이터 센터 및 랙에 대한 각 노드의 매핑을 보다 잘 제어할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-245">GossipingPropertyFileSnitch gives better control in mapping each node to data center and rack.</span></span> <span data-ttu-id="63331-246">클러스터는 가십을 사용하여 이 정보를 전파합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-246">The cluster then uses gossip to propagate this information.</span></span> <span data-ttu-id="63331-247">PropertyFileSnitch에 비해 동적 IP 설정이 훨씬 간단합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-247">This is much simpler in dynamic IP setting relative to PropertyFileSnitch</span></span> |

## <a name="the-software-configuration"></a><span data-ttu-id="63331-248">소프트웨어 구성</span><span class="sxs-lookup"><span data-stu-id="63331-248">THE SOFTWARE CONFIGURATION</span></span>
<span data-ttu-id="63331-249">배포 중에 다음 소프트웨어 버전이 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-249">The following software versions are used during the deployment:</span></span>

<table>
<tr><th><span data-ttu-id="63331-250">소프트웨어</span><span class="sxs-lookup"><span data-stu-id="63331-250">Software</span></span></th><th><span data-ttu-id="63331-251">원본</span><span class="sxs-lookup"><span data-stu-id="63331-251">Source</span></span></th><th><span data-ttu-id="63331-252">버전</span><span class="sxs-lookup"><span data-stu-id="63331-252">Version</span></span></th></tr>
<tr><td><span data-ttu-id="63331-253">JRE</span><span class="sxs-lookup"><span data-stu-id="63331-253">JRE</span></span>    </td><td><span data-ttu-id="63331-254">[JRE 8](http://www.oracle.com/technetwork/java/javase/downloads/server-jre8-downloads-2133154.html) </span><span class="sxs-lookup"><span data-stu-id="63331-254">[JRE 8](http://www.oracle.com/technetwork/java/javase/downloads/server-jre8-downloads-2133154.html) </span></span></td><td><span data-ttu-id="63331-255">8U5</span><span class="sxs-lookup"><span data-stu-id="63331-255">8U5</span></span></td></tr>
<tr><td><span data-ttu-id="63331-256">JNA</span><span class="sxs-lookup"><span data-stu-id="63331-256">JNA</span></span>    </td><td><span data-ttu-id="63331-257">[JNA](https://github.com/twall/jna) </span><span class="sxs-lookup"><span data-stu-id="63331-257">[JNA](https://github.com/twall/jna) </span></span></td><td> <span data-ttu-id="63331-258">3.2.7</span><span class="sxs-lookup"><span data-stu-id="63331-258">3.2.7</span></span></td></tr>
<tr><td><span data-ttu-id="63331-259">Cassandra</span><span class="sxs-lookup"><span data-stu-id="63331-259">Cassandra</span></span></td><td>[<span data-ttu-id="63331-260">Apache Cassandra 2.0.8</span><span class="sxs-lookup"><span data-stu-id="63331-260">Apache Cassandra 2.0.8</span></span>](http://www.apache.org/dist/cassandra/2.0.8/apache-cassandra-2.0.8-bin.tar.gz)</td><td> <span data-ttu-id="63331-261">2.0.8</span><span class="sxs-lookup"><span data-stu-id="63331-261">2.0.8</span></span></td></tr>
<tr><td><span data-ttu-id="63331-262">Ubuntu</span><span class="sxs-lookup"><span data-stu-id="63331-262">Ubuntu</span></span>    </td><td><span data-ttu-id="63331-263">[Microsoft Azure](https://azure.microsoft.com/) </span><span class="sxs-lookup"><span data-stu-id="63331-263">[Microsoft Azure](https://azure.microsoft.com/) </span></span></td><td><span data-ttu-id="63331-264">14.04 LTS</span><span class="sxs-lookup"><span data-stu-id="63331-264">14.04 LTS</span></span></td></tr>
</table>

<span data-ttu-id="63331-265">JRE를 다운로드하려면 Oracle 라이선스를 수동으로 승인해야 하므로 배포를 간소화하려면 클러스터 배포 전에 만들려는 Ubuntu 템플릿 이미지에 나중에 업로드할 필수 소프트웨어를 데스크톱에 모두 다운로드합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-265">Since downloading of JRE requires manual acceptance of Oracle license, to simplify the deployment, download all the required software to the desktop for later uploading into the Ubuntu template image we will be creating as a precursor to the cluster deployment.</span></span>

<span data-ttu-id="63331-266">로컬 컴퓨터의 잘 알려진 download 디렉터리(예: Windows의 %TEMP%/downloads 또는 대부분의 Linux 배포나 Mac의 ~/downloads)에 위 소프트웨어를 다운로드합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-266">Download the above software into a well-known download directory (e.g. %TEMP%/downloads on Windows or ~/Downloads on most Linux distributions or Mac) on the local computer.</span></span>

### <a name="create-ubuntu-vm"></a><span data-ttu-id="63331-267">UBUNTU VM 만들기</span><span class="sxs-lookup"><span data-stu-id="63331-267">CREATE UBUNTU VM</span></span>
<span data-ttu-id="63331-268">이 프로세스 단계에서는 여러 개의 Cassandra 노드를 프로비전하는 데 이미지를 다시 사용할 수 있도록 필수 조건 소프트웨어로 Ubuntu 이미지를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="63331-268">In this step of the process we will create Ubuntu image with the pre-requisite software so that the image can be reused for provisioning several Cassandra nodes.</span></span>  

#### <a name="step-1-generate-ssh-key-pair"></a><span data-ttu-id="63331-269">1단계: SSH 키 쌍 생성</span><span class="sxs-lookup"><span data-stu-id="63331-269">STEP 1: Generate SSH key pair</span></span>
<span data-ttu-id="63331-270">Azure는 프로비전 시간에 PEM 또는 DER 인코딩된 X509 공개 키를 필요로 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-270">Azure needs an X509 public key that is either PEM or DER encoded at the provisioning time.</span></span> <span data-ttu-id="63331-271">Azure에서 Linux와 함께 SSH를 사용하는 방법에 설명된 지침에 따라 공개/개인 키 쌍을 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-271">Generate a public/private key pair using the instructions located at How to Use SSH with Linux on Azure.</span></span> <span data-ttu-id="63331-272">Windows 또는 Linux에서 putty.exe를 SSH 클라이언트로 사용할 계획이면 PEM 인코딩된 RSA 개인 키를 puttygen.exe를 사용하여 PPK 형식으로 변환해야 합니다. 이에 대한 지침은 위의 웹 페이지를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-272">If you plan to use putty.exe as an SSH client either on Windows or Linux, you have to convert the PEM encoded RSA private key to PPK format using puttygen.exe; the instructions for this can be found in the above web page.</span></span>

#### <a name="step-2-create-ubuntu-template-vm"></a><span data-ttu-id="63331-273">2단계: Ubuntu 템플릿 VM 만들기</span><span class="sxs-lookup"><span data-stu-id="63331-273">STEP 2: Create Ubuntu template VM</span></span>
<span data-ttu-id="63331-274">템플릿 VM을 만들려면 Azure 클래식 포털에 로그인하고 다음 시퀀스를 사용합니다. NEW, COMPUTE, VIRTUAL MACHINE, FROM GALLERY, UBUNTU, Ubuntu Server 14.04 LTS를 클릭한 다음 오른쪽 화살표를 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-274">To create the template VM, log into the Azure classic portal and use the following sequence: Click NEW, COMPUTE, VIRTUAL MACHINE, FROM GALLERY, UBUNTU, Ubuntu Server 14.04 LTS, and then click the right arrow.</span></span> <span data-ttu-id="63331-275">Linux VM을 만드는 방법을 설명하는 자습서는 Linux를 실행하는 가상 컴퓨터 만들기를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-275">For a tutorial that describes how to create a Linux VM, see Create a Virtual Machine Running Linux.</span></span>

<span data-ttu-id="63331-276">"가상 컴퓨터 구성" 화면 #1에서 다음 정보를 입력합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-276">Enter the following information on the “Virtual machine configuration” screen #1:</span></span>

<table>
<tr><th><span data-ttu-id="63331-277">필드 이름</span><span class="sxs-lookup"><span data-stu-id="63331-277">FIELD NAME</span></span>              </td><td>       <span data-ttu-id="63331-278">필드 값</span><span class="sxs-lookup"><span data-stu-id="63331-278">FIELD VALUE</span></span>               </td><td>         <span data-ttu-id="63331-279">설명</span><span class="sxs-lookup"><span data-stu-id="63331-279">REMARKS</span></span>                </td><tr>
<tr><td><span data-ttu-id="63331-280">버전 릴리스 날짜</span><span class="sxs-lookup"><span data-stu-id="63331-280">VERSION RELEASE DATE</span></span>    </td><td> <span data-ttu-id="63331-281">드롭다운에서 날짜 선택</span><span class="sxs-lookup"><span data-stu-id="63331-281">Select a date from the drop down</span></span></td><td></td><tr>
<tr><td><span data-ttu-id="63331-282">가상 컴퓨터 이름</span><span class="sxs-lookup"><span data-stu-id="63331-282">VIRTUAL MACHINE NAME</span></span>    </td><td> <span data-ttu-id="63331-283">cass-template</span><span class="sxs-lookup"><span data-stu-id="63331-283">cass-template</span></span>                   </td><td> <span data-ttu-id="63331-284">VM의 호스트 이름입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-284">This is the hostname of the VM</span></span> </td><tr>
<tr><td><span data-ttu-id="63331-285">계층</span><span class="sxs-lookup"><span data-stu-id="63331-285">TIER</span></span>                     </td><td> <span data-ttu-id="63331-286">표준</span><span class="sxs-lookup"><span data-stu-id="63331-286">STANDARD</span></span>                           </td><td> <span data-ttu-id="63331-287">기본값을 그대로 둡니다.</span><span class="sxs-lookup"><span data-stu-id="63331-287">Leave the default</span></span>              </td><tr>
<tr><td><span data-ttu-id="63331-288">크기</span><span class="sxs-lookup"><span data-stu-id="63331-288">SIZE</span></span>                     </td><td> <span data-ttu-id="63331-289">A1</span><span class="sxs-lookup"><span data-stu-id="63331-289">A1</span></span>                              </td><td><span data-ttu-id="63331-290">IO 요구에 따라 VM을 선택합니다. 여기서는 기본값을 그대로 둡니다.</span><span class="sxs-lookup"><span data-stu-id="63331-290">Select the VM based on the IO needs; for this purpose leave the default</span></span> </td><tr>
<tr><td> <span data-ttu-id="63331-291">새 사용자 이름</span><span class="sxs-lookup"><span data-stu-id="63331-291">NEW USER NAME</span></span>             </td><td> <span data-ttu-id="63331-292">localadmin</span><span class="sxs-lookup"><span data-stu-id="63331-292">localadmin</span></span>                       </td><td> <span data-ttu-id="63331-293">"admin"은 Ubuntu 12.xx 이상에서 예약된 사용자 이름입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-293">"admin" is a reserved user name in Ubuntu 12.xx and after</span></span></td><tr>
<tr><td> <span data-ttu-id="63331-294">인증</span><span class="sxs-lookup"><span data-stu-id="63331-294">AUTHENTICATION</span></span>         </td><td> <span data-ttu-id="63331-295">확인란을 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-295">Click check box</span></span>                 </td><td><span data-ttu-id="63331-296">SSH 키를 사용하여 보안을 유지하려면 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-296">Check if you want to secure with an SSH key</span></span> </td><tr>
<tr><td> <span data-ttu-id="63331-297">인증서</span><span class="sxs-lookup"><span data-stu-id="63331-297">CERTIFICATE</span></span>             </td><td> <span data-ttu-id="63331-298">공개 키 인증서의 파일 이름</span><span class="sxs-lookup"><span data-stu-id="63331-298">file name of the public key certificate</span></span> </td><td> <span data-ttu-id="63331-299">이전에 생성된 공개 키를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-299">Use the public key generated previously</span></span></td><tr>
<tr><td> <span data-ttu-id="63331-300">새 암호</span><span class="sxs-lookup"><span data-stu-id="63331-300">New Password</span></span>    </td><td> <span data-ttu-id="63331-301">강력한 암호</span><span class="sxs-lookup"><span data-stu-id="63331-301">strong password</span></span> </td><td> </td><tr>
<tr><td> <span data-ttu-id="63331-302">암호 확인</span><span class="sxs-lookup"><span data-stu-id="63331-302">Confirm Password</span></span>    </td><td> <span data-ttu-id="63331-303">강력한 암호</span><span class="sxs-lookup"><span data-stu-id="63331-303">strong password</span></span> </td><td></td><tr>
</table>

<span data-ttu-id="63331-304">"가상 컴퓨터 구성" 화면 #2에서 다음 정보를 입력합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-304">Enter the following information on the “Virtual machine configuration” screen #2:</span></span>

<table>
<tr><th><span data-ttu-id="63331-305">필드 이름</span><span class="sxs-lookup"><span data-stu-id="63331-305">FIELD NAME</span></span>             </th><th> <span data-ttu-id="63331-306">필드 값</span><span class="sxs-lookup"><span data-stu-id="63331-306">FIELD VALUE</span></span>                       </th><th> <span data-ttu-id="63331-307">설명</span><span class="sxs-lookup"><span data-stu-id="63331-307">REMARKS</span></span>                                 </th></tr>
<tr><td> <span data-ttu-id="63331-308">클라우드 서비스</span><span class="sxs-lookup"><span data-stu-id="63331-308">CLOUD SERVICE</span></span>    </td><td> <span data-ttu-id="63331-309">새 클라우드 서비스 만들기</span><span class="sxs-lookup"><span data-stu-id="63331-309">Create a new cloud service</span></span>    </td><td><span data-ttu-id="63331-310">클라우드 서비스는 가상 컴퓨터와 같은 계산 리소스의 컨테이너입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-310">Cloud service is a container compute resources like virtual machines</span></span></td></tr>
<tr><td> <span data-ttu-id="63331-311">클라우드 서비스 DNS 이름</span><span class="sxs-lookup"><span data-stu-id="63331-311">CLOUD SERVICE DNS NAME</span></span>    </td><td><span data-ttu-id="63331-312">ubuntu-template.cloudapp.net</span><span class="sxs-lookup"><span data-stu-id="63331-312">ubuntu-template.cloudapp.net</span></span>    </td><td><span data-ttu-id="63331-313">컴퓨터에 알 수 없는 부하 분산 장치 이름을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-313">Give a machine agnostic load balancer name</span></span></td></tr>
<tr><td> <span data-ttu-id="63331-314">지역/선호도 그룹/가상 네트워크</span><span class="sxs-lookup"><span data-stu-id="63331-314">REGION/AFFINITY GROUP/VIRTUAL NETWORK</span></span> </td><td>    <span data-ttu-id="63331-315">미국 서부</span><span class="sxs-lookup"><span data-stu-id="63331-315">West US</span></span>    </td><td> <span data-ttu-id="63331-316">웹 응용 프로그램이 Cassandra 클러스터에 액세스하는 지역을 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-316">Select a region from which your web applications access the Cassandra cluster</span></span></td></tr>
<tr><td><span data-ttu-id="63331-317">저장소 계정</span><span class="sxs-lookup"><span data-stu-id="63331-317">STORAGE ACCOUNT</span></span> </td><td>    <span data-ttu-id="63331-318">기본값 사용</span><span class="sxs-lookup"><span data-stu-id="63331-318">Use default</span></span>    </td><td><span data-ttu-id="63331-319">기본 저장소 계정이나 특정 지역에 미리 생성된 저장소 계정을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-319">Use the default storage account  or a pre-created storage account in a particular region</span></span></td></tr>
<tr><td><span data-ttu-id="63331-320">가용성 집합</span><span class="sxs-lookup"><span data-stu-id="63331-320">AVAILABILITY SET</span></span> </td><td>    <span data-ttu-id="63331-321">없음</span><span class="sxs-lookup"><span data-stu-id="63331-321">None</span></span> </td><td>    <span data-ttu-id="63331-322">비워 둡니다.</span><span class="sxs-lookup"><span data-stu-id="63331-322">Leave it blank</span></span></td></tr>
<tr><td><span data-ttu-id="63331-323">끝점</span><span class="sxs-lookup"><span data-stu-id="63331-323">ENDPOINTS</span></span>    </td><td><span data-ttu-id="63331-324">기본값 사용</span><span class="sxs-lookup"><span data-stu-id="63331-324">Use default</span></span> </td><td>    <span data-ttu-id="63331-325">기본 SSH 구성을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-325">Use the default SSH configuration</span></span> </td></tr>
</table>

<span data-ttu-id="63331-326">오른쪽 화살표를 클릭하고 화면 #3의 기본값을 그대로 둔 다음 "확인" 단추를 클릭하여 VM 프로비저닝 프로세스를 완료합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-326">Click right arrow, leave the defaults on the screen #3 and click the “check” button to complete the VM provisioning process.</span></span> <span data-ttu-id="63331-327">몇 분 후에 이름이 "ubuntu-template"인 VM이 "실행 중" 상태가 되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-327">After a few minutes, the VM with the name “ubuntu-template” should be in a “running” status.</span></span>

### <a name="install-the-necessary-software"></a><span data-ttu-id="63331-328">필수 소프트웨어 설치</span><span class="sxs-lookup"><span data-stu-id="63331-328">INSTALL THE NECESSARY SOFTWARE</span></span>
#### <a name="step-1-upload-tarballs"></a><span data-ttu-id="63331-329">1단계: tarball 업로드</span><span class="sxs-lookup"><span data-stu-id="63331-329">STEP 1: Upload tarballs</span></span>
<span data-ttu-id="63331-330">scp 또는 pscp를 사용하여 다음 명령 형식으로 이전에 다운로드한 소프트웨어를 ~/downloads 디렉터리로 복사합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-330">Using scp or pscp, copy the previously downloaded software to ~/downloads directory using the following command format:</span></span>

##### <a name="pscp-server-jre-8u5-linux-x64targz-localadminhk-cas-templatecloudappnethomelocaladmindownloadsserver-jre-8u5-linux-x64targz"></a><span data-ttu-id="63331-331">pscp server-jre-8u5-linux-x64.tar.gz localadmin@hk-cas-template.cloudapp.net:/home/localadmin/downloads/server-jre-8u5-linux-x64.tar.gz</span><span class="sxs-lookup"><span data-stu-id="63331-331">pscp server-jre-8u5-linux-x64.tar.gz localadmin@hk-cas-template.cloudapp.net:/home/localadmin/downloads/server-jre-8u5-linux-x64.tar.gz</span></span>
<span data-ttu-id="63331-332">JRE 및 Cassandra 비트에 대해 위 명령을 반복합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-332">Repeat the above command for JRE as well as for the Cassandra bits.</span></span>

#### <a name="step-2-prepare-the-directory-structure-and-extract-the-archives"></a><span data-ttu-id="63331-333">2단계: 디렉터리 구조 준비 및 압축 파일 추출</span><span class="sxs-lookup"><span data-stu-id="63331-333">STEP 2: Prepare the directory structure and extract the archives</span></span>
<span data-ttu-id="63331-334">VM에 로그인한 다음 아래 bash 스크립트를 사용하여 슈퍼 사용자로 디렉터리 구조를 만들고 소프트웨어를 추출합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-334">Log into the VM and create the directory structure and extract software as a super user using the bash script below:</span></span>

    #!/bin/bash
    CASS_INSTALL_DIR="/opt/cassandra"
    JRE_INSTALL_DIR="/opt/java"
    CASS_DATA_DIR="/var/lib/cassandra"
    CASS_LOG_DIR="/var/log/cassandra"
    DOWNLOADS_DIR="~/downloads"
    JRE_TARBALL="server-jre-8u5-linux-x64.tar.gz"
    CASS_TARBALL="apache-cassandra-2.0.8-bin.tar.gz"
    SVC_USER="localadmin"

    RESET_ERROR=1
    MKDIR_ERROR=2

    reset_installation ()
    {
       rm -rf $CASS_INSTALL_DIR 2> /dev/null
       rm -rf $JRE_INSTALL_DIR 2> /dev/null
       rm -rf $CASS_DATA_DIR 2> /dev/null
       rm -rf $CASS_LOG_DIR 2> /dev/null
    }
    make_dir ()
    {
       if [ -z "$1" ]
       then
          echo "make_dir: invalid directory name"
          exit $MKDIR_ERROR
       fi

       if [ -d "$1" ]
       then
          echo "make_dir: directory already exists"
          exit $MKDIR_ERROR
       fi

       mkdir $1 2>/dev/null
       if [ $? != 0 ]
       then
          echo "directory creation failed"
          exit $MKDIR_ERROR
       fi
    }

    unzip()
    {
       if [ $# == 2 ]
       then
          tar xzf $1 -C $2
       else
          echo "archive error"
       fi

    }

    if [ -n "$1" ]
    then
       SVC_USER=$1
    fi

    reset_installation
    make_dir $CASS_INSTALL_DIR
    make_dir $JRE_INSTALL_DIR
    make_dir $CASS_DATA_DIR
    make_dir $CASS_LOG_DIR

    #unzip JRE and Cassandra
    unzip $HOME/downloads/$JRE_TARBALL $JRE_INSTALL_DIR
    unzip $HOME/downloads/$CASS_TARBALL $CASS_INSTALL_DIR

    #Change the ownership to the service credentials

    chown -R $SVC_USER:$GROUP $CASS_DATA_DIR
    chown -R $SVC_USER:$GROUP $CASS_LOG_DIR
    echo "edit /etc/profile to add JRE to the PATH"
    echo "installation is complete"


<span data-ttu-id="63331-335">이 스크립트를 vim 창에 붙여 넣는 경우 다음 명령을 사용하여 캐리지 리턴('\r')을 제거해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-335">If you paste this script into vim window, make sure to remove the carriage return (‘\r”) using the following command:</span></span>

    tr -d '\r' <infile.sh >outfile.sh

#### <a name="step-3-edit-etcprofile"></a><span data-ttu-id="63331-336">3단계: etc/profile 편집</span><span class="sxs-lookup"><span data-stu-id="63331-336">Step 3: Edit etc/profile</span></span>
<span data-ttu-id="63331-337">다음 내용을 끝에 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-337">Append the following at the end:</span></span>

    JAVA_HOME=/opt/java/jdk1.8.0_05
    CASS_HOME= /opt/cassandra/apache-cassandra-2.0.8
    PATH=$PATH:$HOME/bin:$JAVA_HOME/bin:$CASS_HOME/bin
    export JAVA_HOME
    export CASS_HOME
    export PATH

#### <a name="step-4-install-jna-for-production-systems"></a><span data-ttu-id="63331-338">4단계: 프로덕션 시스템용 JNA 설치</span><span class="sxs-lookup"><span data-stu-id="63331-338">Step 4: Install JNA for production systems</span></span>
<span data-ttu-id="63331-339">다음 명령 시퀀스를 사용하여 jna-3.2.7.jar 및 jna-platform-3.2.7.jar을 /usr/share.java directory sudo apt-get install libjna-java에 설치합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-339">Use the following command sequence: The following command will install jna-3.2.7.jar and jna-platform-3.2.7.jar to /usr/share.java directory sudo apt-get install libjna-java</span></span>

<span data-ttu-id="63331-340">Cassandra 시작 스크립트에서 이러한 jar을 찾을 수 있도록 $CASS_HOME/lib 디렉터리에 바로 가기 링크를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="63331-340">Create symbolic links in $CASS_HOME/lib directory so that Cassandra startup script can find these jars:</span></span>

    ln -s /usr/share/java/jna-3.2.7.jar $CASS_HOME/lib/jna.jar

    ln -s /usr/share/java/jna-platform-3.2.7.jar $CASS_HOME/lib/jna-platform.jar

#### <a name="step-5-configure-cassandrayaml"></a><span data-ttu-id="63331-341">5단계: cassandra.yaml 구성</span><span class="sxs-lookup"><span data-stu-id="63331-341">Step 5: Configure cassandra.yaml</span></span>
<span data-ttu-id="63331-342">모든 가상 컴퓨터에 필요한 구성을 반영하도록 각 VM에서 cassandra.yaml을 편집합니다.[실제 프로비저닝 중에는 이 내용이 조정됩니다.]</span><span class="sxs-lookup"><span data-stu-id="63331-342">Edit cassandra.yaml on each VM to reflect configuration needed by all the virtual machines [we will tweak this during the actual provisioning]:</span></span>

<table>
<tr><th><span data-ttu-id="63331-343">필드 이름</span><span class="sxs-lookup"><span data-stu-id="63331-343">Field Name</span></span>   </th><th> <span data-ttu-id="63331-344">값</span><span class="sxs-lookup"><span data-stu-id="63331-344">Value</span></span>  </th><th>    <span data-ttu-id="63331-345">설명</span><span class="sxs-lookup"><span data-stu-id="63331-345">Remarks</span></span> </th></tr>
<tr><td><span data-ttu-id="63331-346">cluster_name</span><span class="sxs-lookup"><span data-stu-id="63331-346">cluster_name</span></span> </td><td>    <span data-ttu-id="63331-347">"CustomerService"</span><span class="sxs-lookup"><span data-stu-id="63331-347">“CustomerService”</span></span>    </td><td> <span data-ttu-id="63331-348">배포를 반영하는 이름을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-348">Use the name that reflects your deployment</span></span></td></tr>
<tr><td><span data-ttu-id="63331-349">listen_address</span><span class="sxs-lookup"><span data-stu-id="63331-349">listen_address</span></span>    </td><td><span data-ttu-id="63331-350">[비워 둠]</span><span class="sxs-lookup"><span data-stu-id="63331-350">[leave it blank]</span></span>    </td><td> <span data-ttu-id="63331-351">"localhost"를 삭제합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-351">Delete “localhost”</span></span> </td></tr>
<tr><td><span data-ttu-id="63331-352">rpc_addres</span><span class="sxs-lookup"><span data-stu-id="63331-352">rpc_addres</span></span>   </td><td><span data-ttu-id="63331-353">[비워 둠]</span><span class="sxs-lookup"><span data-stu-id="63331-353">[leave it blank]</span></span>    </td><td> <span data-ttu-id="63331-354">"localhost"를 삭제합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-354">Delete “localhost”</span></span> </td></tr>
<tr><td><span data-ttu-id="63331-355">seeds</span><span class="sxs-lookup"><span data-stu-id="63331-355">seeds</span></span>    </td><td><span data-ttu-id="63331-356">"10.1.2.4, 10.1.2.6, 10.1.2.8"</span><span class="sxs-lookup"><span data-stu-id="63331-356">"10.1.2.4, 10.1.2.6, 10.1.2.8"</span></span>    </td><td><span data-ttu-id="63331-357">시드로 지정된 모든 IP 주소 목록입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-357">List of  all the IP addresses which are designated as seeds.</span></span></td></tr>
<tr><td><span data-ttu-id="63331-358">endpoint_snitch</span><span class="sxs-lookup"><span data-stu-id="63331-358">endpoint_snitch</span></span> </td><td> <span data-ttu-id="63331-359">org.apache.cassandra.locator.GossipingPropertyFileSnitch</span><span class="sxs-lookup"><span data-stu-id="63331-359">org.apache.cassandra.locator.GossipingPropertyFileSnitch</span></span> </td><td> <span data-ttu-id="63331-360">NetworkTopologyStrateg에서 VM의 랙과 데이터 센터를 유추하는 데 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-360">This is used by the NetworkTopologyStrateg for inferring the data center and the rack of the VM</span></span></td></tr>
</table>

#### <a name="step-6-capture-the-vm-image"></a><span data-ttu-id="63331-361">6단계: VM 이미지 캡처</span><span class="sxs-lookup"><span data-stu-id="63331-361">Step 6: Capture the VM image</span></span>
<span data-ttu-id="63331-362">이전에 만든 호스트 이름(hk-cas-template.cloudapp.net) 및 SSH 개인 키를 사용하여 가상 컴퓨터에 로그인합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-362">Log into the virtual machine using the hostname (hk-cas-template.cloudapp.net) and the SSH private key previously created.</span></span> <span data-ttu-id="63331-363">명령 ssh 또는 putty.exe를 사용하여 로그인하는 방법에 대한 자세한 내용은 Azure에서 Linux와 함께 SSH를 사용하는 방법을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-363">See How to Use SSH with Linux on Azure for details on how to log in using the command ssh or putty.exe.</span></span>

<span data-ttu-id="63331-364">다음 작업 시퀀스를 실행하여 이미지를 캡처합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-364">Execute the following sequence of actions to capture the image:</span></span>

##### <a name="1-deprovision"></a><span data-ttu-id="63331-365">1. 프로비전 해제</span><span class="sxs-lookup"><span data-stu-id="63331-365">1. Deprovision</span></span>
<span data-ttu-id="63331-366">"sudo waagent –deprovision+user" 명령을 사용하여 가상 컴퓨터 인스턴스 특정 정보를 제거합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-366">Use the command “sudo waagent –deprovision+user” to remove Virtual Machine instance specific information.</span></span> <span data-ttu-id="63331-367">이미지 캡처 프로세스에 대한 자세한 내용은 템플릿으로 사용할 [Linux 가상 컴퓨터를 캡처하는 방법](capture-image.md) 을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-367">See for [How to Capture a Linux Virtual Machine](capture-image.md) to Use as a Template more details on the image capture process.</span></span>

##### <a name="2-shutdown-the-vm"></a><span data-ttu-id="63331-368">2: VM 종료</span><span class="sxs-lookup"><span data-stu-id="63331-368">2: Shutdown the VM</span></span>
<span data-ttu-id="63331-369">가상 컴퓨터를 강조 표시하고 아래쪽 명령 모음에서 종료 링크를 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-369">Make sure that the virtual machine is highlighted and click the SHUTDOWN link from the bottom command bar.</span></span>

##### <a name="3-capture-the-image"></a><span data-ttu-id="63331-370">3: 이미지 캡처</span><span class="sxs-lookup"><span data-stu-id="63331-370">3: Capture the image</span></span>
<span data-ttu-id="63331-371">가상 컴퓨터를 강조 표시하고 아래쪽 명령 모음에서 캡처 링크를 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-371">Make sure that the virtual machine is highlighted and click the CAPTURE link from the bottom command bar.</span></span> <span data-ttu-id="63331-372">다음 화면에서 이미지 이름(예: hk-cas-2-08-ub-14-04-2014071) 및 적절한 이미지 설명을 제공하고 "확인" 표시를 클릭하여 캡처 프로세스를 마칩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-372">In the next screen, give an IMAGE NAME (e.g. hk-cas-2-08-ub-14-04-2014071), appropriate IMAGE DESCRIPTION, and click the “check” mark to finish the CAPTURE process.</span></span>

<span data-ttu-id="63331-373">이 작업은 몇 초 정도 걸리며, 이미지 갤러리의 내 이미지 섹션에서 해당 이미지를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-373">This will take a few seconds and the image should be available in MY IMAGES section of the image gallery.</span></span> <span data-ttu-id="63331-374">이미지가 성공적으로 캡처되면 원본 VM이 자동으로 삭제됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-374">The source VM will be automatically deleted after the image is successfully captured.</span></span> 

## <a name="single-region-deployment-process"></a><span data-ttu-id="63331-375">단일 지역 배포 프로세스</span><span class="sxs-lookup"><span data-stu-id="63331-375">Single Region Deployment Process</span></span>
<span data-ttu-id="63331-376">**1단계: 가상 네트워크 만들기** Azure Portal에 로그인한 후 다음 표에 나열된 특성을 사용하여 가상 네트워크(클래식)를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="63331-376">**Step 1: Create the Virtual Network** Log into the Azure portal and create a virtual network (classic) with the attributes shown in the following table.</span></span> <span data-ttu-id="63331-377">프로세스의 자세한 단계는 [Azure Portal을 사용하여 가상 네트워크(클래식) 만들기](../../../virtual-network/virtual-networks-create-vnet-classic-pportal.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-377">See [Create a virtual network (classic) using the Azure portal](../../../virtual-network/virtual-networks-create-vnet-classic-pportal.md) for detailed steps of the process.</span></span>      

<table>
<tr><th><span data-ttu-id="63331-378">VM 특성 이름</span><span class="sxs-lookup"><span data-stu-id="63331-378">VM Attribute Name</span></span></th><th><span data-ttu-id="63331-379">값</span><span class="sxs-lookup"><span data-stu-id="63331-379">Value</span></span></th><th><span data-ttu-id="63331-380">설명</span><span class="sxs-lookup"><span data-stu-id="63331-380">Remarks</span></span></th></tr>
<tr><td><span data-ttu-id="63331-381">이름</span><span class="sxs-lookup"><span data-stu-id="63331-381">Name</span></span></td><td><span data-ttu-id="63331-382">vnet-cass-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-382">vnet-cass-west-us</span></span></td><td></td></tr>
<tr><td><span data-ttu-id="63331-383">지역</span><span class="sxs-lookup"><span data-stu-id="63331-383">Region</span></span></td><td><span data-ttu-id="63331-384">미국 서부</span><span class="sxs-lookup"><span data-stu-id="63331-384">West US</span></span></td><td></td></tr>
<tr><td><span data-ttu-id="63331-385">DNS 서버</span><span class="sxs-lookup"><span data-stu-id="63331-385">DNS Servers</span></span></td><td><span data-ttu-id="63331-386">없음</span><span class="sxs-lookup"><span data-stu-id="63331-386">None</span></span></td><td><span data-ttu-id="63331-387">DNS 서버를 사용하지 않으므로 이 특성을 무시합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-387">Ignore this as we are not using a DNS Server</span></span></td></tr>
<tr><td><span data-ttu-id="63331-388">주소 공간</span><span class="sxs-lookup"><span data-stu-id="63331-388">Address Space</span></span></td><td><span data-ttu-id="63331-389">10.1.0.0/16</span><span class="sxs-lookup"><span data-stu-id="63331-389">10.1.0.0/16</span></span></td><td></td></tr>    
<tr><td><span data-ttu-id="63331-390">시작 IP</span><span class="sxs-lookup"><span data-stu-id="63331-390">Starting IP</span></span></td><td><span data-ttu-id="63331-391">10.1.0.0</span><span class="sxs-lookup"><span data-stu-id="63331-391">10.1.0.0</span></span></td><td></td></tr>    
<tr><td><span data-ttu-id="63331-392">CIDR</span><span class="sxs-lookup"><span data-stu-id="63331-392">CIDR</span></span> </td><td><span data-ttu-id="63331-393">/16 (65531)</span><span class="sxs-lookup"><span data-stu-id="63331-393">/16 (65531)</span></span></td><td></td></tr>
</table>

<span data-ttu-id="63331-394">다음 서브넷을 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-394">Add the following subnets:</span></span>

<table>
<tr><th><span data-ttu-id="63331-395">이름</span><span class="sxs-lookup"><span data-stu-id="63331-395">Name</span></span></th><th><span data-ttu-id="63331-396">시작 IP</span><span class="sxs-lookup"><span data-stu-id="63331-396">Starting IP</span></span></th><th><span data-ttu-id="63331-397">CIDR</span><span class="sxs-lookup"><span data-stu-id="63331-397">CIDR</span></span></th><th><span data-ttu-id="63331-398">설명</span><span class="sxs-lookup"><span data-stu-id="63331-398">Remarks</span></span></th></tr>
<tr><td><span data-ttu-id="63331-399">web</span><span class="sxs-lookup"><span data-stu-id="63331-399">web</span></span></td><td><span data-ttu-id="63331-400">10.1.1.0</span><span class="sxs-lookup"><span data-stu-id="63331-400">10.1.1.0</span></span></td><td><span data-ttu-id="63331-401">/24 (251)</span><span class="sxs-lookup"><span data-stu-id="63331-401">/24 (251)</span></span></td><td><span data-ttu-id="63331-402">웹 팜에 대한 서브넷입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-402">Subnet for the web farm</span></span></td></tr>
<tr><td><span data-ttu-id="63331-403">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-403">data</span></span></td><td><span data-ttu-id="63331-404">10.1.2.0</span><span class="sxs-lookup"><span data-stu-id="63331-404">10.1.2.0</span></span></td><td><span data-ttu-id="63331-405">/24 (251)</span><span class="sxs-lookup"><span data-stu-id="63331-405">/24 (251)</span></span></td><td><span data-ttu-id="63331-406">데이터베이스 노드에 대한 서브넷입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-406">Subnet for the database nodes</span></span></td></tr>
</table>

<span data-ttu-id="63331-407">Data 및 Web 서브넷은 이 문서를 범위를 벗어난 네트워크 보안 그룹을 통해 보호할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-407">Data and Web subnets can be protected through network security groups the coverage of which is out of scope for this article.</span></span>  

<span data-ttu-id="63331-408">**2단계: 가상 컴퓨터 프로비전** 이전에 만든 이미지를 사용하여 클라우드 서버 "hk-c-svc-west"에 다음 가상 컴퓨터를 만들고 아래와 같이 해당 서브넷에 바인딩합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-408">**Step 2: Provision Virtual Machines** Using the image created previously, we will create the following virtual machines in the cloud server “hk-c-svc-west” and bind them to the respective subnets as shown below:</span></span>

<table>
<tr><th><span data-ttu-id="63331-409">컴퓨터 이름</span><span class="sxs-lookup"><span data-stu-id="63331-409">Machine Name</span></span>    </th><th><span data-ttu-id="63331-410">서브넷</span><span class="sxs-lookup"><span data-stu-id="63331-410">Subnet</span></span>    </th><th><span data-ttu-id="63331-411">IP 주소</span><span class="sxs-lookup"><span data-stu-id="63331-411">IP Address</span></span>    </th><th><span data-ttu-id="63331-412">가용성 집합</span><span class="sxs-lookup"><span data-stu-id="63331-412">Availability set</span></span></th><th><span data-ttu-id="63331-413">DC/랙</span><span class="sxs-lookup"><span data-stu-id="63331-413">DC/Rack</span></span></th><th><span data-ttu-id="63331-414">시드 여부</span><span class="sxs-lookup"><span data-stu-id="63331-414">Seed?</span></span></th></tr>
<tr><td><span data-ttu-id="63331-415">hk-c1-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-415">hk-c1-west-us</span></span>    </td><td><span data-ttu-id="63331-416">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-416">data</span></span>    </td><td><span data-ttu-id="63331-417">10.1.2.4</span><span class="sxs-lookup"><span data-stu-id="63331-417">10.1.2.4</span></span>    </td><td><span data-ttu-id="63331-418">hk-c-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-418">hk-c-aset-1</span></span>    </td><td><span data-ttu-id="63331-419">dc =WESTUS rack =rack1</span><span class="sxs-lookup"><span data-stu-id="63331-419">dc =WESTUS rack =rack1</span></span> </td><td><span data-ttu-id="63331-420">예</span><span class="sxs-lookup"><span data-stu-id="63331-420">Yes</span></span></td></tr>
<tr><td><span data-ttu-id="63331-421">hk-c2-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-421">hk-c2-west-us</span></span>    </td><td><span data-ttu-id="63331-422">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-422">data</span></span>    </td><td><span data-ttu-id="63331-423">10.1.2.5</span><span class="sxs-lookup"><span data-stu-id="63331-423">10.1.2.5</span></span>    </td><td><span data-ttu-id="63331-424">hk-c-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-424">hk-c-aset-1</span></span>    </td><td><span data-ttu-id="63331-425">dc =WESTUS rack =rack1</span><span class="sxs-lookup"><span data-stu-id="63331-425">dc =WESTUS rack =rack1</span></span>    </td><td><span data-ttu-id="63331-426">아니요</span><span class="sxs-lookup"><span data-stu-id="63331-426">No</span></span> </td></tr>
<tr><td><span data-ttu-id="63331-427">hk-c3-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-427">hk-c3-west-us</span></span>    </td><td><span data-ttu-id="63331-428">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-428">data</span></span>    </td><td><span data-ttu-id="63331-429">10.1.2.6</span><span class="sxs-lookup"><span data-stu-id="63331-429">10.1.2.6</span></span>    </td><td><span data-ttu-id="63331-430">hk-c-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-430">hk-c-aset-1</span></span>    </td><td><span data-ttu-id="63331-431">dc =WESTUS rack =rack2</span><span class="sxs-lookup"><span data-stu-id="63331-431">dc =WESTUS rack =rack2</span></span>    </td><td><span data-ttu-id="63331-432">예</span><span class="sxs-lookup"><span data-stu-id="63331-432">Yes</span></span></td></tr>
<tr><td><span data-ttu-id="63331-433">hk-c4-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-433">hk-c4-west-us</span></span>    </td><td><span data-ttu-id="63331-434">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-434">data</span></span>    </td><td><span data-ttu-id="63331-435">10.1.2.7</span><span class="sxs-lookup"><span data-stu-id="63331-435">10.1.2.7</span></span>    </td><td><span data-ttu-id="63331-436">hk-c-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-436">hk-c-aset-1</span></span>    </td><td><span data-ttu-id="63331-437">dc =WESTUS rack =rack2</span><span class="sxs-lookup"><span data-stu-id="63331-437">dc =WESTUS rack =rack2</span></span>    </td><td><span data-ttu-id="63331-438">아니요</span><span class="sxs-lookup"><span data-stu-id="63331-438">No</span></span> </td></tr>
<tr><td><span data-ttu-id="63331-439">hk-c5-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-439">hk-c5-west-us</span></span>    </td><td><span data-ttu-id="63331-440">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-440">data</span></span>    </td><td><span data-ttu-id="63331-441">10.1.2.8</span><span class="sxs-lookup"><span data-stu-id="63331-441">10.1.2.8</span></span>    </td><td><span data-ttu-id="63331-442">hk-c-aset-2</span><span class="sxs-lookup"><span data-stu-id="63331-442">hk-c-aset-2</span></span>    </td><td><span data-ttu-id="63331-443">dc =WESTUS rack =rack3</span><span class="sxs-lookup"><span data-stu-id="63331-443">dc =WESTUS rack =rack3</span></span>    </td><td><span data-ttu-id="63331-444">예</span><span class="sxs-lookup"><span data-stu-id="63331-444">Yes</span></span></td></tr>
<tr><td><span data-ttu-id="63331-445">hk-c6-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-445">hk-c6-west-us</span></span>    </td><td><span data-ttu-id="63331-446">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-446">data</span></span>    </td><td><span data-ttu-id="63331-447">10.1.2.9</span><span class="sxs-lookup"><span data-stu-id="63331-447">10.1.2.9</span></span>    </td><td><span data-ttu-id="63331-448">hk-c-aset-2</span><span class="sxs-lookup"><span data-stu-id="63331-448">hk-c-aset-2</span></span>    </td><td><span data-ttu-id="63331-449">dc =WESTUS rack =rack3</span><span class="sxs-lookup"><span data-stu-id="63331-449">dc =WESTUS rack =rack3</span></span>    </td><td><span data-ttu-id="63331-450">아니요</span><span class="sxs-lookup"><span data-stu-id="63331-450">No</span></span> </td></tr>
<tr><td><span data-ttu-id="63331-451">hk-c7-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-451">hk-c7-west-us</span></span>    </td><td><span data-ttu-id="63331-452">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-452">data</span></span>    </td><td><span data-ttu-id="63331-453">10.1.2.10</span><span class="sxs-lookup"><span data-stu-id="63331-453">10.1.2.10</span></span>    </td><td><span data-ttu-id="63331-454">hk-c-aset-2</span><span class="sxs-lookup"><span data-stu-id="63331-454">hk-c-aset-2</span></span>    </td><td><span data-ttu-id="63331-455">dc =WESTUS rack =rack4</span><span class="sxs-lookup"><span data-stu-id="63331-455">dc =WESTUS rack =rack4</span></span>    </td><td><span data-ttu-id="63331-456">예</span><span class="sxs-lookup"><span data-stu-id="63331-456">Yes</span></span></td></tr>
<tr><td><span data-ttu-id="63331-457">hk-c8-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-457">hk-c8-west-us</span></span>    </td><td><span data-ttu-id="63331-458">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-458">data</span></span>    </td><td><span data-ttu-id="63331-459">10.1.2.11</span><span class="sxs-lookup"><span data-stu-id="63331-459">10.1.2.11</span></span>    </td><td><span data-ttu-id="63331-460">hk-c-aset-2</span><span class="sxs-lookup"><span data-stu-id="63331-460">hk-c-aset-2</span></span>    </td><td><span data-ttu-id="63331-461">dc =WESTUS rack =rack4</span><span class="sxs-lookup"><span data-stu-id="63331-461">dc =WESTUS rack =rack4</span></span>    </td><td><span data-ttu-id="63331-462">아니요</span><span class="sxs-lookup"><span data-stu-id="63331-462">No</span></span> </td></tr>
<tr><td><span data-ttu-id="63331-463">hk-w1-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-463">hk-w1-west-us</span></span>    </td><td><span data-ttu-id="63331-464">web</span><span class="sxs-lookup"><span data-stu-id="63331-464">web</span></span>    </td><td><span data-ttu-id="63331-465">10.1.1.4</span><span class="sxs-lookup"><span data-stu-id="63331-465">10.1.1.4</span></span>    </td><td><span data-ttu-id="63331-466">hk-w-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-466">hk-w-aset-1</span></span>    </td><td>                       </td><td><span data-ttu-id="63331-467">해당 없음</span><span class="sxs-lookup"><span data-stu-id="63331-467">N/A</span></span></td></tr>
<tr><td><span data-ttu-id="63331-468">hk-w2-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-468">hk-w2-west-us</span></span>    </td><td><span data-ttu-id="63331-469">web</span><span class="sxs-lookup"><span data-stu-id="63331-469">web</span></span>    </td><td><span data-ttu-id="63331-470">10.1.1.5</span><span class="sxs-lookup"><span data-stu-id="63331-470">10.1.1.5</span></span>    </td><td><span data-ttu-id="63331-471">hk-w-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-471">hk-w-aset-1</span></span>    </td><td>                       </td><td><span data-ttu-id="63331-472">해당 없음</span><span class="sxs-lookup"><span data-stu-id="63331-472">N/A</span></span></td></tr>
</table>

<span data-ttu-id="63331-473">위의 VM 목록을 만들려면 다음 프로세스가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-473">Creation of the above list of VMs requires the following process:</span></span>

1. <span data-ttu-id="63331-474">특정 지역에 빈 클라우드 서비스를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="63331-474">Create an empty cloud service in a particular region</span></span>
2. <span data-ttu-id="63331-475">이전에 캡처된 이미지에서 VM을 만든 다음 이전에 만든 가상 네트워크에 연결합니다. 모든 VM에 대해 이 단계를 반복합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-475">Create a VM from the previously captured image and attach it to the virtual network created previously; repeat this for all the VMs</span></span>
3. <span data-ttu-id="63331-476">클라우드 서비스에 내부 부하 분산 장치를 추가하고 "data" 서브넷에 연결합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-476">Add an internal load balancer to the cloud service and attach it to the “data” subnet</span></span>
4. <span data-ttu-id="63331-477">이전에 만든 각 VM에 대해 이전에 만든 내부 부하 분산 장치에 연결된 부하 분산 집합을 통해 쓰리프트 트래픽에 대한 부하 분산 끝점을 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-477">For each VM created previously, add a load balanced endpoint for thrift traffic through a load balanced set connected to the previously created internal load balancer</span></span>

<span data-ttu-id="63331-478">위 프로세스는 Azure 클래식 포털을 사용하여 실행할 수 있습니다. Windows 컴퓨터를 사용하고(Windows 컴퓨터에 대한 액세스 권한이 없는 경우 Azure에서 VM 사용) 다음 PowerShell 스크립트를 사용하여 VM 8개를 모두 자동으로 프로비전합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-478">The above process can be executed using Azure classic portal; use a Windows machine (use a VM on Azure if you don't have access to a Windows machine), use the following PowerShell script to provision all 8 VMs automatically.</span></span>

<span data-ttu-id="63331-479">**목록 1: 가상 컴퓨터 프로비전을 위한 PowerShell 스크립트**</span><span class="sxs-lookup"><span data-stu-id="63331-479">**List 1: PowerShell script for provisioning virtual machines**</span></span>

        #Tested with Azure Powershell - November 2014
        #This powershell script deployes a number of VMs from an existing image inside an Azure region
        #Import your Azure subscription into the current Powershell session before proceeding
        #The process: 1. create Azure Storage account, 2. create virtual network, 3.create the VM template, 2. crate a list of VMs from the template

        #fundamental variables - change these to reflect your subscription
        $country="us"; $region="west"; $vnetName = "your_vnet_name";$storageAccount="your_storage_account"
        $numVMs=8;$prefix = "hk-cass";$ilbIP="your_ilb_ip"
        $subscriptionName = "Azure_subscription_name";
        $vmSize="ExtraSmall"; $imageName="your_linux_image_name"
        $ilbName="ThriftInternalLB"; $thriftEndPoint="ThriftEndPoint"

        #generated variables
        $serviceName = "$prefix-svc-$region-$country"; $azureRegion = "$region $country"

        $vmNames = @()
        for ($i=0; $i -lt $numVMs; $i++)
        {
           $vmNames+=("$prefix-vm"+($i+1) + "-$region-$country" );
        }

        #select an Azure subscription already imported into Powershell session
        Select-AzureSubscription -SubscriptionName $subscriptionName -Current
        Set-AzureSubscription -SubscriptionName $subscriptionName -CurrentStorageAccountName $storageAccount

        #create an empty cloud service
        New-AzureService -ServiceName $serviceName -Label "hkcass$region" -Location $azureRegion
        Write-Host "Created $serviceName"

        $VMList= @()   # stores the list of azure vm configuration objects
        #create the list of VMs
        foreach($vmName in $vmNames)
        {
           $VMList += New-AzureVMConfig -Name $vmName -InstanceSize ExtraSmall -ImageName $imageName |
           Add-AzureProvisioningConfig -Linux -LinuxUser "localadmin" -Password "Local123" |
           Set-AzureSubnet "data"
        }

        New-AzureVM -ServiceName $serviceName -VNetName $vnetName -VMs $VMList

        #Create internal load balancer
        Add-AzureInternalLoadBalancer -ServiceName $serviceName -InternalLoadBalancerName $ilbName -SubnetName "data" -StaticVNetIPAddress "$ilbIP"
        Write-Host "Created $ilbName"
        #Add add the thrift endpoint to the internal load balancer for all the VMs
        foreach($vmName in $vmNames)
        {
            Get-AzureVM -ServiceName $serviceName -Name $vmName |
                Add-AzureEndpoint -Name $thriftEndPoint -LBSetName "ThriftLBSet" -Protocol tcp -LocalPort 9160 -PublicPort 9160 -ProbePort 9160 -ProbeProtocol tcp -ProbeIntervalInSeconds 10 -InternalLoadBalancerName $ilbName |
                Update-AzureVM

            Write-Host "created $vmName"     
        }

<span data-ttu-id="63331-480">**3단계: 각 VM에서 Cassandra 구성**</span><span class="sxs-lookup"><span data-stu-id="63331-480">**Step 3: Configure Cassandra on each VM**</span></span>

<span data-ttu-id="63331-481">VM에 로그인하고 다음을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-481">Log into the VM and perform the following:</span></span>

* <span data-ttu-id="63331-482">$CASS_HOME/conf/cassandra-rackdc.properties를 편집하여 데이터 센터 및 랙 속성을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-482">Edit $CASS_HOME/conf/cassandra-rackdc.properties to specify the data center and rack properties:</span></span>
  
       dc =EASTUS, rack =rack1
* <span data-ttu-id="63331-483">cassandra.yaml을 편집하여 시드 노드를 아래와 같이 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-483">Edit cassandra.yaml to configure seed nodes as below:</span></span>
  
       Seeds: "10.1.2.4,10.1.2.6,10.1.2.8,10.1.2.10"

<span data-ttu-id="63331-484">**4단계: VM 시작 및 클러스터 테스트**</span><span class="sxs-lookup"><span data-stu-id="63331-484">**Step 4: Start the VMs and test the cluster**</span></span>

<span data-ttu-id="63331-485">노드 중 하나(예: hk-c1-west-us)에 로그인하고 다음 명령을 실행하여 클러스터의 상태를 확인합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-485">Log into one of the nodes (e.g. hk-c1-west-us) and run the following command to see the status of the cluster:</span></span>

       nodetool –h 10.1.2.4 –p 7199 status

<span data-ttu-id="63331-486">8 노드 클러스터의 경우 아래와 유사한 표시가 나타나야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-486">You should see the display similar to the one below for an 8-node cluster:</span></span>

<table>
<tr><th><span data-ttu-id="63331-487">가동 상태</span><span class="sxs-lookup"><span data-stu-id="63331-487">Status</span></span></th><th><span data-ttu-id="63331-488">주소</span><span class="sxs-lookup"><span data-stu-id="63331-488">Address</span></span>    </th><th><span data-ttu-id="63331-489">로드</span><span class="sxs-lookup"><span data-stu-id="63331-489">Load</span></span>    </th><th><span data-ttu-id="63331-490">토큰</span><span class="sxs-lookup"><span data-stu-id="63331-490">Tokens</span></span>    </th><th><span data-ttu-id="63331-491">소유 비율</span><span class="sxs-lookup"><span data-stu-id="63331-491">Owns</span></span> </th><th><span data-ttu-id="63331-492">호스트 ID</span><span class="sxs-lookup"><span data-stu-id="63331-492">Host ID</span></span>    </th><th><span data-ttu-id="63331-493">랙</span><span class="sxs-lookup"><span data-stu-id="63331-493">Rack</span></span></th></tr>
<tr><th><span data-ttu-id="63331-494">UN</span><span class="sxs-lookup"><span data-stu-id="63331-494">UN</span></span>    </td><td><span data-ttu-id="63331-495">10.1.2.4</span><span class="sxs-lookup"><span data-stu-id="63331-495">10.1.2.4</span></span>     </td><td><span data-ttu-id="63331-496">87.81 KB</span><span class="sxs-lookup"><span data-stu-id="63331-496">87.81 KB</span></span>    </td><td><span data-ttu-id="63331-497">256</span><span class="sxs-lookup"><span data-stu-id="63331-497">256</span></span>    </td><td><span data-ttu-id="63331-498">38.0%</span><span class="sxs-lookup"><span data-stu-id="63331-498">38.0%</span></span>    </td><td><span data-ttu-id="63331-499">Guid(제거됨)</span><span class="sxs-lookup"><span data-stu-id="63331-499">Guid (removed)</span></span></td><td><span data-ttu-id="63331-500">rack1</span><span class="sxs-lookup"><span data-stu-id="63331-500">rack1</span></span></td></tr>
<tr><th><span data-ttu-id="63331-501">UN</span><span class="sxs-lookup"><span data-stu-id="63331-501">UN</span></span>    </td><td><span data-ttu-id="63331-502">10.1.2.5</span><span class="sxs-lookup"><span data-stu-id="63331-502">10.1.2.5</span></span>     </td><td><span data-ttu-id="63331-503">41.08 KB</span><span class="sxs-lookup"><span data-stu-id="63331-503">41.08 KB</span></span>    </td><td><span data-ttu-id="63331-504">256</span><span class="sxs-lookup"><span data-stu-id="63331-504">256</span></span>    </td><td><span data-ttu-id="63331-505">68.9%</span><span class="sxs-lookup"><span data-stu-id="63331-505">68.9%</span></span>    </td><td><span data-ttu-id="63331-506">Guid(제거됨)</span><span class="sxs-lookup"><span data-stu-id="63331-506">Guid (removed)</span></span></td><td><span data-ttu-id="63331-507">rack1</span><span class="sxs-lookup"><span data-stu-id="63331-507">rack1</span></span></td></tr>
<tr><th><span data-ttu-id="63331-508">UN</span><span class="sxs-lookup"><span data-stu-id="63331-508">UN</span></span>    </td><td><span data-ttu-id="63331-509">10.1.2.6</span><span class="sxs-lookup"><span data-stu-id="63331-509">10.1.2.6</span></span>     </td><td><span data-ttu-id="63331-510">55.29 KB</span><span class="sxs-lookup"><span data-stu-id="63331-510">55.29 KB</span></span>    </td><td><span data-ttu-id="63331-511">256</span><span class="sxs-lookup"><span data-stu-id="63331-511">256</span></span>    </td><td><span data-ttu-id="63331-512">68.8%</span><span class="sxs-lookup"><span data-stu-id="63331-512">68.8%</span></span>    </td><td><span data-ttu-id="63331-513">Guid(제거됨)</span><span class="sxs-lookup"><span data-stu-id="63331-513">Guid (removed)</span></span></td><td><span data-ttu-id="63331-514">rack2</span><span class="sxs-lookup"><span data-stu-id="63331-514">rack2</span></span></td></tr>
<tr><th><span data-ttu-id="63331-515">UN</span><span class="sxs-lookup"><span data-stu-id="63331-515">UN</span></span>    </td><td><span data-ttu-id="63331-516">10.1.2.7</span><span class="sxs-lookup"><span data-stu-id="63331-516">10.1.2.7</span></span>     </td><td><span data-ttu-id="63331-517">55.29 KB</span><span class="sxs-lookup"><span data-stu-id="63331-517">55.29 KB</span></span>    </td><td><span data-ttu-id="63331-518">256</span><span class="sxs-lookup"><span data-stu-id="63331-518">256</span></span>    </td><td><span data-ttu-id="63331-519">68.8%</span><span class="sxs-lookup"><span data-stu-id="63331-519">68.8%</span></span>    </td><td><span data-ttu-id="63331-520">Guid(제거됨)</span><span class="sxs-lookup"><span data-stu-id="63331-520">Guid (removed)</span></span></td><td><span data-ttu-id="63331-521">rack2</span><span class="sxs-lookup"><span data-stu-id="63331-521">rack2</span></span></td></tr>
<tr><th><span data-ttu-id="63331-522">UN</span><span class="sxs-lookup"><span data-stu-id="63331-522">UN</span></span>    </td><td><span data-ttu-id="63331-523">10.1.2.8</span><span class="sxs-lookup"><span data-stu-id="63331-523">10.1.2.8</span></span>     </td><td><span data-ttu-id="63331-524">55.29 KB</span><span class="sxs-lookup"><span data-stu-id="63331-524">55.29 KB</span></span>    </td><td><span data-ttu-id="63331-525">256</span><span class="sxs-lookup"><span data-stu-id="63331-525">256</span></span>    </td><td><span data-ttu-id="63331-526">68.8%</span><span class="sxs-lookup"><span data-stu-id="63331-526">68.8%</span></span>    </td><td><span data-ttu-id="63331-527">Guid(제거됨)</span><span class="sxs-lookup"><span data-stu-id="63331-527">Guid (removed)</span></span></td><td><span data-ttu-id="63331-528">rack3</span><span class="sxs-lookup"><span data-stu-id="63331-528">rack3</span></span></td></tr>
<tr><th><span data-ttu-id="63331-529">UN</span><span class="sxs-lookup"><span data-stu-id="63331-529">UN</span></span>    </td><td><span data-ttu-id="63331-530">10.1.2.9</span><span class="sxs-lookup"><span data-stu-id="63331-530">10.1.2.9</span></span>     </td><td><span data-ttu-id="63331-531">55.29 KB</span><span class="sxs-lookup"><span data-stu-id="63331-531">55.29 KB</span></span>    </td><td><span data-ttu-id="63331-532">256</span><span class="sxs-lookup"><span data-stu-id="63331-532">256</span></span>    </td><td><span data-ttu-id="63331-533">68.8%</span><span class="sxs-lookup"><span data-stu-id="63331-533">68.8%</span></span>    </td><td><span data-ttu-id="63331-534">Guid(제거됨)</span><span class="sxs-lookup"><span data-stu-id="63331-534">Guid (removed)</span></span></td><td><span data-ttu-id="63331-535">rack3</span><span class="sxs-lookup"><span data-stu-id="63331-535">rack3</span></span></td></tr>
<tr><th><span data-ttu-id="63331-536">UN</span><span class="sxs-lookup"><span data-stu-id="63331-536">UN</span></span>    </td><td><span data-ttu-id="63331-537">10.1.2.10</span><span class="sxs-lookup"><span data-stu-id="63331-537">10.1.2.10</span></span>     </td><td><span data-ttu-id="63331-538">55.29 KB</span><span class="sxs-lookup"><span data-stu-id="63331-538">55.29 KB</span></span>    </td><td><span data-ttu-id="63331-539">256</span><span class="sxs-lookup"><span data-stu-id="63331-539">256</span></span>    </td><td><span data-ttu-id="63331-540">68.8%</span><span class="sxs-lookup"><span data-stu-id="63331-540">68.8%</span></span>    </td><td><span data-ttu-id="63331-541">Guid(제거됨)</span><span class="sxs-lookup"><span data-stu-id="63331-541">Guid (removed)</span></span></td><td><span data-ttu-id="63331-542">rack4</span><span class="sxs-lookup"><span data-stu-id="63331-542">rack4</span></span></td></tr>
<tr><th><span data-ttu-id="63331-543">UN</span><span class="sxs-lookup"><span data-stu-id="63331-543">UN</span></span>    </td><td><span data-ttu-id="63331-544">10.1.2.11</span><span class="sxs-lookup"><span data-stu-id="63331-544">10.1.2.11</span></span>     </td><td><span data-ttu-id="63331-545">55.29 KB</span><span class="sxs-lookup"><span data-stu-id="63331-545">55.29 KB</span></span>    </td><td><span data-ttu-id="63331-546">256</span><span class="sxs-lookup"><span data-stu-id="63331-546">256</span></span>    </td><td><span data-ttu-id="63331-547">68.8%</span><span class="sxs-lookup"><span data-stu-id="63331-547">68.8%</span></span>    </td><td><span data-ttu-id="63331-548">Guid(제거됨)</span><span class="sxs-lookup"><span data-stu-id="63331-548">Guid (removed)</span></span></td><td><span data-ttu-id="63331-549">rack4</span><span class="sxs-lookup"><span data-stu-id="63331-549">rack4</span></span></td></tr>
</table>

## <a name="test-the-single-region-cluster"></a><span data-ttu-id="63331-550">단일 지역 클러스터 테스트</span><span class="sxs-lookup"><span data-stu-id="63331-550">Test the Single Region Cluster</span></span>
<span data-ttu-id="63331-551">클러스터를 테스트하려면 다음 단계를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-551">Use the following steps to test the cluster:</span></span>

1. <span data-ttu-id="63331-552">Powershell 명령 Get-AzureInternalLoadbalancer commandlet을 사용하여 내부 부하 분산 장치의 IP 주소를 가져옵니다(예: 10.1.2.101).</span><span class="sxs-lookup"><span data-stu-id="63331-552">Using the Powershell command Get-AzureInternalLoadbalancer commandlet, obtain the IP address of the internal load balancer (e.g.  10.1.2.101).</span></span> <span data-ttu-id="63331-553">명령 구문은 다음과 같습니다. Get-AzureLoadbalancer –ServiceName "hk-c-svc-west-us”[주소와 함께 내부 부하 분산 장치의 세부 정보 표시]</span><span class="sxs-lookup"><span data-stu-id="63331-553">The syntax of the command is shown below: Get-AzureLoadbalancer –ServiceName "hk-c-svc-west-us” [displays the details of the internal load balancer along with its IP address]</span></span>
2. <span data-ttu-id="63331-554">Putty 또는 ssh를 사용하여 웹 팜 VM(예: hk-w1-west-us)에 로그인합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-554">Log into the web farm VM (e.g. hk-w1-west-us) using Putty or ssh</span></span>
3. <span data-ttu-id="63331-555">$CASS_HOME/bin/cqlsh 10.1.2.101 9160을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-555">Execute $CASS_HOME/bin/cqlsh 10.1.2.101 9160</span></span>
4. <span data-ttu-id="63331-556">다음 CQL 명령을 사용하여 클러스터가 작동하는지 확인합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-556">Use the following CQL commands to verify if the cluster is working:</span></span>
   
     <span data-ttu-id="63331-557">CREATE KEYSPACE customers_ks WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 3 };   USE customers_ks;   CREATE TABLE Customers(customer_id int PRIMARY KEY, firstname text, lastname text);   INSERT INTO Customers(customer_id, firstname, lastname) VALUES(1, 'John', 'Doe');   INSERT INTO Customers(customer_id, firstname, lastname) VALUES (2, 'Jane', 'Doe');</span><span class="sxs-lookup"><span data-stu-id="63331-557">CREATE KEYSPACE customers_ks WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 3 };   USE customers_ks;   CREATE TABLE Customers(customer_id int PRIMARY KEY, firstname text, lastname text);   INSERT INTO Customers(customer_id, firstname, lastname) VALUES(1, 'John', 'Doe');   INSERT INTO Customers(customer_id, firstname, lastname) VALUES (2, 'Jane', 'Doe');</span></span>
   
     <span data-ttu-id="63331-558">SELECT * FROM Customers;</span><span class="sxs-lookup"><span data-stu-id="63331-558">SELECT * FROM Customers;</span></span>

<span data-ttu-id="63331-559">아래와 같은 표시가 나타나야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-559">You should see a display like the one below:</span></span>

<table>
  <tr><th> <span data-ttu-id="63331-560">customer_id</span><span class="sxs-lookup"><span data-stu-id="63331-560">customer_id</span></span> </th><th> <span data-ttu-id="63331-561">firstname</span><span class="sxs-lookup"><span data-stu-id="63331-561">firstname</span></span> </th><th> <span data-ttu-id="63331-562">Lastname</span><span class="sxs-lookup"><span data-stu-id="63331-562">lastname</span></span> </th></tr>
  <tr><td> <span data-ttu-id="63331-563">1</span><span class="sxs-lookup"><span data-stu-id="63331-563">1</span></span> </td><td> <span data-ttu-id="63331-564">John</span><span class="sxs-lookup"><span data-stu-id="63331-564">John</span></span> </td><td> <span data-ttu-id="63331-565">Doe</span><span class="sxs-lookup"><span data-stu-id="63331-565">Doe</span></span> </td></tr>
  <tr><td> <span data-ttu-id="63331-566">2</span><span class="sxs-lookup"><span data-stu-id="63331-566">2</span></span> </td><td> <span data-ttu-id="63331-567">Jane</span><span class="sxs-lookup"><span data-stu-id="63331-567">Jane</span></span> </td><td> <span data-ttu-id="63331-568">Doe</span><span class="sxs-lookup"><span data-stu-id="63331-568">Doe</span></span> </td></tr>
</table>

<span data-ttu-id="63331-569">4단계에서 만든 keyspace는 replication_factor 3으로 SimpleStrategy를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-569">Please note that the keyspace created in step 4 uses SimpleStrategy with a  replication_factor of 3.</span></span> <span data-ttu-id="63331-570">SimpleStrategy는 단일 데이터 세터 배포에 권장되고 NetworkTopologyStrategy는 다중 데이터 세터 배포에 권장됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-570">SimpleStrategy is recommended for single data center deployments whereas NetworkTopologyStrategy for multi-data center deployments.</span></span> <span data-ttu-id="63331-571">replication_factor가 3이면 노드 오류에 대한 내결함성이 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-571">A replication_factor of 3 will give tolerance for node failures.</span></span>

## <span data-ttu-id="63331-572"><a id="tworegion"> </a>다중 지역 배포 프로세스</span><span class="sxs-lookup"><span data-stu-id="63331-572"><a id="tworegion"> </a>Multi-Region Deployment Process</span></span>
<span data-ttu-id="63331-573">완료된 단일 지역 배포를 활용하며 두 번째 지역 설치를 위해 동일한 프로세스를 반복합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-573">Will leverage the single region deployment completed and repeat the same process for installing the second region.</span></span> <span data-ttu-id="63331-574">단일 지역 배포와 다중 지역 배포 간의 주요 차이점은 지역 간 통신을 위한 VPN 터널 설정입니다. 네트워크 설치에서 시작하여 VM을 프로비전하고 Cassandra를 구성하겠습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-574">The key difference between the single and multiple region deployment is the VPN tunnel setup for inter-region communication; we will start with the network installation, provision the VMs and configure Cassandra.</span></span>

### <a name="step-1-create-the-virtual-network-at-the-2nd-region"></a><span data-ttu-id="63331-575">1단계: 2번째 지역에 가상 네트워크 만들기</span><span class="sxs-lookup"><span data-stu-id="63331-575">Step 1: Create the Virtual Network at the 2nd Region</span></span>
<span data-ttu-id="63331-576">Azure 클래식 포털에 로그인한 다음 표에 나열된 특성을 사용하여 가상 네트워크를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="63331-576">Log into the Azure classic portal and create a Virtual Network with the attributes show in the table.</span></span> <span data-ttu-id="63331-577">프로세스의 자세한 단계는 [Azure 클래식 포털에서 클라우드 전용 가상 네트워크 구성](../../../virtual-network/virtual-networks-create-vnet-classic-pportal.md) 을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-577">See [Configure a Cloud-Only Virtual Network in the Azure classic portal](../../../virtual-network/virtual-networks-create-vnet-classic-pportal.md) for detailed steps of the process.</span></span>      

<table>
<tr><th><span data-ttu-id="63331-578">특성 이름</span><span class="sxs-lookup"><span data-stu-id="63331-578">Attribute Name</span></span>    </th><th><span data-ttu-id="63331-579">값</span><span class="sxs-lookup"><span data-stu-id="63331-579">Value</span></span>    </th><th><span data-ttu-id="63331-580">설명</span><span class="sxs-lookup"><span data-stu-id="63331-580">Remarks</span></span></th></tr>
<tr><td><span data-ttu-id="63331-581">Name</span><span class="sxs-lookup"><span data-stu-id="63331-581">Name</span></span>    </td><td><span data-ttu-id="63331-582">vnet-cass-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-582">vnet-cass-east-us</span></span></td><td></td></tr>
<tr><td><span data-ttu-id="63331-583">지역</span><span class="sxs-lookup"><span data-stu-id="63331-583">Region</span></span>    </td><td><span data-ttu-id="63331-584">미국 동부</span><span class="sxs-lookup"><span data-stu-id="63331-584">East US</span></span></td><td></td></tr>
<tr><td><span data-ttu-id="63331-585">DNS 서버</span><span class="sxs-lookup"><span data-stu-id="63331-585">DNS Servers</span></span>        </td><td></td><td><span data-ttu-id="63331-586">DNS 서버를 사용하지 않으므로 이 특성을 무시합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-586">Ignore this as we are not using a DNS Server</span></span></td></tr>
<tr><td><span data-ttu-id="63331-587">지점 및 사이트 간 VPN 구성</span><span class="sxs-lookup"><span data-stu-id="63331-587">Configure a point-to-site VPN</span></span></td><td></td><td>        <span data-ttu-id="63331-588">이 특성을 무시합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-588">Ignore this</span></span></td></tr>
<tr><td><span data-ttu-id="63331-589">사이트 간 VPN 구성</span><span class="sxs-lookup"><span data-stu-id="63331-589">Configure a site-to-site VPN</span></span></td><td></td><td>        <span data-ttu-id="63331-590">이 특성을 무시합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-590">Ignore this</span></span></td></tr>
<tr><td><span data-ttu-id="63331-591">주소 공간</span><span class="sxs-lookup"><span data-stu-id="63331-591">Address Space</span></span>    </td><td><span data-ttu-id="63331-592">10.2.0.0/16</span><span class="sxs-lookup"><span data-stu-id="63331-592">10.2.0.0/16</span></span></td><td></td></tr>
<tr><td><span data-ttu-id="63331-593">시작 IP</span><span class="sxs-lookup"><span data-stu-id="63331-593">Starting IP</span></span>    </td><td><span data-ttu-id="63331-594">10.2.0.0</span><span class="sxs-lookup"><span data-stu-id="63331-594">10.2.0.0</span></span>    </td><td></td></tr>
<tr><td><span data-ttu-id="63331-595">CIDR</span><span class="sxs-lookup"><span data-stu-id="63331-595">CIDR</span></span>    </td><td><span data-ttu-id="63331-596">/16 (65531)</span><span class="sxs-lookup"><span data-stu-id="63331-596">/16 (65531)</span></span></td><td></td></tr>
</table>

<span data-ttu-id="63331-597">다음 서브넷을 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-597">Add the following subnets:</span></span>

<table>
<tr><th><span data-ttu-id="63331-598">이름</span><span class="sxs-lookup"><span data-stu-id="63331-598">Name</span></span>    </th><th><span data-ttu-id="63331-599">시작 IP</span><span class="sxs-lookup"><span data-stu-id="63331-599">Starting IP</span></span>    </th><th><span data-ttu-id="63331-600">CIDR</span><span class="sxs-lookup"><span data-stu-id="63331-600">CIDR</span></span>    </th><th><span data-ttu-id="63331-601">설명</span><span class="sxs-lookup"><span data-stu-id="63331-601">Remarks</span></span></th></tr>
<tr><td><span data-ttu-id="63331-602">web</span><span class="sxs-lookup"><span data-stu-id="63331-602">web</span></span>    </td><td><span data-ttu-id="63331-603">10.2.1.0</span><span class="sxs-lookup"><span data-stu-id="63331-603">10.2.1.0</span></span>    </td><td><span data-ttu-id="63331-604">/24 (251)</span><span class="sxs-lookup"><span data-stu-id="63331-604">/24 (251)</span></span>    </td><td><span data-ttu-id="63331-605">웹 팜에 대한 서브넷입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-605">Subnet for the web farm</span></span></td></tr>
<tr><td><span data-ttu-id="63331-606">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-606">data</span></span>    </td><td><span data-ttu-id="63331-607">10.2.2.0</span><span class="sxs-lookup"><span data-stu-id="63331-607">10.2.2.0</span></span>    </td><td><span data-ttu-id="63331-608">/24 (251)</span><span class="sxs-lookup"><span data-stu-id="63331-608">/24 (251)</span></span>    </td><td><span data-ttu-id="63331-609">데이터베이스 노드에 대한 서브넷입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-609">Subnet for the database nodes</span></span></td></tr>
</table>


### <a name="step-2-create-local-networks"></a><span data-ttu-id="63331-610">2단계: 로컬 네트워크 만들기</span><span class="sxs-lookup"><span data-stu-id="63331-610">Step 2: Create Local Networks</span></span>
<span data-ttu-id="63331-611">Azure 가상 네트워킹의 로컬 네트워크는 개인 클라우드 또는 다른 Azure 지역을 비롯한 원격 사이트에 매핑되는 프록시 주소 공간입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-611">A Local Network in Azure virtual networking is a proxy address space that maps to a remote site including a private cloud or another Azure region.</span></span> <span data-ttu-id="63331-612">이 프록시 주소 공간은 네트워크를 올바른 네트워킹 대상에 라우팅하기 위해 원격 게이트웨이에 바인딩됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-612">This proxy address space is bound to a remote gateway for routing network to the right networking destinations.</span></span> <span data-ttu-id="63331-613">VNET 간 연결 설정에 대한 자세한 내용은 [VNet 간 연결 구성](../../../vpn-gateway/virtual-networks-configure-vnet-to-vnet-connection.md) 을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="63331-613">See [Configure a VNet to VNet Connection](../../../vpn-gateway/virtual-networks-configure-vnet-to-vnet-connection.md) for the instructions on establishing VNET-to-VNET connection.</span></span>

<span data-ttu-id="63331-614">다음 세부 정보당 두 개의 로컬 네트워크를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="63331-614">Create two local networks per the following details:</span></span>

| <span data-ttu-id="63331-615">네트워크 이름</span><span class="sxs-lookup"><span data-stu-id="63331-615">Network Name</span></span> | <span data-ttu-id="63331-616">VPN 게이트웨이 주소</span><span class="sxs-lookup"><span data-stu-id="63331-616">VPN Gateway Address</span></span> | <span data-ttu-id="63331-617">주소 공간</span><span class="sxs-lookup"><span data-stu-id="63331-617">Address Space</span></span> | <span data-ttu-id="63331-618">설명</span><span class="sxs-lookup"><span data-stu-id="63331-618">Remarks</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="63331-619">hk-lnet-map-to-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-619">hk-lnet-map-to-east-us</span></span> |<span data-ttu-id="63331-620">23.1.1.1</span><span class="sxs-lookup"><span data-stu-id="63331-620">23.1.1.1</span></span> |<span data-ttu-id="63331-621">10.2.0.0/16</span><span class="sxs-lookup"><span data-stu-id="63331-621">10.2.0.0/16</span></span> |<span data-ttu-id="63331-622">로컬 네트워크를 만드는 동안 자리 표시자 게이트웨이 주소를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-622">While creating the Local Network give a placeholder gateway address.</span></span> <span data-ttu-id="63331-623">게이트웨이를 만들고 나면 실제 게이트웨이 주소가 채워집니다.</span><span class="sxs-lookup"><span data-stu-id="63331-623">The real gateway address is filled once the gateway is created.</span></span> <span data-ttu-id="63331-624">주소 공간이 해당 원격 VNET과 정확히 일치하는지 확인합니다. 여기서는 미국 동부 지역에 생성된 VNET입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-624">Make sure the address space exactly matches the respective remote VNET; in this case the VNET created in the East US region.</span></span> |
| <span data-ttu-id="63331-625">hk-lnet-map-to-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-625">hk-lnet-map-to-west-us</span></span> |<span data-ttu-id="63331-626">23.2.2.2</span><span class="sxs-lookup"><span data-stu-id="63331-626">23.2.2.2</span></span> |<span data-ttu-id="63331-627">10.1.0.0/16</span><span class="sxs-lookup"><span data-stu-id="63331-627">10.1.0.0/16</span></span> |<span data-ttu-id="63331-628">로컬 네트워크를 만드는 동안 자리 표시자 게이트웨이 주소를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-628">While creating the Local Network give a placeholder gateway address.</span></span> <span data-ttu-id="63331-629">게이트웨이를 만들고 나면 실제 게이트웨이 주소가 채워집니다.</span><span class="sxs-lookup"><span data-stu-id="63331-629">The real gateway address is filled once the gateway is created.</span></span> <span data-ttu-id="63331-630">주소 공간이 해당 원격 VNET과 정확히 일치하는지 확인합니다. 여기서는 미국 서부 지역에 생성된 VNET입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-630">Make sure the address space exactly matches the respective remote VNET; in this case the VNET created in the West US region.</span></span> |

### <a name="step-3-map-local-network-to-the-respective-vnets"></a><span data-ttu-id="63331-631">3단계: "로컬" 네트워크를 해당 VNET에 매핑</span><span class="sxs-lookup"><span data-stu-id="63331-631">Step 3: Map “Local” network to the respective VNETs</span></span>
<span data-ttu-id="63331-632">Azure 클래식 포털에서 다음 세부 정보당 각 vnet을 선택하고 "구성"을 클릭한 다음 "로컬 네트워크에 연결", 로컬 네트워크를 차례로 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-632">From the Azure classic portal, select each vnet, click “Configure”, check “Connect to the local network”, and select the Local Networks per the following details:</span></span>

| <span data-ttu-id="63331-633">가상 네트워크</span><span class="sxs-lookup"><span data-stu-id="63331-633">Virtual Network</span></span> | <span data-ttu-id="63331-634">로컬 네트워크</span><span class="sxs-lookup"><span data-stu-id="63331-634">Local Network</span></span> |
| --- | --- |
| <span data-ttu-id="63331-635">hk-vnet-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-635">hk-vnet-west-us</span></span> |<span data-ttu-id="63331-636">hk-lnet-map-to-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-636">hk-lnet-map-to-east-us</span></span> |
| <span data-ttu-id="63331-637">hk-vnet-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-637">hk-vnet-east-us</span></span> |<span data-ttu-id="63331-638">hk-lnet-map-to-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-638">hk-lnet-map-to-west-us</span></span> |

### <a name="step-4-create-gateways-on-vnet1-and-vnet2"></a><span data-ttu-id="63331-639">4단계: VNET1 및 VNET2에 게이트웨이 만들기</span><span class="sxs-lookup"><span data-stu-id="63331-639">Step 4: Create Gateways on VNET1 and VNET2</span></span>
<span data-ttu-id="63331-640">두 가상 네트워크의 대시보드에서 게이트웨이 만들기를 클릭합니다. 그러면 VPN 게이트웨이 프로비저닝 프로세스가 트리거됩니다.</span><span class="sxs-lookup"><span data-stu-id="63331-640">From the dashboard of both the virtual networks, click CREATE GATEWAY which will trigger the VPN gateway provisioning process.</span></span> <span data-ttu-id="63331-641">몇 분 후에 각 가상 네트워크의 대시보드에 실제 게이트웨이 주소가 표시되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-641">After a few minutes the dashboard of each virtual network should display the actual gateway address.</span></span>

### <a name="step-5-update-local-networks-with-the-respective-gateway-addresses"></a><span data-ttu-id="63331-642">5단계: "로컬" 네트워크를 해당 "게이트웨이" 주소로 업데이트</span><span class="sxs-lookup"><span data-stu-id="63331-642">Step 5: Update “Local” networks with the respective “Gateway” addresses</span></span>
<span data-ttu-id="63331-643">두 로컬 네트워크를 편집하여 자리 표시자 게이트웨이 IP 주소를 방금 프로비전한 게이트웨이의 실제 IP 주소로 바꿉니다.</span><span class="sxs-lookup"><span data-stu-id="63331-643">Edit both the local networks to replace the placeholder gateway IP address with the real IP address of the just provisioned gateways.</span></span> <span data-ttu-id="63331-644">다음 매핑을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-644">Use the following mapping:</span></span>

<table>
<tr><th><span data-ttu-id="63331-645">로컬 네트워크</span><span class="sxs-lookup"><span data-stu-id="63331-645">Local Network</span></span>    </th><th><span data-ttu-id="63331-646">가상 네트워크 게이트웨이</span><span class="sxs-lookup"><span data-stu-id="63331-646">Virtual Network Gateway</span></span></th></tr>
<tr><td><span data-ttu-id="63331-647">hk-lnet-map-to-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-647">hk-lnet-map-to-east-us</span></span> </td><td><span data-ttu-id="63331-648">hk-vnet-west-us의 게이트웨이</span><span class="sxs-lookup"><span data-stu-id="63331-648">Gateway of hk-vnet-west-us</span></span></td></tr>
<tr><td><span data-ttu-id="63331-649">hk-lnet-map-to-west-us</span><span class="sxs-lookup"><span data-stu-id="63331-649">hk-lnet-map-to-west-us</span></span> </td><td><span data-ttu-id="63331-650">hk-vnet-east-us의 게이트웨이</span><span class="sxs-lookup"><span data-stu-id="63331-650">Gateway of hk-vnet-east-us</span></span></td></tr>
</table>

### <a name="step-6-update-the-shared-key"></a><span data-ttu-id="63331-651">6단계: 공유 키 업데이트</span><span class="sxs-lookup"><span data-stu-id="63331-651">Step 6: Update the shared key</span></span>
<span data-ttu-id="63331-652">각 VPN 게이트웨이의 IPSec 키를 업데이트하려면 다음 Powershell 스크립트를 사용하여 [두 게이트웨이에서 sake 키 사용]: Set-AzureVNetGatewayKey -VNetName hk-vnet-east-us -LocalNetworkSiteName hk-lnet-map-to-west-us -SharedKey D9E76BKK Set-AzureVNetGatewayKey -VNetName hk-vnet-west-us -LocalNetworkSiteName hk-lnet-map-to-east-us -SharedKey D9E76BKK</span><span class="sxs-lookup"><span data-stu-id="63331-652">Use the following Powershell script to update the IPSec key of each VPN gateway [use the sake key for both the gateways]: Set-AzureVNetGatewayKey -VNetName hk-vnet-east-us -LocalNetworkSiteName hk-lnet-map-to-west-us -SharedKey D9E76BKK Set-AzureVNetGatewayKey -VNetName hk-vnet-west-us -LocalNetworkSiteName hk-lnet-map-to-east-us -SharedKey D9E76BKK</span></span>

### <a name="step-7-establish-the-vnet-to-vnet-connection"></a><span data-ttu-id="63331-653">7단계: VNET 간 연결 설정</span><span class="sxs-lookup"><span data-stu-id="63331-653">Step 7: Establish the VNET-to-VNET connection</span></span>
<span data-ttu-id="63331-654">Azure 클래식 포털에서 두 가상 네트워크의 "대시보드" 메뉴를 사용하여 게이트웨이 간 연결을 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-654">From the Azure classic portal, use the “DASHBOARD” menu of both the virtual networks to establish gateway-to-gateway connection.</span></span> <span data-ttu-id="63331-655">아래쪽 도구 모음의 "연결" 메뉴 항목을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-655">Use the “CONNECT” menu items in the bottom toolbar.</span></span> <span data-ttu-id="63331-656">몇 분 후에 대시보드에 연결 정보가 그래픽으로 표시되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-656">After a few minutes the dashboard should display the connection details graphically.</span></span>

### <a name="step-8-create-the-virtual-machines-in-region-2"></a><span data-ttu-id="63331-657">8단계: 지역 #2에 가상 컴퓨터 만들기</span><span class="sxs-lookup"><span data-stu-id="63331-657">Step 8: Create the virtual machines in region #2</span></span>
<span data-ttu-id="63331-658">동일한 단계를 수행하여 지역 #1 배포에서 설명한 대로 Ubuntu 이미지를 만들거나 이미지 VHD 파일을 지역 #2에 있는 Azure 저장소 계정에 복사하여 이미지를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="63331-658">Create the Ubuntu image as described in region #1 deployment by following the same steps or copy the image VHD file to the Azure storage account located in region #2 and create the image.</span></span> <span data-ttu-id="63331-659">이 이미지를 사용하고 새 클라우드 서비스 hk-c-svc-east-us에 다음 가상 컴퓨터 목록을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="63331-659">Use this image and create the following list of virtual machines into a new cloud service hk-c-svc-east-us:</span></span>

| <span data-ttu-id="63331-660">컴퓨터 이름</span><span class="sxs-lookup"><span data-stu-id="63331-660">Machine Name</span></span> | <span data-ttu-id="63331-661">서브넷</span><span class="sxs-lookup"><span data-stu-id="63331-661">Subnet</span></span> | <span data-ttu-id="63331-662">IP 주소</span><span class="sxs-lookup"><span data-stu-id="63331-662">IP Address</span></span> | <span data-ttu-id="63331-663">가용성 집합</span><span class="sxs-lookup"><span data-stu-id="63331-663">Availability set</span></span> | <span data-ttu-id="63331-664">DC/랙</span><span class="sxs-lookup"><span data-stu-id="63331-664">DC/Rack</span></span> | <span data-ttu-id="63331-665">시드 여부</span><span class="sxs-lookup"><span data-stu-id="63331-665">Seed?</span></span> |
| --- | --- | --- | --- | --- | --- |
| <span data-ttu-id="63331-666">hk-c1-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-666">hk-c1-east-us</span></span> |<span data-ttu-id="63331-667">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-667">data</span></span> |<span data-ttu-id="63331-668">10.2.2.4</span><span class="sxs-lookup"><span data-stu-id="63331-668">10.2.2.4</span></span> |<span data-ttu-id="63331-669">hk-c-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-669">hk-c-aset-1</span></span> |<span data-ttu-id="63331-670">dc =EASTUS rack =rack1</span><span class="sxs-lookup"><span data-stu-id="63331-670">dc =EASTUS rack =rack1</span></span> |<span data-ttu-id="63331-671">예</span><span class="sxs-lookup"><span data-stu-id="63331-671">Yes</span></span> |
| <span data-ttu-id="63331-672">hk-c2-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-672">hk-c2-east-us</span></span> |<span data-ttu-id="63331-673">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-673">data</span></span> |<span data-ttu-id="63331-674">10.2.2.5</span><span class="sxs-lookup"><span data-stu-id="63331-674">10.2.2.5</span></span> |<span data-ttu-id="63331-675">hk-c-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-675">hk-c-aset-1</span></span> |<span data-ttu-id="63331-676">dc =EASTUS rack =rack1</span><span class="sxs-lookup"><span data-stu-id="63331-676">dc =EASTUS rack =rack1</span></span> |<span data-ttu-id="63331-677">아니요</span><span class="sxs-lookup"><span data-stu-id="63331-677">No</span></span> |
| <span data-ttu-id="63331-678">hk-c3-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-678">hk-c3-east-us</span></span> |<span data-ttu-id="63331-679">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-679">data</span></span> |<span data-ttu-id="63331-680">10.2.2.6</span><span class="sxs-lookup"><span data-stu-id="63331-680">10.2.2.6</span></span> |<span data-ttu-id="63331-681">hk-c-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-681">hk-c-aset-1</span></span> |<span data-ttu-id="63331-682">dc =EASTUS rack =rack2</span><span class="sxs-lookup"><span data-stu-id="63331-682">dc =EASTUS rack =rack2</span></span> |<span data-ttu-id="63331-683">예</span><span class="sxs-lookup"><span data-stu-id="63331-683">Yes</span></span> |
| <span data-ttu-id="63331-684">hk-c5-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-684">hk-c5-east-us</span></span> |<span data-ttu-id="63331-685">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-685">data</span></span> |<span data-ttu-id="63331-686">10.2.2.8</span><span class="sxs-lookup"><span data-stu-id="63331-686">10.2.2.8</span></span> |<span data-ttu-id="63331-687">hk-c-aset-2</span><span class="sxs-lookup"><span data-stu-id="63331-687">hk-c-aset-2</span></span> |<span data-ttu-id="63331-688">dc =EASTUS rack =rack3</span><span class="sxs-lookup"><span data-stu-id="63331-688">dc =EASTUS rack =rack3</span></span> |<span data-ttu-id="63331-689">예</span><span class="sxs-lookup"><span data-stu-id="63331-689">Yes</span></span> |
| <span data-ttu-id="63331-690">hk-c6-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-690">hk-c6-east-us</span></span> |<span data-ttu-id="63331-691">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-691">data</span></span> |<span data-ttu-id="63331-692">10.2.2.9</span><span class="sxs-lookup"><span data-stu-id="63331-692">10.2.2.9</span></span> |<span data-ttu-id="63331-693">hk-c-aset-2</span><span class="sxs-lookup"><span data-stu-id="63331-693">hk-c-aset-2</span></span> |<span data-ttu-id="63331-694">dc =EASTUS rack =rack3</span><span class="sxs-lookup"><span data-stu-id="63331-694">dc =EASTUS rack =rack3</span></span> |<span data-ttu-id="63331-695">아니요</span><span class="sxs-lookup"><span data-stu-id="63331-695">No</span></span> |
| <span data-ttu-id="63331-696">hk-c7-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-696">hk-c7-east-us</span></span> |<span data-ttu-id="63331-697">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-697">data</span></span> |<span data-ttu-id="63331-698">10.2.2.10</span><span class="sxs-lookup"><span data-stu-id="63331-698">10.2.2.10</span></span> |<span data-ttu-id="63331-699">hk-c-aset-2</span><span class="sxs-lookup"><span data-stu-id="63331-699">hk-c-aset-2</span></span> |<span data-ttu-id="63331-700">dc =EASTUS rack =rack4</span><span class="sxs-lookup"><span data-stu-id="63331-700">dc =EASTUS rack =rack4</span></span> |<span data-ttu-id="63331-701">예</span><span class="sxs-lookup"><span data-stu-id="63331-701">Yes</span></span> |
| <span data-ttu-id="63331-702">hk-c8-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-702">hk-c8-east-us</span></span> |<span data-ttu-id="63331-703">데이터</span><span class="sxs-lookup"><span data-stu-id="63331-703">data</span></span> |<span data-ttu-id="63331-704">10.2.2.11</span><span class="sxs-lookup"><span data-stu-id="63331-704">10.2.2.11</span></span> |<span data-ttu-id="63331-705">hk-c-aset-2</span><span class="sxs-lookup"><span data-stu-id="63331-705">hk-c-aset-2</span></span> |<span data-ttu-id="63331-706">dc =EASTUS rack =rack4</span><span class="sxs-lookup"><span data-stu-id="63331-706">dc =EASTUS rack =rack4</span></span> |<span data-ttu-id="63331-707">아니요</span><span class="sxs-lookup"><span data-stu-id="63331-707">No</span></span> |
| <span data-ttu-id="63331-708">hk-w1-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-708">hk-w1-east-us</span></span> |<span data-ttu-id="63331-709">web</span><span class="sxs-lookup"><span data-stu-id="63331-709">web</span></span> |<span data-ttu-id="63331-710">10.2.1.4</span><span class="sxs-lookup"><span data-stu-id="63331-710">10.2.1.4</span></span> |<span data-ttu-id="63331-711">hk-w-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-711">hk-w-aset-1</span></span> |<span data-ttu-id="63331-712">해당 없음</span><span class="sxs-lookup"><span data-stu-id="63331-712">N/A</span></span> |<span data-ttu-id="63331-713">해당 없음</span><span class="sxs-lookup"><span data-stu-id="63331-713">N/A</span></span> |
| <span data-ttu-id="63331-714">hk-w2-east-us</span><span class="sxs-lookup"><span data-stu-id="63331-714">hk-w2-east-us</span></span> |<span data-ttu-id="63331-715">web</span><span class="sxs-lookup"><span data-stu-id="63331-715">web</span></span> |<span data-ttu-id="63331-716">10.2.1.5</span><span class="sxs-lookup"><span data-stu-id="63331-716">10.2.1.5</span></span> |<span data-ttu-id="63331-717">hk-w-aset-1</span><span class="sxs-lookup"><span data-stu-id="63331-717">hk-w-aset-1</span></span> |<span data-ttu-id="63331-718">해당 없음</span><span class="sxs-lookup"><span data-stu-id="63331-718">N/A</span></span> |<span data-ttu-id="63331-719">해당 없음</span><span class="sxs-lookup"><span data-stu-id="63331-719">N/A</span></span> |

<span data-ttu-id="63331-720">지역 #1과 동일한 지침을 따르되 10.2.xxx.xxx 주소 공간을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-720">Follow the same instructions as region #1 but use 10.2.xxx.xxx address space.</span></span>

### <a name="step-9-configure-cassandra-on-each-vm"></a><span data-ttu-id="63331-721">9단계: 각 VM에서 Cassandra 구성</span><span class="sxs-lookup"><span data-stu-id="63331-721">Step 9: Configure Cassandra on each VM</span></span>
<span data-ttu-id="63331-722">VM에 로그인하고 다음을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-722">Log into the VM and perform the following:</span></span>

1. <span data-ttu-id="63331-723">$CASS_HOME/conf/cassandra-rackdc.properties를 편집하여 데이터 센터 및 랙 속성을 dc =EASTUS rack =rack1 형식으로 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-723">Edit $CASS_HOME/conf/cassandra-rackdc.properties to specify the data center and rack properties in the format:  dc =EASTUS  rack =rack1</span></span>
2. <span data-ttu-id="63331-724">cassandra.yaml을 편집하여 시드 노드를 구성합니다. "10.1.2.4,10.1.2.6,10.1.2.8,10.1.2.10,10.2.2.4,10.2.2.6,10.2.2.8,10.2.2.10"</span><span class="sxs-lookup"><span data-stu-id="63331-724">Edit cassandra.yaml to configure seed nodes:  Seeds: "10.1.2.4,10.1.2.6,10.1.2.8,10.1.2.10,10.2.2.4,10.2.2.6,10.2.2.8,10.2.2.10"</span></span>

### <a name="step-10-start-cassandra"></a><span data-ttu-id="63331-725">10단계: Cassandra 시작</span><span class="sxs-lookup"><span data-stu-id="63331-725">Step 10: Start Cassandra</span></span>
<span data-ttu-id="63331-726">각 VM에 로그인하고 다음 명령을 실행하여 Cassandra를 백그라운드에서 시작합니다. $CASS_HOME/bin/cassandra</span><span class="sxs-lookup"><span data-stu-id="63331-726">Log into each VM and start Cassandra in the background by running the following command: $CASS_HOME/bin/cassandra</span></span>

## <a name="test-the-multi-region-cluster"></a><span data-ttu-id="63331-727">다중 지역 클러스터 테스트</span><span class="sxs-lookup"><span data-stu-id="63331-727">Test the Multi-Region Cluster</span></span>
<span data-ttu-id="63331-728">지금까지 각 Azure 지역에 8개 노드씩, 16개 노드에 Cassandra가 배포되었습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-728">By now Cassandra has been deployed to 16 nodes with 8 nodes in each Azure region.</span></span> <span data-ttu-id="63331-729">이러한 노드는 공통 클러스터 이름 및 시드 노드 구성으로 인해 동일한 클러스터에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-729">These nodes are in the same cluster by virtue of the common cluster name and the seed node configuration.</span></span> <span data-ttu-id="63331-730">클러스터를 테스트하려면 다음 프로세스를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-730">Use the following process to test the cluster:</span></span>

### <a name="step-1-get-the-internal-load-balancer-ip-for-both-the-regions-using-powershell"></a><span data-ttu-id="63331-731">1단계: PowerShell을 사용하여 두 지역에 대한 내부 부하 분산 장치 IP 가져오기</span><span class="sxs-lookup"><span data-stu-id="63331-731">Step 1: Get the internal load balancer IP for both the regions using PowerShell</span></span>
* <span data-ttu-id="63331-732">Get-AzureInternalLoadbalancer -ServiceName "hk-c-svc-west-us"</span><span class="sxs-lookup"><span data-stu-id="63331-732">Get-AzureInternalLoadbalancer -ServiceName "hk-c-svc-west-us"</span></span>
* <span data-ttu-id="63331-733">Get-AzureInternalLoadbalancer -ServiceName "hk-c-svc-east-us"</span><span class="sxs-lookup"><span data-stu-id="63331-733">Get-AzureInternalLoadbalancer -ServiceName "hk-c-svc-east-us"</span></span>  
  
    <span data-ttu-id="63331-734">표시되는 IP 주소를 확인합니다(예: 서부 - 10.1.2.101, 동부 - 10.2.2.101).</span><span class="sxs-lookup"><span data-stu-id="63331-734">Note the IP addresses (e.g. west - 10.1.2.101, east - 10.2.2.101) displayed.</span></span>

### <a name="step-2-execute-the-following-in-the-west-region-after-logging-into-hk-w1-west-us"></a><span data-ttu-id="63331-735">2단계: hk-w1-west-us에 로그인한 후 서부 지역에서 다음 실행</span><span class="sxs-lookup"><span data-stu-id="63331-735">Step 2: Execute the following in the west region after logging into hk-w1-west-us</span></span>
1. <span data-ttu-id="63331-736">$CASS_HOME/bin/cqlsh 10.1.2.101 9160을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-736">Execute $CASS_HOME/bin/cqlsh 10.1.2.101 9160</span></span>
2. <span data-ttu-id="63331-737">다음 CQL 명령을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-737">Execute the following CQL commands:</span></span>
   
     <span data-ttu-id="63331-738">CREATE KEYSPACE customers_ks   WITH REPLICATION = { 'class' : 'NetworkToplogyStrategy', 'WESTUS' : 3, 'EASTUS' : 3};   USE customers_ks;   CREATE TABLE Customers(customer_id int PRIMARY KEY, firstname text, lastname text);   INSERT INTO Customers(customer_id, firstname, lastname) VALUES(1, 'John', 'Doe');   INSERT INTO Customers(customer_id, firstname, lastname) VALUES (2, 'Jane', 'Doe');   SELECT * FROM Customers;</span><span class="sxs-lookup"><span data-stu-id="63331-738">CREATE KEYSPACE customers_ks   WITH REPLICATION = { 'class' : 'NetworkToplogyStrategy', 'WESTUS' : 3, 'EASTUS' : 3};   USE customers_ks;   CREATE TABLE Customers(customer_id int PRIMARY KEY, firstname text, lastname text);   INSERT INTO Customers(customer_id, firstname, lastname) VALUES(1, 'John', 'Doe');   INSERT INTO Customers(customer_id, firstname, lastname) VALUES (2, 'Jane', 'Doe');   SELECT * FROM Customers;</span></span>

<span data-ttu-id="63331-739">아래와 같은 표시가 나타나야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-739">You should see a display like the one below:</span></span>

| <span data-ttu-id="63331-740">customer_id</span><span class="sxs-lookup"><span data-stu-id="63331-740">customer_id</span></span> | <span data-ttu-id="63331-741">firstname</span><span class="sxs-lookup"><span data-stu-id="63331-741">firstname</span></span> | <span data-ttu-id="63331-742">Lastname</span><span class="sxs-lookup"><span data-stu-id="63331-742">Lastname</span></span> |
| --- | --- | --- |
| <span data-ttu-id="63331-743">1</span><span class="sxs-lookup"><span data-stu-id="63331-743">1</span></span> |<span data-ttu-id="63331-744">John</span><span class="sxs-lookup"><span data-stu-id="63331-744">John</span></span> |<span data-ttu-id="63331-745">Doe</span><span class="sxs-lookup"><span data-stu-id="63331-745">Doe</span></span> |
| <span data-ttu-id="63331-746">2</span><span class="sxs-lookup"><span data-stu-id="63331-746">2</span></span> |<span data-ttu-id="63331-747">Jane</span><span class="sxs-lookup"><span data-stu-id="63331-747">Jane</span></span> |<span data-ttu-id="63331-748">Doe</span><span class="sxs-lookup"><span data-stu-id="63331-748">Doe</span></span> |

### <a name="step-3-execute-the-following-in-the-east-region-after-logging-into-hk-w1-east-us"></a><span data-ttu-id="63331-749">3단계: hk-w1-east-us에 로그인한 후 동부 지역에서 다음 실행</span><span class="sxs-lookup"><span data-stu-id="63331-749">Step 3: Execute the following in the east region after logging into hk-w1-east-us:</span></span>
1. <span data-ttu-id="63331-750">$CASS_HOME/bin/cqlsh 10.2.2.101 9160 실행</span><span class="sxs-lookup"><span data-stu-id="63331-750">Execute $CASS_HOME/bin/cqlsh 10.2.2.101 9160</span></span>
2. <span data-ttu-id="63331-751">다음 CQL 명령을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-751">Execute the following CQL commands:</span></span>
   
     <span data-ttu-id="63331-752">USE customers_ks;   CREATE TABLE Customers(customer_id int PRIMARY KEY, firstname text, lastname text);   INSERT INTO Customers(customer_id, firstname, lastname) VALUES(1, 'John', 'Doe');   INSERT INTO Customers(customer_id, firstname, lastname) VALUES (2, 'Jane', 'Doe');   SELECT * FROM Customers;</span><span class="sxs-lookup"><span data-stu-id="63331-752">USE customers_ks;   CREATE TABLE Customers(customer_id int PRIMARY KEY, firstname text, lastname text);   INSERT INTO Customers(customer_id, firstname, lastname) VALUES(1, 'John', 'Doe');   INSERT INTO Customers(customer_id, firstname, lastname) VALUES (2, 'Jane', 'Doe');   SELECT * FROM Customers;</span></span>

<span data-ttu-id="63331-753">서부 지역과 동일한 표시가 나타나야 합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-753">You should see the same display as seen for the West region:</span></span>

| <span data-ttu-id="63331-754">customer_id</span><span class="sxs-lookup"><span data-stu-id="63331-754">customer_id</span></span> | <span data-ttu-id="63331-755">firstname</span><span class="sxs-lookup"><span data-stu-id="63331-755">firstname</span></span> | <span data-ttu-id="63331-756">Lastname</span><span class="sxs-lookup"><span data-stu-id="63331-756">Lastname</span></span> |
| --- | --- | --- |
| <span data-ttu-id="63331-757">1</span><span class="sxs-lookup"><span data-stu-id="63331-757">1</span></span> |<span data-ttu-id="63331-758">John</span><span class="sxs-lookup"><span data-stu-id="63331-758">John</span></span> |<span data-ttu-id="63331-759">Doe</span><span class="sxs-lookup"><span data-stu-id="63331-759">Doe</span></span> |
| <span data-ttu-id="63331-760">2</span><span class="sxs-lookup"><span data-stu-id="63331-760">2</span></span> |<span data-ttu-id="63331-761">Jane</span><span class="sxs-lookup"><span data-stu-id="63331-761">Jane</span></span> |<span data-ttu-id="63331-762">Doe</span><span class="sxs-lookup"><span data-stu-id="63331-762">Doe</span></span> |

<span data-ttu-id="63331-763">삽입을 몇 개 더 실행하고 클러스터의 west-us 부분에 복제되는지 확인합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-763">Execute a few more inserts and see that those get replicated to west-us part of the cluster.</span></span>

## <a name="test-cassandra-cluster-from-nodejs"></a><span data-ttu-id="63331-764">Node.js에서 Cassandra 클러스터 테스트</span><span class="sxs-lookup"><span data-stu-id="63331-764">Test Cassandra Cluster from Node.js</span></span>
<span data-ttu-id="63331-765">이전에 "web" 계층에 만든 Linux VM 중 하나에서 간단한 Node.js 스크립트를 실행하여 이전에 삽입한 데이터를 읽습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-765">Using one of the Linux VMs crated in the "web" tier previously, we will execute a simple Node.js script to read the previously inserted data</span></span>

<span data-ttu-id="63331-766">**1단계: Node.js 및 Cassandra 클라이언트 설치**</span><span class="sxs-lookup"><span data-stu-id="63331-766">**Step 1: Install Node.js and Cassandra Client**</span></span>

1. <span data-ttu-id="63331-767">Node.js 및 npm을 설치합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-767">Install Node.js and npm</span></span>
2. <span data-ttu-id="63331-768">npm을 사용하여 노드 패키지 "cassandra-client"를 설치합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-768">Install node package "cassandra-client" using npm</span></span>
3. <span data-ttu-id="63331-769">검색된 데이터의 json 문자열을 표시하는 셸 프롬프트에서 다음 스크립트를 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="63331-769">Execute the following script at the shell prompt which displays the json string of the retrieved data:</span></span>
   
        var pooledCon = require('cassandra-client').PooledConnection;
        var ksName = "custsupport_ks";
        var cfName = "customers_cf";
        var hostList = ['internal_loadbalancer_ip:9160'];
        var ksConOptions = { hosts: hostList,
                             keyspace: ksName, use_bigints: false };
   
        function createKeyspace(callback){
           var cql = 'CREATE KEYSPACE ' + ksName + ' WITH strategy_class=SimpleStrategy AND strategy_options:replication_factor=1';
           var sysConOptions = { hosts: hostList,  
                                 keyspace: 'system', use_bigints: false };
           var con = new pooledCon(sysConOptions);
           con.execute(cql,[],function(err) {
           if (err) {
             console.log("Failed to create Keyspace: " + ksName);
             console.log(err);
           }
           else {
             console.log("Created Keyspace: " + ksName);
             callback(ksConOptions, populateCustomerData);
           }
           });
           con.shutdown();
        }
   
        function createColumnFamily(ksConOptions, callback){
          var params = ['customers_cf','custid','varint','custname',
                        'text','custaddress','text'];
          var cql = 'CREATE COLUMNFAMILY ? (? ? PRIMARY KEY,? ?, ? ?)';
        var con =  new pooledCon(ksConOptions);
          con.execute(cql,params,function(err) {
              if (err) {
                 console.log("Failed to create column family: " + params[0]);
                 console.log(err);
              }
              else {
                 console.log("Created column family: " + params[0]);
                 callback();
              }
          });
          con.shutdown();
        }
   
        //populate Data
        function populateCustomerData() {
           var params = ['John','Infinity Dr, TX', 1];
           updateCustomer(ksConOptions,params);
   
           params = ['Tom','Fermat Ln, WA', 2];
           updateCustomer(ksConOptions,params);
        }
   
        //update will also insert the record if none exists
        function updateCustomer(ksConOptions,params)
        {
          var cql = 'UPDATE customers_cf SET custname=?,custaddress=? where custid=?';
          var con = new pooledCon(ksConOptions);
          con.execute(cql,params,function(err) {
              if (err) console.log(err);
              else console.log("Inserted customer : " + params[0]);
          });
          con.shutdown();
        }
   
        //read the two rows inserted above
        function readCustomer(ksConOptions)
        {
          var cql = 'SELECT * FROM customers_cf WHERE custid IN (1,2)';
          var con = new pooledCon(ksConOptions);
          con.execute(cql,[],function(err,rows) {
              if (err)
                 console.log(err);
              else
                 for (var i=0; i<rows.length; i++)
                    console.log(JSON.stringify(rows[i]));
            });
           con.shutdown();
        }
   
        //exectue the code
        createKeyspace(createColumnFamily);
        readCustomer(ksConOptions)

## <a name="conclusion"></a><span data-ttu-id="63331-770">결론</span><span class="sxs-lookup"><span data-stu-id="63331-770">Conclusion</span></span>
<span data-ttu-id="63331-771">Microsoft Azure는 이 연습에서 알 수 있듯이 Microsoft 및 오픈 소스 소프트웨어를 둘 다 실행할 수 있게 해주는 유연한 플랫폼입니다.</span><span class="sxs-lookup"><span data-stu-id="63331-771">Microsoft Azure is a flexible platform that allows the running of both Microsoft as well as open source software as demonstrated by this exercise.</span></span> <span data-ttu-id="63331-772">여러 장애 도메인에 클러스터 노드를 분산하여 단일 데이터 센터에 고가용성 Cassandra 클러스터를 배포할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-772">Highly available Cassandra clusters can be deployed on a single data center through the spreading of the cluster nodes across multiple fault domains.</span></span> <span data-ttu-id="63331-773">재해 증명 시스템을 위해 지역적으로 떨어진 여러 Azure 지역에 Cassandra 클러스터를 배포할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-773">Cassandra clusters can also be deployed across multiple geographically distant Azure regions for disaster proof systems.</span></span> <span data-ttu-id="63331-774">Azure와 Cassandra를 함께 사용하면 오늘날의 인터넷 규모 서비스에 필요한 고확장성, 고가용성 및 재해 복구 가능한 클라우드 서비스를 생성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="63331-774">Azure and Cassandra together enables the construction of highly scalable, highly available and disaster recoverable cloud services needed by today's internet scale services.</span></span>  

## <a name="references"></a><span data-ttu-id="63331-775">참조</span><span class="sxs-lookup"><span data-stu-id="63331-775">References</span></span>
* [<span data-ttu-id="63331-776">http://cassandra.apache.org</span><span class="sxs-lookup"><span data-stu-id="63331-776">http://cassandra.apache.org</span></span>](http://cassandra.apache.org)
* [<span data-ttu-id="63331-777">http://www.datastax.com</span><span class="sxs-lookup"><span data-stu-id="63331-777">http://www.datastax.com</span></span>](http://www.datastax.com)
* [<span data-ttu-id="63331-778">http://www.nodejs.org</span><span class="sxs-lookup"><span data-stu-id="63331-778">http://www.nodejs.org</span></span>](http://www.nodejs.org)

