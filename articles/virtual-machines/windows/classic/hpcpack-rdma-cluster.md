---
title: "MPI 응용 프로그램을 실행하도록 Windows RDMA 클러스터 설정 | Microsoft Docs"
description: "Azure RDMA 네트워크를 사용하여 MPI 앱을 실행하기 위해 크기가 H16r, H16mr, A8 또는 A9인 VM으로 Windows HPC Pack 클러스터를 만드는 방법을 알아보세요."
services: virtual-machines-windows
documentationcenter: 
author: dlepow
manager: timlt
editor: 
tags: azure-service-management,hpc-pack
ms.assetid: 7d9f5bc8-012f-48dd-b290-db81c7592215
ms.service: virtual-machines-windows
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: vm-windows
ms.workload: big-compute
ms.date: 06/01/2017
ms.author: danlep
ms.openlocfilehash: 19be1d693fe13af0f6c1ab0cb6f7bc829b9fad5a
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 08/03/2017
---
# <a name="set-up-a-windows-rdma-cluster-with-hpc-pack-to-run-mpi-applications"></a><span data-ttu-id="83d66-103">MPI 응용 프로그램을 실행하기 위해 HPC Pack을 사용하여 Windows RDMA 클러스터 설정</span><span class="sxs-lookup"><span data-stu-id="83d66-103">Set up a Windows RDMA cluster with HPC Pack to run MPI applications</span></span>
<span data-ttu-id="83d66-104">Azure에서 [Microsoft HPC Pack](https://technet.microsoft.com/library/cc514029) 및 [고성능 계산 VM 크기](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json)를 사용하여 MPI(Message Passing Interface) 응용 프로그램을 병렬로 실행하도록 Windows RDMA 클러스터를 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-104">Set up a Windows RDMA cluster in Azure with [Microsoft HPC Pack](https://technet.microsoft.com/library/cc514029) and [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) to run parallel Message Passing Interface (MPI) applications.</span></span> <span data-ttu-id="83d66-105">HPC 팩 클러스터에서 RDMA 지원, Windows Server 기반 노드를 설정하는 경우 MPI 응용 프로그램은 Azure에서 RDMA(원격 직접 메모리 액세스) 기술을 기반으로 하는 낮은 대기 시간 및 높은 처리량의 네트워크에서 효율적으로 통신합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-105">When you set up RDMA-capable, Windows Server-based nodes in an HPC Pack cluster, MPI applications communicate efficiently over a low latency, high throughput network in Azure that is based on remote direct memory access (RDMA) technology.</span></span>

<span data-ttu-id="83d66-106">Azure RDMA 네트워크에 액세스하는 Linux VM에서 MPI 워크로드를 실행하려는 경우 [MPI 응용 프로그램을 실행하도록 Linux RDMA 클러스터 설정](../../linux/classic/rdma-cluster.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-106">If you want to run MPI workloads on Linux VMs that access the Azure RDMA network, see [Set up a Linux RDMA cluster to run MPI applications](../../linux/classic/rdma-cluster.md).</span></span>

## <a name="hpc-pack-cluster-deployment-options"></a><span data-ttu-id="83d66-107">HPC 팩 클러스터 배포 옵션</span><span class="sxs-lookup"><span data-stu-id="83d66-107">HPC Pack cluster deployment options</span></span>
<span data-ttu-id="83d66-108">Microsoft HPC Pack은 Windows 또는 Linux HPC 응용 프로그램을 실행하기 위해 온-프레미스 또는 Azure에서 HPC 클러스터를 만들 수 있도록 추가 비용 없이 제공되는 도구입니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-108">Microsoft HPC Pack is a tool provided at no additional cost to create HPC clusters on-premises or in Azure to run Windows or Linux HPC applications.</span></span> <span data-ttu-id="83d66-109">HPC Pack에 Windows(MS-MPI)용 메시지 전달 인터페이스의 Microsoft 구현에 대한 런타임 환경을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-109">HPC Pack includes a runtime environment for the Microsoft implementation of the Message Passing Interface for Windows (MS-MPI).</span></span> <span data-ttu-id="83d66-110">HPC Pack을 지원되는 Windows Server 운영 체제를 실행하는 RDMA 지원 인스턴스와 함께 사용하는 경우 Azure RDMA 네트워크에 액세스하는 Windows MPI 응용 프로그램을 효율적으로 실행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-110">When used with RDMA-capable instances running a supported Windows Server operating system, HPC Pack provides an efficient option to run Windows MPI applications that access the Azure RDMA network.</span></span> 

<span data-ttu-id="83d66-111">이 문서에서는 Microsoft HPC Pack을 사용하여 Windows RDMA 클러스터를 설정하기 위한 2가지 시나리오를 소개하고 자세한 지침을 제공하는 링크를 소개합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-111">This article introduces two scenarios and links to detailed guidance to set up a Windows RDMA cluster with Microsoft HPC Pack.</span></span> 

* <span data-ttu-id="83d66-112">시나리오 1.</span><span class="sxs-lookup"><span data-stu-id="83d66-112">Scenario 1.</span></span> <span data-ttu-id="83d66-113">계산 집약적 작업자 역할 인스턴스 배포(PaaS)</span><span class="sxs-lookup"><span data-stu-id="83d66-113">Deploy compute-intensive worker role instances (PaaS)</span></span>
* <span data-ttu-id="83d66-114">시나리오 2.</span><span class="sxs-lookup"><span data-stu-id="83d66-114">Scenario 2.</span></span> <span data-ttu-id="83d66-115">계산 집약적 VM에 계산 노드 배포(IaaS)</span><span class="sxs-lookup"><span data-stu-id="83d66-115">Deploy compute nodes in compute-intensive VMs (IaaS)</span></span>

<span data-ttu-id="83d66-116">Windows에서 계산 집약적 인스턴스를 사용하기 위한 일반적인 필수 구성 요소에 대해서는 [고성능 계산 VM 크기](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-116">For general prerequisites to use compute-intensive instances with Windows, see [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>

## <a name="scenario-1-deploy-compute-intensive-worker-role-instances-paas"></a><span data-ttu-id="83d66-117">시나리오 1: 계산 집약적 작업자 역할 인스턴스 배포(PaaS)</span><span class="sxs-lookup"><span data-stu-id="83d66-117">Scenario 1: Deploy compute-intensive worker role instances (PaaS)</span></span>
<span data-ttu-id="83d66-118">기존 HPC 팩 클러스터에서 클라우드 서비스(PaaS)에서 실행 중인 Azure 작업자 역할 인스턴스(Azure 노드)에 추가 계산 리소스를 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-118">From an existing HPC Pack cluster, add extra compute resources in Azure worker role instances (Azure nodes) running in a cloud service (PaaS).</span></span> <span data-ttu-id="83d66-119">이 기능은 HPC 팩에서 "Azure로 버스트"라고도 하며 작업자 역할 인스턴스에 다양한 크기를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-119">This feature, also called “burst to Azure” from HPC Pack, supports a range of sizes for the worker role instances.</span></span> <span data-ttu-id="83d66-120">Azure 노드를 추가할 때는 RDMA 지원 크기 중 하나를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-120">When adding the Azure nodes, specify one of the RDMA-capable sizes.</span></span>

<span data-ttu-id="83d66-121">다음은 기존 (일반적으로 온-프레미스) 클러스터에서 RDMA 지원 Azure 인스턴스로 버스트하는 단계 및 고려 사항입니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-121">Following are considerations and steps to burst to RDMA-capable Azure instances from an existing (typically on-premises) cluster.</span></span> <span data-ttu-id="83d66-122">유사한 절차를 사용하여 Azure VM에 배포된 HPC 팩 헤드 노드에 작업자 역할 인스턴스를 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-122">Use similar procedures to add worker role instances to an HPC Pack head node that is deployed in an Azure VM.</span></span>

> [!NOTE]
> <span data-ttu-id="83d66-123">HPC 팩을 사용하는 Azure로 버스트에 대한 자습서는 [HPC 팩을 사용하여 하이브리드 클러스터 설정](../../../cloud-services/cloud-services-setup-hybrid-hpcpack-cluster.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-123">For a tutorial to burst to Azure with HPC Pack, see [Set up a hybrid cluster with HPC Pack](../../../cloud-services/cloud-services-setup-hybrid-hpcpack-cluster.md).</span></span> <span data-ttu-id="83d66-124">아래 단계에서 특히 RDMA 지원 Azure 노드에 적용되는 고려 사항을 확인하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-124">Note the considerations in the following steps that apply specifically to RDMA-capable Azure nodes.</span></span>
> 
> 

![Azure로 버스트][burst]

### <a name="steps"></a><span data-ttu-id="83d66-126">단계</span><span class="sxs-lookup"><span data-stu-id="83d66-126">Steps</span></span>
1. <span data-ttu-id="83d66-127">**HPC 팩 2012 R2 헤드 노드 배포 및 구성**</span><span class="sxs-lookup"><span data-stu-id="83d66-127">**Deploy and configure an HPC Pack 2012 R2 head node**</span></span>
   
    <span data-ttu-id="83d66-128">[Microsoft 다운로드 센터](https://www.microsoft.com/download/details.aspx?id=49922)에서 최신 HPC 팩 설치 패키지를 다운로드합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-128">Download the latest HPC Pack installation package from the [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span></span> <span data-ttu-id="83d66-129">Azure 버스트 배포를 준비하기 위한 요구 사항 및 지침은 [Microsoft HPC Pack을 사용하여 Azure 작업자 인스턴스로 버스트](https://technet.microsoft.com/library/gg481749.aspx)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-129">For requirements and instructions to prepare for an Azure burst deployment, see [Burst to Azure Worker Instances with Microsoft HPC Pack](https://technet.microsoft.com/library/gg481749.aspx).</span></span>
2. <span data-ttu-id="83d66-130">**Azure 구독에서 관리 인증서 구성**</span><span class="sxs-lookup"><span data-stu-id="83d66-130">**Configure a management certificate in the Azure subscription**</span></span>
   
    <span data-ttu-id="83d66-131">헤드 노드와 Azure 간 연결을 보호하기 위한 인증서를 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-131">Configure a certificate to secure the connection between the head node and Azure.</span></span> <span data-ttu-id="83d66-132">옵션 및 절차에 대한 자세한 내용은 [HPC 팩용 Azure 관리 인증서 구성 시나리오](http://technet.microsoft.com/library/gg481759.aspx)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-132">For options and procedures, see [Scenarios to Configure the Azure Management Certificate for HPC Pack](http://technet.microsoft.com/library/gg481759.aspx).</span></span> <span data-ttu-id="83d66-133">테스트 배포의 경우 HPC 팩은 Azure 구독에 신속하게 업로드할 수 있는 기본 Microsoft HPC Azure 관리 인증서를 설치합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-133">For test deployments, HPC Pack installs a Default Microsoft HPC Azure Management Certificate you can quickly upload to your Azure subscription.</span></span>
3. <span data-ttu-id="83d66-134">**새 클라우드 서비스 및 저장소 계정 만들기**</span><span class="sxs-lookup"><span data-stu-id="83d66-134">**Create a new cloud service and a storage account**</span></span>
   
    <span data-ttu-id="83d66-135">Azure Portal을 사용하여 RDMA 가능 인스턴스를 사용할 수 있는 지역에 배포하기 위한 클라우드 서비스 및 저장소 계정을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-135">Use the Azure portal to create a cloud service and a storage account for the deployment in a region where the RDMA-capable instances are available.</span></span>
4. <span data-ttu-id="83d66-136">**Azure 노드 템플릿 만들기**</span><span class="sxs-lookup"><span data-stu-id="83d66-136">**Create an Azure node template**</span></span>
   
    <span data-ttu-id="83d66-137">HPC 클러스터 관리자에서 노드 템플릿 마법사를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-137">Use the Create Node Template Wizard in HPC Cluster Manager.</span></span> <span data-ttu-id="83d66-138">단계를 보려면 "Microsoft HPC 팩을 사용하여 Azure 노드를 배포하는 단계"에서 [Azure 노드 템플릿 만들기](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Templ) 를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-138">For steps, see [Create an Azure node template](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Templ) in “Steps to Deploy Azure Nodes with Microsoft HPC Pack”.</span></span>
   
    <span data-ttu-id="83d66-139">초기 테스트에서 템플릿에 수동 가용성 정책을 구성하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-139">For initial tests, we suggest configuring a manual availability policy in the template.</span></span>
5. <span data-ttu-id="83d66-140">**클러스터에 노드 추가**</span><span class="sxs-lookup"><span data-stu-id="83d66-140">**Add nodes to the cluster**</span></span>
   
    <span data-ttu-id="83d66-141">HPC 클러스터 관리자에서 노드 추가 마법사를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-141">Use the Add Node Wizard in HPC Cluster Manager.</span></span> <span data-ttu-id="83d66-142">자세한 내용은 참조 [Windows HPC 클러스터에 Azure 노드 추가](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Add)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-142">For more information, see [Add Azure Nodes to the Windows HPC Cluster](http://technet.microsoft.com/library/gg481758.aspx#BKMK_Add).</span></span>
   
    <span data-ttu-id="83d66-143">노드 크기를 지정하는 경우 RDMA 지원 인스턴스 크기 중 하나를 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-143">When specifying the size of the nodes, select one of the RDMA-capable instance sizes.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="83d66-144">계산 집약적인 인스턴스를 사용하는 각 Azure로 버스트 배포에서 HPC 팩은 사용자가 지정하는 Azure 작업자 역할 인스턴스 이외에 최소 2개 이상의 RDMA 지원 인스턴스(예: A8)를 프록시 노드로 자동 배포합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-144">In each burst to Azure deployment with the compute-intensive instances, HPC Pack automatically deploys a minimum of two RDMA-capable instances (such as A8) as proxy nodes, in addition to the Azure worker role instances you specify.</span></span> <span data-ttu-id="83d66-145">프록시 노드는 구독에 할당된 코어를 사용하고 Azure 작업자 역할 인스턴스와 함께 요금이 청구됩니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-145">The proxy nodes use cores that are allocated to the subscription and incur charges along with the Azure worker role instances.</span></span>
   > 
   > 
6. <span data-ttu-id="83d66-146">**노드를 시작(프로비전)하고 온라인 상태로 전환하여 작업 실행**</span><span class="sxs-lookup"><span data-stu-id="83d66-146">**Start (provision) the nodes and bring them online to run jobs**</span></span>
   
    <span data-ttu-id="83d66-147">노드를 선택하고 HPC 클러스터 관리자에서 **시작** 작업을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-147">Select the nodes and use the **Start** action in HPC Cluster Manager.</span></span> <span data-ttu-id="83d66-148">프로비전 이 완료되면 노드를 선택하고 HPC 클러스터 관리자에서 **온라인 상태로 전환** 작업을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-148">When provisioning is complete, select the nodes and use the **Bring Online** action in HPC Cluster Manager.</span></span> <span data-ttu-id="83d66-149">노드에서 작업을 실행할 준비가 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-149">The nodes are ready to run jobs.</span></span>
7. <span data-ttu-id="83d66-150">**클러스터에 작업 제출**</span><span class="sxs-lookup"><span data-stu-id="83d66-150">**Submit jobs to the cluster**</span></span>
   
   <span data-ttu-id="83d66-151">HPC 팩 작업 제출 도구를 사용하여 클러스터 작업을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-151">Use HPC Pack job submission tools to run cluster jobs.</span></span> <span data-ttu-id="83d66-152">[Microsoft HPC 팩: 작업 관리](http://technet.microsoft.com/library/jj899585.aspx)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-152">See [Microsoft HPC Pack: Job Management](http://technet.microsoft.com/library/jj899585.aspx).</span></span>
8. <span data-ttu-id="83d66-153">**노드 중지(프로 비전 해제)**</span><span class="sxs-lookup"><span data-stu-id="83d66-153">**Stop (deprovision) the nodes**</span></span>
   
   <span data-ttu-id="83d66-154">작업 실행을 마쳤으면 노드를 오프라인으로 전환하고 HPC 클러스터 관리자에서 **중지** 작업을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-154">When you are done running jobs, take the nodes offline and use the **Stop** action in HPC Cluster Manager.</span></span>

## <a name="scenario-2-deploy-compute-nodes-in-compute-intensive-vms-iaas"></a><span data-ttu-id="83d66-155">시나리오 2: 계산 집약적 VM에 계산 노드 배포(IaaS)</span><span class="sxs-lookup"><span data-stu-id="83d66-155">Scenario 2: Deploy compute nodes in compute-intensive VMs (IaaS)</span></span>
<span data-ttu-id="83d66-156">이 시나리오에서는 Azure 가상 네트워크의 VM에 HPC 팩 헤드 노드와 클러스터 계산 노드를 배포합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-156">In this scenario, you deploy the HPC Pack head node and cluster compute nodes on VMs in an Azure virtual network.</span></span> <span data-ttu-id="83d66-157">HPC Pack은 자동 배포 스크립트 및 Azure 빠른 시작 템플릿을 포함하여 다양한 [Azure VM의 배포 옵션](../../linux/hpcpack-cluster-options.md)을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-157">HPC Pack provides several [deployment options in Azure VMs](../../linux/hpcpack-cluster-options.md), including automated deployment scripts and Azure quickstart templates.</span></span> <span data-ttu-id="83d66-158">예를 들어, 다음 고려 사항 및 단계는 [HPC 팩 IaaS 배포 스크립트](hpcpack-cluster-powershell-script.md)를 사용하여 Azure에서 HPC Pack 2012 R2 클러스터의 배포를 자동화하는 방법을 안내합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-158">As an example, the following considerations and steps guide you to use the [HPC Pack IaaS deployment script](hpcpack-cluster-powershell-script.md) to automate the deployment of an HPC Pack 2012 R2 cluster in Azure.</span></span>

![Azure VM의 클러스터][iaas]

### <a name="steps"></a><span data-ttu-id="83d66-160">단계</span><span class="sxs-lookup"><span data-stu-id="83d66-160">Steps</span></span>
1. <span data-ttu-id="83d66-161">**클라이언트 컴퓨터에서 HPC 팩 IaaS 배포 스크립트를 실행하여 클러스터 헤드 노드 및 계산 노드 VM 만들기**</span><span class="sxs-lookup"><span data-stu-id="83d66-161">**Create a cluster head node and compute node VMs by running the HPC Pack IaaS deployment script on a client computer**</span></span>
   
    <span data-ttu-id="83d66-162">[Microsoft 다운로드 센터](https://www.microsoft.com/download/details.aspx?id=49922)에서 HPC 팩 IaaS 배포 스크립트 패키지를 다운로드합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-162">Download the HPC Pack IaaS Deployment Script package from the [Microsoft Download Center](https://www.microsoft.com/download/details.aspx?id=49922).</span></span>
   
    <span data-ttu-id="83d66-163">클라이언트 컴퓨터를 준비하고 스크립트 구성 파일을 만들어 스크립트를 실행하려면 [HPC 팩 IaaS 배포 스크립트를 사용하여 HPC 클러스터 만들기](hpcpack-cluster-powershell-script.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-163">To prepare the client computer, create the script configuration file, and run the script, see [Create an HPC Cluster with the HPC Pack IaaS deployment script](hpcpack-cluster-powershell-script.md).</span></span> 
   
    <span data-ttu-id="83d66-164">RDMA 지원 계산 노드를 배포하려면 다음 추가 고려 사항을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-164">To deploy RDMA-capable compute nodes, note the following additional considerations:</span></span>
   
   * <span data-ttu-id="83d66-165">**가상 네트워크**: 사용하려는 RDMA 지원 인스턴스 크기를 사용할 수 있는 지역에서 새 가상 네트워크를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-165">**Virtual network**: Specify a new virtual network in a region in which the RDMA-capable instance size you want to use is available.</span></span>
   * <span data-ttu-id="83d66-166">**Windows Server 운영 체제**: RDMA 연결을 지원하려면 계산 노드 VM에 대해 Windows Server 2012 R2 또는 Windows Server 2012 운영 체제를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-166">**Windows Server operating system**: To support RDMA connectivity, specify a Windows Server 2012 R2 or Windows Server 2012 operating system for the compute node VMs.</span></span>
   * <span data-ttu-id="83d66-167">**클라우드 서비스**: 헤드 노드를 한 클라우드 서비스에 배포하고 계산 노드를 다른 클라우드 서비스에 배포하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-167">**Cloud services**: We recommend deploying your head node in one cloud service and your compute nodes in a different cloud service.</span></span>
   * <span data-ttu-id="83d66-168">**헤드 노드 크기**: 이 시나리오의 경우 헤드 노드를 위해 최소한 A4 크기(매우 큼)를 고려합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-168">**Head node size**: For this scenario, consider a size of at least A4 (Extra Large) for the head node.</span></span>
   * <span data-ttu-id="83d66-169">**HpcVmDrivers 확장**: Windows Server 운영 체제로 크기가 A8 또는 A9인 계산 노드를 배포할 경우 배포 스크립트는 Azure VM 에이전트와 HpcVmDrivers 확장을 자동으로 설치합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-169">**HpcVmDrivers extension**: The deployment script installs the Azure VM Agent and the HpcVmDrivers extension automatically when you deploy size A8 or A9 compute nodes with a Windows Server operating system.</span></span> <span data-ttu-id="83d66-170">HpcVmDrivers는 계산 노드 VM이 RDMA 네트워크에 연결할 수 있도록 이 VM에 드라이버를 설치합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-170">HpcVmDrivers installs drivers on the compute node VMs so they can connect to the RDMA network.</span></span> <span data-ttu-id="83d66-171">RDMA 지원 H 시리즈 VM에서는 HpcVmDrivers 확장을 수동으로 설치해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-171">On RDMA-capable H-series VMs, you must manually install the HpcVmDrivers extension.</span></span> <span data-ttu-id="83d66-172">[고성능 계산 VM 크기](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-172">See [High performance compute VM sizes](../sizes-hpc.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>
   * <span data-ttu-id="83d66-173">**클러스터 네트워크 구성**: 배포 스크립트는 토폴로지 5(엔터프라이즈 네트워크에 있는 모든 노드)에 HPC Pack 클러스터를 자동으로 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-173">**Cluster network configuration**: The deployment script automatically sets up the HPC Pack cluster in Topology 5 (all nodes on the Enterprise network).</span></span> <span data-ttu-id="83d66-174">이 토폴로지는 VM에서의 모든 HPC Pack 클러스터 배포에 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-174">This topology is required for all HPC Pack cluster deployments in VMs.</span></span> <span data-ttu-id="83d66-175">나중에 클러스터 네트워크 토폴로지를 변경하지 마십시오.</span><span class="sxs-lookup"><span data-stu-id="83d66-175">Do not change the cluster network topology later.</span></span>
2. <span data-ttu-id="83d66-176">**계산 노드를 온라인 상태로 전환하여 작업 실행**</span><span class="sxs-lookup"><span data-stu-id="83d66-176">**Bring the compute nodes online to run jobs**</span></span>
   
    <span data-ttu-id="83d66-177">노드를 선택하고 HPC 클러스터 관리자에서 **온라인 상태로 전환** 작업을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-177">Select the nodes and use the **Bring Online** action in HPC Cluster Manager.</span></span> <span data-ttu-id="83d66-178">노드에서 작업을 실행할 준비가 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-178">The nodes are ready to run jobs.</span></span>
3. <span data-ttu-id="83d66-179">**클러스터에 작업 제출**</span><span class="sxs-lookup"><span data-stu-id="83d66-179">**Submit jobs to the cluster**</span></span>
   
    <span data-ttu-id="83d66-180">작업을 제출하려면 헤드 노드에 연결하거나 온-프레미스 컴퓨터를 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-180">Connect to the head node to submit jobs, or set up an on-premises computer to do this.</span></span> <span data-ttu-id="83d66-181">자세한 내용은 [Azure에서 HPC 클러스터에 작업 제출](../../virtual-machines-windows-hpcpack-cluster-submit-jobs.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-181">For information, see [Submit Jobs to an HPC cluster in Azure](../../virtual-machines-windows-hpcpack-cluster-submit-jobs.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json).</span></span>
4. <span data-ttu-id="83d66-182">**노드를 오프라인 상태로 전환 및 중지(할당 취소)**</span><span class="sxs-lookup"><span data-stu-id="83d66-182">**Take the nodes offline and stop (deallocate) them**</span></span>
   
    <span data-ttu-id="83d66-183">작업 실행을 마쳤으면 HPC 클러스터 관리자에서 노드를 오프라인 상태로 전환합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-183">When you are done running jobs, take the nodes offline in HPC Cluster Manager.</span></span> <span data-ttu-id="83d66-184">그런 다음 Azure 관리 도구를 사용하여 종료합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-184">Then, use Azure management tools to shut them down.</span></span>

## <a name="run-mpi-applications-on-the-cluster"></a><span data-ttu-id="83d66-185">클러스터에서 MPI 응용 프로그램 실행</span><span class="sxs-lookup"><span data-stu-id="83d66-185">Run MPI applications on the cluster</span></span>
### <a name="example-run-mpipingpong-on-an-hpc-pack-cluster"></a><span data-ttu-id="83d66-186">예: HPC 팩 클러스터에서 mpipingpong 실행</span><span class="sxs-lookup"><span data-stu-id="83d66-186">Example: Run mpipingpong on an HPC Pack cluster</span></span>
<span data-ttu-id="83d66-187">RDMA 지원 인스턴스의 HPC 팩 배포를 확인하려면 클러스터에서 HPC 팩 **mpipingpong** 명령을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-187">To verify an HPC Pack deployment of the RDMA-capable instances, run the HPC Pack **mpipingpong** command on the cluster.</span></span> <span data-ttu-id="83d66-188">**mpipingpong** 은 쌍으로 연결된 노드 사이에서 데이터 패킷을 반복적으로 전송하여 RDMA를 사용하는 응용 프로그램 네트워크의 대기 시간, 처리량 측정값 및 통계를 계산합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-188">**mpipingpong** sends packets of data between paired nodes repeatedly to calculate latency and throughput measurements and statistics for the RDMA-enabled application network.</span></span> <span data-ttu-id="83d66-189">이 예제에서는 클러스터 **mpiexec** 명령을 사용하여 MPI 작업(이 경우 **mpipingpong**)을 실행하는 일반적 패턴을 보여줍니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-189">This example shows a typical pattern for running an MPI job (in this case, **mpipingpong**) by using the cluster **mpiexec** command.</span></span>

<span data-ttu-id="83d66-190">이 예제에서는 "Azure로 버스트" 구성에 Azure 노드를 추가했다고 가정합니다([시나리오 1](#scenario-1.-deploy-compute-intensive-worker-role-instances-\(PaaS\) in this article)).</span><span class="sxs-lookup"><span data-stu-id="83d66-190">This example assumes you added Azure nodes in a “burst to Azure” configuration ([Scenario 1](#scenario-1.-deploy-compute-intensive-worker-role-instances-\(PaaS\) in this article).</span></span> <span data-ttu-id="83d66-191">Azure VM의 클러스터에 HPC 팩을 배포한 경우 명령 구문을 수정하여 다른 노드 그룹을 지정하고 추가 변수를 설정하여 네트워크 트래픽이 RDMA 네트워크로 가도록 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-191">If you deployed HPC Pack on a cluster of Azure VMs, you’ll need to modify the command syntax to specify a different node group and set additional environment variables to direct network traffic to the RDMA network.</span></span>

<span data-ttu-id="83d66-192">클러스터에서 mpipingpong을 실행하려면</span><span class="sxs-lookup"><span data-stu-id="83d66-192">To run mpipingpong on the cluster:</span></span>

1. <span data-ttu-id="83d66-193">헤드 노드 또는 올바르게 구성된 클라이언트 컴퓨터에서 명령 프롬프트를 엽니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-193">On the head node or on a properly configured client computer, open a Command Prompt.</span></span>
2. <span data-ttu-id="83d66-194">4개 노드로 구성된 Azure 버스트 배포에서 쌍으로 연결된 노드 사이의 대기 시간을 추정하려면 다음 명령을 입력하여 작업을 제출하고 작은 패킷 크기와 많은 반복을 사용하여 mpipingpong을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-194">To estimate latency between pairs of nodes in an Azure burst deployment of four nodes, type the following command to submit a job to run mpipingpong with a small packet size and many iterations:</span></span>
   
    ```Command
    job submit /nodegroup:azurenodes /numnodes:4 mpiexec -c 1 -affinity mpipingpong -p 1:100000 -op -s nul
    ```
   
    <span data-ttu-id="83d66-195">이 명령은 제출된 작업의 ID를 반환합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-195">The command returns the ID of the job that is submitted.</span></span>
   
    <span data-ttu-id="83d66-196">Azure VM에 배포된 HPC 팩 클러스터를 배포한 경우 단일 클라우드 서비스에 배포된 계산 노드 VM이 포함된 노드 그룹을 지정하고 **mpiexec** 명령을 다음과 같이 수정합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-196">If you deployed the HPC Pack cluster deployed on Azure VMs, specify a node group that contains compute node VMs deployed in a single cloud service, and modify the **mpiexec** command as follows:</span></span>
   
    ```Command
    job submit /nodegroup:vmcomputenodes /numnodes:4 mpiexec -c 1 -affinity -env MSMPI_DISABLE_SOCK 1 -env MSMPI_PRECONNECT all -env MPICH_NETMASK 172.16.0.0/255.255.0.0 mpipingpong -p 1:100000 -op -s nul
    ```
3. <span data-ttu-id="83d66-197">작업이 완료된 다음 출력(이 경우 작업의 작업 1 출력)을 보려면 다음과 같이 입력합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-197">When the job completes, to view the output (in this case, the output of task 1 of the job), type the following</span></span>
   
    ```Command
    task view <JobID>.1
    ```
   
    <span data-ttu-id="83d66-198">여기서 &lt;*JobID*&gt;는 제출된 작업의 ID입니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-198">where &lt;*JobID*&gt; is the ID of the job that was submitted.</span></span>
   
    <span data-ttu-id="83d66-199">출력에는 다음과 유사한 대기 시간 결과가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-199">The output includes latency results similar to the following.</span></span>
   
    ![핑퐁 대기 시간][pingpong1]
4. <span data-ttu-id="83d66-201">쌍으로 연결된 Azure 버스트 노드 사이의 처리량을 추정하려면 다음 명령을 입력하여 작업을 제출하고 작은 패킷 크기와 적은 반복을 사용하여 **mpipingpong**을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-201">To estimate throughput between pairs of Azure burst nodes, type the following command to submit a job to run **mpipingpong** with a large packet size and a few iterations:</span></span>
   
    ```Command
    job submit /nodegroup:azurenodes /numnodes:4 mpiexec -c 1 -affinity mpipingpong -p 4000000:1000 -op -s nul
    ```
   
    <span data-ttu-id="83d66-202">이 명령은 제출된 작업의 ID를 반환합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-202">The command returns the ID of the job that is submitted.</span></span>
   
    <span data-ttu-id="83d66-203">Azure VM에 배포된 HPC 팩 클러스터에서 2단계의 설명과 같이 명령을 수정합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-203">On an HPC Pack cluster deployed on Azure VMs, modify the command as noted in step 2.</span></span>
5. <span data-ttu-id="83d66-204">작업이 완료된 다음 출력(이 경우 작업의 작업 1 출력)을 보려면 다음과 같이 입력합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-204">When the job completes, to view the output (in this case, the output of task 1 of the job), type the following:</span></span>
   
    ```Command
    task view <JobID>.1
    ```
   
   <span data-ttu-id="83d66-205">출력에는 다음과 유사한 처리량 결과가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-205">The output includes throughput results similar to the following.</span></span>
   
   ![핑퐁 처리량][pingpong2]

### <a name="mpi-application-considerations"></a><span data-ttu-id="83d66-207">MPI 응용 프로그램 고려 사항</span><span class="sxs-lookup"><span data-stu-id="83d66-207">MPI application considerations</span></span>
<span data-ttu-id="83d66-208">다음은 Azure에서 HPC Pack을 사용하여 MPI 응용 프로그램을 실행하기 위한 고려 사항입니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-208">Following are considerations for running MPI applications with HPC Pack in Azure.</span></span> <span data-ttu-id="83d66-209">일부는 Azure 노드 배포에만 적용됩니다(작업자 역할 인스턴스가 "Azure로 버스트" 구성에 추가됨).</span><span class="sxs-lookup"><span data-stu-id="83d66-209">Some apply only to deployments of Azure nodes (worker role instances added in a “burst to Azure” configuration).</span></span>

* <span data-ttu-id="83d66-210">클라우드 서비스의 작업자 역할 인스턴스는 Azure에서 미리 알리지 않고 정기적으로 다시 프로비전됩니다(예: 시스템 유지 관리에서 또는 인스턴스가 실패할 경우).</span><span class="sxs-lookup"><span data-stu-id="83d66-210">Worker role instances in a cloud service are periodically reprovisioned without notice by Azure (for example, for system maintenance, or in case an instance fails).</span></span> <span data-ttu-id="83d66-211">MPI 작업을 실행하는 동안 인스턴스를 다시 프로비전한 경우 인스턴스의 데이터가 손실되고 인스턴스가 처음 배포될 당시의 상태로 돌아가며, 이로 인해 MPI 작업이 실패합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-211">If an instance is reprovisioned while it is running an MPI job, the instance loses its data and returns to the state when it was first deployed, which can cause the MPI job to fail.</span></span> <span data-ttu-id="83d66-212">단일 MPI 작업에 사용하는 노드가 많고 작업이 더 오래 실행될수록 작업이 실행되는 동안 인스턴스 중 하나가 다시 프로비전될 가능성이 높아집니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-212">The more nodes that you use for a single MPI job, and the longer the job runs, the more likely that one of the instances is reprovisioned while a job is running.</span></span> <span data-ttu-id="83d66-213">배포에서 단일 노드를 파일 서버로 지정하는 경우에도 이를 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-213">Also consider this if you designate a single node in the deployment as a file server.</span></span>
* <span data-ttu-id="83d66-214">Azure에서 MPI 작업을 실행하기 위해 RDMA 지원 인스턴스를 사용할 필요는 없습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-214">To run MPI jobs in Azure, you don't have to use the RDMA-capable instances.</span></span> <span data-ttu-id="83d66-215">HPC 팩에서 지원되는 모든 인스턴스 크기를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-215">You can use any instance size that is supported by HPC Pack.</span></span> <span data-ttu-id="83d66-216">하지만 RDMA 지원 인스턴스는 대기 시간 및 노드에 연결되는 네트워크 대역폭에 민감하며 상대적으로 큰 규모의 MPI 작업을 실행하는 데 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-216">However, the RDMA-capable instances are recommended for running relatively large-scale MPI jobs that are sensitive to the latency and the bandwidth of the network that connects the nodes.</span></span> <span data-ttu-id="83d66-217">대기 시간 및 대역폭에 민감한 MPI 작업을 실행하는 데 다른 크기를 사용하는 경우 단일 작업이 단 몇 개 노드에서만 실행되는 작은 작업을 실행하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-217">If you use other sizes to run latency- and bandwidth-sensitive MPI jobs, we recommend running small jobs, in which a single task runs on only a few nodes.</span></span>
* <span data-ttu-id="83d66-218">Azure 인스턴스에 배포되는 응용 프로그램은 응용 프로그램과 관련된 라이선스 조건이 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-218">Applications deployed to Azure instances are subject to the licensing terms associated with the application.</span></span> <span data-ttu-id="83d66-219">클라우드에서 실행하기 위해 라이선스나 기타 제한 사항에 대한 상용 응용 프로그램을 공급 업체에 확인합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-219">Check with the vendor of any commercial application for licensing or other restrictions for running in the cloud.</span></span> <span data-ttu-id="83d66-220">일부 공급 업체는 종량제 라이선스를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-220">Not all vendors offer pay-as-you-go licensing.</span></span>
* <span data-ttu-id="83d66-221">온-프레미스 노드, 공유, 라이선스 서버에 액세스하려면 Azure 인스턴스에 추가 설정이 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-221">Azure instances need further setup to access on-premises nodes, shares, and license servers.</span></span> <span data-ttu-id="83d66-222">예를 들어 Azure 노드가 온-프레미스 라이선스 서버에 액세스하도록 하려면 사이트 대 사이트 Azure 가상 네트워크를 구성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-222">For example, to enable the Azure nodes to access an on-premises license server, you can configure a site-to-site Azure virtual network.</span></span>
* <span data-ttu-id="83d66-223">Azure 인스턴스에 MPI 응용 프로그램을 실행하려면 **hpcfwutil** 명령을 실행하여 인스턴스의 Windows 방화벽에 각 MPI 응용 프로그램을 등록합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-223">To run MPI applications on Azure instances, register each MPI application with Windows Firewall on the instances by running the **hpcfwutil** command.</span></span> <span data-ttu-id="83d66-224">그러면 방화벽에서 동적으로 할당한 포트에서 MPI 통신이 이루어집니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-224">This allows MPI communications to take place on a port that is assigned dynamically by the firewall.</span></span>
  
  > [!NOTE]
  > <span data-ttu-id="83d66-225">Azure로 버스트 배포의 경우 방화벽 제외 명령을 구성하여 클러스터에 추가된 모든 새 Azure 노드에서 자동으로 실행할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-225">For burst to Azure deployments, you can also configure a firewall exception command to run automatically on all new Azure nodes that are added to your cluster.</span></span> <span data-ttu-id="83d66-226">**hpcfwutil** 명령을 실행하고 응용 프로그램이 작동하는지 확인한 다음 Azure 노드의 시작 스크립트에 명령을 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-226">After you run the **hpcfwutil** command and verify that your application works, add the command to a startup script for your Azure nodes.</span></span> <span data-ttu-id="83d66-227">자세한 내용은 [Azure 노드에 시작 스크립트 사용](https://technet.microsoft.com/library/jj899632.aspx)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-227">For more information, see [Use a Startup Script for Azure Nodes](https://technet.microsoft.com/library/jj899632.aspx).</span></span>
  > 
  > 
* <span data-ttu-id="83d66-228">HPC 팩은 CCP_MPI_NETMASK 클러스터 환경 변수를 사용하여 MPI 통신에 허용 가능한 다양한 주소를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-228">HPC Pack uses the CCP_MPI_NETMASK cluster environment variable to specify a range of acceptable addresses for MPI communication.</span></span> <span data-ttu-id="83d66-229">HPC 팩 2012 R2부터 CCP_MPI_NETMASK 클러스터 환경 면수는 도메인에 연결된 클러스터 계산 노드(온-프레미스 또는 Azure VM) 간 MPI 통신에만 영향을 미칩니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-229">Starting in HPC Pack 2012 R2, the CCP_MPI_NETMASK cluster environment variable only affects MPI communication between domain-joined cluster compute nodes (either on-premises or in Azure VMs).</span></span> <span data-ttu-id="83d66-230">Azure로 버스트 구성에 추가된 노드는 변수를 무시합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-230">The variable is ignored by nodes added in a burst to Azure configuration.</span></span>
* <span data-ttu-id="83d66-231">MPI 작업은 다른 클라우드 서비스에 배포된 Azure 인스턴스에서 실행할 수 없습니다(예: 다른 노드 템플릿을 사용하는 Azure로 버스트 배포 또는 여러 클라우드 서비스에 배포된 Azure VM 계산 노드).</span><span class="sxs-lookup"><span data-stu-id="83d66-231">MPI jobs can't run across Azure instances that are deployed in different cloud services (for example, in burst to Azure deployments with different node templates, or Azure VM compute nodes deployed in multiple cloud services).</span></span> <span data-ttu-id="83d66-232">다른 노드 템플릿으로 시작된 여러 Azure 노드 배포가 있는 경우 MPI 작업은 하나의 Azure 노드에서만 실행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-232">If you have multiple Azure node deployments that are started with different node templates, the MPI job must run on only one set of Azure nodes.</span></span>
* <span data-ttu-id="83d66-233">클러스터에 Azure 노드를 추가하고 온라인 상태로 전환할 경우 HPC 작업 스케줄러 서비스는 노드에서 즉시 작업을 시작하려고 합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-233">When you add Azure nodes to your cluster and bring them online, the HPC Job Scheduler Service immediately tries to start jobs on the nodes.</span></span> <span data-ttu-id="83d66-234">워크로드 중 일부만 Azure에서 실행할 수 있을 경우 작업 템플릿을 업데이트하거나 만들어 Azure에서 실행 가능한 작업 유형을 정의해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-234">If only a portion of your workload can run on Azure, ensure that you update or create job templates to define what job types can run on Azure.</span></span> <span data-ttu-id="83d66-235">예를 들어 작업 템플릿과 함께 제출된 작업이 Azure 노드에서만 실행되도록 하려면 작업 템플릿에 노드 그룹 속성을 추가하고 필수 값으로 AzureNodes를 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-235">For example, to ensure that jobs submitted with a job template only run on Azure nodes, add the Node Groups property to the job template and select AzureNodes as the required value.</span></span> <span data-ttu-id="83d66-236">Azure 노드에 대해 사용자 지정 그룹을 만들려면 Add-HpcGroup HPC PowerShell cmdlet을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-236">To create custom groups for your Azure nodes, use the Add-HpcGroup HPC PowerShell cmdlet.</span></span>

## <a name="next-steps"></a><span data-ttu-id="83d66-237">다음 단계</span><span class="sxs-lookup"><span data-stu-id="83d66-237">Next steps</span></span>
* <span data-ttu-id="83d66-238">HPC Pack을 사용하는 대신 Azure의 관리되는 계산 노드 풀에서 MPI 응용 프로그램을 실행하기 위해 Azure 배치 서비스를 사용하여 개발합니다.</span><span class="sxs-lookup"><span data-stu-id="83d66-238">As an alternative to using HPC Pack, develop with the Azure Batch service to run MPI applications on managed pools of compute nodes in Azure.</span></span> <span data-ttu-id="83d66-239">[다중 인스턴스 작업을 사용하여 Azure 배치에서 MPI(메시지 전달 인터페이스) 응용 프로그램 실행](../../../batch/batch-mpi.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-239">See [Use multi-instance tasks to run Message Passing Interface (MPI) applications in Azure Batch](../../../batch/batch-mpi.md).</span></span>
* <span data-ttu-id="83d66-240">Azure RDMA 네트워크에 액세스하는 Linux MPI 응용 프로그램을 실행하려는 경우 [MPI 응용 프로그램을 실행하도록 Linux RDMA 클러스터 설정](../../linux/classic/rdma-cluster.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="83d66-240">If you want to run Linux MPI applications that access the Azure RDMA network, see [Set up a Linux RDMA cluster to run MPI applications](../../linux/classic/rdma-cluster.md).</span></span>

<!--Image references-->
[burst]:media/hpcpack-rdma-cluster/burst.png
[iaas]:media/hpcpack-rdma-cluster/iaas.png
[pingpong1]:media/hpcpack-rdma-cluster/pingpong1.png
[pingpong2]:media/hpcpack-rdma-cluster/pingpong2.png
