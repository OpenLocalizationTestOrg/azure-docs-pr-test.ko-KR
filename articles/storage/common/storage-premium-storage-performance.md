---
title: "Azure Premium Storage: 성능을 위한 설계 | Microsoft Docs"
description: "Azure 프리미엄 저장소를 사용하여 고성능 응용 프로그램을 설계합니다. 프리미엄 저장소는 Azure 가상 컴퓨터에서 실행되는 I/O 사용량이 많은 작업에 대해 대기 시간이 짧은 고성능 디스크 지원을 제공합니다."
services: storage
documentationcenter: na
author: aungoo-msft
manager: tadb
editor: tysonn
ms.assetid: e6a409c3-d31a-4704-a93c-0a04fdc95960
ms.service: storage
ms.workload: storage
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 06/27/2017
ms.author: aungoo
ms.openlocfilehash: dde3e60ae4c8387150b65f0715166b5d549891e3
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="azure-premium-storage-design-for-high-performance"></a><span data-ttu-id="a4a03-104">Azure 프리미엄 저장소: 고성능을 위한 설계</span><span class="sxs-lookup"><span data-stu-id="a4a03-104">Azure Premium Storage: Design for High Performance</span></span>
## <a name="overview"></a><span data-ttu-id="a4a03-105">개요</span><span class="sxs-lookup"><span data-stu-id="a4a03-105">Overview</span></span>
<span data-ttu-id="a4a03-106">이 문서는 Azure 프리미엄 저장소를 사용하여 고성능 응용 프로그램을 구축하기 위한 지침을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-106">This article provides guidelines for building high performance applications using Azure Premium Storage.</span></span> <span data-ttu-id="a4a03-107">성능 모범 사례 적용 가능한 tootechnologies 응용 프로그램에서 사용 하는와 함께이 문서에 제공 된 hello 지침을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-107">You can use hello instructions provided in this document combined with performance best practices applicable tootechnologies used by your application.</span></span> <span data-ttu-id="a4a03-108">tooillustrate hello 지침 예를 들어이 문서를 통해 프리미엄 저장소에서 실행 중인 SQL Server 사용 했습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-108">tooillustrate hello guidelines, we have used SQL Server running on Premium Storage as an example throughout this document.</span></span>

<span data-ttu-id="a4a03-109">이 문서의 hello 저장소 계층에 대 한 성능 시나리오를 다루고 있습니다 toooptimize hello 응용 프로그램 계층이 필요 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-109">While we address performance scenarios for hello Storage layer in this article, you will need toooptimize hello application layer.</span></span> <span data-ttu-id="a4a03-110">예를 들어 Azure 프리미엄 저장소에 SharePoint 팜을 호스팅하는 경우에이 문서 toooptimize hello 데이터베이스 서버에서 SQL Server 예제 hello를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-110">For example, if you are hosting a SharePoint Farm on Azure Premium Storage, you can use hello SQL Server examples from this article toooptimize hello database server.</span></span> <span data-ttu-id="a4a03-111">또한 hello SharePoint 팜의 웹 서버 및 응용 프로그램 서버 tooget hello 대부분 성능을 최적화 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-111">Additionally, optimize hello SharePoint Farm's Web server and Application server tooget hello most performance.</span></span>

<span data-ttu-id="a4a03-112">이 문서에서는 Azure 프리미엄 저장소에서 응용 프로그램 성능을 최적화하는 방법에 대한 다음과 같은 일반적인 질문에 대답합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-112">This article will help answer following common questions about optimizing application performance on Azure Premium Storage,</span></span>

* <span data-ttu-id="a4a03-113">어떻게 toomeasure 응용 프로그램 성능을?</span><span class="sxs-lookup"><span data-stu-id="a4a03-113">How toomeasure your application performance?</span></span>  
* <span data-ttu-id="a4a03-114">예상되는 고성능이 표시되지 않는 이유는 무엇입니까?</span><span class="sxs-lookup"><span data-stu-id="a4a03-114">Why are you not seeing expected high performance?</span></span>  
* <span data-ttu-id="a4a03-115">프리미엄 저장소에서 응용 프로그램 성능에 영향을 주는 요인은 무엇입니까?</span><span class="sxs-lookup"><span data-stu-id="a4a03-115">Which factors influence your application performance on Premium Storage?</span></span>  
* <span data-ttu-id="a4a03-116">이러한 요소가 프리미엄 저장소의 응용 프로그램 성능에 주는 영향은 무엇입니까?</span><span class="sxs-lookup"><span data-stu-id="a4a03-116">How do these factors influence performance of your application on Premium Storage?</span></span>  
* <span data-ttu-id="a4a03-117">IOPS, 대역폭 및 대기 시간을 최적화하는 방법은 무엇입니까?</span><span class="sxs-lookup"><span data-stu-id="a4a03-117">How can you optimize for IOPS, Bandwidth and Latency?</span></span>  

<span data-ttu-id="a4a03-118">프리미엄 저장소에서 실행되는 작업은 성능이 매우 중요하므로 특별히 프리미엄 저장소에 대한 지침을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-118">We have provided these guidelines specifically for Premium Storage because workloads running on Premium Storage are highly performance sensitive.</span></span> <span data-ttu-id="a4a03-119">적절한 예제를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-119">We have provided examples where appropriate.</span></span> <span data-ttu-id="a4a03-120">또한 표준 저장소 디스크와 IaaS Vm에서 실행 되는 이러한 지침 tooapplications 중 일부를 적용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-120">You can also apply some of these guidelines tooapplications running on IaaS VMs with Standard Storage disks.</span></span>

<span data-ttu-id="a4a03-121">를 시작 하기 전에 새 tooPremium 저장 하려는 경우, 먼저 hello 읽어 [프리미엄 저장소: Azure 가상 컴퓨터 워크 로드 용 고성능 저장소](../storage-premium-storage.md) 및 [Azure 저장소 확장성 및 성능 목표](storage-scalability-targets.md)문서입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-121">Before you begin, if you are new tooPremium Storage, first read hello [Premium Storage: High-Performance Storage for Azure Virtual Machine Workloads](../storage-premium-storage.md) and [Azure Storage Scalability and Performance Targets](storage-scalability-targets.md) articles.</span></span>

## <a name="application-performance-indicators"></a><span data-ttu-id="a4a03-122">응용 프로그램 성과 지표</span><span class="sxs-lookup"><span data-stu-id="a4a03-122">Application Performance Indicators</span></span>
<span data-ttu-id="a4a03-123">응용 프로그램 성능 지표와 같은 사용 하 여 여부 잘 수행 하는지 여부를 평가, 속도 응용 프로그램이 사용자 요청, 요청에 따라 응용 프로그램에서 처리 하는 데이터의 양을 처리, 특정에서 처리 하는 응용 프로그램 요청 수가 시간, 사용자에 게 toowait tooget 응답의 요청을 제출한 후의 기간입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-123">We assess whether an application is performing well or not using performance indicators like, how fast an application is processing a user request, how much data an application is processing per request, how many requests is an application processing in a specific period of time, how long a user has toowait tooget a response after submitting their request.</span></span> <span data-ttu-id="a4a03-124">이러한 성능 지표에 대 한 hello 기술 용어는, IOPS, 처리량 또는 대역폭 및 대기 시간입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-124">hello technical terms for these performance indicators are, IOPS, Throughput or Bandwidth, and Latency.</span></span>

<span data-ttu-id="a4a03-125">이 섹션에서는 프리미엄 저장소의 hello 컨텍스트에서 hello 일반적인 성능 표시기를 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-125">In this section, we will discuss hello common performance indicators in hello context of Premium Storage.</span></span> <span data-ttu-id="a4a03-126">Hello 섹션 뒤, 응용 프로그램 요구 사항 수집, 배웁니다 어떻게 toomeasure 응용 프로그램에 대 한 이러한 성능 표시기입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-126">In hello following section, Gathering Application Requirements, you will learn how toomeasure these performance indicators for your application.</span></span> <span data-ttu-id="a4a03-127">이러한 성능 지표 및 권장 사항 toooptimize를 영향을 주는 hello 요소에 대해 배웁니다 응용 프로그램 성능 최적화의 뒷부분에 해당 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-127">Later in Optimizing Application Performance, you will learn about hello factors affecting these performance indicators and recommendations toooptimize them.</span></span>

## <a name="iops"></a><span data-ttu-id="a4a03-128">IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-128">IOPS</span></span>
<span data-ttu-id="a4a03-129">IOPS 수는 응용 프로그램을 보내는 지 toohello 저장소 디스크 1 초에 요청 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-129">IOPS is number of requests that your application is sending toohello storage disks in one second.</span></span> <span data-ttu-id="a4a03-130">입력/출력 작업은 읽기나 쓰기, 순차 또는 임의가 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-130">An input/output operation could be read or write, sequential or random.</span></span> <span data-ttu-id="a4a03-131">OLTP 응용 프로그램을 온라인 소매상 웹 사이트와 같은 필요한 tooprocess 많은 동시 사용자가 즉시 요청 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-131">OLTP applications like an online retail website need tooprocess many concurrent user requests immediately.</span></span> <span data-ttu-id="a4a03-132">hello 사용자 요청은 insert 및 hello 응용 프로그램을 신속 하 게 처리 해야 하는 데이터베이스 사용량이 많은 트랜잭션을 업데이트 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-132">hello user requests are insert and update intensive database transactions, which hello application must process quickly.</span></span> <span data-ttu-id="a4a03-133">따라서 OLTP 응용 프로그램에는 매우 높은 IOPS가 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-133">Therefore, OLTP applications require very high IOPS.</span></span> <span data-ttu-id="a4a03-134">이러한 응용 프로그램에서는 수백만 개의 작고 임의의 IO 요청을 처리합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-134">Such applications handle millions of small and random IO requests.</span></span> <span data-ttu-id="a4a03-135">이러한 응용 프로그램의 경우 IOPS에 대 한 hello 응용 프로그램 인프라 toooptimize를 디자인 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-135">If you have such an application, you must design hello application infrastructure toooptimize for IOPS.</span></span> <span data-ttu-id="a4a03-136">Hello에 나중에 섹션 *응용 프로그램 성능 최적화*, tooget 고려해 야 할 모든 hello 요인을 자세하게에서 논의 높은 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-136">In hello later section, *Optimizing Application Performance*, we discuss in detail all hello factors that you must consider tooget high IOPS.</span></span>

<span data-ttu-id="a4a03-137">연결할 때는 프리미엄 저장소 디스크 tooyour 대규모 VM을 하면 hello 디스크 사양에 따라 보장된 IOPS 수에 대 한 Azure 프로 비전 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-137">When you attach a premium storage disk tooyour high scale VM, Azure provisions for you a guaranteed number of IOPS as per hello disk specification.</span></span> <span data-ttu-id="a4a03-138">예를 들어 P50 디스크는 7500IOPS를 프로비전합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-138">For example, a P50 disk provisions 7500 IOPS.</span></span> <span data-ttu-id="a4a03-139">각 높은 확장성의 VM 크기에는 유지할 수 있는 특정 IOPS 제한이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-139">Each high scale VM size also has a specific IOPS limit that it can sustain.</span></span> <span data-ttu-id="a4a03-140">예를 들어 표준 GS5 VM에는 80,000 IOPS 제한이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-140">For example, a Standard GS5 VM has 80,000 IOPS limit.</span></span>

## <a name="throughput"></a><span data-ttu-id="a4a03-141">처리량</span><span class="sxs-lookup"><span data-stu-id="a4a03-141">Throughput</span></span>
<span data-ttu-id="a4a03-142">처리량 또는 대역폭 hello 양의 데이터를 응용 프로그램을 보내는 지 toohello 저장소 디스크에 지정된 된 간격입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-142">Throughput or Bandwidth is hello amount of data that your application is sending toohello storage disks in a specified interval.</span></span> <span data-ttu-id="a4a03-143">응용 프로그램이 대량 IO 단위 크기를 사용하여 입력/출력 작업을 수행하는 경우 높은 처리량이 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-143">If your application is performing input/output operations with large IO unit sizes, it requires high Throughput.</span></span> <span data-ttu-id="a4a03-144">데이터 웨어하우스 응용 프로그램에는 한 번에 많은 양의 데이터를 액세스 하 고 일반적으로 대량 작업을 수행할 tooissue 검사 집약적인 작업은 경향이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-144">Data warehouse applications tend tooissue scan intensive operations that access large portions of data at a time and commonly perform bulk operations.</span></span> <span data-ttu-id="a4a03-145">즉, 이러한 응용 프로그램에는 더 높은 처리량이 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-145">In other words, such applications require higher Throughput.</span></span> <span data-ttu-id="a4a03-146">이러한 응용 프로그램을 사용 하는 경우 처리량에 대 한 해당 인프라 toooptimize를 디자인 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-146">If you have such an application, you must design its infrastructure toooptimize for Throughput.</span></span> <span data-ttu-id="a4a03-147">Hello 다음 섹션에서 자세히 hello 팩터로 논의 tooachieve이 조정 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-147">In hello next section, we discuss in detail hello factors you must tune tooachieve this.</span></span>

<span data-ttu-id="a4a03-148">연결할 때는 프리미엄 저장소 디스크 tooa 대규모 VM을 해당 디스크 사양에 따라 Azure 프로 비전 처리량입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-148">When you attach a premium storage disk tooa high scale VM, Azure provisions Throughput as per that disk specification.</span></span> <span data-ttu-id="a4a03-149">예를 들어 P50 디스크는 초당 250MB 디스크 처리량을 프로비전합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-149">For example, a P50 disk provisions 250 MB per second disk Throughput.</span></span> <span data-ttu-id="a4a03-150">높은 확장성의 VM 크기마다 유지할 수 있는 특정 처리량 제한이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-150">Each high scale VM size also has as specific Throughput limit that it can sustain.</span></span> <span data-ttu-id="a4a03-151">예를 들어 표준 GS5 VM에는 초당 2,000MB의 최대 처리량이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-151">For example, Standard GS5 VM has a maximum throughput of 2,000 MB per second.</span></span> 

<span data-ttu-id="a4a03-152">처리량 및 IOPS hello 수식 아래에 나와 있는 것 처럼 사이의 관계가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-152">There is a relation between Throughput and IOPS as shown in hello formula below.</span></span>

![](media/storage-premium-storage-performance/image1.png)

<span data-ttu-id="a4a03-153">따라서 것이 중요 한 toodetermine hello 최적의 처리량 및 IOPS 응용 프로그램에 필요한 값입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-153">Therefore, it is important toodetermine hello optimal Throughput and IOPS values that your application requires.</span></span> <span data-ttu-id="a4a03-154">Toooptimize 하나를 시도할 때 다른 hello 가져옵니다 영향을 받습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-154">As you try toooptimize one, hello other also gets affected.</span></span> <span data-ttu-id="a4a03-155">이후 섹션 *응용 프로그램 성능 최적화*에서 IOPS 및 처리량 최적화에 대한 자세한 정보에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-155">In a later section, *Optimizing Application Performance*, we will discuss in more details about optimizing IOPS and Throughput.</span></span>

## <a name="latency"></a><span data-ttu-id="a4a03-156">대기 시간</span><span class="sxs-lookup"><span data-stu-id="a4a03-156">Latency</span></span>
<span data-ttu-id="a4a03-157">대기 시간은 hello 시간이 응용 프로그램 tooreceive 단일 요청 하 고 toohello 저장소 디스크를 보낼 hello 응답 toohello 클라이언트 전송 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-157">Latency is hello time it takes an application tooreceive a single request, send it toohello storage disks and send hello response toohello client.</span></span> <span data-ttu-id="a4a03-158">이 중요 한 추가 tooIOPS 및 처리량에 응용 프로그램의 성능 측정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-158">This is a critical measure of an application's performance in addition tooIOPS and Throughput.</span></span> <span data-ttu-id="a4a03-159">프리미엄 저장소 디스크의 대기 시간 hello는 hello 시간 요청에 대 한 tooretrieve hello 정보를 사용 하 고 통신 tooyour 응용 프로그램을 백업 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-159">hello Latency of a premium storage disk is hello time it takes tooretrieve hello information for a request and communicate it back tooyour application.</span></span> <span data-ttu-id="a4a03-160">프리미엄 저장소는 일관된 낮은 대기 시간을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-160">Premium Storage provides consistent low latencies.</span></span> <span data-ttu-id="a4a03-161">프리미엄 저장소 디스크에 읽기 전용 호스트 캐싱을 사용하는 경우 훨씬 더 낮은 읽기 대기 시간을 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-161">If you enable ReadOnly host caching on premium storage disks, you can get much lower read latency.</span></span> <span data-ttu-id="a4a03-162">*응용 프로그램 성능 최적화*의 이후 섹션에서 디스크 캐싱에 대해 자세히 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-162">We will discuss Disk Caching in more detail in later section on *Optimizing Application Performance*.</span></span>

<span data-ttu-id="a4a03-163">응용 프로그램 tooget 최적화할 때 높은 IOPS 및 처리량을 hello 응용 프로그램의 대기 시간에 영향을 줍니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-163">When you are optimizing your application tooget higher IOPS and Throughput, it will affect hello Latency of your application.</span></span> <span data-ttu-id="a4a03-164">Hello 응용 프로그램 성능 튜닝 작업 후 항상 hello hello 응용 프로그램 tooavoid의 대기 시간 평가 대기 시간이 긴 예기치 않은 동작입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-164">After tuning hello application performance, always evaluate hello Latency of hello application tooavoid unexpected high latency behavior.</span></span>

## <a name="gather-application-performance-requirements"></a><span data-ttu-id="a4a03-165">응용 프로그램 성능 요구 사항 수집</span><span class="sxs-lookup"><span data-stu-id="a4a03-165">Gather Application Performance Requirements</span></span>
<span data-ttu-id="a4a03-166">Azure 프리미엄 저장소에서 실행 되는 고성능 응용 프로그램 디자인 hello 첫 번째 단계는 응용 프로그램의 toounderstand hello 성능 요구 사항입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-166">hello first step in designing high performance applications running on Azure Premium Storage is, toounderstand hello performance requirements of your application.</span></span> <span data-ttu-id="a4a03-167">성능 요구 사항을 수집 하 여 응용 프로그램 tooachieve hello 최적의 성능을 최적화할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-167">After you gather performance requirements, you can optimize your application tooachieve hello most optimal performance.</span></span>

<span data-ttu-id="a4a03-168">Hello 이전 섹션에서는 hello 일반적인 성과 지표, IOPS, 처리량 및 대기 시간에 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-168">In hello previous section, we explained hello common performance indicators, IOPS, Throughput and Latency.</span></span> <span data-ttu-id="a4a03-169">이러한 성능 표시기는 중요 한 tooyour 응용 프로그램 toodeliver 원하는 hello 사용자 경험을 식별 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-169">You must identify which of these performance indicators are critical tooyour application toodeliver hello desired user experience.</span></span> <span data-ttu-id="a4a03-170">예를 들어, 높은 IOPS 초당에서 수백만 개의 트랜잭션 처리 하는 대부분 tooOLTP 응용 프로그램을 중요 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-170">For example, high IOPS matters most tooOLTP applications processing millions of transactions in a second.</span></span> <span data-ttu-id="a4a03-171">반면 초당 많은 양의 데이터를 처리하는 데이터 웨어하우스 응용 프로그램에는 높은 처리량이 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-171">Whereas, high Throughput is critical for Data Warehouse applications processing large amounts of data in a second.</span></span> <span data-ttu-id="a4a03-172">라이브 비디오 스트리밍 웹 사이트와 같은 실시간 응용 프로그램에는 매우 짧은 대기 시간이 중요합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-172">Extremely low Latency is crucial for real-time applications like live video streaming websites.</span></span>

<span data-ttu-id="a4a03-173">다음으로 측정 수명 기간 동안 응용 프로그램의 hello 최대 성능을 요구 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-173">Next, measure hello maximum performance requirements of your application throughout its lifetime.</span></span> <span data-ttu-id="a4a03-174">아래 샘플 checklist hello 시작 정보를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-174">Use hello sample checklist below as a start.</span></span> <span data-ttu-id="a4a03-175">보통 동안 레코드 hello 최대 성능 요구 사항, 최고 및 업무 시간 이후 작업 기간입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-175">Record hello maximum performance requirements during normal, peak and off-hours workload periods.</span></span> <span data-ttu-id="a4a03-176">모든 작업 수준에 대 한 요구 사항을 식별 하면 수 toodetermine 됩니다 hello 응용 프로그램의 전체 성능 요구 사항입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-176">By identifying requirements for all workloads levels, you will be able toodetermine hello overall performance requirement of your application.</span></span> <span data-ttu-id="a4a03-177">예를 들어 전자 상거래 웹 사이트의 정상 작업 hello hello 트랜잭션을 대부분 일 년에서 동안 사용 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-177">For example, hello normal workload of an e-commerce website will be hello transactions it serves during most days in a year.</span></span> <span data-ttu-id="a4a03-178">hello 웹 사이트의 최대 작업 hello hello 트랜잭션을 휴일 기간 또는 이벤트 특별 한 판매 하는 동안 사용 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-178">hello peak workload of hello website will be hello transactions it serves during holiday season or special sale events.</span></span> <span data-ttu-id="a4a03-179">hello 최대 작업은 일반적으로 숙련 된 제한 된 기간에 대 한 되지만 사용자 응용 프로그램 tooscale 두 필요할 수 있습니다 또는 일반적인 작업 제한 시간이 더 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-179">hello peak workload is typically experienced for a limited period, but can require your application tooscale two or more times its normal operation.</span></span> <span data-ttu-id="a4a03-180">Hello 50 백분위 수, 90 백분위 수 99 백분위 수 요구 사항에 대해 알아봅니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-180">Find out hello 50 percentile, 90 percentile and 99 percentile requirements.</span></span> <span data-ttu-id="a4a03-181">이렇게 하면 hello 성능 요구 사항에서 이상 값을 필터링 하 고 hello 오른쪽 값에 대 한 최적화에 여 노력을 집중할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-181">This helps filter out any outliers in hello performance requirements and you can focus your efforts on optimizing for hello right values.</span></span>

<span data-ttu-id="a4a03-182">**응용 프로그램 성능 요구 사항 검사 목록**</span><span class="sxs-lookup"><span data-stu-id="a4a03-182">**Application Performance Requirements Checklist**</span></span>

| <span data-ttu-id="a4a03-183">**성능 요구 사항**</span><span class="sxs-lookup"><span data-stu-id="a4a03-183">**Performance requirements**</span></span> | <span data-ttu-id="a4a03-184">**50 백분위수**</span><span class="sxs-lookup"><span data-stu-id="a4a03-184">**50 Percentile**</span></span> | <span data-ttu-id="a4a03-185">**90 백분위수**</span><span class="sxs-lookup"><span data-stu-id="a4a03-185">**90 Percentile**</span></span> | <span data-ttu-id="a4a03-186">**99 백분위수**</span><span class="sxs-lookup"><span data-stu-id="a4a03-186">**99  Percentile**</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="a4a03-187">최대</span><span class="sxs-lookup"><span data-stu-id="a4a03-187">Max.</span></span> <span data-ttu-id="a4a03-188">초당 트랜잭션 수</span><span class="sxs-lookup"><span data-stu-id="a4a03-188">Transactions per second</span></span> | | | |
| <span data-ttu-id="a4a03-189">% 읽기 작업</span><span class="sxs-lookup"><span data-stu-id="a4a03-189">% Read operations</span></span> | | | |
| <span data-ttu-id="a4a03-190">% 쓰기 작업</span><span class="sxs-lookup"><span data-stu-id="a4a03-190">% Write operations</span></span> | | | |
| <span data-ttu-id="a4a03-191">% 임의 작업</span><span class="sxs-lookup"><span data-stu-id="a4a03-191">% Random operations</span></span> | | | |
| <span data-ttu-id="a4a03-192">% 순차적 작업</span><span class="sxs-lookup"><span data-stu-id="a4a03-192">% Sequential operations</span></span> | | | |
| <span data-ttu-id="a4a03-193">IO 요청 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-193">IO request size</span></span> | | | |
| <span data-ttu-id="a4a03-194">평균 처리량</span><span class="sxs-lookup"><span data-stu-id="a4a03-194">Average Throughput</span></span> | | | |
| <span data-ttu-id="a4a03-195">최대</span><span class="sxs-lookup"><span data-stu-id="a4a03-195">Max.</span></span> <span data-ttu-id="a4a03-196">처리량</span><span class="sxs-lookup"><span data-stu-id="a4a03-196">Throughput</span></span> | | | |
| <span data-ttu-id="a4a03-197">최소</span><span class="sxs-lookup"><span data-stu-id="a4a03-197">Min.</span></span> <span data-ttu-id="a4a03-198">대기 시간</span><span class="sxs-lookup"><span data-stu-id="a4a03-198">Latency</span></span> | | | |
| <span data-ttu-id="a4a03-199">평균 대기 시간</span><span class="sxs-lookup"><span data-stu-id="a4a03-199">Average Latency</span></span> | | | |
| <span data-ttu-id="a4a03-200">최대</span><span class="sxs-lookup"><span data-stu-id="a4a03-200">Max.</span></span> <span data-ttu-id="a4a03-201">CPU</span><span class="sxs-lookup"><span data-stu-id="a4a03-201">CPU</span></span> | | | |
| <span data-ttu-id="a4a03-202">평균 CPU</span><span class="sxs-lookup"><span data-stu-id="a4a03-202">Average CPU</span></span> | | | |
| <span data-ttu-id="a4a03-203">최대</span><span class="sxs-lookup"><span data-stu-id="a4a03-203">Max.</span></span> <span data-ttu-id="a4a03-204">메모리</span><span class="sxs-lookup"><span data-stu-id="a4a03-204">Memory</span></span> | | | |
| <span data-ttu-id="a4a03-205">평균 메모리</span><span class="sxs-lookup"><span data-stu-id="a4a03-205">Average Memory</span></span> | | | |
| <span data-ttu-id="a4a03-206">큐 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-206">Queue Depth</span></span> | | | |

> [!NOTE]
> <span data-ttu-id="a4a03-207">응용 프로그램의 예상된 향후 성장에 따라 이러한 숫자를 확장하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-207">You should consider scaling these numbers based on expected future growth of your application.</span></span> <span data-ttu-id="a4a03-208">나중에 성능 향상을 위한 toochange hello 인프라 쉽다는 점 수도 있으므로 미리 증가 위한 것이 좋습니다 tooplan입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-208">It is a good idea tooplan for growth ahead of time, because it could be harder toochange hello infrastructure for improving performance later.</span></span>
>
>

<span data-ttu-id="a4a03-209">기존 응용 프로그램을 한 toomove tooPremium 저장소를 원하는 경우 먼저 구축 hello 기존 응용 프로그램에 대 한 위의 hello 검사 목록입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-209">If you have an existing application and want toomove tooPremium Storage, first build hello checklist above for hello existing application.</span></span> <span data-ttu-id="a4a03-210">그런 다음에 설명 된 지침에 따라 프리미엄 저장소 및 디자인 hello 응용 프로그램에서 응용 프로그램의 프로토타입을 빌드 *응용 프로그램 성능 최적화* 이 문서의 뒷부분에 나오는 섹션에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-210">Then, build a prototype of your application on Premium Storage and design hello application based on guidelines described in *Optimizing Application Performance* in a later section of this document.</span></span> <span data-ttu-id="a4a03-211">다음 섹션 hello toogather hello 성능 측정값을 사용할 수 있습니다 하는 hello 도구를 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-211">hello next section describes hello tools you can use toogather hello performance measurements.</span></span>

<span data-ttu-id="a4a03-212">검사 목록 유사한 tooyour 기존 응용 프로그램 hello 프로토타입에 대 한를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-212">Create a checklist similar tooyour existing application for hello prototype.</span></span> <span data-ttu-id="a4a03-213">Benchmarking 도구를 사용 하 여 hello 작업 부하를 시뮬레이트할 수 있으며 hello 프로토타입 응용 프로그램의 성능을 측정할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-213">Using Benchmarking tools you can simulate hello workloads and measure performance on hello prototype application.</span></span> <span data-ttu-id="a4a03-214">Hello 섹션을 참조 하십시오 [Benchmarking](#benchmarking) toolearn 더 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-214">See hello section on [Benchmarking](#benchmarking) toolearn more.</span></span> <span data-ttu-id="a4a03-215">이렇게 하여 프리미엄 저장소가 응용 프로그램 성능 요구 사항에 일치하거나 능가할 수 있는지 여부를 결정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-215">By doing so you can determine whether Premium Storage can match or surpass your application performance requirements.</span></span> <span data-ttu-id="a4a03-216">구현할 수 있습니다 다음 프로덕션 응용 프로그램에 대 한 동일한 지침 hello 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-216">Then you can implement hello same guidelines for your production application.</span></span>

### <a name="counters-toomeasure-application-performance-requirements"></a><span data-ttu-id="a4a03-217">카운터 toomeasure 응용 프로그램에 대 한 성능 요구 사항</span><span class="sxs-lookup"><span data-stu-id="a4a03-217">Counters toomeasure application performance requirements</span></span>
<span data-ttu-id="a4a03-218">응용 프로그램의 가장 좋은 방법은 toomeasure 성능 요구 hello, toouse 성능 모니터링 도구 hello 서버 hello 운영 체제에서 제공 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-218">hello best way toomeasure performance requirements of your application, is toouse performance-monitoring tools provided by hello operating system of hello server.</span></span> <span data-ttu-id="a4a03-219">Windows용 PerfMon 및 Linux용 iostat를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-219">You can use PerfMon for Windows and iostat for Linux.</span></span> <span data-ttu-id="a4a03-220">이러한 도구는 해당 tooeach 측정값 hello 위의 섹션에서에서 설명 하는 카운터를 캡처합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-220">These tools capture counters corresponding tooeach measure explained in hello above section.</span></span> <span data-ttu-id="a4a03-221">보통, 최고 및 업무 시간 이후 작업 부하의 응용 프로그램을 실행 하는 경우 이러한 카운터의 값 hello를 캡처해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-221">You must capture hello values of these counters when your application is running its normal, peak and off-hours workloads.</span></span>

<span data-ttu-id="a4a03-222">hello PerfMon 카운터는 프로세서, 메모리, 각 논리 디스크 및 서버의 실제 디스크에 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-222">hello PerfMon counters are available for processor, memory and, each logical disk and physical disk of your server.</span></span> <span data-ttu-id="a4a03-223">프리미엄 저장소 디스크는 VM으로 사용 하 여 각 프리미엄 저장소 디스크에 대 한 hello 물리적 디스크 카운터 되며 hello 프리미엄 저장소 디스크에 만들어진 각 볼륨에 대 한 논리 디스크 카운터는.</span><span class="sxs-lookup"><span data-stu-id="a4a03-223">When you use premium storage disks with a VM, hello physical disk counters are for each premium storage disk, and logical disk counters are for each volume created on hello premium storage disks.</span></span> <span data-ttu-id="a4a03-224">응용 프로그램 워크 로드를 호스트 하는 hello 디스크에 대 한 hello 값을 캡처해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-224">You must capture hello values for hello disks that host your application workload.</span></span> <span data-ttu-id="a4a03-225">논리적 및 물리적 디스크 간에 하나의 tooone 매핑을 이면 toophysical 디스크 카운터; 참조할 수 있습니다. 그렇지 않으면 toohello logical disk 카운터를 참조 하십시오.</span><span class="sxs-lookup"><span data-stu-id="a4a03-225">If there is a one tooone mapping between logical and physical disks, you can refer toophysical disk counters; otherwise refer toohello logical disk counters.</span></span> <span data-ttu-id="a4a03-226">Linux에서 hello iostat 명령은 CPU 및 디스크 사용률 보고서를 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-226">On Linux, hello iostat command generates a CPU and disk utilization report.</span></span> <span data-ttu-id="a4a03-227">hello 디스크 사용률 보고서는 물리적 장치 또는 파티션 통계를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-227">hello disk utilization report provides statistics per physical device or partition.</span></span> <span data-ttu-id="a4a03-228">별도 디스크에 해당 데이터와 로그가 있는 데이터베이스 서버가 있는 경우 두 디스크에 대한 이 데이터를 수집합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-228">If you have a database server with its data and log on separate disks, collect this data for both disks.</span></span> <span data-ttu-id="a4a03-229">아래 표에서 디스크, 프로세서 및 메모리에 대한 카운터를 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-229">Below table describes counters for disks, processor and memory:</span></span>

| <span data-ttu-id="a4a03-230">카운터</span><span class="sxs-lookup"><span data-stu-id="a4a03-230">Counter</span></span> | <span data-ttu-id="a4a03-231">설명</span><span class="sxs-lookup"><span data-stu-id="a4a03-231">Description</span></span> | <span data-ttu-id="a4a03-232">PerfMon</span><span class="sxs-lookup"><span data-stu-id="a4a03-232">PerfMon</span></span> | <span data-ttu-id="a4a03-233">Iostat</span><span class="sxs-lookup"><span data-stu-id="a4a03-233">Iostat</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="a4a03-234">**초당 IOPS 또는 트랜잭션**</span><span class="sxs-lookup"><span data-stu-id="a4a03-234">**IOPS or Transactions per second**</span></span> |<span data-ttu-id="a4a03-235">I/O 요청의 수 초당 toohello 저장소 디스크를 발급합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-235">Number of I/O requests issued toohello storage disk per second.</span></span> |<span data-ttu-id="a4a03-236">디스크 읽기/초 </span><span class="sxs-lookup"><span data-stu-id="a4a03-236">Disk Reads/sec</span></span> <br> <span data-ttu-id="a4a03-237">디스크 쓰기/초</span><span class="sxs-lookup"><span data-stu-id="a4a03-237">Disk Writes/sec</span></span> |<span data-ttu-id="a4a03-238">tps </span><span class="sxs-lookup"><span data-stu-id="a4a03-238">tps</span></span> <br> <span data-ttu-id="a4a03-239">r/s </span><span class="sxs-lookup"><span data-stu-id="a4a03-239">r/s</span></span> <br> <span data-ttu-id="a4a03-240">w/s</span><span class="sxs-lookup"><span data-stu-id="a4a03-240">w/s</span></span> |
| <span data-ttu-id="a4a03-241">**디스크 읽기 및 쓰기**</span><span class="sxs-lookup"><span data-stu-id="a4a03-241">**Disk Reads and Writes**</span></span> |<span data-ttu-id="a4a03-242">% 읽기 및 쓰기 작업 hello 디스크에 수행 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-242">% of Reads and Write operations performed on hello disk.</span></span> |<span data-ttu-id="a4a03-243">% 디스크 읽기 시간 </span><span class="sxs-lookup"><span data-stu-id="a4a03-243">% Disk Read Time</span></span> <br> <span data-ttu-id="a4a03-244">% 디스크 쓰기 시간</span><span class="sxs-lookup"><span data-stu-id="a4a03-244">% Disk Write Time</span></span> |<span data-ttu-id="a4a03-245">r/s </span><span class="sxs-lookup"><span data-stu-id="a4a03-245">r/s</span></span> <br> <span data-ttu-id="a4a03-246">w/s</span><span class="sxs-lookup"><span data-stu-id="a4a03-246">w/s</span></span> |
| <span data-ttu-id="a4a03-247">**처리량**</span><span class="sxs-lookup"><span data-stu-id="a4a03-247">**Throughput**</span></span> |<span data-ttu-id="a4a03-248">읽거나 toohello 최대 초당 디스크에 쓴 데이터 양입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-248">Amount of data read from or written toohello disk per second.</span></span> |<span data-ttu-id="a4a03-249">디스크 읽기 바이트/초 </span><span class="sxs-lookup"><span data-stu-id="a4a03-249">Disk Read Bytes/sec</span></span> <br> <span data-ttu-id="a4a03-250">디스크 쓰기 바이트/초</span><span class="sxs-lookup"><span data-stu-id="a4a03-250">Disk Write Bytes/sec</span></span> |<span data-ttu-id="a4a03-251">kB_read/s</span><span class="sxs-lookup"><span data-stu-id="a4a03-251">kB_read/s</span></span> <br> <span data-ttu-id="a4a03-252">kB_wrtn/s</span><span class="sxs-lookup"><span data-stu-id="a4a03-252">kB_wrtn/s</span></span> |
| <span data-ttu-id="a4a03-253">**대기 시간**</span><span class="sxs-lookup"><span data-stu-id="a4a03-253">**Latency**</span></span> |<span data-ttu-id="a4a03-254">총 시간 toocomplete 디스크 IO 요청 수입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-254">Total time toocomplete a disk IO request.</span></span> |<span data-ttu-id="a4a03-255">평균 디스크 초/읽기 </span><span class="sxs-lookup"><span data-stu-id="a4a03-255">Average Disk sec/Read</span></span> <br> <span data-ttu-id="a4a03-256">평균 디스크 초/쓰기</span><span class="sxs-lookup"><span data-stu-id="a4a03-256">Average disk sec/Write</span></span> |<span data-ttu-id="a4a03-257">await </span><span class="sxs-lookup"><span data-stu-id="a4a03-257">await</span></span> <br> <span data-ttu-id="a4a03-258">svctm</span><span class="sxs-lookup"><span data-stu-id="a4a03-258">svctm</span></span> |
| <span data-ttu-id="a4a03-259">**IO 크기**</span><span class="sxs-lookup"><span data-stu-id="a4a03-259">**IO size**</span></span> |<span data-ttu-id="a4a03-260">입/출력 요청 hello 크기 toohello 저장소 디스크를 발급합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-260">hello size of I/O requests issues toohello storage disks.</span></span> |<span data-ttu-id="a4a03-261">평균 디스크 바이트/읽기 </span><span class="sxs-lookup"><span data-stu-id="a4a03-261">Average Disk Bytes/Read</span></span> <br> <span data-ttu-id="a4a03-262">평균 디스크 바이트/쓰기</span><span class="sxs-lookup"><span data-stu-id="a4a03-262">Average Disk Bytes/Write</span></span> |<span data-ttu-id="a4a03-263">avgrq-sz</span><span class="sxs-lookup"><span data-stu-id="a4a03-263">avgrq-sz</span></span> |
| <span data-ttu-id="a4a03-264">**큐 크기**</span><span class="sxs-lookup"><span data-stu-id="a4a03-264">**Queue Depth**</span></span> |<span data-ttu-id="a4a03-265">대기 중인 toobe 폼에 읽거나 쓸 toohello 저장소 디스크를 요청 하는 미해결 I/O 수입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-265">Number of outstanding I/O requests waiting toobe read form or written toohello storage disk.</span></span> |<span data-ttu-id="a4a03-266">현재 디스크 큐 길이</span><span class="sxs-lookup"><span data-stu-id="a4a03-266">Current Disk Queue Length</span></span> |<span data-ttu-id="a4a03-267">avgqu-sz</span><span class="sxs-lookup"><span data-stu-id="a4a03-267">avgqu-sz</span></span> |
| <span data-ttu-id="a4a03-268">**최대 메모리**</span><span class="sxs-lookup"><span data-stu-id="a4a03-268">**Max. Memory**</span></span> |<span data-ttu-id="a4a03-269">원활 하 게 필요한 toorun 응용 프로그램 메모리의 양</span><span class="sxs-lookup"><span data-stu-id="a4a03-269">Amount of memory required toorun application smoothly</span></span> |<span data-ttu-id="a4a03-270">% 사용 중인 커밋된 바이트</span><span class="sxs-lookup"><span data-stu-id="a4a03-270">% Committed Bytes in Use</span></span> |<span data-ttu-id="a4a03-271">vmstat 사용</span><span class="sxs-lookup"><span data-stu-id="a4a03-271">Use vmstat</span></span> |
| <span data-ttu-id="a4a03-272">**최대 CPU**</span><span class="sxs-lookup"><span data-stu-id="a4a03-272">**Max. CPU**</span></span> |<span data-ttu-id="a4a03-273">필요한 toorun 응용 프로그램이 원활 하 게 CPU 양</span><span class="sxs-lookup"><span data-stu-id="a4a03-273">Amount CPU required toorun application smoothly</span></span> |<span data-ttu-id="a4a03-274">% 프로세서 시간</span><span class="sxs-lookup"><span data-stu-id="a4a03-274">% Processor time</span></span> |<span data-ttu-id="a4a03-275">%util</span><span class="sxs-lookup"><span data-stu-id="a4a03-275">%util</span></span> |

<span data-ttu-id="a4a03-276">[iostat](http://linuxcommand.org/man_pages/iostat1.html) 및 [PerfMon](https://msdn.microsoft.com/library/aa645516.aspx)에 대해 자세히 알아봅니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-276">Learn more about [iostat](http://linuxcommand.org/man_pages/iostat1.html) and [PerfMon](https://msdn.microsoft.com/library/aa645516.aspx).</span></span>

## <a name="optimizing-application-performance"></a><span data-ttu-id="a4a03-277">응용 프로그램 성능 최적화</span><span class="sxs-lookup"><span data-stu-id="a4a03-277">Optimizing Application Performance</span></span>
<span data-ttu-id="a4a03-278">프리미엄 저장소에서 실행 중인 응용 프로그램의 성능에 영향을 주는 hello 주요 요소는 특성의 IO 요청이, VM 크기, 디스크 크기, 디스크, 디스크 캐싱, 다중 스레딩 및 큐 깊이 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-278">hello main factors that influence performance of an application running on Premium Storage are Nature of IO Requests, VM size, Disk size, Number of disks, Disk Caching, Multithreading and Queue Depth.</span></span> <span data-ttu-id="a4a03-279">노브 hello 시스템에서 제공 된 일부의이 요소를 제어할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-279">You can control some of these factors with knobs provided by hello system.</span></span> <span data-ttu-id="a4a03-280">대부분의 응용 프로그램 올바르게 있습니다 옵션 tooalter hello IO 크기와 큐 깊이 직접 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-280">Most applications may not give you an option tooalter hello IO size and Queue Depth directly.</span></span> <span data-ttu-id="a4a03-281">예를 들어 SQL Server를 사용 하는 경우 hello IO 크기와 큐 깊이 선택할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-281">For example, if you are using SQL Server, you cannot choose hello IO size and queue depth.</span></span> <span data-ttu-id="a4a03-282">SQL Server는 대부분의 성능 hello 최적의 IO 크기와 큐 깊이 값 tooget hello를 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-282">SQL Server chooses hello optimal IO size and queue depth values tooget hello most performance.</span></span> <span data-ttu-id="a4a03-283">적절 한 리소스가 toomeet 성능 요구를 프로 비전 할 수 있도록 것이 중요 한 toounderstand hello에 미치는 영향 요인 두 가지 유형의 응용 프로그램 성능 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-283">It is important toounderstand hello effects of both types of factors on your application performance, so that you can provision appropriate resources toomeet performance needs.</span></span>

<span data-ttu-id="a4a03-284">이 단원 전반의 toohello 응용 프로그램 요구 사항 검사 목록 만든 tooidentify 참조 toooptimize를 필요한 얼마나 응용 프로그램 성능을 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-284">Throughout this section, refer toohello application requirements checklist that you created, tooidentify how much you need toooptimize your application performance.</span></span> <span data-ttu-id="a4a03-285">에 따라 수 toodetermine 됩니다, tootune가 필요 합니다를 놓은이 섹션에서 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-285">Based on that, you will be able toodetermine which factors from this section you will need tootune.</span></span> <span data-ttu-id="a4a03-286">toowitness hello 각 요인의 성능에 미치는 영향 프로그램 응용 프로그램을 실행 응용 프로그램 설치에 대 한 도구, 즉 벤치마킹 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-286">toowitness hello effects of each factor on your application performance, run benchmarking tools on your application setup.</span></span> <span data-ttu-id="a4a03-287">Toohello 참조 [Benchmarking](#Benchmarking) hello Windows 및 Linux Vm에 도구, 즉 벤치마킹 일반적인 단계 toorun에 대 한이 문서의 뒷부분에 나오는 섹션.</span><span class="sxs-lookup"><span data-stu-id="a4a03-287">Refer toohello [Benchmarking](#Benchmarking) section at hello end of this article for steps toorun common benchmarking tools on Windows and Linux VMs.</span></span>

### <a name="optimizing-iops-throughput-and-latency-at-a-glance"></a><span data-ttu-id="a4a03-288">한 눈에 IOPS, 처리량 및 대기 시간 최적화</span><span class="sxs-lookup"><span data-stu-id="a4a03-288">Optimizing IOPS, Throughput and Latency at a glance</span></span>
<span data-ttu-id="a4a03-289">모든 성능 요소 hello 및 hello 단계 toooptimize IOPS, 처리량 및 대기 시간 hello 테이블 아래에 요약 되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-289">hello table below summarizes all hello performance factors and hello steps toooptimize IOPS, Throughput and Latency.</span></span> <span data-ttu-id="a4a03-290">hello이 요약 다음 섹션에서는 설명 각 요소에는 훨씬 더 깊이입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-290">hello sections following this summary will describe each factor is much more depth.</span></span>

| &nbsp; | <span data-ttu-id="a4a03-291">**IOPS**</span><span class="sxs-lookup"><span data-stu-id="a4a03-291">**IOPS**</span></span> | <span data-ttu-id="a4a03-292">**처리량**</span><span class="sxs-lookup"><span data-stu-id="a4a03-292">**Throughput**</span></span> | <span data-ttu-id="a4a03-293">**대기 시간**</span><span class="sxs-lookup"><span data-stu-id="a4a03-293">**Latency**</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="a4a03-294">**예제 시나리오**</span><span class="sxs-lookup"><span data-stu-id="a4a03-294">**Example Scenario**</span></span> |<span data-ttu-id="a4a03-295">초당 비율로 매우 높은 트랜잭션이 필요한 엔터프라이즈 OLTP 응용 프로그램입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-295">Enterprise OLTP application requiring very high transactions per second rate.</span></span> |<span data-ttu-id="a4a03-296">다량의 데이터를 처리하는 엔터프라이즈 데이터 웨어하우징 응용 프로그램입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-296">Enterprise Data warehousing application processing large amounts of data.</span></span> |<span data-ttu-id="a4a03-297">거의 실시간 응용 프로그램을 온라인 게임 등 인스턴트 응답 toouser 요청을 요구 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-297">Near real-time applications requiring instant responses toouser requests, like online gaming.</span></span> |
| <span data-ttu-id="a4a03-298">성능 요인</span><span class="sxs-lookup"><span data-stu-id="a4a03-298">Performance factors</span></span> | &nbsp; | &nbsp; | &nbsp; |
| <span data-ttu-id="a4a03-299">**IO 크기**</span><span class="sxs-lookup"><span data-stu-id="a4a03-299">**IO size**</span></span> |<span data-ttu-id="a4a03-300">작은 크기의 IO는 더 높은 IOPS를 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-300">Smaller IO size yields higher IOPS.</span></span> |<span data-ttu-id="a4a03-301">더 큰 IO 크기 tooyields 처리량을 더 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-301">Larger IO size tooyields higher Throughput.</span></span> | &nbsp;|
| <span data-ttu-id="a4a03-302">**VM 크기**</span><span class="sxs-lookup"><span data-stu-id="a4a03-302">**VM size**</span></span> |<span data-ttu-id="a4a03-303">응용 프로그램 요구 사항보다 큰 IOPS를 제공하는 VM 크기를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-303">Use a VM size that offers IOPS greater than your application requirement.</span></span> <span data-ttu-id="a4a03-304">VM 크기 및 IOPS 한계는 여기를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="a4a03-304">See VM sizes and their IOPS limits here.</span></span> |<span data-ttu-id="a4a03-305">응용 프로그램 요구 사항보다 큰 처리량 한계가 있는 VM 크기를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-305">Use a VM size with Throughput limit greater than your application requirement.</span></span> <span data-ttu-id="a4a03-306">VM 크기 및 처리량 한계는 여기를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="a4a03-306">See VM sizes and their Throughput limits here.</span></span> |<span data-ttu-id="a4a03-307">응용 프로그램 요구 사항보다 큰 규모 제한을 제공하는 VM 크기를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-307">Use a VM size that offers scale limits greater than your application requirement.</span></span> <span data-ttu-id="a4a03-308">VM 크기 및 한계는 여기를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="a4a03-308">See VM sizes and their limits here.</span></span> |
| <span data-ttu-id="a4a03-309">**디스크 크기**</span><span class="sxs-lookup"><span data-stu-id="a4a03-309">**Disk size**</span></span> |<span data-ttu-id="a4a03-310">응용 프로그램 요구 사항보다 큰 IOPS를 제공하는 디스크 크기를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-310">Use a disk size that offers IOPS greater than your application requirement.</span></span> <span data-ttu-id="a4a03-311">디스크 크기 및 IOPS 한계는 여기를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="a4a03-311">See disk sizes and their IOPS limits here.</span></span> |<span data-ttu-id="a4a03-312">응용 프로그램 요구 사항보다 큰 처리량 한계가 있는 디스크 크기를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-312">Use a disk size with Throughput limit greater than your application requirement.</span></span> <span data-ttu-id="a4a03-313">디스크 크기 및 처리량 한계는 여기를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="a4a03-313">See disk sizes and their Throughput limits here.</span></span> |<span data-ttu-id="a4a03-314">응용 프로그램 요구 사항보다 큰 규모 제한을 제공하는 디스크 크기를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-314">Use a disk size that offers scale limits greater than your application requirement.</span></span> <span data-ttu-id="a4a03-315">디스크 크기 및 한계는 여기를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="a4a03-315">See disk sizes and their limits here.</span></span> |
| <span data-ttu-id="a4a03-316">**VM 및 디스크 규모 제한**</span><span class="sxs-lookup"><span data-stu-id="a4a03-316">**VM and Disk Scale Limits**</span></span> |<span data-ttu-id="a4a03-317">IOPS 제한은 hello VM 크기 선택의 프리미엄 저장소 디스크에 의해 발생 하는 총 IOPS tooit 연결 보다 커야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-317">IOPS limit of hello VM size chosen should be greater than total IOPS driven by premium storage disks attached tooit.</span></span> |<span data-ttu-id="a4a03-318">hello VM 크기가 선택한 처리량 한도 프리미엄 저장소 디스크에 의해 발생 하는 총 처리량 tooit 연결 된 이후 여야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-318">Throughput limit of hello VM size chosen should be greater than total Throughput driven by premium storage disks attached tooit.</span></span> |<span data-ttu-id="a4a03-319">Hello VM 크기 선택의 규모 제한을 연결 된 프리미엄 저장소 디스크의 총 배율 제한 값 보다 커야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-319">Scale limits of hello VM size chosen must be greater than total scale limits of attached premium storage disks.</span></span> |
| <span data-ttu-id="a4a03-320">**디스크 캐싱**</span><span class="sxs-lookup"><span data-stu-id="a4a03-320">**Disk Caching**</span></span> |<span data-ttu-id="a4a03-321">읽기 리소스 사용량이 많은 작업 tooget 있는 프리미엄 저장소 디스크에서 읽기 전용 캐시를 사용 합니다. 더 높은 읽기 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-321">Enable ReadOnly Cache on premium storage disks with Read heavy operations tooget higher Read IOPS.</span></span> | &nbsp; |<span data-ttu-id="a4a03-322">준비 리소스 사용량이 많은 작업 tooget 매우 낮은 읽기 대기 시간이 프리미엄 저장소 디스크에서 읽기 전용 캐시를 사용 하도록 설정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-322">Enable ReadOnly Cache on premium storage disks with Ready heavy operations tooget very low Read latencies.</span></span> |
| <span data-ttu-id="a4a03-323">**디스크 스트라이프**</span><span class="sxs-lookup"><span data-stu-id="a4a03-323">**Disk Striping**</span></span> |<span data-ttu-id="a4a03-324">여러 디스크를 사용 하 고 함께 tooget 결합 된 더 높은 IOPS 및 처리량 한도 스트라이프 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-324">Use multiple disks and stripe them together tooget a combined higher IOPS and Throughput limit.</span></span> <span data-ttu-id="a4a03-325">VM 당 결합 된 제한 hello는 hello 연결 된 프리미엄 디스크의 결합 된 한계 보다 높아야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-325">Note that hello combined limit per VM should be higher than hello combined limits of attached premium disks.</span></span> | &nbsp; | &nbsp; |
| <span data-ttu-id="a4a03-326">**스트라이프 크기**</span><span class="sxs-lookup"><span data-stu-id="a4a03-326">**Stripe Size**</span></span> |<span data-ttu-id="a4a03-327">OLTP 응용 프로그램에 표시된 작은 임의 IO 패턴에 대한 더 작은 스트라이프 크기입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-327">Smaller stripe size for random small IO pattern seen in OLTP applications.</span></span> <span data-ttu-id="a4a03-328">예: SQL Server OLTP 응용 프로그램에 대해 64KB의 스트라이프 크기를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-328">E.g., use stripe size of 64KB for SQL Server OLTP application.</span></span> |<span data-ttu-id="a4a03-329">데이터 웨어하우스에 응용 프로그램에 표시된 대형 순차 IO 패턴에 대한 더 큰 스트라이프 크기입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-329">Larger stripe size for sequential large IO pattern seen in Data Warehouse applications.</span></span> <span data-ttu-id="a4a03-330">예: SQL Server 데이터 웨어하우스 응용 프로그램에 대해 256KB의 스트라이프 크기를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-330">E.g., use 256KB stripe size for SQL Server Data warehouse application.</span></span> | &nbsp; |
| <span data-ttu-id="a4a03-331">**멀티 스레드**</span><span class="sxs-lookup"><span data-stu-id="a4a03-331">**Multithreading**</span></span> |<span data-ttu-id="a4a03-332">다중 스레딩 toopush 수가 높을수록 요청 tooPremium toohigher IOPS 밝혀 저장소 및 처리량을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-332">Use multithreading toopush higher number of requests tooPremium Storage that will lead toohigher IOPS and Throughput.</span></span> <span data-ttu-id="a4a03-333">예를 들어 SQL Server에 설정 높은 MAXDOP 값 tooallocate 더 많은 Cpu tooSQL 서버.</span><span class="sxs-lookup"><span data-stu-id="a4a03-333">For example, on SQL Server set a high MAXDOP value tooallocate more CPUs tooSQL Server.</span></span> | &nbsp; | &nbsp; |
| <span data-ttu-id="a4a03-334">**큐 크기**</span><span class="sxs-lookup"><span data-stu-id="a4a03-334">**Queue Depth**</span></span> |<span data-ttu-id="a4a03-335">더 큰 큐 크기는 더 높은 IOPS를 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-335">Larger Queue Depth yields higher IOPS.</span></span> |<span data-ttu-id="a4a03-336">더 큰 큐 크기는 더 높은 처리량을 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-336">Larger Queue Depth yields higher Throughput.</span></span> |<span data-ttu-id="a4a03-337">더 작은 큐 크기는 더 짧은 대기 시간을 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-337">Smaller Queue Depth yields lower latencies.</span></span> |

## <a name="nature-of-io-requests"></a><span data-ttu-id="a4a03-338">IO 요청의 특성</span><span class="sxs-lookup"><span data-stu-id="a4a03-338">Nature of IO Requests</span></span>
<span data-ttu-id="a4a03-339">IO 요청은 응용 프로그램에서 수행하는 입력/출력 작업의 단위입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-339">An IO request is a unit of input/output operation that your application will be performing.</span></span> <span data-ttu-id="a4a03-340">난수 또는 순차적, I/O 요청이의 hello 특성을 식별을 읽거나 쓰기 파일 그룹, 소형 또는 대형, 응용 프로그램의 hello 성능 요구 사항을 결정 하는 데 도움이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-340">Identifying hello nature of IO requests, random or sequential, read or write, small or large, will help you determine hello performance requirements of your application.</span></span> <span data-ttu-id="a4a03-341">것은 매우 중요 한 toounderstand hello 특성 toomake hello 올바른 결정 응용 프로그램 인프라를 디자인할 때 IO 요청의 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-341">It is very important toounderstand hello nature of IO requests, toomake hello right decisions when designing your application infrastructure.</span></span>

<span data-ttu-id="a4a03-342">IO 크기가 더 중요 한 요인 hello 중 하나입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-342">IO size is one of hello more important factors.</span></span> <span data-ttu-id="a4a03-343">hello IO 크기는 응용 프로그램에 의해 생성 된 hello 입/출력 작업 요청의 hello 크기입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-343">hello IO size is hello size of hello input/output operation request generated by your application.</span></span> <span data-ttu-id="a4a03-344">hello IO 크기 hello IOPS에 특히는 성능에 상당한 영향 되며 응용 프로그램 hello 대역폭 tooachieve 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-344">hello IO size has a significant impact on performance especially on hello IOPS and Bandwidth that hello application is able tooachieve.</span></span> <span data-ttu-id="a4a03-345">hello 수식인 관계를 보여 줍니다 hello IOPS, IO 크기와 대역폭/처리량입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-345">hello following formula shows hello relationship between IOPS, IO size and Bandwidth/Throughput.</span></span>  
    ![](media/storage-premium-storage-performance/image1.png)

<span data-ttu-id="a4a03-346">일부 응용 프로그램을 사용 하면 일부 응용 프로그램 하지 않는 동안 자신의 IO 크기 tooalter 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-346">Some applications allow you tooalter their IO size, while some applications do not.</span></span> <span data-ttu-id="a4a03-347">SQL Server 자체 hello 최적의 IO 크기를 결정 하 고 모든 노브 toochange와 사용자가 제공 하지 않습니다 예를 들어 것입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-347">For example, SQL Server determines hello optimal IO size itself, and does not provide users with any knobs toochange it.</span></span> <span data-ttu-id="a4a03-348">다른 손 hello, 호출 매개 변수를 제공 하는 Oracle [DB\_차단\_크기](https://docs.oracle.com/cd/B19306_01/server.102/b14211/iodesign.htm#i28815) hello 데이터베이스의 I/O 요청 크기 hello 구성할 수 있는 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-348">On hello other hand, Oracle provides a parameter called [DB\_BLOCK\_SIZE](https://docs.oracle.com/cd/B19306_01/server.102/b14211/iodesign.htm#i28815) using which you can configure hello I/O request size of hello database.</span></span>

<span data-ttu-id="a4a03-349">응용 프로그램 있습니다 toochange hello IO 크기를 허용 하지 않는 사용 하는 경우이 문서 toooptimize hello 성능이 가장 관련성이 높은 tooyour 응용 프로그램이 KPI hello 지침을 따르세요.</span><span class="sxs-lookup"><span data-stu-id="a4a03-349">If you are using an application, which does not allow you toochange hello IO size, use hello guidelines in this article toooptimize hello performance KPI that is most relevant tooyour application.</span></span> <span data-ttu-id="a4a03-350">예를 들면 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-350">For example,</span></span>

* <span data-ttu-id="a4a03-351">OLTP 응용 프로그램에서는 수백만 개의 작고 임의적인 IO 요청을 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-351">An OLTP application generates millions of small and random IO requests.</span></span> <span data-ttu-id="a4a03-352">응용 프로그램 인프라 tooget 디자인 해야 이러한 IO 유형의 toohandle 요청, 높은 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-352">toohandle these type of IO requests, you must design your application infrastructure tooget higher IOPS.</span></span>  
* <span data-ttu-id="a4a03-353">데이터 웨어하우징 응용 프로그램은 크고 순차적인 IO 요청을 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-353">A data warehousing application generates large and sequential IO requests.</span></span> <span data-ttu-id="a4a03-354">IO 요청의 입력 이러한 toohandle, 응용 프로그램 인프라 tooget 더 높은 대역폭이 또는 처리량을 디자인 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-354">toohandle these type of IO requests, you must design your application infrastructure tooget higher Bandwidth or Throughput.</span></span>

<span data-ttu-id="a4a03-355">Toochange hello IO 크기를 허용 하는 응용 프로그램을 사용 하는 경우 hello IO 크기 또한 tooother 성능 지침에 대 한 가장이 사용</span><span class="sxs-lookup"><span data-stu-id="a4a03-355">If you are using an application, which allows you toochange hello IO size, use this rule of thumb for hello IO size in addition tooother performance guidelines,</span></span>

* <span data-ttu-id="a4a03-356">작은 IO 크기 tooget 더 높은 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-356">Smaller IO size tooget higher IOPS.</span></span> <span data-ttu-id="a4a03-357">예를 들어 OLTP 응용 프로그램의 경우 8KB입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-357">For example, 8 KB for an OLTP application.</span></span>  
* <span data-ttu-id="a4a03-358">더 큰 IO 크기 tooget 대역폭/처리량을 더 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-358">Larger IO size tooget higher Bandwidth/Throughput.</span></span> <span data-ttu-id="a4a03-359">예를 들어 데이터 웨어하우스 응용 프로그램의 경우 1024KB입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-359">For example, 1024 KB for a data warehouse application.</span></span>

<span data-ttu-id="a4a03-360">응용 프로그램에 대 한 hello IOPS 및 처리량/대역폭을 계산 하는 방법은에 예가입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-360">Here is an example on how you can calculate hello IOPS and Throughput/Bandwidth for your application.</span></span> <span data-ttu-id="a4a03-361">P30 디스크를 사용하여 응용 프로그램을 고려합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-361">Consider an application using a P30 disk.</span></span> <span data-ttu-id="a4a03-362">hello 최대 IOPS 및 처리량/대역폭 P30 디스크 ä à ï 5,000 IOPS 및 200MB 초당 각각입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-362">hello maximum IOPS and Throughput/Bandwidth a P30 disk can achieve is 5000 IOPS and 200 MB per second respectively.</span></span> <span data-ttu-id="a4a03-363">이제 응용 프로그램에 필요한 hello P30 디스크에서 최대 IOPS 사용 하 여 더 작은 IO 크기 8KB를 같은 hello 됩니다 대역폭으로 인해 발생 하는 hello 수 tooget 40MB / 초입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-363">Now, if your application requires hello maximum IOPS from hello P30 disk and you use a smaller IO size like 8 KB, hello resulting Bandwidth you will be able tooget is 40 MB per second.</span></span> <span data-ttu-id="a4a03-364">그러나 응용 프로그램 P30 디스크에서 최대 처리량/대역폭 hello 및 1024KB와 같은 더 큰 IO 크기를 사용 하면 필요한 경우 hello 결과 IOPS 됩니다, 200 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-364">However, if your application requires hello maximum Throughput/Bandwidth from P30 disk, and you use a larger IO size like 1024 KB, hello resulting IOPS will be less, 200 IOPS.</span></span> <span data-ttu-id="a4a03-365">따라서 두 응용 프로그램의 IOPS 및 처리량/대역폭 요구 사항이 충족 되도록 hello IO 크기를 조정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-365">Therefore, tune hello IO size such that it meets both your application's IOPS and Throughput/Bandwidth requirement.</span></span> <span data-ttu-id="a4a03-366">다음 표에서 P30 디스크에 대 한 hello 다른 IO 크기 및 해당 IOPS 및 처리량을 요약합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-366">Table below summarizes hello different IO sizes and their corresponding IOPS and Throughput for a P30 disk.</span></span>

| <span data-ttu-id="a4a03-367">응용 프로그램 요구 사항</span><span class="sxs-lookup"><span data-stu-id="a4a03-367">Application Requirement</span></span> | <span data-ttu-id="a4a03-368">I/O 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-368">I/O size</span></span> | <span data-ttu-id="a4a03-369">IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-369">IOPS</span></span> | <span data-ttu-id="a4a03-370">처리량/대역폭</span><span class="sxs-lookup"><span data-stu-id="a4a03-370">Throughput/Bandwidth</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="a4a03-371">최대 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-371">Max IOPS</span></span> |<span data-ttu-id="a4a03-372">8KB</span><span class="sxs-lookup"><span data-stu-id="a4a03-372">8 KB</span></span> |<span data-ttu-id="a4a03-373">5, 000</span><span class="sxs-lookup"><span data-stu-id="a4a03-373">5,000</span></span> |<span data-ttu-id="a4a03-374">초당 40MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-374">40 MB per second</span></span> |
| <span data-ttu-id="a4a03-375">최대 처리량</span><span class="sxs-lookup"><span data-stu-id="a4a03-375">Max Throughput</span></span> |<span data-ttu-id="a4a03-376">1024KB</span><span class="sxs-lookup"><span data-stu-id="a4a03-376">1024 KB</span></span> |<span data-ttu-id="a4a03-377">200</span><span class="sxs-lookup"><span data-stu-id="a4a03-377">200</span></span> |<span data-ttu-id="a4a03-378">초당 200MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-378">200 MB per second</span></span> |
| <span data-ttu-id="a4a03-379">최대 처리량 + 높은 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-379">Max Throughput + high IOPS</span></span> |<span data-ttu-id="a4a03-380">64KB</span><span class="sxs-lookup"><span data-stu-id="a4a03-380">64 KB</span></span> |<span data-ttu-id="a4a03-381">3,200</span><span class="sxs-lookup"><span data-stu-id="a4a03-381">3,200</span></span> |<span data-ttu-id="a4a03-382">초당 200MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-382">200 MB per second</span></span> |
| <span data-ttu-id="a4a03-383">최대 IOPS + 높은 처리량</span><span class="sxs-lookup"><span data-stu-id="a4a03-383">Max IOPS + high Throughput</span></span> |<span data-ttu-id="a4a03-384">32KB</span><span class="sxs-lookup"><span data-stu-id="a4a03-384">32 KB</span></span> |<span data-ttu-id="a4a03-385">5, 000</span><span class="sxs-lookup"><span data-stu-id="a4a03-385">5,000</span></span> |<span data-ttu-id="a4a03-386">초당 160MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-386">160 MB per second</span></span> |

<span data-ttu-id="a4a03-387">tooget IOPS 및 대역폭 hello 단일 프리미엄 저장소 디스크의 최 댓 값 보다 더 높은 함께 스트라이프된 여러 프리미엄 디스크를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-387">tooget IOPS and Bandwidth higher than hello maximum value of a single premium storage disk, use multiple premium disks striped together.</span></span> <span data-ttu-id="a4a03-388">예를 들어 스트라이프 두 P30 디스크 tooget는 결합 된 IOPS의 10000 IOPS 또는 400MB의 결합 된 처리량 초당 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-388">For example, stripe two P30 disks tooget a combined IOPS of 10,000 IOPS or a combined Throughput of 400 MB per second.</span></span> <span data-ttu-id="a4a03-389">Hello 다음 섹션에서 설명 했 듯이 결합 hello 디스크 IOPS 및 처리량 지 원하는 VM 크기를 사용 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-389">As explained in hello next section, you must use a VM size that supports hello combined disk IOPS and Throughput.</span></span>

> [!NOTE]
> <span data-ttu-id="a4a03-390">어느 IOPS 늘리거나 다른 처리량 hello 또한 증가 하는 대로 클릭 하지 않으면 처리량 또는 hello 디스크나 VM의 IOPS 제한 중 하나를 늘릴 때 있는지 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-390">As you increase either IOPS or Throughput hello other also increases, make sure you do not hit throughput or IOPS limits of hello disk or VM when increasing either one.</span></span>
>
>

<span data-ttu-id="a4a03-391">toowitness hello IO 크기 응용 프로그램 성능에 미치는 영향, VM 및 디스크에서 벤치마킹 도구를 실행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-391">toowitness hello effects of IO size on application performance, you can run benchmarking tools on your VM and disks.</span></span> <span data-ttu-id="a4a03-392">여러 개의 테스트 실행을 만들고 각 실행된 toosee hello 영향에 대 한 다른 IO 크기를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-392">Create multiple test runs and use different IO size for each run toosee hello impact.</span></span> <span data-ttu-id="a4a03-393">Toohello 참조 [Benchmarking](#Benchmarking) hello에 대 한 자세한 내용은이 문서의 뒷부분에 나오는 섹션.</span><span class="sxs-lookup"><span data-stu-id="a4a03-393">Refer toohello [Benchmarking](#Benchmarking) section at hello end of this article for more details.</span></span>

## <a name="high-scale-vm-sizes"></a><span data-ttu-id="a4a03-394">높은 확장성의 VM 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-394">High Scale VM Sizes</span></span>
<span data-ttu-id="a4a03-395">응용 프로그램 디자인을 시작할 때 hello 첫 번째 작업 toodo 중 하나 이면 VM toohost 응용 프로그램을 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-395">When you start designing an application, one of hello first things toodo is, choose a VM toohost your application.</span></span> <span data-ttu-id="a4a03-396">프리미엄 저장소는 높은 계산 능력 및 높은 로컬 디스크 I/O 성능이 필요한 응용 프로그램을 실행할 수 있는 높은 확장성의 VM 크기와 함께 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-396">Premium Storage comes with High Scale VM sizes that can run applications requiring higher compute power and a high local disk I/O performance.</span></span> <span data-ttu-id="a4a03-397">이러한 Vm hello 로컬 디스크에 대 한 빠른 프로세서, 더 높은 메모리 대 코어 비율, 및는 Solid-State 드라이브 (SSD)를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-397">These VMs provide faster processors, a higher memory-to-core ratio, and a Solid-State Drive (SSD) for hello local disk.</span></span> <span data-ttu-id="a4a03-398">프리미엄 저장소를 지 원하는 높은 눈금 Vm의 예로 hello DS, DSv2 및 GS 시리즈 Vm입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-398">Examples of High Scale VMs supporting Premium Storage are hello DS, DSv2 and GS series VMs.</span></span>

<span data-ttu-id="a4a03-399">높은 확장성의 VM은 다양한 수의 CPU 코어, 메모리, OS 및 임시 디스크 크기와 함께 다양한 크기에서 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-399">High Scale VMs are available in different sizes with a different number of CPU cores, memory, OS and temporary disk size.</span></span> <span data-ttu-id="a4a03-400">각 VM 크기 또한 개수가 최대 데이터 디스크를 VM toohello를 연결할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-400">Each VM size also has maximum number of data disks that you can attach toohello VM.</span></span> <span data-ttu-id="a4a03-401">따라서 hello 선택한 VM 크기는 처리, 메모리 및 저장소 용량의 양과 응용 프로그램에 사용할 수 있는 적용 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-401">Therefore, hello chosen VM size will affect how much processing, memory, and storage capacity is available for your application.</span></span> <span data-ttu-id="a4a03-402">또한 hello 계산 및 저장소 비용 영향을 줍니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-402">It also affects hello Compute and Storage cost.</span></span> <span data-ttu-id="a4a03-403">예를 들어 다음은 가장 큰 VM 크기 DS 시리즈, DSv2 시리즈 및 GS 시리즈의 hello hello 사양:</span><span class="sxs-lookup"><span data-stu-id="a4a03-403">For example, below are hello specifications of hello largest VM size in a DS series, DSv2 series and a GS series:</span></span>

| <span data-ttu-id="a4a03-404">VM 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-404">VM size</span></span> | <span data-ttu-id="a4a03-405">CPU 코어</span><span class="sxs-lookup"><span data-stu-id="a4a03-405">CPU cores</span></span> | <span data-ttu-id="a4a03-406">메모리</span><span class="sxs-lookup"><span data-stu-id="a4a03-406">Memory</span></span> | <span data-ttu-id="a4a03-407">VM 디스크 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-407">VM disk sizes</span></span> | <span data-ttu-id="a4a03-408">최대</span><span class="sxs-lookup"><span data-stu-id="a4a03-408">Max.</span></span> <span data-ttu-id="a4a03-409">데이터 디스크</span><span class="sxs-lookup"><span data-stu-id="a4a03-409">data disks</span></span> | <span data-ttu-id="a4a03-410">캐시 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-410">Cache size</span></span> | <span data-ttu-id="a4a03-411">IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-411">IOPS</span></span> | <span data-ttu-id="a4a03-412">대역폭 캐시 IO 제한</span><span class="sxs-lookup"><span data-stu-id="a4a03-412">Bandwidth Cache IO limits</span></span> |
| --- | --- | --- | --- | --- | --- | --- | --- |
| <span data-ttu-id="a4a03-413">Standard_DS14</span><span class="sxs-lookup"><span data-stu-id="a4a03-413">Standard_DS14</span></span> |<span data-ttu-id="a4a03-414">16</span><span class="sxs-lookup"><span data-stu-id="a4a03-414">16</span></span> |<span data-ttu-id="a4a03-415">112GB</span><span class="sxs-lookup"><span data-stu-id="a4a03-415">112 GB</span></span> |<span data-ttu-id="a4a03-416">OS = 1023GB </span><span class="sxs-lookup"><span data-stu-id="a4a03-416">OS = 1023 GB</span></span> <br> <span data-ttu-id="a4a03-417">로컬 SSD = 224GB</span><span class="sxs-lookup"><span data-stu-id="a4a03-417">Local SSD = 224 GB</span></span> |<span data-ttu-id="a4a03-418">32</span><span class="sxs-lookup"><span data-stu-id="a4a03-418">32</span></span> |<span data-ttu-id="a4a03-419">576GB</span><span class="sxs-lookup"><span data-stu-id="a4a03-419">576 GB</span></span> |<span data-ttu-id="a4a03-420">50,000 IOPS </span><span class="sxs-lookup"><span data-stu-id="a4a03-420">50,000 IOPS</span></span> <br> <span data-ttu-id="a4a03-421">초당 512MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-421">512 MB per second</span></span> |<span data-ttu-id="a4a03-422">4,000 IOPS 및 초당 33MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-422">4,000 IOPS and 33 MB per second</span></span> |
| <span data-ttu-id="a4a03-423">Standard_GS5</span><span class="sxs-lookup"><span data-stu-id="a4a03-423">Standard_GS5</span></span> |<span data-ttu-id="a4a03-424">32</span><span class="sxs-lookup"><span data-stu-id="a4a03-424">32</span></span> |<span data-ttu-id="a4a03-425">448GB</span><span class="sxs-lookup"><span data-stu-id="a4a03-425">448 GB</span></span> |<span data-ttu-id="a4a03-426">OS = 1023GB </span><span class="sxs-lookup"><span data-stu-id="a4a03-426">OS = 1023 GB</span></span> <br> <span data-ttu-id="a4a03-427">로컬 SSD = 896GB</span><span class="sxs-lookup"><span data-stu-id="a4a03-427">Local SSD = 896 GB</span></span> |<span data-ttu-id="a4a03-428">64</span><span class="sxs-lookup"><span data-stu-id="a4a03-428">64</span></span> |<span data-ttu-id="a4a03-429">4224GB</span><span class="sxs-lookup"><span data-stu-id="a4a03-429">4224 GB</span></span> |<span data-ttu-id="a4a03-430">80,000 IOPS </span><span class="sxs-lookup"><span data-stu-id="a4a03-430">80,000 IOPS</span></span> <br> <span data-ttu-id="a4a03-431">초당 2,000MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-431">2,000 MB per second</span></span> |<span data-ttu-id="a4a03-432">5,000 IOPS 및 초당 50MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-432">5,000 IOPS and 50 MB per second</span></span> |

<span data-ttu-id="a4a03-433">사용 가능한 모든 Azure VM 크기의 전체 목록은 tooview 너무 참조[Windows VM 크기](../../virtual-machines/windows/sizes.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) 또는 [Linux VM 크기](../../virtual-machines/windows/sizes.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json)합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-433">tooview a complete list of all available Azure VM sizes, refer too[Windows VM sizes](../../virtual-machines/windows/sizes.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) or [Linux VM sizes](../../virtual-machines/windows/sizes.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json).</span></span> <span data-ttu-id="a4a03-434">충족 하 고 원하는 tooyour 응용 프로그램에 대 한 성능 요구 사항을 확장할 수 있는 VM 크기를 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-434">Choose a VM size that can meet and scale tooyour desired application performance requirements.</span></span> <span data-ttu-id="a4a03-435">또한 toothis, VM 크기를 선택할 때 고려해 야 할 다음을 고려해.</span><span class="sxs-lookup"><span data-stu-id="a4a03-435">In addition toothis, take into account following important considerations when choosing VM sizes.</span></span>

<span data-ttu-id="a4a03-436">*규모 제한*</span><span class="sxs-lookup"><span data-stu-id="a4a03-436">*Scale Limits*</span></span>  
<span data-ttu-id="a4a03-437">hello 최대 IOPS 제한 및 디스크 VM 당이 다르고 서로 독립적입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-437">hello maximum IOPS limits per VM and per disk are different and independent of each other.</span></span> <span data-ttu-id="a4a03-438">hello 응용 프로그램 제어 IOPS로 hello VM hello 프리미엄 디스크에 대 한 연결 된 tooit hello 제한 내에 있는지 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-438">Make sure that hello application is driving IOPS within hello limits of hello VM as well as hello premium disks attached tooit.</span></span> <span data-ttu-id="a4a03-439">그렇지 않은 경우 응용 프로그램 성능에 제한이 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-439">Otherwise, application performance will experience throttling.</span></span>

<span data-ttu-id="a4a03-440">한 예로 응용 프로그램 요구 사항이 최대 4,000 IOPS라 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-440">As an example, suppose an application requirement is a maximum of 4,000 IOPS.</span></span> <span data-ttu-id="a4a03-441">tooachieve P30 디스크 DS1 VM에 구축 하이 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-441">tooachieve this, you provision a P30 disk on a DS1 VM.</span></span> <span data-ttu-id="a4a03-442">hello P30 디스크 too5, 000 IOPS 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-442">hello P30 disk can deliver up too5,000 IOPS.</span></span> <span data-ttu-id="a4a03-443">그러나 hello DS1 VM 제한 too3, 200 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-443">However, hello DS1 VM is limited too3,200 IOPS.</span></span> <span data-ttu-id="a4a03-444">따라서 3,200 iops hello VM 제한 hello 응용 프로그램의 성능을 제한지 것입니다 하 고 성능이 저하 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-444">Consequently, hello application performance will be constrained by hello VM limit at 3,200 IOPS and there will be degraded performance.</span></span> <span data-ttu-id="a4a03-445">tooprevent이이 경우 VM을 선택 하 고 디스크 요구 사항을 모두 충족 응용 프로그램은 크기.</span><span class="sxs-lookup"><span data-stu-id="a4a03-445">tooprevent this situation, choose a VM and disk size that will both meet application requirements.</span></span>

<span data-ttu-id="a4a03-446">*작업 비용*</span><span class="sxs-lookup"><span data-stu-id="a4a03-446">*Cost of Operation*</span></span>  
<span data-ttu-id="a4a03-447">대부분의 경우에서 프리미엄 저장소를 사용하는 작업의 전체 비용은 표준 저장소를 사용하는 비용보다 낮을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-447">In many cases, it is possible that your overall cost of operation using Premium Storage is lower than using Standard Storage.</span></span>

<span data-ttu-id="a4a03-448">예를 들어 16,000 IOPS를 필요로 하는 응용 프로그램을 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-448">For example, consider an application requiring 16,000 IOPS.</span></span> <span data-ttu-id="a4a03-449">tooachieve이이 성능 표준 해야\_D14 Azure IaaS VM의 16,000 32 개의 표준 저장소 1TB 디스크를 사용 하 여 최대 IOPS 수 있는 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-449">tooachieve this performance, you will need a Standard\_D14 Azure IaaS VM, which can give a maximum IOPS of 16,000 using 32 standard storage 1TB disks.</span></span> <span data-ttu-id="a4a03-450">각 1TB 표준 저장소 디스크는 최대 500 IOPS를 달성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-450">Each 1TB standard storage disk can achieve a maximum of 500 IOPS.</span></span> <span data-ttu-id="a4a03-451">hello 예상 비용 한 달이이 VM의 $1,570 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-451">hello estimated cost of this VM per month will be $1,570.</span></span> <span data-ttu-id="a4a03-452">32 개의 표준 저장소 디스크 월별 비용이 hello $1,638 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-452">hello monthly cost of 32 standard storage disks will be $1,638.</span></span> <span data-ttu-id="a4a03-453">hello 예상 월간 총 비용 $3,208 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-453">hello estimated total monthly cost will be $3,208.</span></span>

<span data-ttu-id="a4a03-454">그러나 호스트 된 경우 hello 동일 프리미엄 저장소에 응용 프로그램을 및 필요 합니다. 더 작은 VM 크기를 더 적은 프리미엄 저장소 디스크 hello 전반적인 비용을 줄입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-454">However, if you hosted hello same application on Premium Storage, you will need a smaller VM size and fewer premium storage disks, thus reducing hello overall cost.</span></span> <span data-ttu-id="a4a03-455">표준\_DS13 VM 4 개 P30 디스크를 사용 하 여 hello 16,000 IOPS 요구를 충족할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-455">A Standard\_DS13 VM can meet hello 16,000 IOPS requirement using four P30 disks.</span></span> <span data-ttu-id="a4a03-456">hello DS13 VM 25,600의 최대 IOPS 많고 P30 디스크당 5000 최대 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-456">hello DS13 VM has a maximum IOPS of 25,600 and each P30 disk has a maximum IOPS of 5,000.</span></span> <span data-ttu-id="a4a03-457">전체적으로 이 구성은 5,000 x 4 = 20,000 IOPS를 달성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-457">Overall, this configuration can achieve 5,000 x 4 = 20,000 IOPS.</span></span> <span data-ttu-id="a4a03-458">hello 예상 비용 한 달이이 VM의 $1,003 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-458">hello estimated cost of this VM per month will be $1,003.</span></span> <span data-ttu-id="a4a03-459">4 개의 P30 프리미엄 저장소 디스크의 월별 비용이 hello $544.34 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-459">hello monthly cost of four P30 premium storage disks will be $544.34.</span></span> <span data-ttu-id="a4a03-460">hello 예상 월간 총 비용 $1,544 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-460">hello estimated total monthly cost will be $1,544.</span></span>

<span data-ttu-id="a4a03-461">다음 표에서 표준 및 프리미엄 저장소에 대 한이 시나리오의 hello 비용 분석 결과 요약합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-461">Table below summarizes hello cost breakdown of this scenario for Standard and Premium Storage.</span></span>

| &nbsp; | <span data-ttu-id="a4a03-462">**Standard**</span><span class="sxs-lookup"><span data-stu-id="a4a03-462">**Standard**</span></span> | <span data-ttu-id="a4a03-463">**Premium**</span><span class="sxs-lookup"><span data-stu-id="a4a03-463">**Premium**</span></span> |
| --- | --- | --- |
| <span data-ttu-id="a4a03-464">**월별 VM 비용**</span><span class="sxs-lookup"><span data-stu-id="a4a03-464">**Cost of VM per month**</span></span> |<span data-ttu-id="a4a03-465">$1,570.58(Standard\_D14)</span><span class="sxs-lookup"><span data-stu-id="a4a03-465">$1,570.58 (Standard\_D14)</span></span> |<span data-ttu-id="a4a03-466">$1,003.66(Standard\_DS13)</span><span class="sxs-lookup"><span data-stu-id="a4a03-466">$1,003.66 (Standard\_DS13)</span></span> |
| <span data-ttu-id="a4a03-467">**월별 디스크 비용**</span><span class="sxs-lookup"><span data-stu-id="a4a03-467">**Cost of Disks per month**</span></span> |<span data-ttu-id="a4a03-468">$1,638.40(32 x 1 TB 디스크)</span><span class="sxs-lookup"><span data-stu-id="a4a03-468">$1,638.40 (32 x 1 TB disks)</span></span> |<span data-ttu-id="a4a03-469">$544.34(4 x P30 디스크)</span><span class="sxs-lookup"><span data-stu-id="a4a03-469">$544.34 (4 x P30 disks)</span></span> |
| <span data-ttu-id="a4a03-470">**월별 전체 비용**</span><span class="sxs-lookup"><span data-stu-id="a4a03-470">**Overall Cost per month**</span></span> |<span data-ttu-id="a4a03-471">$3,208.98</span><span class="sxs-lookup"><span data-stu-id="a4a03-471">$3,208.98</span></span> |<span data-ttu-id="a4a03-472">$1,544.34</span><span class="sxs-lookup"><span data-stu-id="a4a03-472">$1,544.34</span></span> |

<span data-ttu-id="a4a03-473">*Linux 배포판*</span><span class="sxs-lookup"><span data-stu-id="a4a03-473">*Linux Distros*</span></span>  

<span data-ttu-id="a4a03-474">얻게 hello Azure 프리미엄 저장소와 동일한 수준의 성능 Windows 및 Linux를 실행 하는 Vm에 대 한 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-474">With Azure Premium Storage, you get hello same level of Performance for VMs running Windows and Linux.</span></span> <span data-ttu-id="a4a03-475">여러 버전의 Linux 배포판을 지원 하 고 hello 전체 목록을 볼 수 있습니다 [여기](../../virtual-machines/linux/endorsed-distros.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json)합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-475">We support many flavors of Linux distros, and you can see hello complete list [here](../../virtual-machines/linux/endorsed-distros.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json).</span></span> <span data-ttu-id="a4a03-476">다른 유형의 작업에 대해 적합 한 다른 배포판은 더 나은 toonote 유용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-476">It is important toonote that different distros are better suited for different types of workloads.</span></span> <span data-ttu-id="a4a03-477">서로 다른 수준의 hello distro에서 실행 중인 작업에 따라 성능이 표시 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-477">You will see different levels of performance depending on hello distro your workload is running on.</span></span> <span data-ttu-id="a4a03-478">응용 프로그램과 함께 hello Linux 배포판을 테스트 하 고 hello 가장 잘 작동 하는 하나를 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-478">Test hello Linux distros with your application and choose hello one that works best.</span></span>

<span data-ttu-id="a4a03-479">프리미엄 저장소로 Linux를 실행 하는 경우 hello tooensure 높은 성능이 필요한 드라이버에 대 한 최신 업데이트를 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-479">When running Linux with Premium Storage, check hello latest updates about required drivers tooensure high performance.</span></span>

## <a name="premium-storage-disk-sizes"></a><span data-ttu-id="a4a03-480">프리미엄 저장소 디스크 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-480">Premium Storage Disk Sizes</span></span>
<span data-ttu-id="a4a03-481">Azure Premium Storage는 현재 일곱 가지 디스크 크기를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-481">Azure Premium Storage offers seven disk sizes currently.</span></span> <span data-ttu-id="a4a03-482">각 디스크 크기는 IOPS, 대역폭 및 저장소에 대한 다른 규모 한도를 가집니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-482">Each disk size has a different scale limit for IOPS, Bandwidth and Storage.</span></span> <span data-ttu-id="a4a03-483">Hello hello 응용 프로그램 요구 사항 및 hello 대규모 VM 크기에 따라 올바른 프리미엄 저장소 디스크 크기를 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-483">Choose hello right Premium Storage Disk size depending on hello application requirements and hello high scale VM size.</span></span> <span data-ttu-id="a4a03-484">hello 표에서 hello 7 개 디스크 크기와 기능을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-484">hello table below shows hello seven disks sizes and their capabilities.</span></span> <span data-ttu-id="a4a03-485">P4 및 P6 크기는 현재 Managed Disks에 대해서만 지원됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-485">P4 and P6 sizes are currently only supported for Managed Disks.</span></span>

| <span data-ttu-id="a4a03-486">프리미엄 디스크 유형</span><span class="sxs-lookup"><span data-stu-id="a4a03-486">Premium Disks Type</span></span>  | <span data-ttu-id="a4a03-487">P4</span><span class="sxs-lookup"><span data-stu-id="a4a03-487">P4</span></span>    | <span data-ttu-id="a4a03-488">P6</span><span class="sxs-lookup"><span data-stu-id="a4a03-488">P6</span></span>    | <span data-ttu-id="a4a03-489">P10</span><span class="sxs-lookup"><span data-stu-id="a4a03-489">P10</span></span>   | <span data-ttu-id="a4a03-490">P20</span><span class="sxs-lookup"><span data-stu-id="a4a03-490">P20</span></span>   | <span data-ttu-id="a4a03-491">P30</span><span class="sxs-lookup"><span data-stu-id="a4a03-491">P30</span></span>   | <span data-ttu-id="a4a03-492">P40</span><span class="sxs-lookup"><span data-stu-id="a4a03-492">P40</span></span>   | <span data-ttu-id="a4a03-493">P50</span><span class="sxs-lookup"><span data-stu-id="a4a03-493">P50</span></span>   | 
|---------------------|-------|-------|-------|-------|-------|-------|-------|
| <span data-ttu-id="a4a03-494">디스크 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-494">Disk size</span></span>           | <span data-ttu-id="a4a03-495">32GB</span><span class="sxs-lookup"><span data-stu-id="a4a03-495">32 GB</span></span> | <span data-ttu-id="a4a03-496">64GB</span><span class="sxs-lookup"><span data-stu-id="a4a03-496">64 GB</span></span> | <span data-ttu-id="a4a03-497">128GB</span><span class="sxs-lookup"><span data-stu-id="a4a03-497">128 GB</span></span>| <span data-ttu-id="a4a03-498">512GB</span><span class="sxs-lookup"><span data-stu-id="a4a03-498">512 GB</span></span>            | <span data-ttu-id="a4a03-499">1,024GB(1TB)</span><span class="sxs-lookup"><span data-stu-id="a4a03-499">1024 GB (1 TB)</span></span>    | <span data-ttu-id="a4a03-500">2,048GB(2TB)</span><span class="sxs-lookup"><span data-stu-id="a4a03-500">2048 GB (2 TB)</span></span>    | <span data-ttu-id="a4a03-501">4,095GB(4TB)</span><span class="sxs-lookup"><span data-stu-id="a4a03-501">4095 GB (4 TB)</span></span>    | 
| <span data-ttu-id="a4a03-502">디스크당 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-502">IOPS per disk</span></span>       | <span data-ttu-id="a4a03-503">120</span><span class="sxs-lookup"><span data-stu-id="a4a03-503">120</span></span>   | <span data-ttu-id="a4a03-504">240</span><span class="sxs-lookup"><span data-stu-id="a4a03-504">240</span></span>   | <span data-ttu-id="a4a03-505">500</span><span class="sxs-lookup"><span data-stu-id="a4a03-505">500</span></span>   | <span data-ttu-id="a4a03-506">2,300</span><span class="sxs-lookup"><span data-stu-id="a4a03-506">2300</span></span>              | <span data-ttu-id="a4a03-507">5,000</span><span class="sxs-lookup"><span data-stu-id="a4a03-507">5000</span></span>              | <span data-ttu-id="a4a03-508">7,500</span><span class="sxs-lookup"><span data-stu-id="a4a03-508">7500</span></span>              | <span data-ttu-id="a4a03-509">7,500</span><span class="sxs-lookup"><span data-stu-id="a4a03-509">7500</span></span>              | 
| <span data-ttu-id="a4a03-510">디스크당 처리량</span><span class="sxs-lookup"><span data-stu-id="a4a03-510">Throughput per disk</span></span> | <span data-ttu-id="a4a03-511">초당 25MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-511">25 MB per second</span></span>  | <span data-ttu-id="a4a03-512">초당 50MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-512">50 MB per second</span></span>  | <span data-ttu-id="a4a03-513">초당 100MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-513">100 MB per second</span></span> | <span data-ttu-id="a4a03-514">초당 150MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-514">150 MB per second</span></span> | <span data-ttu-id="a4a03-515">초당 200MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-515">200 MB per second</span></span> | <span data-ttu-id="a4a03-516">초당 250MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-516">250 MB per second</span></span> | <span data-ttu-id="a4a03-517">초당 250MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-517">250 MB per second</span></span> | 


<span data-ttu-id="a4a03-518">Hello 디스크에 따라 선택 하는 디스크 수에 선택한 크기입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-518">How many disks you choose depends on hello disk size chosen.</span></span> <span data-ttu-id="a4a03-519">사용자 응용 프로그램 요구 사항이 단일 P50 디스크 또는 여러 P10 디스크 toomeet 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-519">You could use a single P50 disk or multiple P10 disks toomeet your application requirement.</span></span> <span data-ttu-id="a4a03-520">계정 고려 사항 hello 선택 하는 경우 아래에 나열 된 고려 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-520">Take into account considerations listed below when making hello choice.</span></span>

<span data-ttu-id="a4a03-521">*규모 제한(IOPS 및 처리량)*</span><span class="sxs-lookup"><span data-stu-id="a4a03-521">*Scale Limits (IOPS and Throughput)*</span></span>  
<span data-ttu-id="a4a03-522">각 프리미엄 디스크 크기의 hello IOPS 및 처리량 제한은 서로 다른 독립적 hello VM 규모 조정 한도에서입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-522">hello IOPS and Throughput limits of each Premium disk size is different and independent from hello VM scale limits.</span></span> <span data-ttu-id="a4a03-523">Hello 디스크에서 처리량의 hello 확장 제한 내에서 선택 된 VM 크기 및 총 IOPS hello를 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-523">Make sure that hello total IOPS and Throughput from hello disks are within scale limits of hello chosen VM size.</span></span>

<span data-ttu-id="a4a03-524">예를 들어 응용 프로그램 요구 사항이 최대 250MB/초의 처리량이고 단일 P30 디스크와 함께 DS4 VM을 사용하는 경우를 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-524">For example, if an application requirement is a maximum of 250 MB/sec Throughput and you are using a DS4 VM with a single P30 disk.</span></span> <span data-ttu-id="a4a03-525">hello DS4 VM too256 m B/초의 처리량을 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-525">hello DS4 VM can give up too256 MB/sec Throughput.</span></span> <span data-ttu-id="a4a03-526">그러나 단일 P30 디스크의 처리량 제한은 200 m B/초입니다. 따라서 200MB/sec toohello 디스크 제한 때문에 hello 응용 프로그램에 제한이 적용 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-526">However, a single P30 disk has Throughput limit of 200 MB/sec. Consequently, hello application will be constrained at 200 MB/sec due toohello disk limit.</span></span> <span data-ttu-id="a4a03-527">tooovercome이 한이도 둘 이상의 데이터 디스크 toohello VM을 프로 비전 하거나 디스크 tooP40 또는 P50 크기를 조정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-527">tooovercome this limit, provision more than one data disks toohello VM or resize your disks tooP40 or P50.</span></span>

> [!NOTE]
> <span data-ttu-id="a4a03-528">Hello 캐시에서 제공 하는 읽기 hello 디스크 IOPS 및 처리량에 포함 되지 않은, 따라서 toodisk 제한 대상이 아닙니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-528">Reads served by hello cache are not included in hello disk IOPS and Throughput, hence not subject toodisk limits.</span></span> <span data-ttu-id="a4a03-529">캐시에는 VM당 별도 IOPS 및 처리량 제한이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-529">Cache has its separate IOPS and Throughput limit per VM.</span></span>
>
> <span data-ttu-id="a4a03-530">예를 들어 처음에 읽기 및 쓰기는 각각 60MB/초 및 40MB/초입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-530">For example, initially your reads and writes are 60MB/sec and 40MB/sec respectively.</span></span> <span data-ttu-id="a4a03-531">시간이 지남에 따라 hello 캐시 warms 하 고 hello 캐시에서 점점 더 많은 hello 읽기를 서비스 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-531">Over time, hello cache warms up and serves more and more of hello reads from hello cache.</span></span> <span data-ttu-id="a4a03-532">그런 다음 hello 디스크에서 높은 쓰기 처리량을 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-532">Then, you can get higher write Throughput from hello disk.</span></span>
>
>

<span data-ttu-id="a4a03-533">*디스크 수*</span><span class="sxs-lookup"><span data-stu-id="a4a03-533">*Number of Disks*</span></span>  
<span data-ttu-id="a4a03-534">응용 프로그램 요구 사항을 평가 하 여 해야 하는 디스크 hello 수를 결정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-534">Determine hello number of disks you will need by assessing application requirements.</span></span> <span data-ttu-id="a4a03-535">각 VM 크기에 hello toohello VM를 연결할 수 있는 디스크 수에는 제한이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-535">Each VM size also has a limit on hello number of disks that you can attach toohello VM.</span></span> <span data-ttu-id="a4a03-536">일반적으로 코어 수를 두 번 hello입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-536">Typically, this is twice hello number of cores.</span></span> <span data-ttu-id="a4a03-537">해당 hello hello 필요한 디스크 수를 지원할 수를 선택 하는 VM 크기를 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-537">Ensure that hello VM size you choose can support hello number of disks needed.</span></span>

<span data-ttu-id="a4a03-538">Hello 프리미엄 저장소 디스크는 더 높은 성능 비교 기능 tooStandard 저장소 디스크를 기억 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-538">Remember, hello Premium Storage disks have higher performance capabilities compared tooStandard Storage disks.</span></span> <span data-ttu-id="a4a03-539">따라서 표준 저장소 tooPremium 저장소를 사용 하 여 Azure IaaS VM에서 응용 프로그램을 마이그레이션하려는 경우 하면 더 적은 프리미엄 디스크 tooachieve hello 응용 프로그램에 대해 동일 하거나 더 높은 성능입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-539">Therefore, if you are migrating your application from Azure IaaS VM using Standard Storage tooPremium Storage, you will likely need fewer premium disks tooachieve hello same or higher performance for your application.</span></span>

## <a name="disk-caching"></a><span data-ttu-id="a4a03-540">디스크 캐싱</span><span class="sxs-lookup"><span data-stu-id="a4a03-540">Disk Caching</span></span>
<span data-ttu-id="a4a03-541">Azure 프리미엄 저장소를 활용하는 높은 확장성의 VM에는 BlobCache 라는 다중 계층 캐싱 기술이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-541">High Scale VMs that leverage Azure Premium Storage have a multi-tier caching technology called BlobCache.</span></span> <span data-ttu-id="a4a03-542">BlobCache 캐싱에 대 한 가상 컴퓨터 RAM hello 및 로컬 SSD의 조합을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-542">BlobCache uses a combination of hello Virtual Machine RAM and local SSD for caching.</span></span> <span data-ttu-id="a4a03-543">이 캐시는 hello 프리미엄 저장소 영구 디스크 및 hello VM 로컬 디스크에 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-543">This cache is available for hello Premium Storage persistent disks and hello VM local disks.</span></span> <span data-ttu-id="a4a03-544">기본적으로이 캐시 설정은 tooRead/운영 체제 디스크에 대 한 쓰기 및 읽기 전용 데이터 디스크를 프리미엄 저장소에서 호스트에 대 한 설정 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-544">By default, this cache setting is set tooRead/Write for OS disks and ReadOnly for data disks hosted on Premium Storage.</span></span> <span data-ttu-id="a4a03-545">디스크 캐싱을 hello 프리미엄 저장소 디스크에 사용 hello 대규모 Vm hello 기본 디스크 성능을 초과 하는 매우 높은 수준의 성능 달성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-545">With disk caching enabled on hello Premium Storage disks, hello high scale VMs can achieve extremely high levels of performance that exceed hello underlying disk performance.</span></span>

> [!WARNING]
> <span data-ttu-id="a4a03-546">Azure 디스크의 hello 캐시 설정을 변경를 분리 한 다시 hello 대상 디스크를 연결 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-546">Changing hello cache setting of an Azure disk detaches and re-attaches hello target disk.</span></span> <span data-ttu-id="a4a03-547">Hello 운영 체제 디스크 이면 hello VM 다시 시작 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-547">If it is hello operating system disk, hello VM is restarted.</span></span> <span data-ttu-id="a4a03-548">Hello 디스크 캐시 설정을 변경 하기 전에이 중단의 영향을 받을 수 있는 모든 응용 프로그램/서비스를 중지 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-548">Stop all applications/services that might be affected by this disruption before changing hello disk cache setting.</span></span>
>
>

<span data-ttu-id="a4a03-549">BlobCache 작동 방식에 대해 자세히 toolearn 참조 내 toohello [Azure 프리미엄 저장소](https://azure.microsoft.com/blog/azure-premium-storage-now-generally-available-2/) 블로그 게시물입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-549">toolearn more about how BlobCache works, refer toohello Inside [Azure Premium Storage](https://azure.microsoft.com/blog/azure-premium-storage-now-generally-available-2/) blog post.</span></span>

<span data-ttu-id="a4a03-550">이 hello 오른쪽 디스크 세트에 중요 한 tooenable 캐시입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-550">It is important tooenable cache on hello right set of disks.</span></span> <span data-ttu-id="a4a03-551">프리미엄 디스크에 디스크 캐시를 사용 해야 하거나 하지에 따라 달라 집니다 hello 작업 패턴 해당 디스크를 처리 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-551">Whether you should enable disk caching on a premium disk or not will depend on hello workload pattern that disk will be handling.</span></span> <span data-ttu-id="a4a03-552">다음 표에서 hello 기본 OS 및 데이터 디스크에 대 한 캐시 설정을 보여줍니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-552">Table below shows hello default cache settings for OS and Data disks.</span></span>

| <span data-ttu-id="a4a03-553">**디스크 유형**</span><span class="sxs-lookup"><span data-stu-id="a4a03-553">**Disk Type**</span></span> | <span data-ttu-id="a4a03-554">**기본 캐시 설정**</span><span class="sxs-lookup"><span data-stu-id="a4a03-554">**Default Cache Setting**</span></span> |
| --- | --- |
| <span data-ttu-id="a4a03-555">OS 디스크</span><span class="sxs-lookup"><span data-stu-id="a4a03-555">OS disk</span></span> |<span data-ttu-id="a4a03-556">ReadWrite</span><span class="sxs-lookup"><span data-stu-id="a4a03-556">ReadWrite</span></span> |
| <span data-ttu-id="a4a03-557">데이터 디스크 </span><span class="sxs-lookup"><span data-stu-id="a4a03-557">Data disk</span></span> |<span data-ttu-id="a4a03-558">없음</span><span class="sxs-lookup"><span data-stu-id="a4a03-558">None</span></span> |

<span data-ttu-id="a4a03-559">다음에 데이터 디스크에 대 한 권장 되는 디스크 캐시 설정을 hello 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-559">Following are hello recommended disk cache settings for data disks,</span></span>

| <span data-ttu-id="a4a03-560">**디스크 캐싱 설정**</span><span class="sxs-lookup"><span data-stu-id="a4a03-560">**Disk Caching Setting**</span></span> | <span data-ttu-id="a4a03-561">**경우에 권장 구성을 toouse이이 설정은**</span><span class="sxs-lookup"><span data-stu-id="a4a03-561">**Recommendation on when toouse this setting**</span></span> |
| --- | --- |
| <span data-ttu-id="a4a03-562">없음</span><span class="sxs-lookup"><span data-stu-id="a4a03-562">None</span></span> |<span data-ttu-id="a4a03-563">쓰기 전용 및 쓰기가 많은 디스크에 대해 None으로 호스트-캐시를 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-563">Configure host-cache as None for write-only and write-heavy disks.</span></span> |
| <span data-ttu-id="a4a03-564">ReadOnly</span><span class="sxs-lookup"><span data-stu-id="a4a03-564">ReadOnly</span></span> |<span data-ttu-id="a4a03-565">읽기 전용 및 읽기-쓰기 디스크에 대해 ReadOnly로 호스트-캐시를 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-565">Configure host-cache as ReadOnly for read-only and read-write disks.</span></span> |
| <span data-ttu-id="a4a03-566">ReadWrite</span><span class="sxs-lookup"><span data-stu-id="a4a03-566">ReadWrite</span></span> |<span data-ttu-id="a4a03-567">응용 프로그램 작성 적절히 처리 하는 경우에 / 쓰기 데이터 toopersistent 디스크 필요할 때 캐시 된 대로 호스트 캐시를 구성 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-567">Configure host-cache as ReadWrite only if your application properly  handles writing cached data toopersistent disks when needed.</span></span> |

<span data-ttu-id="a4a03-568">*ReadOnly*</span><span class="sxs-lookup"><span data-stu-id="a4a03-568">*ReadOnly*</span></span>  
<span data-ttu-id="a4a03-569">프리미엄 저장소 데이터 디스크에 ReadOnly 캐싱을 구성하여 짧은 읽기 대기 시간을 달성하고 응용 프로그램에 대한 매우 높은 읽기 IOPS 및 처리량을 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-569">By configuring ReadOnly caching on Premium Storage data disks, you can achieve low Read latency and get very high Read IOPS and Throughput for your application.</span></span> <span data-ttu-id="a4a03-570">다음 두 가지 이유로 인한 것입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-570">This is due two reasons,</span></span>

1. <span data-ttu-id="a4a03-571">읽기는 hello VM 메모리 및 로컬 SSD에 있는 캐시에서 수행, hello Azure blob 저장소에 있는 hello 데이터 디스크에서 읽기 보다 훨씬 빠릅니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-571">Reads performed from cache, which is on hello VM memory and local SSD, are much faster than reads from hello data disk, which is on hello Azure blob storage.</span></span>  
2. <span data-ttu-id="a4a03-572">프리미엄 저장소에서 읽기 쪽 hello 디스크 IOPS 및 처리량으로 캐시에서 제공 하는 hello를 계산 하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-572">Premium Storage does not count hello Reads served from cache, towards hello disk IOPS and Throughput.</span></span> <span data-ttu-id="a4a03-573">따라서 응용 프로그램은 더 높은 수 tooachieve 전체 IOPS 및 처리량입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-573">Therefore, your application is able tooachieve higher total IOPS and Throughput.</span></span>

<span data-ttu-id="a4a03-574">*ReadWrite*</span><span class="sxs-lookup"><span data-stu-id="a4a03-574">*ReadWrite*</span></span>  
<span data-ttu-id="a4a03-575">기본적으로 hello OS 디스크/쓰기 캐싱이 설정 되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-575">By default, hello OS disks have ReadWrite caching enabled.</span></span> <span data-ttu-id="a4a03-576">최근에 데이터 디스크에 ReadWrite 캐싱에 대한 지원을 추가했습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-576">We have recently added support for ReadWrite caching on data disks as well.</span></span> <span data-ttu-id="a4a03-577">ReadWrite caching을 사용 하는 경우에 적절 한 방법은 toowrite hello 디스크 데이터를 캐시 toopersistent 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-577">If you are using ReadWrite caching, you must have a proper way toowrite hello data from cache toopersistent disks.</span></span> <span data-ttu-id="a4a03-578">예를 들어 SQL Server 핸들 작성 자체적으로 데이터 toohello 영구 저장소 디스크 캐시.</span><span class="sxs-lookup"><span data-stu-id="a4a03-578">For example, SQL Server handles writing cached data toohello persistent storage disks on its own.</span></span> <span data-ttu-id="a4a03-579">지속 hello를 처리 하지 않는 응용 프로그램 으로/쓰기 캐시를 사용 하 여 필요한 데이터 toodata 손실 될 수 있습니다 hello VM가 충돌 하는 경우.</span><span class="sxs-lookup"><span data-stu-id="a4a03-579">Using ReadWrite cache with an application that does not handle persisting hello required data can lead toodata loss, if hello VM crashes.</span></span>

<span data-ttu-id="a4a03-580">예를 들어, 이러한 지침 tooSQL 서버를 적용할 수 있습니다 hello 다음을 수행 하 여 프리미엄 저장소에서 실행 중인</span><span class="sxs-lookup"><span data-stu-id="a4a03-580">As an example, you can apply these guidelines tooSQL Server running on Premium Storage by doing hello following,</span></span>

1. <span data-ttu-id="a4a03-581">데이터 파일을 호스트하는 Premium Storage 디스크에 “ReadOnly” 캐시를 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-581">Configure "ReadOnly" cache on premium storage disks hosting data files.</span></span>  
   <span data-ttu-id="a4a03-582">a.</span><span class="sxs-lookup"><span data-stu-id="a4a03-582">a.</span></span>  <span data-ttu-id="a4a03-583">데이터 페이지는 hello 데이터 디스크에서 캐시 비교 toodirectly hello에서에서 훨씬 빠르게 검색 한 이후 hello 빠른 캐시 낮은 hello SQL Server 쿼리 시간에서 읽습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-583">hello fast reads from cache lower hello SQL Server query time since data pages are retrieved much faster from hello cache compared toodirectly from hello data disks.</span></span>  
   <span data-ttu-id="a4a03-584">b.</span><span class="sxs-lookup"><span data-stu-id="a4a03-584">b.</span></span>  <span data-ttu-id="a4a03-585">캐시에서 읽기 제공은 프리미엄 데이터 디스크에서 사용할 수 있는 추가 처리량이 있음을 의미합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-585">Serving reads from cache, means there is additional Throughput available from premium data disks.</span></span> <span data-ttu-id="a4a03-586">SQL Server는 이 추가 처리량을 사용하여 더 많은 데이터 페이지와 백업/복원, 배치 처리 및 인덱스 다시 빌드와 같은 다른 작업을 검색할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-586">SQL Server can use this additional Throughput towards retrieving more data pages and other operations like backup/restore, batch loads, and index rebuilds.</span></span>  
2. <span data-ttu-id="a4a03-587">"None" 구성 호스팅 hello 로그 파일 디스크를 프리미엄 저장소에 캐시 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-587">Configure "None" cache on premium storage disks hosting hello log files.</span></span>  
   <span data-ttu-id="a4a03-588">a.</span><span class="sxs-lookup"><span data-stu-id="a4a03-588">a.</span></span>  <span data-ttu-id="a4a03-589">로그 파일은 주로 많은 쓰기 작업을 가집니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-589">Log files have primarily write-heavy operations.</span></span> <span data-ttu-id="a4a03-590">따라서은 유용 하지 않습니다 hello 읽기 전용 캐시에서.</span><span class="sxs-lookup"><span data-stu-id="a4a03-590">Therefore, they do not benefit from hello ReadOnly cache.</span></span>

## <a name="disk-striping"></a><span data-ttu-id="a4a03-591">디스크 스트라이프</span><span class="sxs-lookup"><span data-stu-id="a4a03-591">Disk Striping</span></span>
<span data-ttu-id="a4a03-592">대규모 VM 여러 프리미엄 저장소 영구 디스크, hello 디스크와 연결 된 작업을 수 함께 스트라이프된 tooaggregate 자신의 IOPs, 대역폭 및 저장소 용량입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-592">When a high scale VM is attached with several premium storage persistent disks, hello disks can be striped together tooaggregate their IOPs, bandwidth, and storage capacity.</span></span>

<span data-ttu-id="a4a03-593">Windows에서는 저장소 공간 toostripe 디스크를 함께 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-593">On Windows, you can use Storage Spaces toostripe disks together.</span></span> <span data-ttu-id="a4a03-594">풀에서 각 디스크마다 하나의 열을 구성해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-594">You must configure one column for each disk in a pool.</span></span> <span data-ttu-id="a4a03-595">그렇지 않으면 hello 스트라이프 볼륨의 전반적인 성능 수 hello 디스크에 걸쳐 트래픽의 toouneven 배포 인해 예상 보다 더 낮은 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-595">Otherwise, hello overall performance of striped volume can be lower than expected, due toouneven distribution of traffic across hello disks.</span></span>

<span data-ttu-id="a4a03-596">중요: 서버 관리자 UI를 사용 하 hello 스트라이프 볼륨에 대 한 too8 열의 총 수를 설정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-596">Important: Using Server Manager UI, you can set hello total number of columns up too8 for a striped volume.</span></span> <span data-ttu-id="a4a03-597">8 개 이상의 디스크를 연결 하는 경우 PowerShell toocreate hello 볼륨을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-597">When attaching more than 8 disks, use PowerShell toocreate hello volume.</span></span> <span data-ttu-id="a4a03-598">PowerShell을 사용 하 설정할 수 있습니다. 있습니다 hello 열 수가 동일 toohello 디스크 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-598">Using PowerShell, you can set hello number of columns equal toohello number of disks.</span></span> <span data-ttu-id="a4a03-599">예를 들어, 16 개의 디스크 단일 스트라이프 세트;에 있는 경우 hello에 16 개의 열을 지정 *NumberOfColumns* hello의 매개 변수 *New-virtualdisk* PowerShell cmdlet.</span><span class="sxs-lookup"><span data-stu-id="a4a03-599">For example, if there are 16 disks in a single stripe set; specify 16 columns in hello *NumberOfColumns* parameter of hello *New-VirtualDisk* PowerShell cmdlet.</span></span>

<span data-ttu-id="a4a03-600">Linux에서 hello MDADM 유틸리티 toostripe 디스크를 함께 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-600">On Linux, use hello MDADM utility toostripe disks together.</span></span> <span data-ttu-id="a4a03-601">에 대 한 스트라이프 디스크 Linux에 관련 된 자세한 단계는 너무 참조[Linux에서 소프트웨어 RAID 구성](../../virtual-machines/linux/configure-raid.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json)합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-601">For detailed steps on striping disks on Linux refer too[Configure Software RAID on Linux](../../virtual-machines/linux/configure-raid.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json).</span></span>

<span data-ttu-id="a4a03-602">*스트라이프 크기*</span><span class="sxs-lookup"><span data-stu-id="a4a03-602">*Stripe Size*</span></span>  
<span data-ttu-id="a4a03-603">중요 한 구성에서 디스크 스트라이프는 hello 스트라이프 크기입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-603">An important configuration in disk striping is hello stripe size.</span></span> <span data-ttu-id="a4a03-604">hello 스트라이프 크기 또는 블록 크기는 응용 프로그램 스트라이프 볼륨에 해결할 수 있는 데이터의 가장 작은 청크 hello 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-604">hello stripe size or block size is hello smallest chunk of data that application can address on a striped volume.</span></span> <span data-ttu-id="a4a03-605">구성한 hello 스트라이프 크기의 응용 프로그램 및 해당 요청 패턴 hello 유형에 따라 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-605">hello stripe size you configure depends on hello type of application and its request pattern.</span></span> <span data-ttu-id="a4a03-606">Hello 잘못 스트라이프 크기를 선택 하면 응용 프로그램의 성능을 toodegraded 본질적 tooIO 잘못 맞춤을 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-606">If you choose hello wrong stripe size, it could lead tooIO misalignment, which leads toodegraded performance of your application.</span></span>

<span data-ttu-id="a4a03-607">예를 들어 응용 프로그램에서 생성 하는 IO 요청 hello 디스크 스트라이프 크기 보다 큰 경우 hello 저장소 시스템이 씁니다 stripe 간에 단위 경계 둘 이상의 디스크에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-607">For example, if an IO request generated by your application is bigger than hello disk stripe size, hello storage system writes it across stripe unit boundaries on more than one disk.</span></span> <span data-ttu-id="a4a03-608">해당 데이터 tooaccess 시간는 것을 하는 경우 둘 이상의 stripe 단위 toocomplete hello 요청 간에 tooseek은입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-608">When it is time tooaccess that data, it will have tooseek across more than one stripe units toocomplete hello request.</span></span> <span data-ttu-id="a4a03-609">이러한 동작의 hello 누적 된 효과가 toosubstantial 성능 저하를 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-609">hello cumulative effect of such behavior can lead toosubstantial performance degradation.</span></span> <span data-ttu-id="a4a03-610">Hello에 hello IO 요청 크기 스트라이프 크기 보다 작으면 고 본질적으로 무작위 경우 hello I/O 요청이 추가할 수 있습니다 hello에 동일한 경우 디스크 병목 현상이 발생 하 고 궁극적으로 hello IO 성능을 저하 시키는 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-610">On hello other hand, if hello IO request size is smaller than stripe size, and if it is random in nature, hello IO requests may add up on hello same disk causing a bottleneck and ultimately degrading hello IO performance.</span></span>

<span data-ttu-id="a4a03-611">응용 프로그램을 실행 하는 워크 로드의 hello 형식에 따라 적절 한 스트라이프 크기를 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-611">Depending on hello type of workload your application is running, choose an appropriate stripe size.</span></span> <span data-ttu-id="a4a03-612">작은 임의 IO 요청의 경우 더 작은 스트라이프 크기를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-612">For random small IO requests, use a smaller stripe size.</span></span> <span data-ttu-id="a4a03-613">반면 큰 순차 IO 요청의 경우 더 큰 스트라이프 크기를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-613">Whereas, for large sequential IO requests use a larger stripe size.</span></span> <span data-ttu-id="a4a03-614">프리미엄 저장소에 실행 하려는 hello 응용 프로그램에 대 한 hello 스트라이프 크기 권장을 확인 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-614">Find out hello stripe size recommendations for hello application you will be running on Premium Storage.</span></span> <span data-ttu-id="a4a03-615">SQL Server의 경우 OLTP 작업에 대해 64KB의 스트라이프 크기, 데이터 웨어하우징 작업에 대해 256KB의 스트라이프 크기를 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-615">For SQL Server, configure stripe size of 64KB for OLTP workloads and 256KB for data warehousing workloads.</span></span> <span data-ttu-id="a4a03-616">참조 [Azure Vm에서 SQL Server에 대 한 성능 모범 사례](../../virtual-machines/windows/sql/virtual-machines-windows-sql-performance.md#disks-guidance) toolearn 더 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-616">See [Performance best practices for SQL Server on Azure VMs](../../virtual-machines/windows/sql/virtual-machines-windows-sql-performance.md#disks-guidance) toolearn more.</span></span>

> [!NOTE]
> <span data-ttu-id="a4a03-617">DS 시리즈 VM에 최대 32개의 프리미엄 저장소 디스크를 GS 시리즈 VM에 64개의 프리미엄 저장소 디스크를 함께 스트라이프할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-617">You can stripe together a maximum of 32 premium storage disks on a DS series VM and 64 premium storage disks on a GS series VM.</span></span>
>
>

## <a name="multi-threading"></a><span data-ttu-id="a4a03-618">다중 스레드</span><span class="sxs-lookup"><span data-stu-id="a4a03-618">Multi-threading</span></span>
<span data-ttu-id="a4a03-619">Azure는 프리미엄 저장소 플랫폼 toobe 대규모 병렬 위해 디자인 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-619">Azure has designed Premium Storage platform toobe massively parallel.</span></span> <span data-ttu-id="a4a03-620">따라서 다중 스레드 응용 프로그램은 단일 스레드 응용 프로그램에 비해 훨씬 더 높은 성능을 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-620">Therefore, a multi-threaded application achieves much higher performance than a single-threaded application.</span></span> <span data-ttu-id="a4a03-621">여러 스레드에서 작업을 분할 하 고 VM hello 사용 하 여 해당 실행의 효율성 및 디스크 리소스 toohello 최대 증가 하는 다중 스레드 응용 프로그램.</span><span class="sxs-lookup"><span data-stu-id="a4a03-621">A multi-threaded application splits up its tasks across multiple threads and increases efficiency of its execution by utilizing hello VM and disk resources toohello maximum.</span></span>

<span data-ttu-id="a4a03-622">예를 들어 응용 프로그램이 단일 코어 두 개의 스레드를 사용 하 여 VM에서 실행 되는 경우 hello CPU hello 스레드가 각각 두 tooachieve 효율성 간에 전환할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-622">For example, if your application is running on a single core VM using two threads, hello CPU can switch between hello two threads tooachieve efficiency.</span></span> <span data-ttu-id="a4a03-623">한 스레드가 디스크 IO toocomplete에서 대기 하는 동안 CPU hello 전환할 수 toohello 다른 스레드가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-623">While one thread is waiting on a disk IO toocomplete, hello CPU can switch toohello other thread.</span></span> <span data-ttu-id="a4a03-624">이러한 방식으로 두 스레드는 단일 스레드보다 더 많은 작업을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-624">In this way, two threads can accomplish more than a single thread would.</span></span> <span data-ttu-id="a4a03-625">Hello VM 한 개 이상의 코어에 있는 경우 문제가 각 코어에서 병렬 작업을 실행할 수는 실행 시간이 더 약화 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-625">If hello VM has more than one core, it further decreases running time since each core can execute tasks in parallel.</span></span>

<span data-ttu-id="a4a03-626">단일 기본 제공 응용 프로그램을 구현 하는 수 toochange hello 방법은 필요가 없는 스레딩 또는 다중 스레딩을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-626">You may not be able toochange hello way an off-the-shelf application implements single threading or multi-threading.</span></span> <span data-ttu-id="a4a03-627">예를 들어 SQL Server는 다중 CPU 및 다중 코어를 처리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-627">For example, SQL Server is capable of handling multi-CPU and multi-core.</span></span> <span data-ttu-id="a4a03-628">그러나 SQL Server 어떤 조건에서 하나 이상의 스레드 tooprocess 쿼리를 활용 것을 결정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-628">However, SQL Server decides under what conditions it will leverage one or more threads tooprocess a query.</span></span> <span data-ttu-id="a4a03-629">다중 스레드를 사용하여 쿼리를 실행하고 인덱스를 작성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-629">It can run queries and build indexes using multi-threading.</span></span> <span data-ttu-id="a4a03-630">큰 테이블을 조인 하 고 toohello 사용자를 반환 하기 전에 데이터를 정렬 하는 쿼리에 대 한 SQL Server는 여러 스레드를 사용할 가능성이 많습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-630">For a query that involves joining large tables and sorting data before returning toohello user, SQL Server will likely use multiple threads.</span></span> <span data-ttu-id="a4a03-631">그러나 사용자는 SQL Server에서 단일 스레드 또는 다중 스레드를 사용하여 쿼리를 실행할지 여부를 제어할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-631">However, a user cannot control whether SQL Server executes a query using a single thread or multiple threads.</span></span>

<span data-ttu-id="a4a03-632">이 다중 스레딩을 사용 또는 병렬 tooinfluence를 변경할 수 구성 설정은 응용 프로그램의 처리 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-632">There are configuration settings that you can alter tooinfluence this multi-threading or parallel processing of an application.</span></span> <span data-ttu-id="a4a03-633">예를 들어, SQL server hello 최대 Degree of Parallelism 구성입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-633">For example, in case of SQL Server it is hello maximum Degree of Parallelism configuration.</span></span> <span data-ttu-id="a4a03-634">MAXDOP를 호출 합니다.이 설정을 통해 tooconfigure hello 최대 프로세서 수가 병렬 처리 하는 경우 SQL Server를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-634">This setting called MAXDOP, allows you tooconfigure hello maximum number of processors SQL Server can use when parallel processing.</span></span> <span data-ttu-id="a4a03-635">개별 쿼리 또는 인덱스 작업에 대한 MAXDOP를 구성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-635">You can configure MAXDOP for individual queries or index operations.</span></span> <span data-ttu-id="a4a03-636">이 성능이 중요 한 응용 프로그램에 대 한 시스템의 toobalance 리소스를 원하는 유용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-636">This is beneficial when you want toobalance resources of your system for a performance critical application.</span></span>

<span data-ttu-id="a4a03-637">예를 들어, SQL Server를 사용 하 여 응용 프로그램 큰 쿼리와 hello에서 인덱스 작업을 실행 중인 동시 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-637">For example, say your application using SQL Server is executing a large query and an index operation at hello same time.</span></span> <span data-ttu-id="a4a03-638">원하는 hello 인덱스 작업 toobe 자세한 비교는 고성능 toohello 큰 쿼리에서 가정해 보십시오.</span><span class="sxs-lookup"><span data-stu-id="a4a03-638">Let us assume that you wanted hello index operation toobe more performant compared toohello large query.</span></span> <span data-ttu-id="a4a03-639">이러한 경우 hello 인덱스 작업 toobe hello hello 쿼리에 대 한 MAXDOP 값 보다 높은의 MAXDOP 값을 설정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-639">In such a case, you can set MAXDOP value of hello index operation toobe higher than hello MAXDOP value for hello query.</span></span> <span data-ttu-id="a4a03-640">이러한 방식으로 SQL Server에 더 많은 수의 hello 인덱스 비교 작업 toohello 프로세서 수가 전념할 수에 대 한 활용할 수 있는 프로세서 toohello 큰 쿼리 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-640">This way, SQL Server has more number of processors that it can leverage for hello index operation compared toohello number of processors it can dedicate toohello large query.</span></span> <span data-ttu-id="a4a03-641">기억 hello 각 작업에 대해 SQL Server에서 사용 하는 스레드 수를 제어 하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-641">Remember, you do not control hello number of threads SQL Server will use for each operation.</span></span> <span data-ttu-id="a4a03-642">Hello에 대 한 전용 되는 프로세서의 최대 수를 제어할 수 있습니다 다중 스레딩을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-642">You can control hello maximum number of processors being dedicated for multi-threading.</span></span>

<span data-ttu-id="a4a03-643">SQL Server에 [병렬 처리의 정도](https://technet.microsoft.com/library/ms188611.aspx) 에 대한 자세한 정보가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-643">Learn more about [Degrees of Parallelism](https://technet.microsoft.com/library/ms188611.aspx) in SQL Server.</span></span> <span data-ttu-id="a4a03-644">확인 이러한 설정에 영향을 주는 응용 프로그램 및 구성 toooptimize 성능에 다중 스레딩을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-644">Find out such settings that influence multi-threading in your application and their configurations toooptimize performance.</span></span>

## <a name="queue-depth"></a><span data-ttu-id="a4a03-645">큐 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-645">Queue Depth</span></span>
<span data-ttu-id="a4a03-646">큐 깊이 또는 큐 길이 hello 또는 큐 크기는 hello 시스템에서 보류 중인 IO 요청 수가 hello 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-646">hello Queue Depth or Queue Length or Queue Size is hello number of pending IO requests in hello system.</span></span> <span data-ttu-id="a4a03-647">큐 깊이 hello 값 IO 작업의 수 응용 프로그램 정렬할 수 있는 hello 저장소 디스크 처리할를 결정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-647">hello value of Queue Depth determines how many IO operations your application can line up, which hello storage disks will be processing.</span></span> <span data-ttu-id="a4a03-648">모든 hello 세 개의 응용 프로그램 성능 지표를이 문서 viz. IOPS, 처리량 및 대기 시간에서에서 설명한 영향을 줍니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-648">It affects all hello three application performance indicators that we discussed in this article viz., IOPS, Throughput and Latency.</span></span>

<span data-ttu-id="a4a03-649">큐 크기 및 다중 스레딩은 밀접한 관련이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-649">Queue Depth and multi-threading are closely related.</span></span> <span data-ttu-id="a4a03-650">큐 깊이 값 hello 나타냅니다 다중 스레드는 hello 응용 프로그램에서 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-650">hello Queue Depth value indicates how much multi-threading can be achieved by hello application.</span></span> <span data-ttu-id="a4a03-651">Hello 큐 크기가 클 경우 응용 프로그램 더 많은 작업이 동시에 실행할 수, 즉, 더 다중 스레딩을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-651">If hello Queue Depth is large, application can execute more operations concurrently, in other words, more multi-threading.</span></span> <span data-ttu-id="a4a03-652">큐 깊이 hello 작으면 다중 스레드 응용 프로그램은 경우에, 동시 실행에 대 한 정렬 되도록 충분 한 요청 않아도 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-652">If hello Queue Depth is small, even though application is multi-threaded, it will not have enough requests lined up for concurrent execution.</span></span>

<span data-ttu-id="a4a03-653">일반적으로 hello 오프 선반 응용 프로그램 수 없습니다. toochange hello 큐 깊이 때문에 경우 올바르게 않습니다 하지 유익한 것 설정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-653">Typically, off hello shelf applications do not allow you toochange hello queue depth, because if set incorrectly it will do more harm than good.</span></span> <span data-ttu-id="a4a03-654">응용 프로그램의 큐 깊이 tooget hello 최적의 성능 hello 오른쪽 값을 설정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-654">Applications will set hello right value of queue depth tooget hello optimal performance.</span></span> <span data-ttu-id="a4a03-655">그러나 것은 중요 한 toounderstand이이 개념 응용 프로그램과 함께 성능 문제를 해결할 수 있도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-655">However, it is important toounderstand this concept so that you can troubleshoot performance issues with your application.</span></span> <span data-ttu-id="a4a03-656">또한 시스템에서 벤치마킹 도구를 실행 하 여 큐 깊이의 hello 효과 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-656">You can also observe hello effects of queue depth by running benchmarking tools on your system.</span></span>

<span data-ttu-id="a4a03-657">일부 응용 프로그램 설정을 tooinfluence hello 큐 깊이 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-657">Some applications provide settings tooinfluence hello Queue Depth.</span></span> <span data-ttu-id="a4a03-658">예를 들어 hello MAXDOP (최대 병렬 처리 수준) 설정을 SQL Server의 이전 섹션에서 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-658">For example, hello MAXDOP (maximum degree of parallelism) setting in SQL Server explained in previous section.</span></span> <span data-ttu-id="a4a03-659">MAXDOP 방법을 tooinfluence 큐 깊이 다중 스레드 및 SQL Server의 hello 큐 깊이 값을 직접 변경 하지 않지만 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-659">MAXDOP is a way tooinfluence Queue Depth and multi-threading, although it does not directly change hello Queue Depth value of SQL Server.</span></span>

<span data-ttu-id="a4a03-660">*높은 큐 크기*</span><span class="sxs-lookup"><span data-stu-id="a4a03-660">*High Queue Depth*</span></span>  
<span data-ttu-id="a4a03-661">높은 큐 깊이 hello 디스크에는 다양 한 작업 정렬 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-661">A high queue depth lines up more operations on hello disk.</span></span> <span data-ttu-id="a4a03-662">hello 디스크 hello 미리 큐에 다음 요청을 알고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-662">hello disk knows hello next request in its queue ahead of time.</span></span> <span data-ttu-id="a4a03-663">따라서 hello 디스크 미리 작업을 예약 하 고 최적의 순서에서 처리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-663">Consequently, hello disk can schedule operations ahead of time and process them in an optimal sequence.</span></span> <span data-ttu-id="a4a03-664">Hello 응용 프로그램에서 더 많은 요청 toohello 디스크를 보내고, 이후 hello 디스크에 더 많은 병렬 IOs 처리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-664">Since hello application is sending more requests toohello disk, hello disk can process more parallel IOs.</span></span> <span data-ttu-id="a4a03-665">Hello 응용 프로그램 수 tooachieve 됩니다 궁극적으로, 높은 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-665">Ultimately, hello application will be able tooachieve higher IOPS.</span></span> <span data-ttu-id="a4a03-666">응용 프로그램이 더 많은 요청을 처리 하 고, 이후 hello hello 응용 프로그램의 총 처리량도 증가 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-666">Since application is processing more requests, hello total Throughput of hello application also increases.</span></span>

<span data-ttu-id="a4a03-667">일반적으로 응용 프로그램에서 연결된 디스크당 8-16+ 미해결 IO로 최대 처리량을 달성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-667">Typically, an application can achieve maximum Throughput with 8-16+ outstanding IOs per attached disk.</span></span> <span data-ttu-id="a4a03-668">큐 깊이 하나 경우 응용 프로그램은 충분 한 IOs toohello 시스템 푸시 하지 못하는 하 고 지정 된 기간 동안에서 적은 양의 처리 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-668">If a Queue Depth is one, application is not pushing enough IOs toohello system, and it will process less amount of in a given period.</span></span> <span data-ttu-id="a4a03-669">즉, 적은 처리량입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-669">In other words, less Throughput.</span></span>

<span data-ttu-id="a4a03-670">예를 들어 SQL Server의 설정을 hello MAXDOP 값 쿼리에 대 한 너무 "4" toofour 코어 tooexecute hello 쿼리를 사용할 수 있는 SQL Server에 알립니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-670">For example, in SQL Server, setting hello MAXDOP value for a query too"4" informs SQL Server that it can use up toofour cores tooexecute hello query.</span></span> <span data-ttu-id="a4a03-671">SQL Server 수는 얼마 입니까 최적의 큐 깊이 값과 hello hello 쿼리 실행에 대 한 코어를 결정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-671">SQL Server will determine what is best queue depth value and hello number of cores for hello query execution.</span></span>

<span data-ttu-id="a4a03-672">*최적의 큐 크기*</span><span class="sxs-lookup"><span data-stu-id="a4a03-672">*Optimal Queue Depth*</span></span>  
<span data-ttu-id="a4a03-673">매우 높은 큐 크기 값 또한 단점이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-673">Very high queue depth value also has its drawbacks.</span></span> <span data-ttu-id="a4a03-674">Hello 응용 프로그램에서 toodrive 시도 큐 깊이 값이 너무 높으면 매우 높은 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-674">If queue depth value is too high, hello application will try toodrive very high IOPS.</span></span> <span data-ttu-id="a4a03-675">응용 프로그램에 프로비전된 충분한 IOPS의 영구 디스크가 있지 않는 한 응용 프로그램 대기 시간이 늘어날 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-675">Unless application has persistent disks with sufficient provisioned IOPS, this can negatively affect application latencies.</span></span> <span data-ttu-id="a4a03-676">다음 수식을 IOPS, 대기 시간 및 큐 깊이 hello 관계를 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-676">Following formula shows hello relationship between IOPS, Latency and Queue Depth.</span></span>  
    ![](media/storage-premium-storage-performance/image6.png)

<span data-ttu-id="a4a03-677">큐 깊이 tooany 높은 값과 동일 하지만 대기 시간이 영향을 주지 않고 hello 응용 프로그램에 대 한 충분 한 IOPS를 배달할 수는 tooan 최적 값으로 구성 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-677">You should not configure Queue Depth tooany high value, but tooan optimal value, which can deliver enough IOPS for hello application without affecting latencies.</span></span> <span data-ttu-id="a4a03-678">예를 들어 hello 응용 프로그램 대기 시간 요구 toobe 1 밀리초, hello 큐 깊이 tooachieve 5,000 IOPS는 QD 필요한 = 5000 x 0.001 = 5.</span><span class="sxs-lookup"><span data-stu-id="a4a03-678">For example, if hello application latency needs toobe 1 millisecond, hello Queue Depth required tooachieve 5,000 IOPS is, QD = 5000 x 0.001 = 5.</span></span>

<span data-ttu-id="a4a03-679">*스트라이프 볼륨에 대한 큐 크기*</span><span class="sxs-lookup"><span data-stu-id="a4a03-679">*Queue Depth for Striped Volume*</span></span>  
<span data-ttu-id="a4a03-680">그러한 충분한 큐 크기를 유지하는 스트라이프 볼륨의 경우 모든 디스크는 개별적으로 최대 큐 크기를 가집니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-680">For a striped volume, maintain a high enough queue depth such that, every disk has a peak queue depth individually.</span></span> <span data-ttu-id="a4a03-681">예를 들어 2 개 큐 깊이 푸시하는 응용 프로그램 및 hello stripe 된 4 개의 디스크가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-681">For example, consider an application that pushes a queue depth of 2 and there are 4 disks in hello stripe.</span></span> <span data-ttu-id="a4a03-682">hello 두 I/O 요청이 tootwo 디스크 되 고 나머지 두 개 이상의 디스크 유휴 상태가 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-682">hello two IO requests will go tootwo disks and remaining two disks will be idle.</span></span> <span data-ttu-id="a4a03-683">따라서 구성할 hello 큐 깊이 hello 디스크를 모두 사용 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-683">Therefore, configure hello queue depth such that all hello disks can be busy.</span></span> <span data-ttu-id="a4a03-684">아래 수식을 toodetermine 스트라이프 볼륨 큐 깊이 hello 하는 방법을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-684">Formula below shows how toodetermine hello queue depth of striped volumes.</span></span>  
    ![](media/storage-premium-storage-performance/image7.png)

## <a name="throttling"></a><span data-ttu-id="a4a03-685">제한</span><span class="sxs-lookup"><span data-stu-id="a4a03-685">Throttling</span></span>
<span data-ttu-id="a4a03-686">Azure 프리미엄 저장소 프로 비전 hello VM 크기와 선택한 디스크 크기에 따라 처리량 및 IOPS 수를 지정 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-686">Azure Premium Storage provisions specified number of IOPS and Throughput depending on hello VM sizes and disk sizes you choose.</span></span> <span data-ttu-id="a4a03-687">응용 프로그램이 어떤 hello VM 또는 디스크를 처리할 수의이 제한 보다 높게 toodrive IOPS 또는 처리량을 시도 하면, 언제 든 지 것 프리미엄 저장소 조절 됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-687">Anytime your application tries toodrive IOPS or Throughput above these limits of what hello VM or disk can handle, Premium Storage will throttle it.</span></span> <span data-ttu-id="a4a03-688">이 응용 프로그램에서 성능 저하의 hello 형태로 나타납니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-688">This manifests in hello form of degraded performance in your application.</span></span> <span data-ttu-id="a4a03-689">이는 더 높은 대기 시간, 더 낮은 처리량 또는 더 낮은 IOPS를 의미할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-689">This can mean higher latency, lower Throughput or lower IOPS.</span></span> <span data-ttu-id="a4a03-690">프리미엄 저장소가 제한하지 않는 경우 응용 프로그램은 리소스가 달성할 수 있는 한도를 초과하여 완전히 실패할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-690">If Premium Storage does not throttle, your application could completely fail by exceeding what its resources are capable of achieving.</span></span> <span data-ttu-id="a4a03-691">따라서 tooavoid 성능 문제 due toothrottling, 응용 프로그램에 대 한 충분 한 리소스가 프로 비전 항상 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-691">So, tooavoid performance issues due toothrottling, always provision sufficient resources for your application.</span></span> <span data-ttu-id="a4a03-692">Hello VM 크기 및 디스크 크기 위의 섹션에서 설명한 고려 고려 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-692">Take into consideration what we discussed in hello VM sizes and Disk sizes sections above.</span></span> <span data-ttu-id="a4a03-693">가장 좋은 방법은 toofigure hello은 벤치마킹 어떤 리소스를 해야 toohost 응용 프로그램입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-693">Benchmarking is hello best way toofigure out what resources you will need toohost your application.</span></span>

## <a name="benchmarking"></a><span data-ttu-id="a4a03-694">벤치마킹</span><span class="sxs-lookup"><span data-stu-id="a4a03-694">Benchmarking</span></span>
<span data-ttu-id="a4a03-695">벤치 마크는 응용 프로그램에 다양 한 작업 부하를 시뮬레이션 하 고 각 작업에 대 한 hello 응용 프로그램 성능을 측정의 hello 프로세스입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-695">Benchmarking is hello process of simulating different workloads on your application and measuring hello application performance for each workload.</span></span> <span data-ttu-id="a4a03-696">이전 섹션에서 설명 하는 hello 단계를 사용 하 여 수집한 hello 응용 프로그램에 대 한 성능 요구 사항입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-696">Using hello steps described in an earlier section, you have gathered hello application performance requirements.</span></span> <span data-ttu-id="a4a03-697">Hello 응용 프로그램을 호스트 하는 hello Vm에 도구, 즉 벤치마킹를 실행 하 여 응용 프로그램 프리미엄 저장소를 얻을 수 있는 hello 성능 수준을 결정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-697">By running benchmarking tools on hello VMs hosting hello application, you can determine hello performance levels that your application can achieve with Premium Storage.</span></span> <span data-ttu-id="a4a03-698">이 섹션에서는 Azure 프리미엄 저장소 디스크로 프로비전된 Standard DS14 VM 벤치마킹의 예를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-698">In this section, we provide you examples of benchmarking a Standard DS14 VM provisioned with Azure Premium Storage disks.</span></span>

<span data-ttu-id="a4a03-699">Windows 및 Linux용으로 각각 일반 벤치마킹 도구 Iometer 및 FIO를 사용했습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-699">We have used common benchmarking tools Iometer and FIO, for Windows and Linux respectively.</span></span> <span data-ttu-id="a4a03-700">이러한 도구는 여러 스레드를 프로덕션과 유사한 작업 및 hello 시스템 성능을 측정 시뮬레이션을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-700">These tools spawn multiple threads simulating a production like workload, and measure hello system performance.</span></span> <span data-ttu-id="a4a03-701">Hello 도구를 사용 하 여 일반적으로 응용 프로그램에 대 한 변경할 수 없습니다 블록 크기 및 큐 깊이 같은 매개 변수를 구성할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-701">Using hello tools you can also configure parameters like block size and queue depth, which you normally cannot change for an application.</span></span> <span data-ttu-id="a4a03-702">이렇게 하면 더 많은 유연성 toodrive hello 최대 성능을 대규모 VM 프로 비전 되어 다양 한 유형의 응용 프로그램 작업에 대 한 프리미엄 디스크에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-702">This gives you more flexibility toodrive hello maximum performance on a high scale VM provisioned with premium disks for different types of application workloads.</span></span> <span data-ttu-id="a4a03-703">방문 벤치마킹 각 도구에 대 한 자세한 toolearn [Iometer](http://www.iometer.org/) 및 [FIO](http://freecode.com/projects/fio)합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-703">toolearn more about each benchmarking tool visit [Iometer](http://www.iometer.org/) and [FIO](http://freecode.com/projects/fio).</span></span>

<span data-ttu-id="a4a03-704">toofollow hello 아래의 예제에서 표준 DS14 VM을 만들고 11 프리미엄 저장소 디스크 toohello VM을 연결 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-704">toofollow hello examples below, create a Standard DS14 VM and attach 11 Premium Storage disks toohello VM.</span></span> <span data-ttu-id="a4a03-705">Hello 11 디스크의 캐싱 "None"으로 호스트와 10 디스크를 구성 하 고 NoCacheWrites를 호출 하는 볼륨으로이 스트라이프 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-705">Of hello 11 disks, configure 10 disks with host caching as "None" and stripe them into a volume called NoCacheWrites.</span></span> <span data-ttu-id="a4a03-706">Hello 남아 있는 디스크에 "ReadOnly"로 캐시 호스트를 구성 하 고이 디스크를 사용 하 여 CacheReads를 호출 하는 볼륨을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-706">Configure host caching as "ReadOnly" on hello remaining disk and create a volume called CacheReads with this disk.</span></span> <span data-ttu-id="a4a03-707">이 설치 프로그램을 사용 하 여 수 toosee hello 최대 읽기 및 쓰기 성능을 표준 DS14 VM에서 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-707">Using this setup, you will be able toosee hello maximum Read and Write performance from a Standard DS14 VM.</span></span> <span data-ttu-id="a4a03-708">프리미엄 디스크를 사용 하 여 DS14 VM 만들기에 대 한 자세한 단계에 대 한 이동 너무[만들기 및 사용 하 여 데이터 디스크를 가상 컴퓨터에 대 한 프리미엄 저장소 계정](../storage-premium-storage.md)합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-708">For detailed steps about creating a DS14 VM with premium disks, go too[Create and use a Premium Storage account for a virtual machine data disk](../storage-premium-storage.md).</span></span>

<span data-ttu-id="a4a03-709">*Hello 캐시를 준비 중*</span><span class="sxs-lookup"><span data-stu-id="a4a03-709">*Warming up hello Cache*</span></span>  
<span data-ttu-id="a4a03-710">읽기 전용 호스트 캐싱 hello 디스크 수 toogive 됩니다 hello 디스크 제한 보다 더 높은 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-710">hello disk with ReadOnly host caching will be able toogive higher IOPS than hello disk limit.</span></span> <span data-ttu-id="a4a03-711">tooget이이 최대 성능 hello 호스트 캐시에서 읽어, 먼저이 디스크의 hello 캐시를 준비 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-711">tooget this maximum read performance from hello host cache, first you must warm up hello cache of this disk.</span></span> <span data-ttu-id="a4a03-712">이렇게 하면 해당 hello 읽기 IOs 벤치마킹 도구 CacheReads 볼륨에 드라이브는 실제로 도달 hello 캐시와 hello 디스크가 아닌 직접 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-712">This ensures that hello Read IOs which benchmarking tool will drive on CacheReads volume actually hits hello cache and not hello disk directly.</span></span> <span data-ttu-id="a4a03-713">hello 캐시 적중 결과 hello 단일 캐시에서 추가 IOPS에 디스크를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-713">hello cache hits result in additional IOPS from hello single cache enabled disk.</span></span>

> <span data-ttu-id="a4a03-714">**중요:**</span><span class="sxs-lookup"><span data-stu-id="a4a03-714">**Important:**</span></span>  
> <span data-ttu-id="a4a03-715">VM 다시 부팅 될 때마다 벤치마킹를 실행 하기 전에 hello 캐시를 준비 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-715">You must warm up hello cache before running benchmarking, every time VM is rebooted.</span></span>
>
>

#### <a name="iometer"></a><span data-ttu-id="a4a03-716">Iometer</span><span class="sxs-lookup"><span data-stu-id="a4a03-716">Iometer</span></span>
<span data-ttu-id="a4a03-717">[Hello Iometer 도구를 다운로드](http://sourceforge.net/projects/iometer/files/iometer-stable/2006-07-27/iometer-2006.07.27.win32.i386-setup.exe/download) hello VM에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-717">[Download hello Iometer tool](http://sourceforge.net/projects/iometer/files/iometer-stable/2006-07-27/iometer-2006.07.27.win32.i386-setup.exe/download) on hello VM.</span></span>

<span data-ttu-id="a4a03-718">*테스트 파일*</span><span class="sxs-lookup"><span data-stu-id="a4a03-718">*Test file*</span></span>  
<span data-ttu-id="a4a03-719">Iometer는 테스트, 즉 벤치마킹 hello 실행 될 hello 볼륨에 저장 된 테스트 파일을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-719">Iometer uses a test file that is stored on hello volume on which you will run hello benchmarking test.</span></span> <span data-ttu-id="a4a03-720">계획과 읽기 및 쓰기에이 파일 toomeasure hello 디스크 IOPS 및 처리량 테스트 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-720">It drives Reads and Writes on this test file toomeasure hello disk IOPS and Throughput.</span></span> <span data-ttu-id="a4a03-721">Iometer는 이 테스트 파일을 제공받지 않은 경우 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-721">Iometer creates this test file if you have not provided one.</span></span> <span data-ttu-id="a4a03-722">Hello CacheReads 및 NoCacheWrites 볼륨에 iobw.tst 라는 200GB 테스트 파일을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-722">Create a 200GB test file called iobw.tst on hello CacheReads and NoCacheWrites volumes.</span></span>

<span data-ttu-id="a4a03-723">*액세스 사양*</span><span class="sxs-lookup"><span data-stu-id="a4a03-723">*Access Specifications*</span></span>  
<span data-ttu-id="a4a03-724">hello 사양, 요청 크기 IO % 읽기/쓰기, % 임의/순차적 구성 해 보고 Iometer hello "Access 사양" 탭을 사용 하 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-724">hello specifications, request IO size, % read/write, % random/sequential are configured using hello "Access Specifications" tab in Iometer.</span></span> <span data-ttu-id="a4a03-725">각 아래에 설명 된 hello 시나리오에 대 한 액세스 사양을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-725">Create an access specification for each of hello scenarios described below.</span></span> <span data-ttu-id="a4a03-726">Hello 액세스 사양이 만들고 "저장" 가능한 적절 한 이름을 같은 – RandomWrites\_8k RandomReads\_8k 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-726">Create hello access specifications and "Save" with an appropriate name like – RandomWrites\_8K, RandomReads\_8K.</span></span> <span data-ttu-id="a4a03-727">Hello 테스트 시나리오를 실행 하는 경우 해당 하는 hello 설정을 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-727">Select hello corresponding specification when running hello test scenario.</span></span>

<span data-ttu-id="a4a03-728">최대 쓰기 IOPS 시나리오에 대한 액세스 사양의 예는 아래와 같습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-728">An example of access specifications for maximum Write IOPS scenario is shown below,</span></span>  
    ![](media/storage-premium-storage-performance/image8.png)

<span data-ttu-id="a4a03-729">*최대 IOPS 테스트 사양*</span><span class="sxs-lookup"><span data-stu-id="a4a03-729">*Maximum IOPS Test Specifications*</span></span>  
<span data-ttu-id="a4a03-730">toodemonstrate 최대 IOPs 보다 작은 요청 크기를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-730">toodemonstrate maximum IOPs, use smaller request size.</span></span> <span data-ttu-id="a4a03-731">8K 요청 크기를 사용하고 임의 쓰기 및 읽기에 대한 사양을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-731">Use 8K request size and create specifications for Random Writes and Reads.</span></span>

| <span data-ttu-id="a4a03-732">액세스 사양</span><span class="sxs-lookup"><span data-stu-id="a4a03-732">Access Specification</span></span> | <span data-ttu-id="a4a03-733">요청 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-733">Request size</span></span> | <span data-ttu-id="a4a03-734">임의 %</span><span class="sxs-lookup"><span data-stu-id="a4a03-734">Random %</span></span> | <span data-ttu-id="a4a03-735">읽기 %</span><span class="sxs-lookup"><span data-stu-id="a4a03-735">Read %</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="a4a03-736">RandomWrites\_8K</span><span class="sxs-lookup"><span data-stu-id="a4a03-736">RandomWrites\_8K</span></span> |<span data-ttu-id="a4a03-737">8K</span><span class="sxs-lookup"><span data-stu-id="a4a03-737">8K</span></span> |<span data-ttu-id="a4a03-738">100</span><span class="sxs-lookup"><span data-stu-id="a4a03-738">100</span></span> |<span data-ttu-id="a4a03-739">0</span><span class="sxs-lookup"><span data-stu-id="a4a03-739">0</span></span> |
| <span data-ttu-id="a4a03-740">RandomReads\_8K</span><span class="sxs-lookup"><span data-stu-id="a4a03-740">RandomReads\_8K</span></span> |<span data-ttu-id="a4a03-741">8K</span><span class="sxs-lookup"><span data-stu-id="a4a03-741">8K</span></span> |<span data-ttu-id="a4a03-742">100</span><span class="sxs-lookup"><span data-stu-id="a4a03-742">100</span></span> |<span data-ttu-id="a4a03-743">100</span><span class="sxs-lookup"><span data-stu-id="a4a03-743">100</span></span> |

<span data-ttu-id="a4a03-744">*최대 처리량 테스트 사양*</span><span class="sxs-lookup"><span data-stu-id="a4a03-744">*Maximum Throughput Test Specifications*</span></span>  
<span data-ttu-id="a4a03-745">toodemonstrate 최대 처리량을 더 큰 요청 크기를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-745">toodemonstrate maximum Throughput, use larger request size.</span></span> <span data-ttu-id="a4a03-746">64K 요청 크기를 사용하여 임의 쓰기 및 읽기에 대한 사양을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-746">Use 64K request size and create specifications for Random Writes and Reads.</span></span>

| <span data-ttu-id="a4a03-747">액세스 사양</span><span class="sxs-lookup"><span data-stu-id="a4a03-747">Access Specification</span></span> | <span data-ttu-id="a4a03-748">요청 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-748">Request size</span></span> | <span data-ttu-id="a4a03-749">임의 %</span><span class="sxs-lookup"><span data-stu-id="a4a03-749">Random %</span></span> | <span data-ttu-id="a4a03-750">읽기 %</span><span class="sxs-lookup"><span data-stu-id="a4a03-750">Read %</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="a4a03-751">RandomWrites\_64K</span><span class="sxs-lookup"><span data-stu-id="a4a03-751">RandomWrites\_64K</span></span> |<span data-ttu-id="a4a03-752">64K</span><span class="sxs-lookup"><span data-stu-id="a4a03-752">64K</span></span> |<span data-ttu-id="a4a03-753">100</span><span class="sxs-lookup"><span data-stu-id="a4a03-753">100</span></span> |<span data-ttu-id="a4a03-754">0</span><span class="sxs-lookup"><span data-stu-id="a4a03-754">0</span></span> |
| <span data-ttu-id="a4a03-755">RandomReads\_64K</span><span class="sxs-lookup"><span data-stu-id="a4a03-755">RandomReads\_64K</span></span> |<span data-ttu-id="a4a03-756">64K</span><span class="sxs-lookup"><span data-stu-id="a4a03-756">64K</span></span> |<span data-ttu-id="a4a03-757">100</span><span class="sxs-lookup"><span data-stu-id="a4a03-757">100</span></span> |<span data-ttu-id="a4a03-758">100</span><span class="sxs-lookup"><span data-stu-id="a4a03-758">100</span></span> |

<span data-ttu-id="a4a03-759">*Hello Iometer 테스트 실행*</span><span class="sxs-lookup"><span data-stu-id="a4a03-759">*Running hello Iometer Test*</span></span>  
<span data-ttu-id="a4a03-760">캐시를 toowarm 아래 hello 단계를 수행 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-760">Perform hello steps below toowarm up cache</span></span>

1. <span data-ttu-id="a4a03-761">아래에 표시된 값으로 두 액세스 사양을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-761">Create two access specifications with values shown below,</span></span>

   | <span data-ttu-id="a4a03-762">이름</span><span class="sxs-lookup"><span data-stu-id="a4a03-762">Name</span></span> | <span data-ttu-id="a4a03-763">요청 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-763">Request size</span></span> | <span data-ttu-id="a4a03-764">임의 %</span><span class="sxs-lookup"><span data-stu-id="a4a03-764">Random %</span></span> | <span data-ttu-id="a4a03-765">읽기 %</span><span class="sxs-lookup"><span data-stu-id="a4a03-765">Read %</span></span> |
   | --- | --- | --- | --- |
   | <span data-ttu-id="a4a03-766">RandomWrites\_1MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-766">RandomWrites\_1MB</span></span> |<span data-ttu-id="a4a03-767">1MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-767">1MB</span></span> |<span data-ttu-id="a4a03-768">100</span><span class="sxs-lookup"><span data-stu-id="a4a03-768">100</span></span> |<span data-ttu-id="a4a03-769">0</span><span class="sxs-lookup"><span data-stu-id="a4a03-769">0</span></span> |
   | <span data-ttu-id="a4a03-770">RandomReads\_1MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-770">RandomReads\_1MB</span></span> |<span data-ttu-id="a4a03-771">1MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-771">1MB</span></span> |<span data-ttu-id="a4a03-772">100</span><span class="sxs-lookup"><span data-stu-id="a4a03-772">100</span></span> |<span data-ttu-id="a4a03-773">100</span><span class="sxs-lookup"><span data-stu-id="a4a03-773">100</span></span> |
2. <span data-ttu-id="a4a03-774">다음 매개 변수가 있는 캐시 디스크를 초기화 하기 위한 hello Iometer 테스트를 실행 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-774">Run hello Iometer test for initializing cache disk with following parameters.</span></span> <span data-ttu-id="a4a03-775">Hello 대상 볼륨 및 128 개 큐 깊이 대 한 세 개의 작업자 스레드를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-775">Use three worker threads for hello target volume and a queue depth of 128.</span></span> <span data-ttu-id="a4a03-776">설정 "실행 시간" hello "테스트 설정" 탭에서 테스트 too2hrs hello 기간 hello 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-776">Set hello "Run time" duration of hello test too2hrs on hello "Test Setup" tab.</span></span>

   | <span data-ttu-id="a4a03-777">시나리오</span><span class="sxs-lookup"><span data-stu-id="a4a03-777">Scenario</span></span> | <span data-ttu-id="a4a03-778">대상 볼륨</span><span class="sxs-lookup"><span data-stu-id="a4a03-778">Target Volume</span></span> | <span data-ttu-id="a4a03-779">이름</span><span class="sxs-lookup"><span data-stu-id="a4a03-779">Name</span></span> | <span data-ttu-id="a4a03-780">기간</span><span class="sxs-lookup"><span data-stu-id="a4a03-780">Duration</span></span> |
   | --- | --- | --- | --- |
   | <span data-ttu-id="a4a03-781">디스크 캐시 초기화</span><span class="sxs-lookup"><span data-stu-id="a4a03-781">Initialize Cache Disk</span></span> |<span data-ttu-id="a4a03-782">CacheReads</span><span class="sxs-lookup"><span data-stu-id="a4a03-782">CacheReads</span></span> |<span data-ttu-id="a4a03-783">RandomWrites\_1MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-783">RandomWrites\_1MB</span></span> |<span data-ttu-id="a4a03-784">2hrs</span><span class="sxs-lookup"><span data-stu-id="a4a03-784">2hrs</span></span> |
3. <span data-ttu-id="a4a03-785">다음 매개 변수가 있는 디스크 캐시를 준비 하는 중에 대 한 hello Iometer 테스트를 실행 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-785">Run hello Iometer test for warming up cache disk with following parameters.</span></span> <span data-ttu-id="a4a03-786">Hello 대상 볼륨 및 128 개 큐 깊이 대 한 세 개의 작업자 스레드를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-786">Use three worker threads for hello target volume and a queue depth of 128.</span></span> <span data-ttu-id="a4a03-787">설정 "실행 시간" hello "테스트 설정" 탭에서 테스트 too2hrs hello 기간 hello 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-787">Set hello "Run time" duration of hello test too2hrs on hello "Test Setup" tab.</span></span>

   | <span data-ttu-id="a4a03-788">시나리오</span><span class="sxs-lookup"><span data-stu-id="a4a03-788">Scenario</span></span> | <span data-ttu-id="a4a03-789">대상 볼륨</span><span class="sxs-lookup"><span data-stu-id="a4a03-789">Target Volume</span></span> | <span data-ttu-id="a4a03-790">이름</span><span class="sxs-lookup"><span data-stu-id="a4a03-790">Name</span></span> | <span data-ttu-id="a4a03-791">기간</span><span class="sxs-lookup"><span data-stu-id="a4a03-791">Duration</span></span> |
   | --- | --- | --- | --- |
   | <span data-ttu-id="a4a03-792">캐시 디스크 준비</span><span class="sxs-lookup"><span data-stu-id="a4a03-792">Warm up Cache Disk</span></span> |<span data-ttu-id="a4a03-793">CacheReads</span><span class="sxs-lookup"><span data-stu-id="a4a03-793">CacheReads</span></span> |<span data-ttu-id="a4a03-794">RandomReads\_1MB</span><span class="sxs-lookup"><span data-stu-id="a4a03-794">RandomReads\_1MB</span></span> |<span data-ttu-id="a4a03-795">2hrs</span><span class="sxs-lookup"><span data-stu-id="a4a03-795">2hrs</span></span> |

<span data-ttu-id="a4a03-796">캐시 디스크 준비는 후에 아래에 나열 된 hello 테스트 시나리오를 진행 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-796">After cache disk is warmed up, proceed with hello test scenarios listed below.</span></span> <span data-ttu-id="a4a03-797">toorun hello Iometer 테스트에 대 한 세 개 이상의 작업자 스레드를 사용 하 여 **각** 볼륨 대상으로 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-797">toorun hello Iometer test, use at least three worker threads for **each** target volume.</span></span> <span data-ttu-id="a4a03-798">각 작업자 스레드에 대해 hello 대상 볼륨을 선택 하 고 큐 깊이 설정 toorun hello 해당 테스트 시나리오 아래 hello 표에 표시 된 대로 저장 하는 hello 테스트 사양 중 하나를 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-798">For each worker thread, select hello target volume, set queue depth and select one of hello saved test specifications, as shown in hello table below, toorun hello corresponding test scenario.</span></span> <span data-ttu-id="a4a03-799">hello 테이블도 예상된 결과가 나와 IOPS 및 처리량에 대 한 이러한 테스트를 실행 하는 경우.</span><span class="sxs-lookup"><span data-stu-id="a4a03-799">hello table also shows expected results for IOPS and Throughput when running these tests.</span></span> <span data-ttu-id="a4a03-800">모든 시나리오의 경우 8KB의 작은 IO 크기 및 128의 높은 큐 크기가 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-800">For all scenarios, a small IO size of 8KB and a high queue depth of 128 is used.</span></span>

| <span data-ttu-id="a4a03-801">테스트 시나리오</span><span class="sxs-lookup"><span data-stu-id="a4a03-801">Test Scenario</span></span> | <span data-ttu-id="a4a03-802">대상 볼륨</span><span class="sxs-lookup"><span data-stu-id="a4a03-802">Target Volume</span></span> | <span data-ttu-id="a4a03-803">이름</span><span class="sxs-lookup"><span data-stu-id="a4a03-803">Name</span></span> | <span data-ttu-id="a4a03-804">결과</span><span class="sxs-lookup"><span data-stu-id="a4a03-804">Result</span></span> |
| --- | --- | --- | --- |
| <span data-ttu-id="a4a03-805">최대</span><span class="sxs-lookup"><span data-stu-id="a4a03-805">Max.</span></span> <span data-ttu-id="a4a03-806">읽기 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-806">Read IOPS</span></span> |<span data-ttu-id="a4a03-807">CacheReads</span><span class="sxs-lookup"><span data-stu-id="a4a03-807">CacheReads</span></span> |<span data-ttu-id="a4a03-808">RandomWrites\_8K</span><span class="sxs-lookup"><span data-stu-id="a4a03-808">RandomWrites\_8K</span></span> |<span data-ttu-id="a4a03-809">50,000 IOPS </span><span class="sxs-lookup"><span data-stu-id="a4a03-809">50,000 IOPS</span></span> |
| <span data-ttu-id="a4a03-810">최대</span><span class="sxs-lookup"><span data-stu-id="a4a03-810">Max.</span></span> <span data-ttu-id="a4a03-811">쓰기 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-811">Write IOPS</span></span> |<span data-ttu-id="a4a03-812">NoCacheWrites</span><span class="sxs-lookup"><span data-stu-id="a4a03-812">NoCacheWrites</span></span> |<span data-ttu-id="a4a03-813">RandomReads\_8K</span><span class="sxs-lookup"><span data-stu-id="a4a03-813">RandomReads\_8K</span></span> |<span data-ttu-id="a4a03-814">64,000 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-814">64,000 IOPS</span></span> |
| <span data-ttu-id="a4a03-815">최대</span><span class="sxs-lookup"><span data-stu-id="a4a03-815">Max.</span></span> <span data-ttu-id="a4a03-816">결합된 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-816">Combined IOPS</span></span> |<span data-ttu-id="a4a03-817">CacheReads</span><span class="sxs-lookup"><span data-stu-id="a4a03-817">CacheReads</span></span> |<span data-ttu-id="a4a03-818">RandomWrites\_8K</span><span class="sxs-lookup"><span data-stu-id="a4a03-818">RandomWrites\_8K</span></span> |<span data-ttu-id="a4a03-819">100,000 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-819">100,000 IOPS</span></span> |
| <span data-ttu-id="a4a03-820">NoCacheWrites</span><span class="sxs-lookup"><span data-stu-id="a4a03-820">NoCacheWrites</span></span> |<span data-ttu-id="a4a03-821">RandomReads\_8K</span><span class="sxs-lookup"><span data-stu-id="a4a03-821">RandomReads\_8K</span></span> | &nbsp; | &nbsp; |
| <span data-ttu-id="a4a03-822">최대</span><span class="sxs-lookup"><span data-stu-id="a4a03-822">Max.</span></span> <span data-ttu-id="a4a03-823">읽기 MB/초</span><span class="sxs-lookup"><span data-stu-id="a4a03-823">Read MB/sec</span></span> |<span data-ttu-id="a4a03-824">CacheReads</span><span class="sxs-lookup"><span data-stu-id="a4a03-824">CacheReads</span></span> |<span data-ttu-id="a4a03-825">RandomWrites\_64K</span><span class="sxs-lookup"><span data-stu-id="a4a03-825">RandomWrites\_64K</span></span> |<span data-ttu-id="a4a03-826">524MB/초</span><span class="sxs-lookup"><span data-stu-id="a4a03-826">524 MB/sec</span></span> |
| <span data-ttu-id="a4a03-827">최대</span><span class="sxs-lookup"><span data-stu-id="a4a03-827">Max.</span></span> <span data-ttu-id="a4a03-828">쓰기 MB/초</span><span class="sxs-lookup"><span data-stu-id="a4a03-828">Write MB/sec</span></span> |<span data-ttu-id="a4a03-829">NoCacheWrites</span><span class="sxs-lookup"><span data-stu-id="a4a03-829">NoCacheWrites</span></span> |<span data-ttu-id="a4a03-830">RandomReads\_64K</span><span class="sxs-lookup"><span data-stu-id="a4a03-830">RandomReads\_64K</span></span> |<span data-ttu-id="a4a03-831">524MB/초</span><span class="sxs-lookup"><span data-stu-id="a4a03-831">524 MB/sec</span></span> |
| <span data-ttu-id="a4a03-832">결합된 MB/초</span><span class="sxs-lookup"><span data-stu-id="a4a03-832">Combined MB/sec</span></span> |<span data-ttu-id="a4a03-833">CacheReads</span><span class="sxs-lookup"><span data-stu-id="a4a03-833">CacheReads</span></span> |<span data-ttu-id="a4a03-834">RandomWrites\_64K</span><span class="sxs-lookup"><span data-stu-id="a4a03-834">RandomWrites\_64K</span></span> |<span data-ttu-id="a4a03-835">1000MB/초</span><span class="sxs-lookup"><span data-stu-id="a4a03-835">1000 MB/sec</span></span> |
| <span data-ttu-id="a4a03-836">NoCacheWrites</span><span class="sxs-lookup"><span data-stu-id="a4a03-836">NoCacheWrites</span></span> |<span data-ttu-id="a4a03-837">RandomReads\_64K</span><span class="sxs-lookup"><span data-stu-id="a4a03-837">RandomReads\_64K</span></span> | &nbsp; | &nbsp; |

<span data-ttu-id="a4a03-838">Hello의 스크린 샷을 결합 된 IOPS 및 처리량 시나리오에 대 한 해 보고 Iometer 테스트 결과 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-838">Below are screenshots of hello Iometer test results for combined IOPS and Throughput scenarios.</span></span>

<span data-ttu-id="a4a03-839">*읽기 및 쓰기 최대 IOPS를 결합*</span><span class="sxs-lookup"><span data-stu-id="a4a03-839">*Combined Reads and Writes Maximum IOPS*</span></span>  
![](media/storage-premium-storage-performance/image9.png)

<span data-ttu-id="a4a03-840">*읽기 및 쓰기 최대 처리량을 결합*</span><span class="sxs-lookup"><span data-stu-id="a4a03-840">*Combined Reads and Writes Maximum Throughput*</span></span>  
![](media/storage-premium-storage-performance/image10.png)

### <a name="fio"></a><span data-ttu-id="a4a03-841">FIO</span><span class="sxs-lookup"><span data-stu-id="a4a03-841">FIO</span></span>
<span data-ttu-id="a4a03-842">FIO는 hello Linux Vm의 경우에 인기 있는 도구 toobenchmark 저장소입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-842">FIO is a popular tool toobenchmark storage on hello Linux VMs.</span></span> <span data-ttu-id="a4a03-843">Hello 유연성 tooselect 다른 IO 크기, 순차 또는 임의 읽기 및 쓰기를에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-843">It has hello flexibility tooselect different IO sizes, sequential or random reads and writes.</span></span> <span data-ttu-id="a4a03-844">작업자 스레드를 생성 또는 프로세스 tooperform hello I/O 작업을 지정 하십시오.</span><span class="sxs-lookup"><span data-stu-id="a4a03-844">It spawns worker threads or processes tooperform hello specified I/O operations.</span></span> <span data-ttu-id="a4a03-845">각 작업자 스레드가 작업 파일을 사용 하 여 수행 해야 하는 I/O 작업의 hello 유형을 지정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-845">You can specify hello type of I/O operations each worker thread must perform using job files.</span></span> <span data-ttu-id="a4a03-846">아래의 hello 예제에 나와 있는 시나리오로 당 하나의 작업 파일을 만들었습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-846">We created one job file per scenario illustrated in hello examples below.</span></span> <span data-ttu-id="a4a03-847">이러한 작업 파일 toobenchmark 다른 작업에서 프리미엄 저장소에서 실행 중인 hello 사양을 변경할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-847">You can change hello specifications in these job files toobenchmark different workloads running on Premium Storage.</span></span> <span data-ttu-id="a4a03-848">Hello 예제에서 사용 하 여 표준 DS 14 VM 실행 **Ubuntu**합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-848">In hello examples, we are using a Standard DS 14 VM running **Ubuntu**.</span></span> <span data-ttu-id="a4a03-849">사용 하 여 hello hello의 hello 시작 부분에 설명 된 동일한 설치 [섹션, 즉 벤치마킹](#Benchmarking) 및 테스트, 즉 벤치마킹 hello를 실행 하기 전에 hello 캐시를 준비 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-849">Use hello same setup described in hello beginning of hello [Benchmarking section](#Benchmarking) and warm up hello cache before running hello benchmarking tests.</span></span>

<span data-ttu-id="a4a03-850">시작하기 전에 [FIO를 다운로드](https://github.com/axboe/fio) 하고 가상 컴퓨터에 설치합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-850">Before you begin, [download FIO](https://github.com/axboe/fio) and install it on your virtual machine.</span></span>

<span data-ttu-id="a4a03-851">Hello, Ubuntu 용 다음 명령을 실행 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-851">Run hello following command for Ubuntu,</span></span>

```
apt-get install fio
```

<span data-ttu-id="a4a03-852">Hello 디스크에서 구동 읽기 작업에 대 한 쓰기 작업을 이끌어내기 위한 4 개의 작업자 스레드 및 4 개의 작업자 스레드가 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-852">We will use four worker threads for driving Write operations and four worker threads for driving Read operations on hello disks.</span></span> <span data-ttu-id="a4a03-853">hello 쓰기 작업 자가 됩니다 수 운전 트래픽을 캐시와 10 디스크가 nocache"hello" 볼륨에 "None"입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-853">hello Write workers will be driving traffic on hello "nocache" volume, which has 10 disks with cache set too"None".</span></span> <span data-ttu-id="a4a03-854">hello 읽기 작업 자가 됩니다 수 운전 트래픽을 캐시 집합 1 디스크가 너무 readcache"hello" 볼륨에 "ReadOnly"입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-854">hello Read workers will be driving traffic on hello "readcache" volume, which has 1 disk with cache set too"ReadOnly".</span></span>

<span data-ttu-id="a4a03-855">*최대 쓰기 IOPS*</span><span class="sxs-lookup"><span data-stu-id="a4a03-855">*Maximum Write IOPS*</span></span>  
<span data-ttu-id="a4a03-856">다음 사양 tooget으로 hello 작업 파일을 만들어 최대 쓰기 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-856">Create hello job file with following specifications tooget maximum Write IOPS.</span></span> <span data-ttu-id="a4a03-857">“fiowrite.ini”로 이름을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-857">Name it "fiowrite.ini".</span></span>

```
[global]
size=30g
direct=1
iodepth=256
ioengine=libaio
bs=8k

[writer1]
rw=randwrite
directory=/mnt/nocache
[writer2]
rw=randwrite
directory=/mnt/nocache
[writer3]
rw=randwrite
directory=/mnt/nocache
[writer4]
rw=randwrite
directory=/mnt/nocache
```

<span data-ttu-id="a4a03-858">참고 hello 이전 섹션에서 설명 하는 hello 디자인 지침에 일치 하는 주요 작업을 수행 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-858">Note hello follow key things that are in line with hello design guidelines discussed in previous sections.</span></span> <span data-ttu-id="a4a03-859">이러한 사양은 필수 toodrive 최대 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-859">These specifications are essential toodrive maximum IOPS,</span></span>  

* <span data-ttu-id="a4a03-860">256의 높은 큐 크기.</span><span class="sxs-lookup"><span data-stu-id="a4a03-860">A high queue depth of 256.</span></span>  
* <span data-ttu-id="a4a03-861">8KB의 작은 블록 크기.</span><span class="sxs-lookup"><span data-stu-id="a4a03-861">A small block size of 8KB.</span></span>  
* <span data-ttu-id="a4a03-862">임의 쓰기를 수행하는 다중 스레드.</span><span class="sxs-lookup"><span data-stu-id="a4a03-862">Multiple threads performing random writes.</span></span>

<span data-ttu-id="a4a03-863">Hello FIO 30 초 동안 테스트 hello 해제 명령을 tookick 다음 실행</span><span class="sxs-lookup"><span data-stu-id="a4a03-863">Run hello following command tookick off hello FIO test for 30 seconds,</span></span>  

```
sudo fio --runtime 30 fiowrite.ini
```

<span data-ttu-id="a4a03-864">Hello 테스트를 실행할 수 toosee hello 수가 쓰기 IOPS hello VM 및 프리미엄 디스크를 배달 하는 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-864">While hello test runs, you will be able toosee hello number of write IOPS hello VM and Premium disks are delivering.</span></span> <span data-ttu-id="a4a03-865">Hello 샘플 아래에 나와 있는 것 처럼 해당 최대 쓰기 IOPS 제한은 50, 000 IOPS의 hello DS14 VM에 제공 하는 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-865">As shown in hello sample below, hello DS14 VM is delivering its maximum write IOPS limit of 50,000 IOPS.</span></span>  
    ![](media/storage-premium-storage-performance/image11.png)

<span data-ttu-id="a4a03-866">*최대 읽기 IOPS*</span><span class="sxs-lookup"><span data-stu-id="a4a03-866">*Maximum Read IOPS*</span></span>  
<span data-ttu-id="a4a03-867">다음 사양 tooget으로 hello 작업 파일을 만들어 최대 읽기 IOPS입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-867">Create hello job file with following specifications tooget maximum Read IOPS.</span></span> <span data-ttu-id="a4a03-868">"fioread.ini"로 이름을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-868">Name it "fioread.ini".</span></span>

```
[global]
size=30g
direct=1
iodepth=256
ioengine=libaio
bs=8k

[reader1]
rw=randread
directory=/mnt/readcache
[reader2]
rw=randread
directory=/mnt/readcache
[reader3]
rw=randread
directory=/mnt/readcache
[reader4]
rw=randread
directory=/mnt/readcache
```

<span data-ttu-id="a4a03-869">참고 hello 이전 섹션에서 설명 하는 hello 디자인 지침에 일치 하는 주요 작업을 수행 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-869">Note hello follow key things that are in line with hello design guidelines discussed in previous sections.</span></span> <span data-ttu-id="a4a03-870">이러한 사양은 필수 toodrive 최대 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-870">These specifications are essential toodrive maximum IOPS,</span></span>

* <span data-ttu-id="a4a03-871">256의 높은 큐 크기.</span><span class="sxs-lookup"><span data-stu-id="a4a03-871">A high queue depth of 256.</span></span>  
* <span data-ttu-id="a4a03-872">8KB의 작은 블록 크기.</span><span class="sxs-lookup"><span data-stu-id="a4a03-872">A small block size of 8KB.</span></span>  
* <span data-ttu-id="a4a03-873">임의 쓰기를 수행하는 다중 스레드.</span><span class="sxs-lookup"><span data-stu-id="a4a03-873">Multiple threads performing random writes.</span></span>

<span data-ttu-id="a4a03-874">Hello FIO 30 초 동안 테스트 hello 해제 명령을 tookick 다음 실행</span><span class="sxs-lookup"><span data-stu-id="a4a03-874">Run hello following command tookick off hello FIO test for 30 seconds,</span></span>

```
sudo fio --runtime 30 fioread.ini
```

<span data-ttu-id="a4a03-875">Hello 테스트 실행 되는 동안 읽기 IOPS hello VM 수 toosee hello 수 있습니다 및 프리미엄 디스크를 배달 하는 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-875">While hello test runs, you will be able toosee hello number of read IOPS hello VM and Premium disks are delivering.</span></span> <span data-ttu-id="a4a03-876">아래 hello 예제와 같이 hello DS14 VM 64, 000 개 이상의 읽기 IOPS 전달 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-876">As shown in hello sample below, hello DS14 VM is delivering more than 64,000 Read IOPS.</span></span> <span data-ttu-id="a4a03-877">이 hello 디스크와 hello 캐시 성능의 조합입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-877">This is a combination of hello disk and hello cache performance.</span></span>  
    ![](media/storage-premium-storage-performance/image12.png)

<span data-ttu-id="a4a03-878">*최대 읽기 및 쓰기 IOPS*</span><span class="sxs-lookup"><span data-stu-id="a4a03-878">*Maximum Read and Write IOPS*</span></span>  
<span data-ttu-id="a4a03-879">만들 최대 다음 사양 tooget hello 작업 파일 읽기 및 쓰기 IOPS를 결합 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-879">Create hello job file with following specifications tooget maximum combined Read and Write IOPS.</span></span> <span data-ttu-id="a4a03-880">"fioreadwrite.ini"로 이름을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-880">Name it "fioreadwrite.ini".</span></span>

```
[global]
size=30g
direct=1
iodepth=128
ioengine=libaio
bs=4k

[reader1]
rw=randread
directory=/mnt/readcache
[reader2]
rw=randread
directory=/mnt/readcache
[reader3]
rw=randread
directory=/mnt/readcache
[reader4]
rw=randread
directory=/mnt/readcache

[writer1]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
[writer2]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
[writer3]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
[writer4]
rw=randwrite
directory=/mnt/nocache
rate_iops=12500
```

<span data-ttu-id="a4a03-881">참고 hello 이전 섹션에서 설명 하는 hello 디자인 지침에 일치 하는 주요 작업을 수행 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-881">Note hello follow key things that are in line with hello design guidelines discussed in previous sections.</span></span> <span data-ttu-id="a4a03-882">이러한 사양은 필수 toodrive 최대 IOPS</span><span class="sxs-lookup"><span data-stu-id="a4a03-882">These specifications are essential toodrive maximum IOPS,</span></span>

* <span data-ttu-id="a4a03-883">128의 높은 큐 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-883">A high queue depth of 128.</span></span>  
* <span data-ttu-id="a4a03-884">4KB의 작은 블록 크기</span><span class="sxs-lookup"><span data-stu-id="a4a03-884">A small block size of 4KB.</span></span>  
* <span data-ttu-id="a4a03-885">임의 읽기 및 쓰기를 수행하는 다중 스레드</span><span class="sxs-lookup"><span data-stu-id="a4a03-885">Multiple threads performing random reads and writes.</span></span>

<span data-ttu-id="a4a03-886">Hello FIO 30 초 동안 테스트 hello 해제 명령을 tookick 다음 실행</span><span class="sxs-lookup"><span data-stu-id="a4a03-886">Run hello following command tookick off hello FIO test for 30 seconds,</span></span>

```
sudo fio --runtime 30 fioreadwrite.ini
```

<span data-ttu-id="a4a03-887">Hello 테스트를 실행할 수 없게 toosee hello 결합 된 읽기 및 쓰기 IOPS VM hello 및 프리미엄 디스크를 배달 하는 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-887">While hello test runs, you will be able toosee hello number of combined read and write IOPS hello VM and Premium disks are delivering.</span></span> <span data-ttu-id="a4a03-888">Hello 샘플 아래에 나와 있는 것 처럼 100, 000 개 이상의 결합 된 읽기 및 쓰기 IOPS hello DS14 VM 전달 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-888">As shown in hello sample below, hello DS14 VM is delivering more than 100,000 combined Read and Write IOPS.</span></span> <span data-ttu-id="a4a03-889">이 hello 디스크와 hello 캐시 성능의 조합입니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-889">This is a combination of hello disk and hello cache performance.</span></span>  
    ![](media/storage-premium-storage-performance/image13.png)

<span data-ttu-id="a4a03-890">*결합된 최대 처리량*</span><span class="sxs-lookup"><span data-stu-id="a4a03-890">*Maximum Combined Throughput*</span></span>  
<span data-ttu-id="a4a03-891">최대 tooget hello 결합 된 읽기 및 쓰기 처리량, 읽기 및 쓰기를 수행 하는 여러 스레드가 더 큰 블록 크기 및 큰 큐 깊이 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-891">tooget hello maximum combined Read and Write Throughput, use a larger block size and large queue depth with multiple threads performing reads and writes.</span></span> <span data-ttu-id="a4a03-892">64KB의 블록 크기와 128의 큐 크기를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="a4a03-892">You can use a block size of 64KB and queue depth of 128.</span></span>

## <a name="next-steps"></a><span data-ttu-id="a4a03-893">다음 단계</span><span class="sxs-lookup"><span data-stu-id="a4a03-893">Next Steps</span></span>
<span data-ttu-id="a4a03-894">Azure 프리미엄 저장소에 대한 자세한 정보</span><span class="sxs-lookup"><span data-stu-id="a4a03-894">Learn more about Azure Premium Storage:</span></span>

* [<span data-ttu-id="a4a03-895">프리미엄 저장소: Azure 가상 컴퓨터 워크로드를 위한 고성능 저장소</span><span class="sxs-lookup"><span data-stu-id="a4a03-895">Premium Storage: High-Performance Storage for Azure Virtual Machine Workloads</span></span>](../storage-premium-storage.md)  

<span data-ttu-id="a4a03-896">SQL Server 사용자의 경우 SQL Server에 대한 성능 모범 사례의 문서를 읽으세요.</span><span class="sxs-lookup"><span data-stu-id="a4a03-896">For SQL Server users, read articles on Performance Best Practices for SQL Server:</span></span>

* [<span data-ttu-id="a4a03-897">Azure 가상 컴퓨터의 SQL Server에 대한 성능 모범 사례</span><span class="sxs-lookup"><span data-stu-id="a4a03-897">Performance Best Practices for SQL Server in Azure Virtual Machines</span></span>](../../virtual-machines/windows/sql/virtual-machines-windows-sql-performance.md)
* [<span data-ttu-id="a4a03-898">Azure 프리미엄 저장소는 Azure VM의 SQL Server에 대해 가장 높은 성능을 제공합니다</span><span class="sxs-lookup"><span data-stu-id="a4a03-898">Azure Premium Storage provides highest performance for SQL Server in Azure VM</span></span>](http://blogs.technet.com/b/dataplatforminsider/archive/2015/04/23/azure-premium-storage-provides-highest-performance-for-sql-server-in-azure-vm.aspx)
