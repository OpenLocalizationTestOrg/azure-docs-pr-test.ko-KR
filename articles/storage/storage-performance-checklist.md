---
title: "Azure Storage 성능 및 확장성 검사 목록 | Microsoft Docs"
description: "성능이 뛰어난 응용 프로그램 개발 시 Azure 저장소에서 사용하기 위한 검증된 작업 방식에 대한 검사 목록."
services: storage
documentationcenter: 
author: robinsh
manager: timlt
editor: tysonn
ms.assetid: 959d831b-a4fd-4634-a646-0d2c0c462ef8
ms.service: storage
ms.workload: storage
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 12/08/2016
ms.author: robinsh
ms.openlocfilehash: c12f98b069689e335d308d8f8edba2dece21d806
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 07/11/2017
---
# <a name="microsoft-azure-storage-performance-and-scalability-checklist"></a><span data-ttu-id="398f3-103">Microsoft Azure 저장소 성능 및 확장성 검사 목록</span><span class="sxs-lookup"><span data-stu-id="398f3-103">Microsoft Azure Storage Performance and Scalability Checklist</span></span>
## <a name="overview"></a><span data-ttu-id="398f3-104">개요</span><span class="sxs-lookup"><span data-stu-id="398f3-104">Overview</span></span>
<span data-ttu-id="398f3-105">Microsoft Azure 저장소 서비스가 출시된 이후 Microsoft는 이러한 서비스를 성능 기준에 맞는 방식으로 사용할 수 있도록 효율성이 검증된 다양한 작업 방식을 개발했습니다. 이 문서에는 이러한 작업 방식 중 가장 중요한 항목을 검사 목록 스타일의 목록으로 통합되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-105">Since the release of the Microsoft Azure Storage services, Microsoft has developed a number of proven practices for using these services in a performant manner, and this article serves to consolidate the most important of them into a checklist-style list.</span></span> <span data-ttu-id="398f3-106">이 문서에서는 응용 프로그램 개발자가 Azure 저장소와 관련하여 검증된 작업 방식을 사용하고 있는지를 확인하고, 도입을 고려해야 하는 기타 검증된 작업 방식을 파악하는 데 도움이 되는 정보를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-106">The intention of this article is to help application developers verify they are using proven practices with Azure Storage and to help them identify other proven practices they should consider adopting.</span></span> <span data-ttu-id="398f3-107">그러나 가능한 모든 성능 및 확장성 최적화 기능에 대해 다루지는 않으며, 큰 영향을 주지 않거나 광범위하게 적용할 수 없는 기능은 제외됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-107">This article does not attempt to cover every possible performance and scalability optimization — it excludes those that are small in their impact or not broadly applicable.</span></span> <span data-ttu-id="398f3-108">디자인 중에 응용 프로그램 동작을 예측할 수 없는 범위 내에서는 이러한 사항을 초기에 파악해 두면 성능 문제를 야기하는 디자인을 피하는 데 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-108">To the extent that the application's behavior can be predicted during design, it's useful to keep these in mind early on to avoid designs that will run into performance problems.</span></span>  

<span data-ttu-id="398f3-109">Azure 저장소를 사용하는 모든 응용 프로그램 개발자는 시간을 할애하여 이 문서의 내용을 파악하고 자신이 개발한 응용 프로그램이 아래에 나와 있는 각각의 검증된 작업 방식을 따르는지를 확인해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-109">Every application developer using Azure Storage should take the time to read this article, and check that his or her application follows each of the proven practices listed below.</span></span>  

## <a name="checklist"></a><span data-ttu-id="398f3-110">검사 목록</span><span class="sxs-lookup"><span data-stu-id="398f3-110">Checklist</span></span>
<span data-ttu-id="398f3-111">이 문서에는 검증된 작업 방식이 다음과 같은 그룹으로 구성되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-111">This article organizes the proven practices into the following groups.</span></span> <span data-ttu-id="398f3-112">검증된 작업 방식이 적용되는 대상은 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-112">Proven practices applicable to:</span></span>  

* <span data-ttu-id="398f3-113">모든 Azure 저장소 서비스(Blob, 테이블, 큐, 파일)</span><span class="sxs-lookup"><span data-stu-id="398f3-113">All Azure Storage services (blobs, tables, queues, and files)</span></span>
* <span data-ttu-id="398f3-114">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-114">Blobs</span></span>
* <span data-ttu-id="398f3-115">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-115">Tables</span></span>
* <span data-ttu-id="398f3-116">큐</span><span class="sxs-lookup"><span data-stu-id="398f3-116">Queues</span></span>  

| <span data-ttu-id="398f3-117">완료된</span><span class="sxs-lookup"><span data-stu-id="398f3-117">Done</span></span> | <span data-ttu-id="398f3-118">영역</span><span class="sxs-lookup"><span data-stu-id="398f3-118">Area</span></span> | <span data-ttu-id="398f3-119">Category</span><span class="sxs-lookup"><span data-stu-id="398f3-119">Category</span></span> | <span data-ttu-id="398f3-120">질문</span><span class="sxs-lookup"><span data-stu-id="398f3-120">Question</span></span> |
| --- | --- | --- | --- |
| &nbsp; | <span data-ttu-id="398f3-121">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-121">All Services</span></span> |<span data-ttu-id="398f3-122">확장성 목표</span><span class="sxs-lookup"><span data-stu-id="398f3-122">Scalability Targets</span></span> |[<span data-ttu-id="398f3-123">응용 프로그램이 확장성 목표에 도달하지 않도록 설계되어 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-123">Is your application designed to avoid approaching the scalability targets?</span></span>](#subheading1) |
| &nbsp; | <span data-ttu-id="398f3-124">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-124">All Services</span></span> |<span data-ttu-id="398f3-125">확장성 목표</span><span class="sxs-lookup"><span data-stu-id="398f3-125">Scalability Targets</span></span> |[<span data-ttu-id="398f3-126">명명 규칙이 부하 분산 향상에 맞게 설계되었습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-126">Is your naming convention designed to enable better load-balancing?</span></span>](#subheading47) |
| &nbsp; | <span data-ttu-id="398f3-127">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-127">All Services</span></span> |<span data-ttu-id="398f3-128">네트워킹</span><span class="sxs-lookup"><span data-stu-id="398f3-128">Networking</span></span> |[<span data-ttu-id="398f3-129">클라이언트 쪽 장치에서 필요한 성능을 달성할 수 있을 정도로 대역폭은 높고 대기 시간은 낮습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-129">Do client side devices have sufficiently high bandwidth and low latency to achieve the performance needed?</span></span>](#subheading2) |
| &nbsp; | <span data-ttu-id="398f3-130">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-130">All Services</span></span> |<span data-ttu-id="398f3-131">네트워킹</span><span class="sxs-lookup"><span data-stu-id="398f3-131">Networking</span></span> |[<span data-ttu-id="398f3-132">클라이언트 쪽 장치의 링크 품질이 충분히 높습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-132">Do client side devices have a high enough quality link?</span></span>](#subheading3) |
| &nbsp; | <span data-ttu-id="398f3-133">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-133">All Services</span></span> |<span data-ttu-id="398f3-134">네트워킹</span><span class="sxs-lookup"><span data-stu-id="398f3-134">Networking</span></span> |[<span data-ttu-id="398f3-135">클라이언트 응용 프로그램이 저장소 계정 "근처"에 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-135">Is the client application located "near" the storage account?</span></span>](#subheading4) |
| &nbsp; | <span data-ttu-id="398f3-136">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-136">All Services</span></span> |<span data-ttu-id="398f3-137">콘텐츠 배포</span><span class="sxs-lookup"><span data-stu-id="398f3-137">Content Distribution</span></span> |[<span data-ttu-id="398f3-138">콘텐츠 배포를 위해 CDN을 사용합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-138">Are you using a CDN for content distribution?</span></span>](#subheading5) |
| &nbsp; | <span data-ttu-id="398f3-139">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-139">All Services</span></span> |<span data-ttu-id="398f3-140">직접 클라이언트 액세스</span><span class="sxs-lookup"><span data-stu-id="398f3-140">Direct Client Access</span></span> |[<span data-ttu-id="398f3-141">SAS 및 CORS를 사용하여 프록시가 아닌 저장소에 직접 액세스를 허용합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-141">Are you using SAS and CORS to allow direct access to storage instead of proxy?</span></span>](#subheading6) |
| &nbsp; | <span data-ttu-id="398f3-142">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-142">All Services</span></span> |<span data-ttu-id="398f3-143">구성</span><span class="sxs-lookup"><span data-stu-id="398f3-143">Caching</span></span> |[<span data-ttu-id="398f3-144">응용 프로그램에서 반복적으로 사용되며 거의 변경되지 않는 데이터를 캐시합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-144">Is your application caching data that is repeatedly used and changes rarely?</span></span>](#subheading7) |
| &nbsp; | <span data-ttu-id="398f3-145">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-145">All Services</span></span> |<span data-ttu-id="398f3-146">구성</span><span class="sxs-lookup"><span data-stu-id="398f3-146">Caching</span></span> |[<span data-ttu-id="398f3-147">응용 프로그램에서 업데이트를 일괄 처리(클라이언트 쪽에서 업데이트를 캐시한 다음 더 큰 집합으로 업로드)합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-147">Is your application batching updates (caching them client side and then uploading in larger sets)?</span></span>](#subheading8) |
| &nbsp; | <span data-ttu-id="398f3-148">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-148">All Services</span></span> |<span data-ttu-id="398f3-149">.NET 구성</span><span class="sxs-lookup"><span data-stu-id="398f3-149">.NET Configuration</span></span> |[<span data-ttu-id="398f3-150">클라이언트가 충분한 수의 동시 연결을 사용하도록 구성했습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-150">Have you configured your client to use a sufficient number of concurrent connections?</span></span>](#subheading9) |
| &nbsp; | <span data-ttu-id="398f3-151">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-151">All Services</span></span> |<span data-ttu-id="398f3-152">.NET 구성</span><span class="sxs-lookup"><span data-stu-id="398f3-152">.NET Configuration</span></span> |[<span data-ttu-id="398f3-153">.NET이 충분한 수의 스레드를 사용하도록 구성했습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-153">Have you configured .NET to use a sufficient number of threads?</span></span>](#subheading10) |
| &nbsp; | <span data-ttu-id="398f3-154">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-154">All Services</span></span> |<span data-ttu-id="398f3-155">.NET 구성</span><span class="sxs-lookup"><span data-stu-id="398f3-155">.NET Configuration</span></span> |[<span data-ttu-id="398f3-156">가비지 수집 기능이 개선된 .NET 4.5 이상을 사용 중입니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-156">Are you using .NET 4.5 or later, which has improved garbage collection?</span></span>](#subheading11) |
| &nbsp; | <span data-ttu-id="398f3-157">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-157">All Services</span></span> |<span data-ttu-id="398f3-158">병렬 처리</span><span class="sxs-lookup"><span data-stu-id="398f3-158">Parallelism</span></span> |[<span data-ttu-id="398f3-159">클라이언트 기능이나 확장성 목표가 오버로드되지 않도록 병렬 처리의 경계를 적절하게 지정했습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-159">Have you ensured that parallelism is bounded appropriately so that you don't overload either your client capabilities or the scalability targets?</span></span>](#subheading12) |
| &nbsp; | <span data-ttu-id="398f3-160">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-160">All Services</span></span> |<span data-ttu-id="398f3-161">도구</span><span class="sxs-lookup"><span data-stu-id="398f3-161">Tools</span></span> |[<span data-ttu-id="398f3-162">Microsoft 제공 클라이언트 라이브러리와 도구의 최신 버전을 사용하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-162">Are you using the latest version of Microsoft provided client libraries and tools?</span></span>](#subheading13) |
| &nbsp; | <span data-ttu-id="398f3-163">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-163">All Services</span></span> |<span data-ttu-id="398f3-164">다시 시도</span><span class="sxs-lookup"><span data-stu-id="398f3-164">Retries</span></span> |[<span data-ttu-id="398f3-165">제한 시간 및 오류 제한을 위한 지수 백오프 다시 시도 정책을 사용하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-165">Are you using an exponential backoff retry policy for throttling errors and timeouts?</span></span>](#subheading14) |
| &nbsp; | <span data-ttu-id="398f3-166">모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-166">All Services</span></span> |<span data-ttu-id="398f3-167">다시 시도</span><span class="sxs-lookup"><span data-stu-id="398f3-167">Retries</span></span> |[<span data-ttu-id="398f3-168">응용 프로그램에서 다시 시도할 수 없는 오류 발생 시에는 작업을 다시 시도하지 않습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-168">Is your application avoiding retries for non-retryable errors?</span></span>](#subheading15) |
| &nbsp; | <span data-ttu-id="398f3-169">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-169">Blobs</span></span> |<span data-ttu-id="398f3-170">확장성 목표</span><span class="sxs-lookup"><span data-stu-id="398f3-170">Scalability Targets</span></span> |[<span data-ttu-id="398f3-171">동시에 단일 개체에 액세스하는 클라이언트가 많이 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-171">Do you have a large number of clients accessing a single object concurrently?</span></span>](#subheading46) |
| &nbsp; | <span data-ttu-id="398f3-172">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-172">Blobs</span></span> |<span data-ttu-id="398f3-173">확장성 목표</span><span class="sxs-lookup"><span data-stu-id="398f3-173">Scalability Targets</span></span> |[<span data-ttu-id="398f3-174">응용 프로그램에서 단일 Blob에 대한 대역폭 또는 작업의 확장성 목표가 유지됩니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-174">Is your application staying within the bandwidth or operations scalability target for a single blob?</span></span>](#subheading16) |
| &nbsp; | <span data-ttu-id="398f3-175">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-175">Blobs</span></span> |<span data-ttu-id="398f3-176">Blob 복사</span><span class="sxs-lookup"><span data-stu-id="398f3-176">Copying Blobs</span></span> |[<span data-ttu-id="398f3-177">Blob를 효율적으로 복사하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-177">Are you copying blobs in an efficient manner?</span></span>](#subheading17) |
| &nbsp; | <span data-ttu-id="398f3-178">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-178">Blobs</span></span> |<span data-ttu-id="398f3-179">Blob 복사</span><span class="sxs-lookup"><span data-stu-id="398f3-179">Copying Blobs</span></span> |[<span data-ttu-id="398f3-180">대량 Blob 복사에 AzCopy를 사용하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-180">Are you using AzCopy for bulk copies of blobs?</span></span>](#subheading18) |
| &nbsp; | <span data-ttu-id="398f3-181">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-181">Blobs</span></span> |<span data-ttu-id="398f3-182">Blob 복사</span><span class="sxs-lookup"><span data-stu-id="398f3-182">Copying Blobs</span></span> |[<span data-ttu-id="398f3-183">매우 많은 데이터를 전송하는 데 Azure 가져오기/내보내기를 사용하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-183">Are you using Azure Import/Export to transfer very large volumes of data?</span></span>](#subheading19) |
| &nbsp; | <span data-ttu-id="398f3-184">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-184">Blobs</span></span> |<span data-ttu-id="398f3-185">메타데이터 사용</span><span class="sxs-lookup"><span data-stu-id="398f3-185">Use Metadata</span></span> |[<span data-ttu-id="398f3-186">자주 사용되는 Blob 관련 메타데이터를 해당 메타데이터에 저장하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-186">Are you storing frequently used metadata about blobs in their metadata?</span></span>](#subheading20) |
| &nbsp; | <span data-ttu-id="398f3-187">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-187">Blobs</span></span> |<span data-ttu-id="398f3-188">고속 업로드</span><span class="sxs-lookup"><span data-stu-id="398f3-188">Uploading Fast</span></span> |[<span data-ttu-id="398f3-189">Blob 하나를 빠르게 업로드하려는 경우 블록을 병렬로 업로드합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-189">When trying to upload one blob quickly, are you uploading blocks in parallel?</span></span>](#subheading21) |
| &nbsp; | <span data-ttu-id="398f3-190">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-190">Blobs</span></span> |<span data-ttu-id="398f3-191">고속 업로드</span><span class="sxs-lookup"><span data-stu-id="398f3-191">Uploading Fast</span></span> |[<span data-ttu-id="398f3-192">Blob 여러 개를 빠르게 업로드하려는 경우 Blob를 병렬로 업로드합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-192">When trying to upload many blobs quickly, are you uploading blobs in parallel?</span></span>](#subheading22) |
| &nbsp; | <span data-ttu-id="398f3-193">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-193">Blobs</span></span> |<span data-ttu-id="398f3-194">올바른 Blob 유형</span><span class="sxs-lookup"><span data-stu-id="398f3-194">Correct Blob Type</span></span> |[<span data-ttu-id="398f3-195">해당하는 경우 페이지 Blob 또는 블록 Blob를 사용합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-195">Are you using page blobs or block blobs when appropriate?</span></span>](#subheading23) |
| &nbsp; | <span data-ttu-id="398f3-196">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-196">Tables</span></span> |<span data-ttu-id="398f3-197">확장성 목표</span><span class="sxs-lookup"><span data-stu-id="398f3-197">Scalability Targets</span></span> |[<span data-ttu-id="398f3-198">초당 엔터티의 확장 목표에 도달하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-198">Are you approaching the scalability targets for entities per second?</span></span>](#subheading24) |
| &nbsp; | <span data-ttu-id="398f3-199">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-199">Tables</span></span> |<span data-ttu-id="398f3-200">구성</span><span class="sxs-lookup"><span data-stu-id="398f3-200">Configuration</span></span> |[<span data-ttu-id="398f3-201">테이블 요청에 JSON을 사용하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-201">Are you using JSON for your table requests?</span></span>](#subheading25) |
| &nbsp; | <span data-ttu-id="398f3-202">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-202">Tables</span></span> |<span data-ttu-id="398f3-203">구성</span><span class="sxs-lookup"><span data-stu-id="398f3-203">Configuration</span></span> |[<span data-ttu-id="398f3-204">소규모 요청의 성능을 개선하기 위해 Nagle을 해제했습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-204">Have you turned Nagle off to improve the performance of small requests?</span></span>](#subheading26) |
| &nbsp; | <span data-ttu-id="398f3-205">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-205">Tables</span></span> |<span data-ttu-id="398f3-206">테이블 및 파티션</span><span class="sxs-lookup"><span data-stu-id="398f3-206">Tables and Partitions</span></span> |[<span data-ttu-id="398f3-207">데이터를 적절하게 분할했습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-207">Have you properly partitioned your data?</span></span>](#subheading27) |
| &nbsp; | <span data-ttu-id="398f3-208">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-208">Tables</span></span> |<span data-ttu-id="398f3-209">핫 파티션</span><span class="sxs-lookup"><span data-stu-id="398f3-209">Hot Partitions</span></span> |[<span data-ttu-id="398f3-210">추가 전용 및 앞에 추가 전용 패턴을 지양하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-210">Are you avoiding append-only and prepend-only patterns?</span></span>](#subheading28) |
| &nbsp; | <span data-ttu-id="398f3-211">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-211">Tables</span></span> |<span data-ttu-id="398f3-212">핫 파티션</span><span class="sxs-lookup"><span data-stu-id="398f3-212">Hot Partitions</span></span> |[<span data-ttu-id="398f3-213">여러 파티션을 대상으로 삽입/업데이트를 수행합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-213">Are your inserts/updates spread across many partitions?</span></span>](#subheading29) |
| &nbsp; | <span data-ttu-id="398f3-214">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-214">Tables</span></span> |<span data-ttu-id="398f3-215">쿼리 범위</span><span class="sxs-lookup"><span data-stu-id="398f3-215">Query Scope</span></span> |[<span data-ttu-id="398f3-216">대부분의 경우에는 지점 쿼리를 사용하고 테이블 쿼리는 필요한 경우에만 사용하도록 스키마를 디자인했습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-216">Have you designed your schema to allow for point queries to be used in most cases, and table queries to be used sparingly?</span></span>](#subheading30) |
| &nbsp; | <span data-ttu-id="398f3-217">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-217">Tables</span></span> |<span data-ttu-id="398f3-218">쿼리 밀도</span><span class="sxs-lookup"><span data-stu-id="398f3-218">Query Density</span></span> |[<span data-ttu-id="398f3-219">일반적으로 쿼리가 응용 프로그램에서 사용할 행만 스캔하여 반환합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-219">Do your queries typically only scan and return rows that your application will use?</span></span>](#subheading31) |
| &nbsp; | <span data-ttu-id="398f3-220">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-220">Tables</span></span> |<span data-ttu-id="398f3-221">반환되는 데이터 제한</span><span class="sxs-lookup"><span data-stu-id="398f3-221">Limiting Returned Data</span></span> |[<span data-ttu-id="398f3-222">필요하지 않은 엔터티는 반환되지 않도록 필터링을 사용하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-222">Are you using filtering to avoid returning entities that are not needed?</span></span>](#subheading32) |
| &nbsp; | <span data-ttu-id="398f3-223">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-223">Tables</span></span> |<span data-ttu-id="398f3-224">반환되는 데이터 제한</span><span class="sxs-lookup"><span data-stu-id="398f3-224">Limiting Returned Data</span></span> |[<span data-ttu-id="398f3-225">필요하지 않은 속성은 반환되지 않도록 프로젝션을 사용하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-225">Are you using projection to avoid returning properties that are not needed?</span></span>](#subheading33) |
| &nbsp; | <span data-ttu-id="398f3-226">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-226">Tables</span></span> |<span data-ttu-id="398f3-227">비정규화</span><span class="sxs-lookup"><span data-stu-id="398f3-227">Denormalization</span></span> |[<span data-ttu-id="398f3-228">데이터를 가져올 때 비효율적인 쿼리 또는 여러 읽기 요청을 방지하기 위해 데이터를 비정규화했습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-228">Have you denormalized your data such that you avoid inefficient queries or multiple read requests when trying to get data?</span></span>](#subheading34) |
| &nbsp; | <span data-ttu-id="398f3-229">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-229">Tables</span></span> |<span data-ttu-id="398f3-230">삽입/업데이트/삭제</span><span class="sxs-lookup"><span data-stu-id="398f3-230">Insert/Update/Delete</span></span> |[<span data-ttu-id="398f3-231">왕복 횟수를 줄이기 위해 동시에 수행할 수 있거나 트랜잭션 방식으로 수행해야 하는 요청을 일괄 처리하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-231">Are you batching requests that need to be transactional or can be done at the same time to reduce round-trips?</span></span>](#subheading35) |
| &nbsp; | <span data-ttu-id="398f3-232">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-232">Tables</span></span> |<span data-ttu-id="398f3-233">삽입/업데이트/삭제</span><span class="sxs-lookup"><span data-stu-id="398f3-233">Insert/Update/Delete</span></span> |[<span data-ttu-id="398f3-234">단순한 호출 대상(삽입 또는 업데이트) 결정을 위한 엔터티 검색을 지양하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-234">Are you avoiding retrieving an entity just to determine whether to call insert or update?</span></span>](#subheading36) |
| &nbsp; | <span data-ttu-id="398f3-235">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-235">Tables</span></span> |<span data-ttu-id="398f3-236">삽입/업데이트/삭제</span><span class="sxs-lookup"><span data-stu-id="398f3-236">Insert/Update/Delete</span></span> |[<span data-ttu-id="398f3-237">자주 함께 검색할 일련의 데이터를 여러 엔터티가 아닌 단일 엔터티에 속성으로 저장하는 것을 고려한 적이 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-237">Have you considered storing series of data that will frequently be retrieved together in a single entity as properties instead of multiple entities?</span></span>](#subheading37) |
| &nbsp; | <span data-ttu-id="398f3-238">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-238">Tables</span></span> |<span data-ttu-id="398f3-239">삽입/업데이트/삭제</span><span class="sxs-lookup"><span data-stu-id="398f3-239">Insert/Update/Delete</span></span> |[<span data-ttu-id="398f3-240">배치로 쓸 수 있으며 항상 함께 검색할 엔터티(예: 시계열 데이터)에 대해 테이블이 아닌 Blob 사용을 고려한 적이 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-240">For entities that will always be retrieved together and can be written in batches (e.g. time series data), have you considered using blobs instead of tables?</span></span>](#subheading38) |
| &nbsp; | <span data-ttu-id="398f3-241">큐</span><span class="sxs-lookup"><span data-stu-id="398f3-241">Queues</span></span> |<span data-ttu-id="398f3-242">확장성 목표</span><span class="sxs-lookup"><span data-stu-id="398f3-242">Scalability Targets</span></span> |[<span data-ttu-id="398f3-243">초당 메시지의 확장 목표에 도달하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-243">Are you approaching the scalability targets for messages per second?</span></span>](#subheading39) |
| &nbsp; | <span data-ttu-id="398f3-244">큐</span><span class="sxs-lookup"><span data-stu-id="398f3-244">Queues</span></span> |<span data-ttu-id="398f3-245">구성</span><span class="sxs-lookup"><span data-stu-id="398f3-245">Configuration</span></span> |[<span data-ttu-id="398f3-246">소규모 요청의 성능을 개선하기 위해 Nagle을 해제했습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-246">Have you turned Nagle off to improve the performance of small requests?</span></span>](#subheading40) |
| &nbsp; | <span data-ttu-id="398f3-247">큐</span><span class="sxs-lookup"><span data-stu-id="398f3-247">Queues</span></span> |<span data-ttu-id="398f3-248">메시지 크기</span><span class="sxs-lookup"><span data-stu-id="398f3-248">Message Size</span></span> |[<span data-ttu-id="398f3-249">큐 성능을 개선하기 위해 메시지를 압축합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-249">Are your messages compact to improve the performance of the queue?</span></span>](#subheading41) |
| &nbsp; | <span data-ttu-id="398f3-250">큐</span><span class="sxs-lookup"><span data-stu-id="398f3-250">Queues</span></span> |<span data-ttu-id="398f3-251">대량 검색</span><span class="sxs-lookup"><span data-stu-id="398f3-251">Bulk Retrieve</span></span> |[<span data-ttu-id="398f3-252">단일 "Get" 작업으로 여러 메시지를 검색합니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-252">Are you retrieving multiple messages in a single "Get" operation?</span></span>](#subheading42) |
| &nbsp; | <span data-ttu-id="398f3-253">큐</span><span class="sxs-lookup"><span data-stu-id="398f3-253">Queues</span></span> |<span data-ttu-id="398f3-254">폴링 빈도</span><span class="sxs-lookup"><span data-stu-id="398f3-254">Polling Frequency</span></span> |[<span data-ttu-id="398f3-255">응용 프로그램의 체감 대기 시간을 단축할 수 있을 만큼 자주 폴링을 수행하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-255">Are you polling frequently enough to reduce the perceived latency of your application?</span></span>](#subheading43) |
| &nbsp; | <span data-ttu-id="398f3-256">큐</span><span class="sxs-lookup"><span data-stu-id="398f3-256">Queues</span></span> |<span data-ttu-id="398f3-257">메시지 업데이트</span><span class="sxs-lookup"><span data-stu-id="398f3-257">Update Message</span></span> |[<span data-ttu-id="398f3-258">오류 발생 시 전체 메시지를 다시 처리하지 않아도 되도록 UpdateMessage를 사용하여 메시지 처리 진행률을 저장하고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-258">Are you using UpdateMessage to store progress in processing messages, avoiding having to reprocess the entire message if an error occurs?</span></span>](#subheading44) |
| &nbsp; | <span data-ttu-id="398f3-259">큐</span><span class="sxs-lookup"><span data-stu-id="398f3-259">Queues</span></span> |<span data-ttu-id="398f3-260">아키텍처</span><span class="sxs-lookup"><span data-stu-id="398f3-260">Architecture</span></span> |[<span data-ttu-id="398f3-261">장기 실행 작업을 중요 경로 외부에서만 실행하고 독립적으로 확장함으로써 큐를 통해 전체 응용 프로그램의 확장성을 높이고 있습니까?</span><span class="sxs-lookup"><span data-stu-id="398f3-261">Are you using queues to make your entire application more scalable by keeping long-running workloads out of the critical path and scale then independently?</span></span>](#subheading45) |

## <span data-ttu-id="398f3-262"><a name="allservices"></a>모든 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-262"><a name="allservices"></a>All Services</span></span>
<span data-ttu-id="398f3-263">이 섹션에서는 모든 Azure 저장소 서비스(Blob, 테이블, 큐 또는 파일) 사용 시 적용되는 검증된 작업 방식에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-263">This section lists proven practices that are applicable to the use of any of the Azure Storage services (blobs, tables, queues, or files).</span></span>  

### <span data-ttu-id="398f3-264"><a name="subheading1"></a>확장성 목표</span><span class="sxs-lookup"><span data-stu-id="398f3-264"><a name="subheading1"></a>Scalability Targets</span></span>
<span data-ttu-id="398f3-265">각 Azure 저장소 서비스에는 용량(GB), 전송 속도 및 대역폭에 대한 확장성 목표가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-265">Each of the Azure Storage services has scalability targets for capacity (GB), transaction rate, and bandwidth.</span></span> <span data-ttu-id="398f3-266">응용 프로그램이 확장성 목표에 도달하거나 목표를 초과하는 경우 트랜잭션 대기 시간이 길어지거나 제한이 증가할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-266">If your application approaches or exceeds any of the scalability targets, it may encounter increased transaction latencies or throttling.</span></span> <span data-ttu-id="398f3-267">저장소 서비스는 응용 프로그램을 제한할 때 일부 저장소 트랜잭션에 대해 “503 서버 작업 중” 또는 “500 작업 시간 초과” 오류 코드 반환을 시작합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-267">When a Storage service throttles your application, the service begins to return "503 Server busy" or "500 Operation timeout" error codes for some storage transactions.</span></span> <span data-ttu-id="398f3-268">이 섹션에서는 확장성 목표 관련 문제를 해결하는 일반적인 방식을 설명하며, 특히 대역폭 확장성 목표 관련 작업 방식에 대해서도 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-268">This section discusses both the general approach to dealing with scalability targets and bandwidth scalability targets in particular.</span></span> <span data-ttu-id="398f3-269">개별 저장소 서비스에 대해 다루는 이후 섹션에서는 다음과 같은 특정 서비스의 컨텍스트에서 확장성 목표에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-269">Later sections that deal with individual storage services discuss scalability targets in the context of that specific service:</span></span>  

* [<span data-ttu-id="398f3-270">Blob 대역폭 및 초당 요청 수</span><span class="sxs-lookup"><span data-stu-id="398f3-270">Blob bandwidth and requests per second</span></span>](#subheading16)
* [<span data-ttu-id="398f3-271">초당 테이블 엔터티 수</span><span class="sxs-lookup"><span data-stu-id="398f3-271">Table entities per second</span></span>](#subheading24)
* [<span data-ttu-id="398f3-272">초당 큐 메시지 수</span><span class="sxs-lookup"><span data-stu-id="398f3-272">Queue messages per second</span></span>](#subheading39)  

#### <span data-ttu-id="398f3-273"><a name="sub1bandwidth"></a>모든 서비스에 대한 대역폭 확장성 목표</span><span class="sxs-lookup"><span data-stu-id="398f3-273"><a name="sub1bandwidth"></a>Bandwidth Scalability Target for All Services</span></span>
<span data-ttu-id="398f3-274">이 문서를 작성할 당시 미국의 GRS(지역 중복 저장소) 계정에 대한 대역폭 목표는 수신(저장소 계정으로 전송되는 데이터)의 경우 10Gbps(초당 기가비트)이고 송신(저장소 계정에서 전송하는 데이터)의 경우 20Gbps입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-274">At the time of writing, the bandwidth targets in the US for a geo-redundant storage (GRS) account are 10 gigabits per second (Gbps) for ingress (data sent to the storage account) and 20 Gbps for egress (data sent from the storage account).</span></span> <span data-ttu-id="398f3-275">LRS(로컬 중복 저장소) 계정의 경우에는 수신의 경우 20Gbps, 송신의 경우 30Gbps로 제한이 좀 더 높습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-275">For a locally redundant storage (LRS) account, the limits are higher – 20 Gbps for ingress and 30 Gbps for egress.</span></span>  <span data-ttu-id="398f3-276">기타 국가의 대역폭 제한은 이보다 더 낮을 수 있습니다. 관련 정보는 [확장성 목표 페이지](http://msdn.microsoft.com/library/azure/dn249410.aspx)에서 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-276">International bandwidth limits may be lower and can be found on our [scalability targets page](http://msdn.microsoft.com/library/azure/dn249410.aspx).</span></span>  <span data-ttu-id="398f3-277">저장소 중복 옵션에 대한 자세한 내용은 아래 [유용한 리소스](#sub1useful)의 링크를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-277">For more information on the storage redundancy options, see the links in [Useful Resources](#sub1useful) below.</span></span>  

#### <a name="what-to-do-when-approaching-a-scalability-target"></a><span data-ttu-id="398f3-278">확장성 목표에 도달했을 때 수행할 작업</span><span class="sxs-lookup"><span data-stu-id="398f3-278">What to do when approaching a scalability target</span></span>
<span data-ttu-id="398f3-279">응용 프로그램이 특정 저장소 계정의 확장성 목표에 도달한 경우 다음 방법 중 하나를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-279">If your application is approaching the scalability targets for a single storage account, consider adopting one of the following approaches:</span></span>  

* <span data-ttu-id="398f3-280">응용 프로그램이 확장성 목표에 도달하거나 목표를 초과한 원인이 되는 워크로드를 다시 고려합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-280">Reconsider the workload that causes your application to approach or exceed the scalability target.</span></span> <span data-ttu-id="398f3-281">즉, 대역폭이나 용량을 더 적게 사용하거나 트랜잭션을 더 적게 수행하도록 해당 작업을 다시 디자인할 수 있는지를 파악합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-281">Can you design it differently to use less bandwidth or capacity, or fewer transactions?</span></span>
* <span data-ttu-id="398f3-282">응용 프로그램에서 확장성 목표 중 하나를 초과해야 하는 경우에는 여러 저장소 계정을 만들고 해당 계정으로 응용 프로그램 데이터를 분할해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-282">If an application must exceed one of the scalability targets, you should create multiple storage accounts and partition your application data across those multiple storage accounts.</span></span> <span data-ttu-id="398f3-283">이러한 패턴을 사용하는 경우에는 향후 부하 분산을 위해 저장소 계정을 더 추가할 수 있도록 응용 프로그램을 디자인해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-283">If you use this pattern, then be sure to design your application so that you can add more storage accounts in the future for load balancing.</span></span> <span data-ttu-id="398f3-284">이 문서를 작성할 당시 각 Azure 구독은 저장소 계정을 100개까지 포함할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-284">At time of writing, each Azure subscription can have up to 100 storage accounts.</span></span>  <span data-ttu-id="398f3-285">또한 저장소 계정에는 저장하거나 전송하는 데이터 또는 수행하는 트랜잭션과 관련된 사용 요금 외의 기타 비용은 없습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-285">Storage accounts also have no cost other than your usage in terms of data stored, transactions made, or data transferred.</span></span>
* <span data-ttu-id="398f3-286">응용 프로그램의 대역폭 목표에 도달한 경우 클라이언트의 데이터를 압축하여 저장소 서비스로 데이터를 보내는 데 필요한 대역폭을 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-286">If your application hits the bandwidth targets, consider compressing data in the client to reduce the bandwidth required to send the data to the storage service.</span></span>  <span data-ttu-id="398f3-287">이렇게 하면 대역폭을 줄이고 네트워크 성능을 개선할 수는 있지만, 몇 가지 좋지 않은 영향도 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-287">Note that while this may save bandwidth and improve network performance, it can also have some negative impacts.</span></span>  <span data-ttu-id="398f3-288">그러므로 클라이언트에서 데이터를 압축하고 압축을 풀기 위한 추가 처리 요구 사항에 의해 발생하는 성능 관련 영향을 평가해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-288">You should evaluate the performance impact of this due to the additional processing requirements for compressing and decompressing data in the client.</span></span> <span data-ttu-id="398f3-289">뿐만 아니라 압축된 데이터를 저장하는 경우 표준 도구를 사용해 저장된 데이터를 확인하기가 어려워질 수 있으므로 문제를 해결하기도 더 어려워질 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-289">In addition, storing compressed data can make it more difficult to troubleshoot issues since it could be more difficult to view stored data using standard tools.</span></span>
* <span data-ttu-id="398f3-290">응용 프로그램이 확장성 목표에 도달한 경우 다시 시도에 대해 지수 백오프를 사용 중인지 확인합니다( [다시 시도](#subheading14)참조).</span><span class="sxs-lookup"><span data-stu-id="398f3-290">If your application hits the scalability targets, then ensure that you are using an exponential backoff for retries (see [Retries](#subheading14)).</span></span>  <span data-ttu-id="398f3-291">위에서 설명한 방법 중 하나를 사용하여 확장성 목표에 도달하지 않도록 하는 것이 가장 좋지만, 지수 백오프를 사용하면 응용 프로그램이 빠르게 다시 시도를 계속하여 더욱 엄격한 제한이 적용되는 현상을 방지할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-291">It's better to make sure you never approach the scalability targets (by using one of the above methods), but this will ensure your application won't just keep retrying rapidly, making the throttling worse.</span></span>  

#### <a name="useful-resources"></a><span data-ttu-id="398f3-292">유용한 리소스</span><span class="sxs-lookup"><span data-stu-id="398f3-292">Useful Resources</span></span>
<span data-ttu-id="398f3-293">다음 링크에서는 확장성 목표에 대한 추가 정보를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-293">The following links provide additional detail on scalability targets:</span></span>

* <span data-ttu-id="398f3-294">확장성 목표에 대한 자세한 내용은 [Azure 저장소 확장성 및 성능 목표](storage-scalability-targets.md) 를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-294">See [Azure Storage Scalability and Performance Targets](storage-scalability-targets.md) for information about scalability targets.</span></span>
* <span data-ttu-id="398f3-295">저장소 중복 옵션에 대한 내용은 [Azure Storage 복제](storage-redundancy.md) 및 블로그 게시물 [Azure Storage 중복 옵션 및 읽기 액세스 지역 중복 저장소](http://blogs.msdn.com/b/windowsazurestorage/archive/2013/12/11/introducing-read-access-geo-replicated-storage-ra-grs-for-windows-azure-storage.aspx)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-295">See [Azure Storage replication](storage-redundancy.md) and the blog post [Azure Storage Redundancy Options and Read Access Geo Redundant Storage](http://blogs.msdn.com/b/windowsazurestorage/archive/2013/12/11/introducing-read-access-geo-replicated-storage-ra-grs-for-windows-azure-storage.aspx) for information about storage redundancy options.</span></span>
* <span data-ttu-id="398f3-296">Azure 서비스 가격에 대한 최신 정보는 [Azure 가격 책정](https://azure.microsoft.com/pricing/overview/)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-296">For current information about pricing for Azure services, see [Azure pricing](https://azure.microsoft.com/pricing/overview/).</span></span>  

### <span data-ttu-id="398f3-297"><a name="subheading47"></a>파티션 명명 규칙</span><span class="sxs-lookup"><span data-stu-id="398f3-297"><a name="subheading47"></a>Partition Naming Convention</span></span>
<span data-ttu-id="398f3-298">Azure 저장소는 범위 기반 파티션 구성표를 사용하여 시스템을 확장하고 부하를 분산합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-298">Azure Storage uses a range-based partitioning scheme to scale and load balance the system.</span></span> <span data-ttu-id="398f3-299">파티션 키는 데이터를 범위로 파티션하는 데 사용되며 이러한 범위는 시스템 전체에서 부하가 분산됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-299">The partition key is used to partition data into ranges and these ranges are load-balanced across the system.</span></span> <span data-ttu-id="398f3-300">다시 말해 어휘 순서(예: msftpayroll, msftperformance, msftemployees 등)와 같은 명명 규칙 또는 타임 스탬프(log20160101, log20160102, log20160102 등)를 사용할 경우 부하 분산 작업이 파티션을 작은 범위로 분할할 때까지 파티션이 동일한 파티션 서버에 함께 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-300">This means naming conventions such as lexical ordering (e.g. msftpayroll, msftperformance, msftemployees, etc) or using time-stamps (log20160101, log20160102, log20160102, etc) will lend itself to the partitions being potentially co-located on the same partition server, until a load balancing operation splits them out into smaller ranges.</span></span> <span data-ttu-id="398f3-301">예를 들어 컨테이너 내 모든 Blob는 이러한 Blob의 부하가 파티션 범위의 추가 리밸런싱을 요구하기 전까지 단일 서버가 지원할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-301">For example, all blobs within a container can be served by a single server until the load on these blobs requires further rebalancing of the partition ranges.</span></span> <span data-ttu-id="398f3-302">마찬가지로, 이름이 어휘 순서로 정렬된 가벼운 부하의 계정 그룹도 하나 또는 전체 계정의 부하에서 여러 파티션 서버로 분할을 요구할 때까지 단일 서버가 지원할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-302">Similarly, a group of lightly loaded accounts with their names arranged in lexical order may be served by a single server until the load on one or all of these accounts require them to be split across multiple partitions servers.</span></span> <span data-ttu-id="398f3-303">각 부하 분산 작업은 작업 중 저장소 호출의 지연 시간에 영향을 미칠 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-303">Each load balancing operation may impact the latency of storage calls during the operation.</span></span> <span data-ttu-id="398f3-304">파티션에 대한 트래픽 급증을 처리하는 시스템 기능은 부하 분산 작업이 시작되고 파티션 키 범위가 리밸런싱될 때까지 단일 파티션 서버의 확장성에 의해 제한될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-304">The system's ability to handle a sudden burst of traffic to a partition is limited by the scalability of a single partition server until the load balancing operation kicks-in and rebalances the partition key range.</span></span>  

<span data-ttu-id="398f3-305">이러한 작업의 빈도를 줄이려면 몇 가지 모범 사례를 따르십시오.</span><span class="sxs-lookup"><span data-stu-id="398f3-305">You can follow some best practices to reduce the frequency of such operations.</span></span>  

* <span data-ttu-id="398f3-306">계정, 컨테이너, Blob, 테이블, 큐에 사용하는 명명 규칙을 자세히 확인합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-306">Examine the naming convention you use for accounts, containers, blobs, tables and queues, closely.</span></span> <span data-ttu-id="398f3-307">계정 이름에 요구 사항에 가장 적합한 해싱 함수를 사용하는 3자릿수 해시의 접두사를 추가해 보십시오.</span><span class="sxs-lookup"><span data-stu-id="398f3-307">Consider prefixing account names with a 3-digit hash using a hashing function that best suits your needs.</span></span>  
* <span data-ttu-id="398f3-308">타임스탬프 또는 숫자 식별자를 사용하여 데이터를 정리할 경우 추가만 가능한(또는 앞에만 추가할 수 있는) 트래픽 패턴을 사용하지 않아야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-308">If you organize your data using timestamps or numerical identifiers, you have to ensure you are not using an append-only (or prepend-only) traffic patterns.</span></span> <span data-ttu-id="398f3-309">이러한 패턴은 범위 기반 파티셔닝 시스템에 적합하지 않으며 모든 트래픽이 단일 파티션으로 이동하여 시스템이 부하 분산을 효과적으로 수행하지 못할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-309">These patterns are not suitable for a range -based partitioning system, and could lead to all the traffic going to a single partition and limiting the system from effectively load balancing.</span></span> <span data-ttu-id="398f3-310">예를 들어 일상적 작업에서 타임스탬프(예: yyyymmdd)가 포함된 Blob 개체를 사용하는 경우 이러한 일상적 작업의 모든 트래픽이 단일 파티션 서버에서 지원하는 단일 개체로 전송될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-310">For instance, if you have daily operations that use a blob object with a timestamp such as yyyymmdd, then all the traffic for that daily operation is directed to a single object which is served by a single partition server.</span></span> <span data-ttu-id="398f3-311">Blob당 한계와 파티션당 한계가 요구 사항을 충족하는지 확인하고 필요에 따라 이 작업을 여러 Blob으로 나누는 것을 고려해 보십시오.</span><span class="sxs-lookup"><span data-stu-id="398f3-311">Look at whether the per blob limits and per partition limits meet your needs, and consider breaking this operation into multiple blobs if needed.</span></span> <span data-ttu-id="398f3-312">마찬가지로 테이블에 시계열 데이터를 저장하는 경우 모든 트래픽이 키 네임스페이스의 마지막 부분으로 전송될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-312">Similarly, if you store time series data in your tables, all the traffic could be directed to the last part of the key namespace.</span></span> <span data-ttu-id="398f3-313">타임스탬프 또는 숫자 ID를 사용해야 하는 경우에는 3자릿수 해시로 접두사를 추가합니다. 타임스탬프의 경우에는 ssyyyymmdd와 같이 시간의 초 부분을 접두사로 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-313">If you must use timestamps or numerical IDs, prefix the id with a 3-digit hash, or in the case of timestamps prefix the seconds part of the time such as ssyyyymmdd.</span></span> <span data-ttu-id="398f3-314">열거 및 쿼리 작업을 일상적으로 수행하는 경우 쿼리 수를 제한하는 해시 함수를 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-314">If listing and querying operations are routinely performed, choose a hashing function that will limit your number of queries.</span></span> <span data-ttu-id="398f3-315">다른 경우에는 임의의 접두사로도 충분할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-315">In other cases, a random prefix may be sufficient.</span></span>  
* <span data-ttu-id="398f3-316">Azure 저장소에 사용된 파티션 구성표에 대한 자세한 내용은 [여기](http://sigops.org/sosp/sosp11/current/2011-Cascais/printable/11-calder.pdf)에서 SOSP 백서를 읽으십시오.</span><span class="sxs-lookup"><span data-stu-id="398f3-316">For additional information on the partitioning scheme used in Azure Storage, read the SOSP paper [here](http://sigops.org/sosp/sosp11/current/2011-Cascais/printable/11-calder.pdf).</span></span>

### <a name="networking"></a><span data-ttu-id="398f3-317">네트워킹</span><span class="sxs-lookup"><span data-stu-id="398f3-317">Networking</span></span>
<span data-ttu-id="398f3-318">API 호출은 중요한 작업이기는 하지만 응용 프로그램의 실제 네트워크 제약 조건이 성능에 큰 영향을 주는 경우가 많습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-318">While the API calls matter, often the physical network constraints of the application have a significant impact on performance.</span></span> <span data-ttu-id="398f3-319">아래에서는 사용자에게 적용될 수 있는 몇 가지 제한에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-319">The following describe some of limitations users may encounter.</span></span>  

#### <a name="client-network-capability"></a><span data-ttu-id="398f3-320">클라이언트 네트워크 기능</span><span class="sxs-lookup"><span data-stu-id="398f3-320">Client Network Capability</span></span>
##### <span data-ttu-id="398f3-321"><a name="subheading2"></a>처리량</span><span class="sxs-lookup"><span data-stu-id="398f3-321"><a name="subheading2"></a>Throughput</span></span>
<span data-ttu-id="398f3-322">대역폭의 경우에는 클라이언트 기능에 문제가 있는 경우가 많습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-322">For bandwidth, the problem is often the capabilities of the client.</span></span> <span data-ttu-id="398f3-323">예를 들어 저장소 계정 하나가 수신 데이터 10Gbps 이상을 처리할 수 있더라도([대역폭 확장성 목표](#sub1bandwidth) 참조) “소규모” Azure 작업자 역할 인스턴스의 네트워크 속도는 약 100Mbps에 불과합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-323">For example, while a single storage account can handle 10 Gbps or more of ingress (see [bandwidth scalability targets](#sub1bandwidth)), the network speed in a "Small" Azure Worker Role instance is only capable of approximately 100 Mbps.</span></span> <span data-ttu-id="398f3-324">대규모 Azure 인스턴스에는 용량이 더 많은 NIC가 포함되므로 컴퓨터 하나의 네트워크 제한을 높여야 하는 경우에는 더 큰 인스턴스나 더 많은 VM을 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-324">Larger Azure instances have NICs with greater capacity, so you should consider using a larger instance or more VM's if you need higher network limits from a single machine.</span></span> <span data-ttu-id="398f3-325">온-프레미스 응용 프로그램에서 저장소 서비스에 액세스하는 경우에도 동일한 규칙이 적용됩니다. 즉, 클라이언트 장치의 네트워크 기능과 Azure 저장소 위치에 대한 네트워크 연결을 파악한 다음 필요에 따라 기능과 연결을 개선하거나 해당 기능 내에서 작동하도록 응용 프로그램을 디자인해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-325">If you are accessing a Storage service from an on premises application, then the same rule applies: understand the network capabilities of the client device and the network connectivity to the Azure Storage location and either improve them as needed or design your application to work within their capabilities.</span></span>  

##### <span data-ttu-id="398f3-326"><a name="subheading3"></a>링크 속도</span><span class="sxs-lookup"><span data-stu-id="398f3-326"><a name="subheading3"></a>Link Quality</span></span>
<span data-ttu-id="398f3-327">네트워크를 어떤 방식으로 사용하든 네트워크의 상태로 인해 오류와 패킷 손실이 발생하면 효율적인 처리량을 달성하는 시간이 길어집니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-327">As with any network usage, be aware that network conditions resulting in errors and packet loss will slow effective throughput.</span></span>  <span data-ttu-id="398f3-328">WireShark 또는 NetMon을 사용하면 이 문제를 진단하는 데 도움이 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-328">Using WireShark or NetMon may help in diagnosing this issue.</span></span>  

##### <a name="useful-resources"></a><span data-ttu-id="398f3-329">유용한 리소스</span><span class="sxs-lookup"><span data-stu-id="398f3-329">Useful Resources</span></span>
<span data-ttu-id="398f3-330">가상 컴퓨터 크기 및 할당된 대역폭에 대한 자세한 내용은 [Windows VM 크기](../virtual-machines/windows/sizes.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) 또는 [Linux VM 크기](../virtual-machines/linux/sizes.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-330">For more information about virtual machine sizes and allocated bandwidth, see [Windows VM sizes](../virtual-machines/windows/sizes.md?toc=%2fazure%2fvirtual-machines%2fwindows%2ftoc.json) or [Linux VM sizes](../virtual-machines/linux/sizes.md?toc=%2fazure%2fvirtual-machines%2flinux%2ftoc.json).</span></span>  

#### <span data-ttu-id="398f3-331"><a name="subheading4"></a>위치</span><span class="sxs-lookup"><span data-stu-id="398f3-331"><a name="subheading4"></a>Location</span></span>
<span data-ttu-id="398f3-332">모든 분산 환경에서는 클라이언트를 서버 근처에 배치하면 성능을 최대화할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-332">In any distributed environment, placing the client near to the server delivers in the best performance.</span></span> <span data-ttu-id="398f3-333">Azure 저장소 액세스 시 대기 시간을 최소화하려는 경우에는 클라이언트를 같은 Azure 지역 내에 배치하는 것이 가장 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-333">For accessing Azure Storage with the lowest latency, the best location for your client is within the same Azure region.</span></span> <span data-ttu-id="398f3-334">예를 들어 Azure 웹 사이트에서 Azure 저장소를 사용하는 경우 웹 사이트와 저장소를 모두 단일 하위 지역(예: 미국 서부 또는 동남 아시아) 내에 배치해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-334">For example, if you have an Azure Web Site that uses Azure Storage, you should locate them both within a single region (for example, US West or Asia Southeast).</span></span> <span data-ttu-id="398f3-335">그러면 대기 시간과 비용이 감소합니다. 이 문서를 작성할 당시 단일 하위 지역 내의 대역폭 사용은 무료입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-335">This reduces the latency and the cost — at the time of writing, bandwidth usage within a single region is free.</span></span>  

<span data-ttu-id="398f3-336">모바일 장치 앱이나 온-프레미스 엔터프라이즈 서비스와 같이 클라이언트 응용 프로그램이 Azure 내에서 호스트되지 않는 경우에도 저장소 계정을 해당 계정에 액세스할 장치와 가까운 하위 지역에 배치하면 대체적으로 대기 시간이 짧아집니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-336">If your client applications are not hosted within Azure (such as mobile device apps or on premises enterprise services), then again placing the storage account in a region near to the devices that will access it, will generally reduce latency.</span></span> <span data-ttu-id="398f3-337">클라이언트가 일부는 북아메리카에 있고 일부는 유럽에 있는 등 광범위하게 분산되어 있다면 여러 저장소 계정(하나는 북아메리카 지역에 있고 하나는 유럽 지역에 있음)을 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-337">If your clients are broadly distributed (for example, some in North America, and some in Europe), then you should consider using multiple storage accounts: one located in a North American region and one in a European region.</span></span> <span data-ttu-id="398f3-338">이렇게 하면 두 지역 사용자의 대기 시간이 모두 짧아집니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-338">This will help to reduce latency for users in both regions.</span></span> <span data-ttu-id="398f3-339">일반적으로 응용 프로그램에서 개별 사용자 관련 데이터를 저장하며 저장소 계정 간에 데이터를 복제하지 않아도 되는 경우 이 방식을 보다 쉽게 구현할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-339">This approach is usually easier to implement if the data the application stores is specific to individual users, and does not require replicating data between storage accounts.</span></span>  <span data-ttu-id="398f3-340">콘텐츠를 광범위하게 배포하려는 경우에는 CDN을 사용하는 것이 좋습니다. 자세한 내용은 다음 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-340">For broad content distribution, a CDN is recommended – see the next section for more details.</span></span>  

### <span data-ttu-id="398f3-341"><a name="subheading5"></a>콘텐츠 배포</span><span class="sxs-lookup"><span data-stu-id="398f3-341"><a name="subheading5"></a>Content Distribution</span></span>
<span data-ttu-id="398f3-342">응용 프로그램이 같은 지역이나 여러 지역의 많은 사용자에게 같은 콘텐츠(예: 웹 사이트의 홈 페이지에 사용되는 제품 데모 비디오)를 제공해야 하는 경우가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-342">Sometimes, an application needs to serve the same content to many users (e.g. a product demo video used in the home page of a website), located in either the same or multiple regions.</span></span> <span data-ttu-id="398f3-343">이러한 경우에는 Azure CDN(콘텐츠 배달 네트워크)과 같은 CDN을 사용해야 합니다. Azure CDN은 데이터 출처로 Azure 저장소를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-343">In this scenario, you should use a Content Delivery Network (CDN) such as Azure CDN, and the CDN would use Azure storage as the origin of the data.</span></span> <span data-ttu-id="398f3-344">단일 하위 지역에 있으며 짧은 대기 시간 내에 다른 하위 지역으로 콘텐츠를 배달할 수 없는 Azure 저장소 계정과는 달리 Azure CDN은 전 세계 여러 데이터 센터의 서버를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-344">Unlike an Azure Storage account that exists in a single region and that cannot deliver content with low latency to other regions, Azure CDN uses servers in multiple data centers around the world.</span></span> <span data-ttu-id="398f3-345">또한 CDN은 일반적으로 단일 저장소 계정보다 더 높은 송신 제한을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-345">Additionally, a CDN can typically support much higher egress limits than a single storage account.</span></span>  

<span data-ttu-id="398f3-346">Azure CDN에 대한 자세한 내용은 [Azure CDN](https://azure.microsoft.com/services/cdn/)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-346">For more information about Azure CDN, see [Azure CDN](https://azure.microsoft.com/services/cdn/).</span></span>  

### <span data-ttu-id="398f3-347"><a name="subheading6"></a>SAS 및 CORS 사용</span><span class="sxs-lookup"><span data-stu-id="398f3-347"><a name="subheading6"></a>Using SAS and CORS</span></span>
<span data-ttu-id="398f3-348">사용자의 웹 브라우저나 휴대폰 앱에서 JavaScript와 같은 코드가 Azure Storage의 데이터에 액세스하도록 권한을 부여해야 하는 경우 사용할 수 있는 방법 중 하나는 웹 역할에서 응용 프로그램을 프록시로 사용하는 것입니다. 즉, 사용자의 장치는 웹 역할에 인증하고 웹 역할은 다시 저장소 서비스에 인증합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-348">When you need to authorize code such as JavaScript in a user's web browser or a mobile phone app to access data in Azure Storage, one approach is to use an application in web role as a proxy: the user's device authenticates with the web role, which in turn authenticates with the storage service.</span></span> <span data-ttu-id="398f3-349">이러한 방식을 사용하면 안전하지 않은 장치에서 저장소 계정 키가 노출되는 상황을 방지할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-349">In this way, you can avoid exposing your storage account keys on insecure devices.</span></span> <span data-ttu-id="398f3-350">그러나 사용자의 장치와 저장소 서비스 간에 전송되는 모든 데이터가 웹 역할을 통과해야 하므로 이 방식을 사용하는 경우 웹 역할에 큰 오버헤드가 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-350">However, this places a big overhead on the web role because all the data transferred between the user's device and the storage service must pass through the web role.</span></span> <span data-ttu-id="398f3-351">SAS(공유 액세스 서명)를 경우에 따라 CORS(크로스-원본 자원 공유) 헤더와 함께 사용하면 저장소 서비스에 대해 웹 역할을 프록시로 사용하지 않아도 됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-351">You can avoid using a web role as a proxy for the storage service by using Shared Access Signatures (SAS), sometimes in conjunction with Cross-Origin Resource Sharing headers (CORS).</span></span> <span data-ttu-id="398f3-352">SAS를 사용하는 경우 제한된 액세스 토큰을 통해 사용자 장치가 저장소 서비스에 직접 요청을 하도록 허용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-352">Using SAS, you can allow your user's device to make requests directly to a storage service by means of a limited access token.</span></span> <span data-ttu-id="398f3-353">예를 들어 사용자가 응용 프로그램에 사진을 업로드하려는 경우 웹 역할이 이후 30분 동안 특정 Blob 또는 컨테이너에 대한 쓰기 권한을 부여하는 SAS 토큰을 생성한 다음 사용자 장치로 전송할 수 있습니다. 30분이 지나면 SAS 토큰은 만료됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-353">For example, if a user wants to upload a photo to your application, your web role can generate and send to the user's device a SAS token that grants permission to write to a specific blob or container for the next 30 minutes (after which the SAS token expires).</span></span>

<span data-ttu-id="398f3-354">일반적으로 브라우저는 특정 도메인의 웹 사이트에서 호스트하는 페이지의 JavaScript가 다른 도메인에 대해 “PUT”과 같은 특정 작업을 수행하도록 허용하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-354">Normally, a browser will not allow JavaScript in a page hosted by a website on one domain to perform specific operations such as a "PUT" to another domain.</span></span> <span data-ttu-id="398f3-355">예를 들어 “contosomarketing.cloudapp.net”에서 웹 역할을 호스트하는 경우 클라이언트 쪽 JavaScript를 사용해 “contosoproducts.blob.core.windows.net”에서 저장소 계정에 Blob을 업로드하려고 하면 브라우저의 “동일 원본 정책”으로 인해 해당 작업이 차단됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-355">For example, if you host a web role at "contosomarketing.cloudapp.net," and want to use client side JavaScript to upload a blob to your storage account at "contosoproducts.blob.core.windows.net," the browser's "same origin policy" will forbid this operation.</span></span> <span data-ttu-id="398f3-356">CORS는 대상 도메인(여기서는 저장소 계정)이 원본 도메인(여기서는 웹 역할)에서 생성되는 요청을 신뢰함을 브라우저에 전달할 수 있도록 하는 브라우저 기능입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-356">CORS is a browser feature that allows the target domain (in this case the storage account) to communicate to the browser that it trusts requests originating in the source domain (in this case the web role).</span></span>  

<span data-ttu-id="398f3-357">이 두 기술을 사용하면 웹 응용 프로그램에서 불필요한 로드와 병목 현상을 방지할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-357">Both of these technologies can help you avoid unnecessary load (and bottlenecks) on your web application.</span></span>  

#### <a name="useful-resources"></a><span data-ttu-id="398f3-358">유용한 리소스</span><span class="sxs-lookup"><span data-stu-id="398f3-358">Useful Resources</span></span>
<span data-ttu-id="398f3-359">SAS에 대한 자세한 내용은 [공유 액세스 서명, 1부: SAS 모델 이해](storage-dotnet-shared-access-signature-part-1.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-359">For more information about SAS, see [Shared Access Signatures, Part 1: Understanding the SAS Model](storage-dotnet-shared-access-signature-part-1.md).</span></span>  

<span data-ttu-id="398f3-360">CORS에 대한 자세한 내용은 [Azure 저장소 서비스에 대한 CORS(Cross-Origin Resource Sharing) 지원](http://msdn.microsoft.com/library/azure/dn535601.aspx)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-360">For more information about CORS, see [Cross-Origin Resource Sharing (CORS) Support for the Azure Storage Services](http://msdn.microsoft.com/library/azure/dn535601.aspx).</span></span>  

### <a name="caching"></a><span data-ttu-id="398f3-361">구성</span><span class="sxs-lookup"><span data-stu-id="398f3-361">Caching</span></span>
#### <span data-ttu-id="398f3-362"><a name="subheading7"></a>데이터 가져오기</span><span class="sxs-lookup"><span data-stu-id="398f3-362"><a name="subheading7"></a>Getting Data</span></span>
<span data-ttu-id="398f3-363">일반적으로는 서비스에서 데이터를 가져오는 횟수가 적을수록 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-363">In general, getting data from a service once is better than getting it twice.</span></span> <span data-ttu-id="398f3-364">웹 역할에서 실행 중인 MVC 웹 응용 프로그램이 사용자에게 콘텐츠로 제공하기 위해 저장소 서비스에서 50MB의 Blob을 이미 검색했다고 가정해 보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-364">Consider the example of an MVC web application running in a web role that has already retrieved a 50MB blob from the storage service to serve as content to a user.</span></span> <span data-ttu-id="398f3-365">이 응용 프로그램은 사용자가 요청할 때마다 같은 Blob을 검색할 수도 있고, 해당 Blob을 디스크에 로컬로 캐시한 다음 후속 사용자 요청에 대해 캐시된 버전을 다시 사용할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-365">The application could then retrieve that same blob every time a user requests it, or it could cache it locally to disk and reuse the cached version for subsequent user requests.</span></span> <span data-ttu-id="398f3-366">또한 사용자가 데이터를 요청할 때 응용 프로그램은 수정 시간에 대한 조건부 헤더가 포함된 GET을 실행할 수도 있습니다. 이 경우 Blob이 수정되지 않았으면 전체 Blob을 가져오지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-366">Furthermore, whenever a user requests the data, the application could issue GET with a conditional header for modification time, which would avoid getting the entire blob if it hasn't been modified.</span></span> <span data-ttu-id="398f3-367">테이블 엔터티 사용 시에도 이와 같은 패턴을 적용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-367">You can apply this same pattern to working with table entities.</span></span>  

<span data-ttu-id="398f3-368">Blob이 검색 후 잠시 동안 유효한 상태로 유지된다고 가정하며, 해당 시간 동안에는 Blob 수정 여부를 확인하지 않아도 되도록 응용 프로그램을 설정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-368">In some cases, you may decide that your application can assume that the blob remains valid for a short period after retrieving it, and that during this period the application does not need to check if the blob was modified.</span></span>

<span data-ttu-id="398f3-369">응용 프로그램에서 항상 사용하는 구성, 조회 및 기타 데이터는 캐시하면 매우 효율적입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-369">Configuration, lookup, and other data that are always used by the application are great candidates for caching.</span></span>  

<span data-ttu-id="398f3-370">.NET을 사용하여 Blob 속성을 가져와 마지막으로 수정한 날짜를 확인하는 방법의 예는 [속성과 메타데이터 설정 및 검색](storage-properties-metadata.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-370">For an example of how to get a blob's properties to discover the last modified date using .NET, see [Set and Retrieve Properties and Metadata](storage-properties-metadata.md).</span></span> <span data-ttu-id="398f3-371">조건부 다운로드에 대한 자세한 내용은 [Blob의 로컬 복사본을 조건부로 새로 고침](http://msdn.microsoft.com/library/azure/dd179371.aspx)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-371">For more information about conditional downloads, see [Conditionally Refresh a Local Copy of a Blob](http://msdn.microsoft.com/library/azure/dd179371.aspx).</span></span>  

#### <span data-ttu-id="398f3-372"><a name="subheading8"></a>데이터 일괄 업로드</span><span class="sxs-lookup"><span data-stu-id="398f3-372"><a name="subheading8"></a>Uploading Data in Batches</span></span>
<span data-ttu-id="398f3-373">데이터를 로컬로 집계한 다음 각 데이터 부분을 즉시 업로드하는 대신 주기적으로 일괄 업로드할 수 있는 응용 프로그램 시나리오가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-373">In some application scenarios, you can aggregate data locally, and then periodically upload it in a batch instead of uploading each piece of data immediately.</span></span> <span data-ttu-id="398f3-374">예를 들어 웹 응용 프로그램이 작업의 로그 파일을 유지할 수 있습니다. 모든 작업이 수행될 때 해당 세부 정보를 테이블 엔터티로 업로드할 수도 있고(저장소 작업을 여러 번 수행해야 함), 로컬 로그 파일에 작업 세부 정보를 저장한 다음 모든 작업 세부 정보를 구분된 파일로 Blob에 주기적으로 업로드할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-374">For example, a web application might keep a log file of activities: the application could either upload details of every activity as it happens as a table entity (which requires many storage operations), or it could save activity details to a local log file, and then periodically upload all activity details as a delimited file to a blob.</span></span> <span data-ttu-id="398f3-375">각 로그 항목의 크기가 1KB이면 단일 “Put Blob” 트랜잭션에서 수천 개의 항목을 업로드할 수 있습니다. 단일 트랜잭션에서 크기가 최대 64MB인 Blob을 업로드할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-375">If each log entry is 1KB in size, you can upload thousands in a single "Put Blob" transaction (you can upload a blob of up to 64MB in size in a single transaction).</span></span> <span data-ttu-id="398f3-376">물론, 업로드 전에 로컬 컴퓨터가 크래시할 경우 일부 로그 데이터가 손실될 수 있습니다. 따라서 응용 프로그램 개발자는 클라이언트 장치 또는 업로드 실패의 가능성을 고려하여 디자인해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-376">Of course, if the local machine crashes prior to the upload, you will potentially lose some log data: the application developer must design for the possibility of client device or upload failures.</span></span>  <span data-ttu-id="398f3-377">단일 작업이 아닌 시간 범위에 대해 작업 데이터를 다운로드해야 하는 경우에는 테이블보다 Blob를 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-377">If the activity data needs to be downloaded for timespans (not just single activity), then blobs are recommended over tables.</span></span>

### <a name="net-configuration"></a><span data-ttu-id="398f3-378">.NET 구성</span><span class="sxs-lookup"><span data-stu-id="398f3-378">.NET Configuration</span></span>
<span data-ttu-id="398f3-379">이 섹션에서는 .NET Framework를 사용하는 경우 성능을 크게 개선하기 위해 사용할 수 있는 다양한 빠른 구성 설정을 소개합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-379">If using the .NET Framework, this section lists several quick configuration settings that you can use to make significant performance improvements.</span></span>  <span data-ttu-id="398f3-380">다른 언어를 사용하는 경우에는 선택한 언어에 비슷한 개념이 적용되는지를 확인하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-380">If using other languages, check to see if similar concepts apply in your chosen language.</span></span>  

#### <span data-ttu-id="398f3-381"><a name="subheading9"></a>기본 연결 제한 늘리기</span><span class="sxs-lookup"><span data-stu-id="398f3-381"><a name="subheading9"></a>Increase default connection limit</span></span>
<span data-ttu-id="398f3-382">.NET에서 다음 코드는 기본 연결 제한(일반적으로 클라이언트 환경에서는 2이고, 서버 환경에서는 10임)을 100으로 늘립니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-382">In .NET, the following code increases the default connection limit (which is usually 2 in a client environment or 10 in a server environment) to 100.</span></span> <span data-ttu-id="398f3-383">일반적으로 이 값을 응용 프로그램에서 사용되는 대략적인 스레드 수로 설정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-383">Typically, you should set the value to approximately the number of threads used by your application.</span></span>  

```csharp
ServicePointManager.DefaultConnectionLimit = 100; //(Or More)  
```

<span data-ttu-id="398f3-384">연결을 열기 전에 연결 제한을 설정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-384">You must set the connection limit before opening any connections.</span></span>  

<span data-ttu-id="398f3-385">기타 프로그래밍 언어의 경우 해당 언어의 설명서에서 연결 제한을 설정하는 방법을 확인하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-385">For other programming languages, see that language's documentation to determine how to set the connection limit.</span></span>  

<span data-ttu-id="398f3-386">자세한 내용은 블로그 게시물 [웹 서비스: 동시 연결](http://blogs.msdn.com/b/darrenj/archive/2005/03/07/386655.aspx)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-386">For additional information, see the blog post [Web Services: Concurrent Connections](http://blogs.msdn.com/b/darrenj/archive/2005/03/07/386655.aspx).</span></span>  

#### <span data-ttu-id="398f3-387"><a name="subheading10"></a>비동기 작업에서 동기 코드를 사용하는 경우 스레드 풀의 최소 스레드 수 늘리기</span><span class="sxs-lookup"><span data-stu-id="398f3-387"><a name="subheading10"></a>Increase ThreadPool Min Threads if using synchronous code with Async Tasks</span></span>
<span data-ttu-id="398f3-388">다음 코드를 사용하면 스레드 풀의 최소 스레드 수를 늘릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-388">This code will increase the thread pool min threads:</span></span>  

```csharp
ThreadPool.SetMinThreads(100,100); //(Determine the right number for your application)  
```

<span data-ttu-id="398f3-389">자세한 내용은 [ThreadPool.SetMinThreads 메서드](http://msdn.microsoft.com/library/system.threading.threadpool.setminthreads%28v=vs.110%29.aspx)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-389">For more information, see [ThreadPool.SetMinThreads Method](http://msdn.microsoft.com/library/system.threading.threadpool.setminthreads%28v=vs.110%29.aspx).</span></span>  

#### <span data-ttu-id="398f3-390"><a name="subheading11"></a>.NET 4.5 가비지 수집 기능 활용</span><span class="sxs-lookup"><span data-stu-id="398f3-390"><a name="subheading11"></a>Take advantage of .NET 4.5 Garbage Collection</span></span>
<span data-ttu-id="398f3-391">클라이언트 응용 프로그램에 .NET 4.5를 사용하면 서버 가비지 수집 시 성능을 개선할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-391">Use .NET 4.5 or later for the client application to take advantage of performance improvements in server garbage collection.</span></span>

<span data-ttu-id="398f3-392">자세한 내용은 [.NET 4.5의 성능 개선 사항 개요](http://msdn.microsoft.com/magazine/hh882452.aspx)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-392">For more information, see the article [An Overview of Performance Improvements in .NET 4.5](http://msdn.microsoft.com/magazine/hh882452.aspx).</span></span>  

### <span data-ttu-id="398f3-393"><a name="subheading12"></a>제한 없는 병렬 처리</span><span class="sxs-lookup"><span data-stu-id="398f3-393"><a name="subheading12"></a>Unbounded Parallelism</span></span>
<span data-ttu-id="398f3-394">병렬 처리가 성능을 개선하는 데 매우 효율적이기는 하지만, 제한 없는 병렬 처리(스레드 및/또는 병렬 요청 수에 제한이 없음)를 사용하여 데이터를 업로드 또는 다운로드하거나 여러 작업자를 사용하여 같은 저장소 계정의 여러 파티션(컨테이너, 큐 또는 테이블 파티션)에 액세스하거나 같은 파티션의 여러 항목에 액세스할 때는 주의해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-394">While parallelism can be great for performance, be careful about using unbounded parallelism (no limit on the number of threads and/or parallel requests) to upload or download data, using multiple workers to access multiple partitions (containers, queues, or table partitions) in the same storage account or to access multiple items in the same partition.</span></span> <span data-ttu-id="398f3-395">병렬 처리에 제한이 없는 경우 응용 프로그램에서 클라이언트 장치의 기능 또는 저장소 계정의 확장성 목표를 초과하여 대기 시간이 길어지고 제한이 증가할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-395">If the parallelism is unbounded, your application can exceed the client device's capabilities or the storage account's scalability targets resulting in longer latencies and throttling.</span></span>  

### <span data-ttu-id="398f3-396"><a name="subheading13"></a>저장소 클라이언트 라이브러리 및 도구</span><span class="sxs-lookup"><span data-stu-id="398f3-396"><a name="subheading13"></a>Storage Client Libraries and Tools</span></span>
<span data-ttu-id="398f3-397">항상 Microsoft에서 제공하는 최신 클라이언트 라이브러리와 도구를 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-397">Always use the latest Microsoft provided client libraries and tools.</span></span> <span data-ttu-id="398f3-398">이 문서를 작성할 당시에는 .NET, Windows Phone, Windows Runtime, Java, C++의 클라이언트 라이브러리와 다른 언어의 미리 보기 라이브러리를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-398">At the time of writing, there are client libraries available for .NET, Windows Phone, Windows Runtime, Java, and C++, as well as preview libraries for other languages.</span></span> <span data-ttu-id="398f3-399">또한 Microsoft에서는 Azure 저장소 작업을 위해 PowerShell cmdlet 및 Azure CLI 명령도 출시했습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-399">In addition, Microsoft has released PowerShell cmdlets and Azure CLI commands for working with Azure Storage.</span></span> <span data-ttu-id="398f3-400">Microsoft는 성능을 고려하여 이러한 도구를 활발하게 개발하고, 최신 서비스 버전으로 해당 도구를 최신 상태로 유지하며, 해당 도구가 대부분의 검증된 작업 방식을 처리할 수 있는지를 내부적으로 확인하고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-400">Microsoft actively develops these tools with performance in mind, keeps them up to date with the latest service versions, and ensures they handle many of the proven performance practices internally.</span></span>  

### <a name="retries"></a><span data-ttu-id="398f3-401">다시 시도</span><span class="sxs-lookup"><span data-stu-id="398f3-401">Retries</span></span>
#### <span data-ttu-id="398f3-402"><a name="subheading14"></a>제한/서버 작업 중</span><span class="sxs-lookup"><span data-stu-id="398f3-402"><a name="subheading14"></a>Throttling/ServerBusy</span></span>
<span data-ttu-id="398f3-403">저장소 서비스에서 응용 프로그램을 제한하거나 일시적인 상황으로 인해 요청을 처리하지 못해 “503 서버 작업 중” 메시지 또는 “500 시간 초과”를 반환하는 경우가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-403">In some cases, the storage service may throttle your application or may simply be unable to serve the request due to some transient condition and return a "503 Server busy" message or "500 Timeout".</span></span>  <span data-ttu-id="398f3-404">응용 프로그램에서 확장성 목표에 도달했거나 시스템이 처리량을 높이기 위해 분할된 데이터의 균형을 다시 조정하는 경우 이러한 현상이 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-404">This can happen if your application is approaching any of the scalability targets, or if the system is rebalancing your partitioned data to allow for higher throughput.</span></span>  <span data-ttu-id="398f3-405">클라이언트 응용 프로그램은 일반적으로 이러한 오류를 발생시키는 작업을 다시 시도해야 합니다. 동일한 요청을 나중에 시도하면 성공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-405">The client application should typically retry the operation that causes such an error: attempting the same request later can succeed.</span></span> <span data-ttu-id="398f3-406">그러나 응용 프로그램이 확장성 목표에 도달하여 저장소 서비스에서 응용 프로그램을 제한하는 경우 또는 서비스가 다른 이유로 인해 요청을 처리하지 못한 경우에는 작업을 적극적으로 다시 시도하면 대개 문제가 악화됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-406">However, if the storage service is throttling your application because it is exceeding scalability targets, or even if the service was unable to serve the request for some other reason, aggressive retries usually make the problem worse.</span></span> <span data-ttu-id="398f3-407">따라서 지수 백오프를 사용해야 합니다. 클라이언트 라이브러리에서는 이 동작을 기본적으로 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-407">For this reason, you should use an exponential back off (the client libraries default to this behavior).</span></span> <span data-ttu-id="398f3-408">예를 들어 응용 프로그램은 작업을 2초, 4초, 10초, 30초 후에 다시 시도한 다음 계속 실패하면 작업을 완전히 포기할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-408">For example, your application may retry after 2 seconds, then 4 seconds, then 10 seconds, then 30 seconds, and then give up completely.</span></span> <span data-ttu-id="398f3-409">이 동작을 적용하면 서비스에 대한 응용 프로그램의 로드가 크게 감소하며 문제가 악화되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-409">This behavior results in your application significantly reducing its load on the service rather than exacerbating any problems.</span></span>  

<span data-ttu-id="398f3-410">연결 오류는 제한으로 인해 발생하는 것이 아니며 일시적인 것이므로 즉시 다시 시도할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-410">Note that connectivity errors can be retried immediately, because they are not the result of throttling and are expected to be transient.</span></span>  

#### <span data-ttu-id="398f3-411"><a name="subheading15"></a>다시 시도할 수 없는 오류</span><span class="sxs-lookup"><span data-stu-id="398f3-411"><a name="subheading15"></a>Non-Retryable Errors</span></span>
<span data-ttu-id="398f3-412">클라이언트 라이브러리는 다시 시도할 수 있는 오류와 그렇지 않은 오류를 인식할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-412">The client libraries are aware of which errors are retry-able and which are not.</span></span> <span data-ttu-id="398f3-413">그러나 저장소 REST API에 대해 사용자 고유의 코드를 작성하는 경우 다시 시도해서는 안 되는 오류도 있다는 사실을 기억하세요. 예를 들어 400(잘못된 요청) 응답은 클라이언트 응용 프로그램이 형식이 잘못되어 처리할 수 없는 요청을 보냈음을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-413">However, if you are writing your own code against the storage REST API, remember there are some errors that you should not retry: for example, a 400 (Bad Request) response indicates that the client application sent a request that could not be processed because it was not in an expected form.</span></span> <span data-ttu-id="398f3-414">이 요청을 다시 보내면 매번 같은 응답이 반환되므로 다시 시도해도 아무런 의미가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-414">Resending this request will result the same response every time, so there is no point in retrying it.</span></span> <span data-ttu-id="398f3-415">저장소 REST API를 기준으로 코드를 직접 작성하는 경우에는 오류 코드의 의미와 각 오류 코드에 대해 작업을 적절하게 다시 시도하거나 시도하지 않는 방법을 파악해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-415">If you are writing your own code against the storage REST API, be aware of what the error codes mean and the proper way to retry (or not) for each of them.</span></span>  

#### <a name="useful-resources"></a><span data-ttu-id="398f3-416">유용한 리소스</span><span class="sxs-lookup"><span data-stu-id="398f3-416">Useful Resources</span></span>
<span data-ttu-id="398f3-417">저장소 오류 코드에 대한 자세한 내용은 Microsoft Azure 웹 사이트의 [상태 및 오류 코드](http://msdn.microsoft.com/library/azure/dd179382.aspx) 를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-417">For more information about storage error codes, see [Status and Error Codes](http://msdn.microsoft.com/library/azure/dd179382.aspx) on the Microsoft Azure web site.</span></span>  

## <a name="blobs"></a><span data-ttu-id="398f3-418">Blob</span><span class="sxs-lookup"><span data-stu-id="398f3-418">Blobs</span></span>
<span data-ttu-id="398f3-419">위에서 설명한 [모든 서비스](#allservices) 에 대한 검증된 작업 방식 외에 Blob 서비스에만 적용되는 다음과 같은 검증된 작업 방식도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-419">In addition to the proven practices for [All Services](#allservices) described previously, the following proven practices apply specifically to the blob service.</span></span>  

### <a name="blob-specific-scalability-targets"></a><span data-ttu-id="398f3-420">Blob 관련 확장성 목표</span><span class="sxs-lookup"><span data-stu-id="398f3-420">Blob-Specific Scalability Targets</span></span>
#### <span data-ttu-id="398f3-421"><a name="subheading46"></a>동시에 단일 개체를 액세스하는 여러 클라이언트</span><span class="sxs-lookup"><span data-stu-id="398f3-421"><a name="subheading46"></a>Multiple clients accessing a single object concurrently</span></span>
<span data-ttu-id="398f3-422">동시에 단일 개체에 액세스하는 많은 수의 클라이언트가 있는 경우 개체 기준 및 저장소 계정 기준 확장성 목표를 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-422">If you have a large number of clients accessing a single object concurrently you will need to consider per object and storage account scalability targets.</span></span> <span data-ttu-id="398f3-423">단일 개체에 액세스할 수 있는 클라이언트의 정확한 수는 동시에 해당 개체를 요청하는 클라이언트의 수, 개체의 크기, 네트워크 상태 등의 요인에 따라 달라집니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-423">The exact number of clients that can access a single object will vary depending on factors such as the number of clients requesting the object simultaneously, the size of the object, network conditions etc.</span></span>

<span data-ttu-id="398f3-424">개체를 웹 사이트에서 제공된 이미지 또는 비디오와 같은 CDN을 통해 배포할 수 있는 경우 CDN을 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-424">If the object can be distributed through a CDN such as images or videos served from a website then you should use a CDN.</span></span> <span data-ttu-id="398f3-425">[여기](#subheading5)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-425">See [here](#subheading5).</span></span>

<span data-ttu-id="398f3-426">데이터가 기밀인 과학 시뮬레이션 등의 기타 시나리오에서는 두 가지 옵션을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-426">In other scenarios such as scientific simulations where the data is confidential you have two options.</span></span> <span data-ttu-id="398f3-427">첫 번째는 워크로드 액세스를 스태거하면서 일정 기간 동안 개체에 액세스하거나 동시에 액세스하는 방식입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-427">The first is to stagger your workload's access such that the object is accessed over a period of time vs being accessed simultaneously.</span></span> <span data-ttu-id="398f3-428">또는 개체를 임시로 여러 저장소 계정으로 복사하여 저장소 계정 전체에서 개체당 총 IOPS를 늘릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-428">Alternatively, you can temporarily copy the object to multiple storage accounts thus increasing the total IOPS per object and across storage accounts.</span></span> <span data-ttu-id="398f3-429">제한된 테스트에서 약 25개의 VM이 동시에 100GB Blob을 다운로드할 수 있다는 사실이 확인되었습니다(각 VM이 32개의 스레드를 사용하여 다운로드를 병렬화함).</span><span class="sxs-lookup"><span data-stu-id="398f3-429">In limited testing we found that around 25 VMs could simultaneously download a 100GB blob in parallel (each VM was parallelizing the download using 32 threads).</span></span> <span data-ttu-id="398f3-430">100개의 클라이언트가 개체에 액세스해야 하는 경우 먼저 두 번째 저장소 계정으로 복사한 다음 처음 50개의 VM은 첫 번째 Blob에 액세스하도록 하고 두 번째 50개의 VM은 두 번째 Blob에 액세스하도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-430">If you had 100 clients needing to access the object, first copy it to a second storage account and then have the first 50 VMs access the first blob and the second 50 VMs access the second blob.</span></span> <span data-ttu-id="398f3-431">결과는 응용 프로그램 동작에 따라 다르므로 설계 중에 이 동작을 테스트해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-431">Results will vary depending on your applications behavior so you should test this during design.</span></span> 

#### <span data-ttu-id="398f3-432"><a name="subheading16"></a>Blob당 대역폭 및 작업</span><span class="sxs-lookup"><span data-stu-id="398f3-432"><a name="subheading16"></a>Bandwidth and operations per Blob</span></span>
<span data-ttu-id="398f3-433">최대 초당 60MB의 속도로 단일 Blob을 읽거나 Blob에 쓸 수 있습니다. 이 속도는 약 480Mbps이므로 대부분의 클라이언트 쪽 네트워크 기능을 초과합니다(클라이언트 장치의 실제 NIC 포함).</span><span class="sxs-lookup"><span data-stu-id="398f3-433">You can read or write to a single blob at up to a maximum of 60 MB/second (this is approximately 480 Mbps which exceeds the capabilities of many client side networks (including the physical NIC on the client device).</span></span> <span data-ttu-id="398f3-434">또한 단일 Blob는 요청을 초당 500개까지 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-434">In addition, a single blob supports up to 500 requests per second.</span></span> <span data-ttu-id="398f3-435">여러 클라이언트가 같은 Blob을 읽어야 해서 이 제한이 초과될 수 있는 경우에는 CDN을 사용해 Blob을 분산시켜야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-435">If you have multiple clients that need to read the same blob and you might exceed these limits, you should consider using a CDN for distributing the blob.</span></span>  

<span data-ttu-id="398f3-436">Blob의 목표 처리량에 대한 자세한 내용은 [Azure 저장소 확장성 및 성능 목표](storage-scalability-targets.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-436">For more information about target throughput for blobs, see [Azure Storage Scalability and Performance Targets](storage-scalability-targets.md).</span></span>  

### <a name="copying-and-moving-blobs"></a><span data-ttu-id="398f3-437">Blob 복사 및 이동</span><span class="sxs-lookup"><span data-stu-id="398f3-437">Copying and Moving Blobs</span></span>
#### <span data-ttu-id="398f3-438"><a name="subheading17"></a>Blob 복사</span><span class="sxs-lookup"><span data-stu-id="398f3-438"><a name="subheading17"></a>Copy Blob</span></span>
<span data-ttu-id="398f3-439">저장소 REST API 버전 2012-02-12에는 유용한 계정 간 Blob 복사 기능이 도입되었습니다. 클라이언트 응용 프로그램은 다른 원본(다른 저장소 계정일 수 있음)의 Blob을 복사하도록 저장소 서비스에 명령한 다음 해당 서비스가 비동기식으로 복사를 수행하도록 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-439">The storage REST API version 2012-02-12 introduced the useful ability to copy blobs across accounts: a client application can instruct the storage service to copy a blob from another source (possibly in a different storage account), and then let the service perform the copy asynchronously.</span></span> <span data-ttu-id="398f3-440">이 경우 데이터를 다운로드 및 업로드하지 않아도 되므로 다른 저장소 계정에서 데이터를 마이그레이션할 때 응용 프로그램에 필요한 대역폭을 크게 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-440">This can significantly reduce the bandwidth needed for the application when you are migrating data from other storage accounts because you do not need to download and upload the data.</span></span>  

<span data-ttu-id="398f3-441">그러나 저장소 계정 간에 복사할 때는 복사 완료 시간이 보장되지 않는다는 점을 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-441">One consideration, however, is that, when copying between storage accounts, there is no time guarantee on when the copy will complete.</span></span> <span data-ttu-id="398f3-442">응용 프로그램이 개발자의 제어 아래에서 Blob 복사를 빠르게 완료해야 하는 경우에는 Blob을 VM에 다운로드한 다음 대상으로 업로드하는 방식으로 복사하는 것이 더 효율적일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-442">If your application needs to complete a blob copy quickly under your control, it may be better to copy the blob by downloading it to a VM and then uploading it to the destination.</span></span>  <span data-ttu-id="398f3-443">해당 사항을 완벽하게 예측하려면 같은 Azure 지역에서 실행되는 VM이 복사를 수행하도록 합니다. 그렇지 않으면 네트워크 상태가 복사 성능에 영향을 줄 수 있으며 대부분의 경우에는 영향을 주게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-443">For full predictability in that situation, ensure that the copy is performed by a VM running in the same Azure region, or else network conditions may (and probably will) affect your copy performance.</span></span>  <span data-ttu-id="398f3-444">비동기 복사의 진행률을 프로그래밍 방식으로 모니터링할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-444">In addition, you can monitor the progress of an asynchronous copy programmatically.</span></span>  

<span data-ttu-id="398f3-445">같은 저장소 계정 자체 내의 복사는 보통 빠르게 완료됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-445">Note that copies within the same storage account itself are generally completed quickly.</span></span>  

<span data-ttu-id="398f3-446">자세한 내용은 [Blob 복사](http://msdn.microsoft.com/library/azure/dd894037.aspx)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-446">For more information, see [Copy Blob](http://msdn.microsoft.com/library/azure/dd894037.aspx).</span></span>  

#### <span data-ttu-id="398f3-447"><a name="subheading18"></a>AzCopy 사용</span><span class="sxs-lookup"><span data-stu-id="398f3-447"><a name="subheading18"></a>Use AzCopy</span></span>
<span data-ttu-id="398f3-448">Azure Storage 팀은 여러 저장소 계정으로/계정에서/계정 간에 많은 Blob을 대량으로 전송하는 데 사용할 수 있는 명령줄 도구인 "AzCopy"를 공개했습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-448">The Azure Storage team has released a command-line tool "AzCopy" that is meant to help with bulk transferring many blobs to, from, and across storage accounts.</span></span>  <span data-ttu-id="398f3-449">이 도구는 이러한 시나리오용으로 최적화되어 있으며 높은 전송 속도를 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-449">This tool is optimized for this scenario, and can achieve high transfer rates.</span></span>  <span data-ttu-id="398f3-450">대량 업로드, 다운로드 및 복사 시나리오에는 이 도구를 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-450">Its use is encouraged for bulk upload, download, and copy scenarios.</span></span> <span data-ttu-id="398f3-451">이 도구에 대해 자세히 알아보고 도구를 다운로드하려면 [AzCopy 명령줄 유틸리티로 데이터 전송](storage-use-azcopy.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-451">To learn more about it and download it, see [Transfer data with the AzCopy Command-Line Utility](storage-use-azcopy.md).</span></span>  

#### <span data-ttu-id="398f3-452"><a name="subheading19"></a>Azure 가져오기/내보내기 서비스</span><span class="sxs-lookup"><span data-stu-id="398f3-452"><a name="subheading19"></a>Azure Import/Export Service</span></span>
<span data-ttu-id="398f3-453">1TB가 넘는 매우 많은 양의 데이터에 대해 Azure 저장소에서는 가져오기/내보내기 서비스를 제공합니다. 이 서비스를 사용하는 경우 하드 드라이브를 배송하여 Blob Storage에서 데이터를 업로드하고 다운로드할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-453">For very large volumes of data (more than 1TB), the Azure Storage offers the Import/Export service, which allows for uploading and downloading from blob storage by shipping hard drives.</span></span>  <span data-ttu-id="398f3-454">데이터를 하드 드라이브에 저장한 다음 업로드용으로 Microsoft에 보내거나 데이터 다운로드를 위해 빈 하드 드라이브를 Microsoft에 보낼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-454">You can put your data on a hard drive and send it to Microsoft for upload, or send a blank hard drive to Microsoft to download data.</span></span>  <span data-ttu-id="398f3-455">자세한 내용은 [Microsoft Azure Import/Export Service를 사용하여 Blob Storage에 데이터 전송](storage-import-export-service.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-455">For more information, see [Use the Microsoft Azure Import/Export Service to Transfer Data to Blob Storage](storage-import-export-service.md).</span></span>  <span data-ttu-id="398f3-456">네트워크를 통해 많은 양의 데이터를 업로드/다운로드하는 것보다 이 서비스를 사용하는 것이 훨씬 더 효율적일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-456">This can be much more efficient than uploading/downloading this volume of data over the network.</span></span>  

### <span data-ttu-id="398f3-457"><a name="subheading20"></a>메타데이터 사용</span><span class="sxs-lookup"><span data-stu-id="398f3-457"><a name="subheading20"></a>Use metadata</span></span>
<span data-ttu-id="398f3-458">Blob 서비스는 HEAD 요청을 지원하며, 여기에는 Blob 관련 메타데이터가 포함될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-458">The blob service supports head requests, which can include metadata about the blob.</span></span> <span data-ttu-id="398f3-459">예를 들어 응용 프로그램은 사진에서 EXIF 데이터를 추출해야 하는 경우 사진을 검색해 데이터를 추출할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-459">For example, if your application needed the EXIF data out of a photo, it could retrieve the photo and extract it.</span></span> <span data-ttu-id="398f3-460">대역폭을 줄이고 성능을 개선하려면 응용 프로그램이 사진을 업로드할 때 Blob의 메타데이터에 EXIF 데이터를 저장하면 됩니다. 그런 다음 HEAD 요청만 사용하여 메타데이터에서 EXIF 데이터를 검색함으로써, Blob을 읽을 때마다 EXIF 데이터를 추출하는 데 필요한 상당한 대역폭과 처리 시간을 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-460">To save bandwidth and improve performance, your application could store the EXIF data in the blob's metadata when the application uploaded the photo: you can then retrieve the EXIF data in metadata using only a HEAD request, saving significant bandwidth and the processing time needed to extract the EXIF data each time the blob is read.</span></span> <span data-ttu-id="398f3-461">Blob의 전체 데이터가 아닌 메타데이터만 필요한 시나리오에서는 이러한 방식이 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-461">This would be useful in scenarios where you only need the metadata, and not the full content of a blob.</span></span>  <span data-ttu-id="398f3-462">메타데이터는 Blob당 8KB만 저장할 수 있으므로(이보다 많은 메타데이터를 저장하려는 요청은 Blob 서비스에서 허용되지 않음) 메타데이터 크기가 8KB를 초과하면 이 방식을 사용할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-462">Note that only 8 KB of metadata can be stored per blob (the service will not accept a request to store more than that), so if the data does not fit in that size, you may not be able to use this approach.</span></span>  

<span data-ttu-id="398f3-463">.NET을 사용하여 Blob의 메타데이터를 가져오는 방법의 예는 [속성과 메타데이터 설정 및 검색](storage-properties-metadata.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-463">For an example of how to get a blob's metadata using .NET, see [Set and Retrieve Properties and Metadata](storage-properties-metadata.md).</span></span>  

### <a name="uploading-fast"></a><span data-ttu-id="398f3-464">고속 업로드</span><span class="sxs-lookup"><span data-stu-id="398f3-464">Uploading Fast</span></span>
<span data-ttu-id="398f3-465">Blob을 빠르게 업로드하려면 답변할 첫 번째 질문은 "Blob을 하나 업로드합니까 아니면 여러 개 업로드합니까?"입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-465">To upload blobs fast, the first question to answer is: are you uploading one blob or many?</span></span>  <span data-ttu-id="398f3-466">아래 지침을 참고하여 시나리오에 따라 사용할 적절한 방법을 결정합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-466">Use the below guidance to determine the correct method to use depending on your scenario.</span></span>  

#### <span data-ttu-id="398f3-467"><a name="subheading21"></a>큰 Blob 하나를 빠르게 업로드</span><span class="sxs-lookup"><span data-stu-id="398f3-467"><a name="subheading21"></a>Uploading one large blob quickly</span></span>
<span data-ttu-id="398f3-468">큰 Blob 하나를 빠르게 업로드하려는 경우 클라이언트 응용 프로그램은 블록이나 페이지를 병렬로 업로드해야 합니다. 이때 개별 Blob의 확장성 목표와 저장소 계정의 전체 확장성 목표를 모두 고려해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-468">To upload a single large blob quickly, your client application should upload its blocks or pages in parallel (being mindful of the scalability targets for individual blobs and the storage account as a whole).</span></span>  <span data-ttu-id="398f3-469">Microsoft에서 제공하는 공식 RTM 저장소 클라이언트 라이브러리(.NET, Java)에는 이러한 작업을 수행하는 기능이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-469">Note that the official Microsoft-provided RTM Storage Client libraries (.NET, Java) have the ability to do this.</span></span>  <span data-ttu-id="398f3-470">각 라이브러리에 대해 아래에 지정된 개체/속성을 사용하여 동시성 수준을 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-470">For each of the libraries, use the below specified object/property to set the level of concurrency:</span></span>  

* <span data-ttu-id="398f3-471">.NET: 사용할 BlobRequestOptions 개체에 대해 ParallelOperationThreadCount를 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-471">.NET: Set ParallelOperationThreadCount on a BlobRequestOptions object to be used.</span></span>
* <span data-ttu-id="398f3-472">Java/Android: BlobRequestOptions.setConcurrentRequestCount()를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-472">Java/Android: Use BlobRequestOptions.setConcurrentRequestCount()</span></span>
* <span data-ttu-id="398f3-473">Node.js: 요청 옵션 또는 Blob 서비스에 대해 parallelOperationThreadCount를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-473">Node.js: Use parallelOperationThreadCount on either the request options or on the blob service.</span></span>
* <span data-ttu-id="398f3-474">C++: blob_request_options::set_parallelism_factor 메서드를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-474">C++: Use the blob_request_options::set_parallelism_factor method.</span></span>

#### <span data-ttu-id="398f3-475"><a name="subheading22"></a>여러 Blob을 빠르게 업로드</span><span class="sxs-lookup"><span data-stu-id="398f3-475"><a name="subheading22"></a>Uploading many blobs quickly</span></span>
<span data-ttu-id="398f3-476">Blob 여러 개를 빠르게 업로드하려면 Blob을 병렬로 업로드합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-476">To upload many blobs quickly, upload blobs in parallel.</span></span> <span data-ttu-id="398f3-477">이 방식은 병렬 블록 업로드를 통해 Blob을 하나씩 업로드하는 것보다 빠릅니다. 저장소 서비스의 여러 파티션으로 업로드가 분산되기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-477">This is faster than uploading single blobs at a time with parallel block uploads because it spreads the upload across multiple partitions of the storage service.</span></span> <span data-ttu-id="398f3-478">단일 Blob은 초당 60MB(약 480Mbps)의 처리량만을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-478">A single blob only supports a throughput of 60 MB/second (approximately 480 Mbps).</span></span> <span data-ttu-id="398f3-479">이 문서를 작성할 당시 미국 기반 LRS 계정은 최대 20Gbps의 수신 속도를 지원합니다. 이 속도는 개별 Blob이 지원하는 처리량보다 훨씬 높습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-479">At the time of writing, a US-based LRS account supports up to 20 Gbps ingress which is far more than the throughput supported by an individual blob.</span></span>  <span data-ttu-id="398f3-480">이 시나리오에서는 기본적으로 업로드를 병렬로 수행하는 [AzCopy](#subheading18)를 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-480">[AzCopy](#subheading18) performs uploads in parallel by default, and is recommended for this scenario.</span></span>  

### <span data-ttu-id="398f3-481"><a name="subheading23"></a>적절한 Blob 유형 선택</span><span class="sxs-lookup"><span data-stu-id="398f3-481"><a name="subheading23"></a>Choosing the correct type of blob</span></span>
<span data-ttu-id="398f3-482">Azure Storage는 두 가지 형식의 Blob 즉, *페이지* Blob과 *블록* Blob을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-482">Azure Storage supports two types of blob: *page* blobs and *block* blobs.</span></span> <span data-ttu-id="398f3-483">지정된 사용 시나리오에 대해 선택하는 Blob 유형은 솔루션의 성능과 확장성에 영향을 줍니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-483">For a given usage scenario, your choice of blob type will affect the performance and scalability of your solution.</span></span> <span data-ttu-id="398f3-484">블록 Blob은 많은 양의 데이터를 효율적으로 업로드하려는 경우 적절합니다. 예를 들어 클라이언트 응용 프로그램이 사진이나 동영상을 Blob Storage에 업로드해야 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-484">Block blobs are appropriate when you want to upload large amounts of data efficiently: for example, a client application may need to upload photos or video to blob storage.</span></span> <span data-ttu-id="398f3-485">페이지 Blob은 응용 프로그램이 데이터에 대해 임의 쓰기를 수행해야 하는 경우 적절합니다. 예를 들어 Azure VHD는 페이지 Blob으로 저장됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-485">Page blobs are appropriate if the application needs to perform random writes on the data: for example, Azure VHDs are stored as page blobs.</span></span>  

<span data-ttu-id="398f3-486">자세한 내용은 [블록 Blob, 추가 Blob 및 페이지 Blob 이해](http://msdn.microsoft.com/library/azure/ee691964.aspx)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-486">For more information, see [Understanding Block Blobs, Append Blobs, and Page Blobs](http://msdn.microsoft.com/library/azure/ee691964.aspx).</span></span>  

## <a name="tables"></a><span data-ttu-id="398f3-487">테이블</span><span class="sxs-lookup"><span data-stu-id="398f3-487">Tables</span></span>
<span data-ttu-id="398f3-488">위에서 설명한 [모든 서비스](#allservices) 에 대한 검증된 작업 방식 외에 테이블 서비스에만 적용되는 다음과 같은 검증된 작업 방식도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-488">In addition to the proven practices for [All Services](#allservices) described previously, the following proven practices apply specifically to the table service.</span></span>  

### <span data-ttu-id="398f3-489"><a name="subheading24"></a>테이블 관련 확장성 목표</span><span class="sxs-lookup"><span data-stu-id="398f3-489"><a name="subheading24"></a>Table-Specific Scalability Targets</span></span>
<span data-ttu-id="398f3-490">전체 저장소 계정의 대역폭 제한 외에 테이블에만 적용되는 확장성 제한도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-490">In addition to the bandwidth limitations of an entire storage account, tables have the following specific scalability limit.</span></span>  <span data-ttu-id="398f3-491">트래픽이 증가하면 시스템에서 부하를 분산하지만 트래픽이 갑자기 증가하면 그에 해당하는 처리량을 즉시 달성하지 못할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-491">Note that the system will load balance as your traffic increases, but if your traffic has sudden bursts, you may not be able to get this volume of throughput immediately.</span></span>  <span data-ttu-id="398f3-492">트래픽 패턴이 갑작스럽게 변화하는 경우 저장소 서비스가 테이블의 부하를 자동으로 분산시키므로 해당 변화 기간 동안에는 제한 및/또는 시간 초과가 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-492">If your pattern has bursts, you should expect to see throttling and/or timeouts during the burst as the storage service automatically load balances out your table.</span></span>  <span data-ttu-id="398f3-493">일반적으로는 트래픽이 서서히 증가하면 시스템이 적절하게 부하를 분산할 수 있는 시간이 있으므로 더 나은 결과를 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-493">Ramping up slowly generally has better results as it gives the system time to load balance appropriately.</span></span>  

#### <a name="entities-per-second-account"></a><span data-ttu-id="398f3-494">초당 엔터티 수(계정)</span><span class="sxs-lookup"><span data-stu-id="398f3-494">Entities per Second (Account)</span></span>
<span data-ttu-id="398f3-495">계정의 테이블 액세스를 위한 확장성 제한은 초당 최대 2만 개 엔터티(각 1KB)입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-495">The scalability limit for accessing tables is up to 20,000 entities (1KB each) per second for an account.</span></span>  <span data-ttu-id="398f3-496">일반적으로는 삽입, 업데이트, 삭제 또는 스캔하는 각 엔터티가 이 목표 수 계산에 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-496">In general, each entity that is inserted, updated, deleted, or scanned counts toward this target.</span></span>  <span data-ttu-id="398f3-497">따라서 엔터티 100개가 포함된 일괄 삽입을 수행하면 엔터티가 100개로 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-497">So a batch insert that contains 100 entities would count as 100 entities.</span></span>  <span data-ttu-id="398f3-498">마찬가지로 1,000개 엔터티를 스캔하여 5를 반환하는 쿼리의 경우 엔터티가 1,000개로 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-498">A query that scans 1000 entities and returns 5 would count as 1000 entities.</span></span>  

#### <a name="entities-per-second-partition"></a><span data-ttu-id="398f3-499">초당 엔터티 수(파티션)</span><span class="sxs-lookup"><span data-stu-id="398f3-499">Entities per Second (Partition)</span></span>
<span data-ttu-id="398f3-500">단일 파티션 내에서 테이블 액세스를 위한 확장성 목표는 초당 2,000개 엔터티(각 1KB)입니다. 파티션의 경우에도 이전 섹션에서 설명한 것과 같은 계산 방법이 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-500">Within a single partition, the scalability target for accessing tables is 2,000 entities (1KB each) per second, using the same counting as described in the previous section.</span></span>  

### <a name="configuration"></a><span data-ttu-id="398f3-501">구성</span><span class="sxs-lookup"><span data-stu-id="398f3-501">Configuration</span></span>
<span data-ttu-id="398f3-502">이 섹션에서는 테이블 서비스에서 성능을 크게 개선하기 위해 사용할 수 있는 다양한 빠른 구성 설정을 소개합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-502">This section lists several quick configuration settings that you can use to make significant performance improvements in the table service:</span></span>  

#### <span data-ttu-id="398f3-503"><a name="subheading25"></a>JSON 사용</span><span class="sxs-lookup"><span data-stu-id="398f3-503"><a name="subheading25"></a>Use JSON</span></span>
<span data-ttu-id="398f3-504">저장소 서비스 버전 2013-08-15부터 테이블 서비스에서는 테이블 데이터를 전송하는 데 XML 기반 AtomPub가 아닌 JSON을 사용할 수 있게 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-504">Beginning with storage service version 2013-08-15, the table service supports using JSON instead of the XML-based AtomPub format for transferring table data.</span></span> <span data-ttu-id="398f3-505">이로 인해 페이로드 크기를 최대 75%까지 줄일 수 있으며 응용 프로그램의 성능을 크게 개선할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-505">This can reduce payload sizes by as much as 75% and can significantly improve the performance of your application.</span></span>

<span data-ttu-id="398f3-506">자세한 내용은 [Microsoft Azure 테이블: JSON 소개](http://blogs.msdn.com/b/windowsazurestorage/archive/2013/12/05/windows-azure-tables-introducing-json.aspx) 및 [Table Service 작업의 페이로드 형식](http://msdn.microsoft.com/library/azure/dn535600.aspx)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-506">For more information, see the post [Microsoft Azure Tables: Introducing JSON](http://blogs.msdn.com/b/windowsazurestorage/archive/2013/12/05/windows-azure-tables-introducing-json.aspx) and [Payload Format for Table Service Operations](http://msdn.microsoft.com/library/azure/dn535600.aspx).</span></span>

#### <span data-ttu-id="398f3-507"><a name="subheading26"></a>Nagle 해제</span><span class="sxs-lookup"><span data-stu-id="398f3-507"><a name="subheading26"></a>Nagle Off</span></span>
<span data-ttu-id="398f3-508">Nagle 알고리즘은 네트워크 성능을 개선하기 위한 수단으로 TCP/IP 네트워크에서 광범위하게 구현됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-508">Nagle's algorithm is widely implemented across TCP/IP networks as a means to improve network performance.</span></span> <span data-ttu-id="398f3-509">그러나 대화형 작업을 많이 수행하는 환경 등 일부 상황에서는 이 알고리즘이 적합하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-509">However, it is not optimal in all circumstances (such as highly interactive environments).</span></span> <span data-ttu-id="398f3-510">Azure Storage의 경우 Nagle 알고리즘은 테이블 및 큐 서비스에 대한 요청 성능을 떨어뜨릴 수 있으므로 가능한 경우에는 해제해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-510">For Azure Storage, Nagle's algorithm has a negative impact on the performance of requests to the table and queue services, and you should disable it if possible.</span></span>  

<span data-ttu-id="398f3-511">자세한 내용은 [소규모 요청에는 적합하지 않은 Nagle 알고리즘](http://blogs.msdn.com/b/windowsazurestorage/archive/2010/06/25/nagle-s-algorithm-is-not-friendly-towards-small-requests.aspx) 블로그 게시물을 참조하세요. 이 게시물에서는 테이블 및 큐 요청에서 Nagle 알고리즘이 부적절하게 상호 작용하는 이유와 클라이언트 응용 프로그램에서 Nagle 알고리즘을 사용하지 않도록 설정하는 방법에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-511">For more information, see our blog post [Nagle's Algorithm is Not Friendly towards Small Requests](http://blogs.msdn.com/b/windowsazurestorage/archive/2010/06/25/nagle-s-algorithm-is-not-friendly-towards-small-requests.aspx), which explains why Nagle's algorithm interacts poorly with table and queue requests, and shows how to disable it in your client application.</span></span>  

### <a name="schema"></a><span data-ttu-id="398f3-512">스키마</span><span class="sxs-lookup"><span data-stu-id="398f3-512">Schema</span></span>
<span data-ttu-id="398f3-513">테이블 서비스의 성능에 영향을 주는 가장 큰 단일 요인은 데이터를 표시 및 쿼리하는 방법입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-513">How you represent and query your data is the biggest single factor that affects the performance of the table service.</span></span> <span data-ttu-id="398f3-514">각 응용 프로그램별로 다르기는 하지만 이 섹션에서는 다음 항목과 관련된 일반적인 검증된 작업 방식 중 몇 가지에 대해 간략하게 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-514">While every application is different, this section outlines some general proven practices that relate to:</span></span>  

* <span data-ttu-id="398f3-515">테이블 디자인</span><span class="sxs-lookup"><span data-stu-id="398f3-515">Table design</span></span>
* <span data-ttu-id="398f3-516">효율적인 쿼리</span><span class="sxs-lookup"><span data-stu-id="398f3-516">Efficient queries</span></span>
* <span data-ttu-id="398f3-517">효율적인 데이터 업데이트</span><span class="sxs-lookup"><span data-stu-id="398f3-517">Efficient data updates</span></span>  

#### <span data-ttu-id="398f3-518"><a name="subheading27"></a>테이블 및 파티션</span><span class="sxs-lookup"><span data-stu-id="398f3-518"><a name="subheading27"></a>Tables and partitions</span></span>
<span data-ttu-id="398f3-519">테이블은 파티션으로 구분됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-519">Tables are divided into partitions.</span></span> <span data-ttu-id="398f3-520">파티션에 저장되는 모든 엔터티는 같은 파티션 키를 공유하며 해당 파티션 내에서 엔터티를 식별하는 데 사용되는 고유한 행 키를 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-520">Every entity stored in a partition shares the same partition key and has a unique row key to identify it within that partition.</span></span> <span data-ttu-id="398f3-521">파티션을 사용하는 경우에는 이점도 있지만 확장성 제한도 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-521">Partitions provide benefits but also introduce scalability limits.</span></span>  

* <span data-ttu-id="398f3-522">이점: 최대 100개의 개별 저장소 작업(총 크기 제한 4MB)을 포함하는 단일 원자성 일괄 처리 트랜잭션에서 같은 파티션의 엔터티를 업데이트할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-522">Benefits: You can update entities in the same partition in a single, atomic, batch transaction that contains up to 100 separate storage operations (limit of 4MB total size).</span></span> <span data-ttu-id="398f3-523">또한 같은 수의 엔터티를 검색한다고 가정할 때 여러 파티션에 분산된 데이터보다 단일 파티션 내의 데이터를 더 효율적으로 쿼리할 수 있습니다. 단, 테이블 데이터 쿼리와 관련된 추가 권장 사항을 확인해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-523">Assuming the same number of entities to be retrieved, you can also query data within a single partition more efficiently than data that spans partitions (though read on for further recommendations on querying table data).</span></span>
* <span data-ttu-id="398f3-524">확장성 제한: 파티션은 원자성 일괄 처리 트랜잭션을 지원하므로 단일 파티션에 저장된 엔터티에 대한 액세스는 부하 분산할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-524">Scalability limit: Access to entities stored in a single partition cannot be load-balanced because partitions support atomic batch transactions.</span></span> <span data-ttu-id="398f3-525">따라서 개별 테이블 파티션의 확장성 목표는 테이블 서비스에 대한 전체 확장성 목표보다 낮습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-525">For this reason, the scalability target for an individual table partition is lower than for the table service as a whole.</span></span>  

<span data-ttu-id="398f3-526">테이블과 파티션의 이러한 특성을 고려할 때 다음과 같은 디자인 원칙을 적용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-526">Because of these characteristics of tables and partitions, you should adopt the following design principles:</span></span>  

* <span data-ttu-id="398f3-527">클라이언트 응용 프로그램이 작업의 동일한 논리 단위에서 자주 업데이트하거나 쿼리하는 데이터는 같은 파티션에 배치해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-527">Data that your client application frequently updated or queried in the same logical unit of work should be located in the same partition.</span></span>  <span data-ttu-id="398f3-528">이렇게 하는 이유는 응용 프로그램이 쓰기를 집계하기 때문일 수도 있고, 원자성 일괄 처리 작업을 활용하기 위해서일 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-528">This may be because your application is aggregating writes, or because you want to take advantage of atomic batch operations.</span></span>  <span data-ttu-id="398f3-529">또한 단일 쿼리에서는 여러 파티션에 분산된 데이터보다 단일 파티션의 데이터를 더 효율적으로 쿼리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-529">Also, data in a single partition can be more efficiently queried in a single query than data across partitions.</span></span>
* <span data-ttu-id="398f3-530">클라이언트 응용 프로그램이 작업의 동일한 논리 단위에서 삽입/업데이트하거나 쿼리하지 않는 데이터(단일 쿼리 또는 일괄 처리 업데이트)는 별도의 파티션에 배치해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-530">Data that your client application does not insert/update or query in the same logical unit of work (single query or batch update) should be located in separate partitions.</span></span>  <span data-ttu-id="398f3-531">이때 주의해야 할 중요한 사항은, 단일 테이블의 파티션 키 수에는 제한이 없으므로 파티션 키가 매우 많아도 문제가 되지 않으며 성능에도 영향을 주지 않는다는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-531">One important note is that there is no limit to the number of partition keys in a single table, so having millions of partition keys is not a problem and will not impact performance.</span></span>  <span data-ttu-id="398f3-532">예를 들어 응용 프로그램이 사용자가 로그인하는 유명 웹 사이트인 경우에는 사용자 ID를 파티션 키로 사용하면 효율적일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-532">For example, if your application is a popular website with user login, using the User Id as the partition key could be a good choice.</span></span>  

#### <a name="hot-partitions"></a><span data-ttu-id="398f3-533">핫 파티션</span><span class="sxs-lookup"><span data-stu-id="398f3-533">Hot Partitions</span></span>
<span data-ttu-id="398f3-534">핫 파티션은 계정에 대해 부적합한 비율의 트래픽을 받으며, 단일 파티션이므로 부하를 분산할 수 없는 파티션입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-534">A hot partition is one that is receiving a disproportionate percentage of the traffic to an account, and cannot be load balanced because it is a single partition.</span></span>  <span data-ttu-id="398f3-535">일반적으로는 다음의 두 가지 방식 중 하나로 핫 파티션을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-535">In general, hot partitions are created one of two ways:</span></span>  

##### <span data-ttu-id="398f3-536"><a name="subheading28"></a>추가 전용 및 앞에 추가 전용 패턴</span><span class="sxs-lookup"><span data-stu-id="398f3-536"><a name="subheading28"></a>Append Only and Prepend Only patterns</span></span>
<span data-ttu-id="398f3-537">“추가 전용” 패턴은 지정된 PK에 대한 모든/거의 모든 트래픽이 현재 시간에 따라 증가 및 감소하는 패턴입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-537">The "Append Only" pattern is one where all (or nearly all) of the traffic to a given PK increases and decreases according to the current time.</span></span>  <span data-ttu-id="398f3-538">응용 프로그램이 현재 날짜를 로그 데이터의 파티션 키로 사용하는 경우를 예로 들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-538">An example is if your application used the current date as a partition key for log data.</span></span>  <span data-ttu-id="398f3-539">이 경우 모든 삽입 항목이 테이블의 마지막 파티션에 저장되며 모든 쓰기가 테이블 끝으로 이동하므로 시스템이 부하를 분산할 수 없게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-539">This results in all of the inserts going to the last partition in your table, and the system cannot load balance because all of the writes are going to the end of your table.</span></span>  <span data-ttu-id="398f3-540">해당 파티션에 대한 트래픽의 양이 파티션 수준 확장성 목표를 초과하면 제한이 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-540">If the volume of traffic to that partition exceeds the partition-level scalability target, then it will result in throttling.</span></span>  <span data-ttu-id="398f3-541">따라서 테이블 전체에서 요청을 부하 분산할 수 있도록 트래픽이 여러 파티션으로 전송되도록 하는 것이 더 효율적입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-541">It's better to ensure that traffic is sent to multiple partitions, to enable load balance the requests across your table.</span></span>  

##### <span data-ttu-id="398f3-542"><a name="subheading29"></a>트래픽이 많은 데이터</span><span class="sxs-lookup"><span data-stu-id="398f3-542"><a name="subheading29"></a>High-Traffic Data</span></span>
<span data-ttu-id="398f3-543">사용 중인 파티션 구성표로 인해 단일 파티션에 다른 파티션보다 훨씬 많이 사용되는 데이터만 포함되는 경우에도 해당 파티션이 단일 파티션의 확장성 목표에 도달하면 제한이 적용될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-543">If your partitioning scheme results in a single partition that just has data that is far more used than other partitions, you may also see throttling as that partition approaches the scalability target for a single partition.</span></span>  <span data-ttu-id="398f3-544">따라서 파티션 구성표로 인해 확장성 목표에 도달하는 단일 파티션이 없는지를 확인하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-544">It's better to make sure that your partition scheme results in no single partition approaching the scalability targets.</span></span>  

#### <a name="querying"></a><span data-ttu-id="398f3-545">쿼리</span><span class="sxs-lookup"><span data-stu-id="398f3-545">Querying</span></span>
<span data-ttu-id="398f3-546">이 섹션에서는 테이블 서비스 쿼리와 관련하여 검증된 작업 방식에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-546">This section describes proven practices for querying the table service.</span></span>  

##### <span data-ttu-id="398f3-547"><a name="subheading30"></a>쿼리 범위</span><span class="sxs-lookup"><span data-stu-id="398f3-547"><a name="subheading30"></a>Query Scope</span></span>
<span data-ttu-id="398f3-548">여러 가지 방법으로 쿼리할 엔터티의 범위를 지정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-548">There are several ways to specify the range of entities to query.</span></span>  <span data-ttu-id="398f3-549">아래에서는 각 방법의 사용법에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-549">The following is a discussion of the uses of each.</span></span>  

<span data-ttu-id="398f3-550">일반적으로 스캔(단일 엔터티보다 큰 쿼리)은 수행하지 않는 것이 좋지만 스캔을 해야 하는 경우에는 불필요한 대량의 엔터티를 스캔하거나 반환하지 않도록 필요한 데이터만 스캔하도록 데이터를 구성합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-550">In general, avoid scans (queries larger than a single entity), but if you must scan, try to organize your data so that your scans retrieve the data you need without scanning or returning significant amounts of entities you don't need.</span></span>  

###### <a name="point-queries"></a><span data-ttu-id="398f3-551">지점 쿼리</span><span class="sxs-lookup"><span data-stu-id="398f3-551">Point Queries</span></span>
<span data-ttu-id="398f3-552">지점 쿼리에서는 엔터티를 하나만 검색합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-552">A point query retrieves exactly one entity.</span></span> <span data-ttu-id="398f3-553">이를 위해 검색할 엔터티의 파티션 키와 행 키를 모두 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-553">It does this by specifying both the partition key and row key of the entity to retrieve.</span></span> <span data-ttu-id="398f3-554">이러한 쿼리는 매우 효율적이므로 가능한 경우 항상 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-554">These queries are very efficient, and you should use them wherever possible.</span></span>  

###### <a name="partition-queries"></a><span data-ttu-id="398f3-555">파티션 쿼리</span><span class="sxs-lookup"><span data-stu-id="398f3-555">Partition Queries</span></span>
<span data-ttu-id="398f3-556">파티션 쿼리는 공통 파티션 키를 공유하는 데이터 집합을 검색하는 쿼리입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-556">A partition query is a query that retrieves a set of data that shares a common partition key.</span></span> <span data-ttu-id="398f3-557">일반적으로 이 쿼리에서는 파티션 키와 함께 일부 엔터티 속성의 값 범위나 행 키 값의 범위를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-557">Typically, the query specifies a range of row key values or a range of values for some entity property in addition to a partition key.</span></span> <span data-ttu-id="398f3-558">파티션 쿼리는 지점 쿼리보다 효율성이 낮으므로 꼭 필요할 때만 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-558">These are less efficient than point queries, and should be used sparingly.</span></span>  

###### <a name="table-queries"></a><span data-ttu-id="398f3-559">테이블 쿼리</span><span class="sxs-lookup"><span data-stu-id="398f3-559">Table Queries</span></span>
<span data-ttu-id="398f3-560">테이블 쿼리는 공통 파티션 키를 공유하지 않는 엔터티 집합을 검색하는 쿼리입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-560">A table query is a query that retrieves a set of entities that does not share a common partition key.</span></span> <span data-ttu-id="398f3-561">이러한 쿼리는 효율적이지 않으므로 가능하면 사용하지 않아야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-561">These queries are not efficient and you should avoid them if possible.</span></span>  

##### <span data-ttu-id="398f3-562"><a name="subheading31"></a>쿼리 밀도</span><span class="sxs-lookup"><span data-stu-id="398f3-562"><a name="subheading31"></a>Query Density</span></span>
<span data-ttu-id="398f3-563">쿼리 효율성에 영향을 주는 또 다른 중요한 요인은 반환되는 집합을 찾기 위해 스캔한 엔터티 수와 비교한 반환된 엔터티 수입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-563">Another key factor in query efficiency is the number of entities returned as compared to the number of entities scanned to find the returned set.</span></span> <span data-ttu-id="398f3-564">응용 프로그램에서 데이터 중 1%만 공유하는 속성 값에 대한 필터를 사용해 테이블 쿼리를 수행하는 경우 쿼리는 반환하는 1개의 엔터티당 100개의 엔터티를 스캔합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-564">If your application performs a table query with a filter for a property value that only 1% of the data shares, the query will scan 100 entities for every one entity it returns.</span></span> <span data-ttu-id="398f3-565">앞에서 설명한 테이블 확장성 목표는 모두 검색된 엔터티 수와 관련되고 반환된 엔터티 수와는 관련이 없습니다. 낮은 쿼리 밀도는 쉽게 테이블 서비스가 응용 프로그램을 제한하도록 할 수 있습니다. 응용 프로그램이 사용자가 찾는 엔터티를 검색하기 위해 너무 많은 엔터티를 검색해야 하기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-565">The table scalability targets discussed previously all relate to the number of entities scanned, and not the number of entities returned: a low query density can easily cause the table service to throttle your application because it must scan so many entities to retrieve the entity you are looking for.</span></span>  <span data-ttu-id="398f3-566">이러한 현상을 방지하는 방법에 대한 자세한 내용은 아래의 [비정규화](#subheading34) 섹션을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-566">See the section below on [denormalization](#subheading34) for more information on how to avoid this.</span></span>  

##### <a name="limiting-the-amount-of-data-returned"></a><span data-ttu-id="398f3-567">반환되는 데이터의 양 제한</span><span class="sxs-lookup"><span data-stu-id="398f3-567">Limiting the Amount of Data Returned</span></span>
###### <span data-ttu-id="398f3-568"><a name="subheading32"></a>필터링</span><span class="sxs-lookup"><span data-stu-id="398f3-568"><a name="subheading32"></a>Filtering</span></span>
<span data-ttu-id="398f3-569">쿼리에서 클라이언트 응용 프로그램에 필요하지 않은 엔터티가 반환되는 경우 필터를 사용하여 반환되는 집합 크기를 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-569">Where you know that a query will return entities that you don't need in the client application, consider using a filter to reduce the size of the returned set.</span></span> <span data-ttu-id="398f3-570">클라이언트로 반환되지 않는 엔터티도 확장성 목표 계산에 포함되기는 하지만, 클라이언트 응용 프로그램이 처리해야 하는 엔터티의 수와 네트워크 페이로드 크기가 감소하므로 응용 프로그램의 성능은 개선됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-570">While the entities not returned to the client still count toward the scalability limits, your application performance will improve because of the reduced network payload size and the reduced number of entities that your client application must process.</span></span>  <span data-ttu-id="398f3-571">단, 위의 [쿼리 밀도](#subheading31)관련 참고 사항에서 설명한 것처럼 확장성 목표는 스캔하는 엔터티의 수와 관련된 것이므로 쿼리에서 많은 엔터티를 필터 처리하여 적은 수의 엔터티만 반환되더라도 제한은 계속 적용될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-571">See above note on [Query Density](#subheading31), however – the scalability targets relate to the number of entities scanned, so a query that filters out many entities may still result in throttling, even if few entities are returned.</span></span>  

###### <span data-ttu-id="398f3-572"><a name="subheading33"></a>프로젝션</span><span class="sxs-lookup"><span data-stu-id="398f3-572"><a name="subheading33"></a>Projection</span></span>
<span data-ttu-id="398f3-573">클라이어트 응용 프로그램에 테이블 내 엔터티의 제한된 속성 집합만 필요한 경우에는 프로젝션을 사용하여 반환되는 데이터 집합의 크기를 제한할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-573">If your client application needs only a limited set of properties from the entities in your table, you can use projection to limit the size of the returned data set.</span></span> <span data-ttu-id="398f3-574">이 경우 필터링과 마찬가지로 네트워크 로드 및 클라이언트 처리를 줄일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-574">As with filtering, this helps to reduce network load and client processing.</span></span>  

##### <span data-ttu-id="398f3-575"><a name="subheading34"></a>비정규화</span><span class="sxs-lookup"><span data-stu-id="398f3-575"><a name="subheading34"></a>Denormalization</span></span>
<span data-ttu-id="398f3-576">관계형 데이터베이스를 사용할 때와는 달리, 테이블 데이터를 효율적으로 쿼리하는 검증된 작업 방식에서는 데이터를 비정규화해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-576">Unlike working with relational databases, the proven practices for efficiently querying table data lead to denormalizing your data.</span></span> <span data-ttu-id="398f3-577">즉, 대량의 엔터티를 스캔하여 응용 프로그램에 필요한 데이터를 찾는 대신 여러 엔터티에서 같은 데이터를 복제(데이터를 찾는 데 사용할 수 있는 각 키에 대해 하나씩)하여 클라이언트에 필요한 데이터를 찾기 위해 쿼리가 스캔해야 하는 엔터티의 수를 최소화해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-577">That is, duplicating the same data in multiple entities (one for each key you may use to find the data) to minimize the number of entities that a query must scan to find the data the client needs, rather than having to scan large numbers of entities to find the data your application needs.</span></span>  <span data-ttu-id="398f3-578">예를 들어 전자 상거래 웹 사이트에서는 고객 ID(특정 고객의 주문 정보 확인) 및 날짜(특정 날짜의 주문 정보 확인)를 모두 기준으로 사용하여 주문으로 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-578">For example, in an e-commerce website, you may want to find an order both by the customer ID (give me this customer's orders) and by the date (give me orders on a date).</span></span>  <span data-ttu-id="398f3-579">테이블 저장소에서는 엔터티 또는 엔터티에 대한 참조를 두 번 저장하는 것이 가장 좋습니다. 방금 설명한 예의 경우 엔터티를 고객 ID별로 쉽게 찾을 수 있도록 테이블 이름/PK/RK와 함께 한 번, 그리고 날짜별로 쉽게 찾을 수 있도록 다시 한 번 저장하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-579">In Table Storage, it is best to store the entity (or a reference to it) twice – once with Table Name, PK, and RK to facilitate finding by customer ID, once to facilitate finding it by the date.</span></span>  

#### <a name="insertupdatedelete"></a><span data-ttu-id="398f3-580">삽입/업데이트/삭제</span><span class="sxs-lookup"><span data-stu-id="398f3-580">Insert/Update/Delete</span></span>
<span data-ttu-id="398f3-581">이 섹션에서는 테이블 서비스에 저장된 엔터티 수정을 위한 검증된 작업 방식에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-581">This section describes proven practices for modifying entities stored in the table service.</span></span>  

##### <span data-ttu-id="398f3-582"><a name="subheading35"></a>일괄 처리</span><span class="sxs-lookup"><span data-stu-id="398f3-582"><a name="subheading35"></a>Batching</span></span>
<span data-ttu-id="398f3-583">Azure 저장소에서는 일괄 처리 트랜잭션을 ETG(엔터티 그룹 트랜잭션)라고 합니다. ETG 내의 모든 작업은 단일 파티션의 단일 테이블에 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-583">Batch transactions are known as Entity Group Transactions (ETG) in Azure Storage; all the operations within an ETG must be on a single partition in a single table.</span></span> <span data-ttu-id="398f3-584">가능한 경우에는 ETG를 사용하여 삽입, 업데이트 및 삭제를 일괄로 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-584">Where possible, use ETGs to perform inserts, updates, and deletes in batches.</span></span> <span data-ttu-id="398f3-585">그러면 클라이언트 응용 프로그램에서 서버로의 왕복 횟수와 청구 가능한 트랜잭션의 수가 줄어듭니다. ETG는 요금 청구 시 단일 트랜잭션으로 계산되며 저장소 작업을 100개까지 포함할 수 있습니다. 또한 원자성 업데이트가 가능하므로 단일 ETG 내에서는 모든 작업이 성공하거나 실패합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-585">This reduces the number of round trips from your client application to the server, reduces the number of billable transactions (an ETG counts as a single transaction for billing purposes and can contain up to 100 storage operations), and enables atomic updates (all operations succeed or all fail within an ETG).</span></span> <span data-ttu-id="398f3-586">모바일 장치와 같이 대기 시간이 긴 환경에서는 ETG를 사용하면 매우 효율적입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-586">Environments with high latencies such as mobile devices will benefit greatly from using ETGs.</span></span>  

##### <span data-ttu-id="398f3-587"><a name="subheading36"></a>Upsert</span><span class="sxs-lookup"><span data-stu-id="398f3-587"><a name="subheading36"></a>Upsert</span></span>
<span data-ttu-id="398f3-588">가능한 경우에는 항상 테이블 **Upsert** 작업을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-588">Use table **Upsert** operations wherever possible.</span></span> <span data-ttu-id="398f3-589">**Upsert**에는 두 가지 형식이 있으며, 두 형식 모두 기존의 **Insert** 및 **Update** 작업보다는 비효율적일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-589">There are two types of **Upsert**, both of which can be more efficient than a traditional **Insert** and **Update** operations:</span></span>  

* <span data-ttu-id="398f3-590">**InsertOrMerge**: 엔터티 속성 중 일부를 업로드해야 하는데 엔터티가 이미 있는지 여부가 확실치 않으면 이 작업을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-590">**InsertOrMerge**: Use this when you want to upload a subset of the entity's properties, but aren't sure whether the entity already exists.</span></span> <span data-ttu-id="398f3-591">엔터티가 있는 경우 이 작업을 수행하면 **Upsert** 작업에 포함된 속성은 업데이트되고 기존의 모든 속성은 그대로 유지됩니다. 엔터티가 없으면 새 엔터티가 삽입됩니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-591">If the entity exists, this call updates the properties included in the **Upsert** operation, and leaves all existing properties as they are, if the entity does not exist, it inserts the new entity.</span></span> <span data-ttu-id="398f3-592">이 작업은 변경되는 속성만 업데이트하면 되므로 쿼리에서 프로젝션을 사용하는 것과 비슷합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-592">This is similar to using projection in a query, in that you only need to upload the properties that are changing.</span></span>
* <span data-ttu-id="398f3-593">**InsertOrReplace**: 완전히 새로운 엔터티를 업로드해야 하는데 엔터티가 이미 있는지 여부가 확실치 않으면 이 옵션을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-593">**InsertOrReplace**: Use this when you want to upload an entirely new entity, but you aren't sure whether it already exists.</span></span> <span data-ttu-id="398f3-594">이 작업을 수행하면 이전 엔터티를 완전히 덮어쓰므로 새로 업로드하는 엔터티가 정확함이 확실한 경우에만 이 작업을 수행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-594">You should only use this when you know that the newly uploaded entity is entirely correct because it completely overwrites the old entity.</span></span> <span data-ttu-id="398f3-595">예를 들어 응용 프로그램이 사용자의 위치 데이터를 이전에 저장했는지 여부에 관계없이 사용자의 현재 위치를 저장하는 엔터티를 업데이트하려고 하며, 새 위치 엔터티가 완전하고 이전 엔터티의 정보는 전혀 필요하지 않은 경우 이 작업을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-595">For example, you want to update the entity that stores a user's current location regardless of whether or not the application has previously stored location data for the user; the new location entity is complete, and you do not need any information from any previous entity.</span></span>

##### <span data-ttu-id="398f3-596"><a name="subheading37"></a>단일 엔터티에 데이터 계열 저장</span><span class="sxs-lookup"><span data-stu-id="398f3-596"><a name="subheading37"></a>Storing Data Series in a Single Entity</span></span>
<span data-ttu-id="398f3-597">경우에 따라 응용 프로그램은 자주 한꺼번에 검색해야 하는 데이터 계열을 저장합니다. 예를 들어 응용 프로그램은 지난 24시간의 데이터에 대한 롤링 차트를 그리기 위해 시간에 따른 CPU 사용량을 추적할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-597">Sometimes, an application stores a series of data that it frequently needs to retrieve all at once: for example, an application might track CPU usage over time in order to plot a rolling chart of the data from the last 24 hours.</span></span> <span data-ttu-id="398f3-598">이 경우 사용할 수 있는 한 가지 방법은 시간당 테이블 엔터티 하나를 저장하는 것입니다. 이때 각 엔터티는 특정 시간을 나타내며 해당 시간의 CPU 사용량을 저장합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-598">One approach is to have one table entity per hour, with each entity representing a specific hour and storing the CPU usage for that hour.</span></span> <span data-ttu-id="398f3-599">이 데이터를 그리려면 응용 프로그램이 가장 최근의 24시간에 해당하는 데이터를 포함하는 엔터티를 검색해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-599">To plot this data, the application needs to retrieve the entities holding the data from the 24 most recent hours.</span></span>  

<span data-ttu-id="398f3-600">또는 응용 프로그램은 단일 엔터티의 별도 속성으로 매시간의 CPU 사용량을 저장할 수 있습니다. 매시간을 업데이트하기 위해 응용 프로그램은 단일 **InsertOrMerge Upsert** 호출을 사용하여 최근 시간에 대한 값을 업데이트할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-600">Alternatively, your application could store the CPU usage for each hour as a separate property of a single entity: to update each hour, your application can use a single **InsertOrMerge Upsert** call to update the value for the most recent hour.</span></span> <span data-ttu-id="398f3-601">이 경우 응용 프로그램은 데이터를 그리기 위해 24시간 동안의 엔터티가 아닌 엔터티 하나만 검색하면 되므로 쿼리의 효율성이 매우 높아집니다(위의 [쿼리 범위](#subheading30) 설명 참조).</span><span class="sxs-lookup"><span data-stu-id="398f3-601">To plot the data, the application only needs to retrieve a single entity instead of 24, making for a very efficient query (see above discussion on [query scope](#subheading30)).</span></span>

##### <span data-ttu-id="398f3-602"><a name="subheading38"></a>Blob에 구조적 데이터 저장</span><span class="sxs-lookup"><span data-stu-id="398f3-602"><a name="subheading38"></a>Storing structured data in blobs</span></span>
<span data-ttu-id="398f3-603">구조적 데이터를 테이블에 저장해야 하는 경우도 있지만 엔터티 범위는 항상 함께 검색되며 일괄로 삽입할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-603">Sometimes structured data feels like it should go in tables, but ranges of entities are always retrieved together and can be batch inserted.</span></span>  <span data-ttu-id="398f3-604">이와 관련한 좋은 예가 로그 파일입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-604">A good example of this is a log file.</span></span>  <span data-ttu-id="398f3-605">몇 분 동안의 로그를 일괄로 생성하여 삽입할 수 있으며 항상 몇 분 동안의 로그를 한 번에 검색할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-605">In this case, you can batch several minutes of logs, insert them, and then you are always retrieving several minutes of logs at a time as well.</span></span>  <span data-ttu-id="398f3-606">성능 측면에서는 테이블 대신 Blob을 사용하는 것이 보다 효율적입니다. 기록/반환되는 개체 수를 크게 줄일 수 있을 뿐 아니라 일반적으로 수행해야 하는 요청 수도 줄일 수 있기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-606">In this case, for performance, it's better to use blobs instead of tables, since you can significantly reduce the number of objects written/returned, as well as usually the number of requests that need made.</span></span>  

## <a name="queues"></a><span data-ttu-id="398f3-607">큐</span><span class="sxs-lookup"><span data-stu-id="398f3-607">Queues</span></span>
<span data-ttu-id="398f3-608">위에서 설명한 [모든 서비스](#allservices)에 대한 검증된 작업 방식 외에 큐 서비스에만 적용되는 다음과 같은 검증된 작업 방식도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-608">In addition to the proven practices for [All Services](#allservices) described previously, the following proven practices apply specifically to the queue service.</span></span>  

### <span data-ttu-id="398f3-609"><a name="subheading39"></a>확장성 제한</span><span class="sxs-lookup"><span data-stu-id="398f3-609"><a name="subheading39"></a>Scalability Limits</span></span>
<span data-ttu-id="398f3-610">단일 큐는 초당 약 2,000개의 메시지(각각 1KB)를 처리할 수 있습니다(여기서는 각 AddMessage, GetMessage 및 DeleteMessage를 메시지로 계산).</span><span class="sxs-lookup"><span data-stu-id="398f3-610">A single queue can process approximately 2,000 messages (1KB each) per second (each AddMessage, GetMessage, and DeleteMessage count as a message here).</span></span> <span data-ttu-id="398f3-611">응용 프로그램에 이 처리량이 부족한 경우 큐를 여러 개 사용하여 메시지를 분산해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-611">If this is insufficient for your application, you should use multiple queues and spread the messages across them.</span></span>  

<span data-ttu-id="398f3-612">[Azure 저장소 확장성 및 성능 목표](storage-scalability-targets.md)에서 현재 확장성 목표를 봅니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-612">View current scalability targets at [Azure Storage Scalability and Performance Targets](storage-scalability-targets.md).</span></span>  

### <span data-ttu-id="398f3-613"><a name="subheading40"></a>Nagle 해제</span><span class="sxs-lookup"><span data-stu-id="398f3-613"><a name="subheading40"></a>Nagle Off</span></span>
<span data-ttu-id="398f3-614">Nagle 알고리즘에 대해 설명하는 테이블 구성 섹션을 참조하세요. Nagle 알고리즘은 대개 큐 요청 성능을 떨어뜨리므로 사용하지 않도록 설정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-614">See the section on table configuration that discusses the Nagle algorithm — the Nagle algorithm is generally bad for the performance of queue requests, and you should disable it.</span></span>  

### <span data-ttu-id="398f3-615"><a name="subheading41"></a>메시지 크기</span><span class="sxs-lookup"><span data-stu-id="398f3-615"><a name="subheading41"></a>Message Size</span></span>
<span data-ttu-id="398f3-616">메시지 크기가 증가함에 따라 큐 성능 및 확장성은 감소합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-616">Queue performance and scalability decreases as message size increases.</span></span> <span data-ttu-id="398f3-617">그러므로 받는 사람이 메시지에서 필요로 하는 정보만 포함해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-617">You should place only the information the receiver needs in a message.</span></span>  

### <span data-ttu-id="398f3-618"><a name="subheading42"></a>일괄 검색</span><span class="sxs-lookup"><span data-stu-id="398f3-618"><a name="subheading42"></a>Batch Retrieval</span></span>
<span data-ttu-id="398f3-619">단일 작업에서 큐의 메시지를 32개까지 검색할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-619">You can retrieve up to 32 messages from a queue in a single operation.</span></span> <span data-ttu-id="398f3-620">따라서 클라이언트 응용 프로그램으로부터의 왕복 횟수를 줄일 수 있으므로 모바일 장치 등 대기 시간이 긴 환경에서 특히 유용합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-620">This can reduce the number of roundtrips from the client application, which is especially useful for environments, such as mobile devices, with high latency.</span></span>  

### <span data-ttu-id="398f3-621"><a name="subheading43"></a>큐 폴링 간격</span><span class="sxs-lookup"><span data-stu-id="398f3-621"><a name="subheading43"></a>Queue Polling Interval</span></span>
<span data-ttu-id="398f3-622">대부분의 응용 프로그램은 큐에서 메시지를 폴링하는데 이는 해당 응용 프로그램에 대한 트랜잭션의 최대 소스 중 하나일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-622">Most applications poll for messages from a queue, which can be one of the largest sources of transactions for that application.</span></span> <span data-ttu-id="398f3-623">폴링 간격은 현명하게 선택하세요. 너무 자주 폴링하면 응용 프로그램이 큐의 확장성 목표에 근접할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-623">Select your polling interval wisely: polling too frequently could cause your application to approach the scalability targets for the queue.</span></span> <span data-ttu-id="398f3-624">그러나 0.01달러(작성 시점의 경우)로 200,000개의 트랜잭션을 처리하는 단일 프로세서가 1초에 한 번씩 폴링할 경우 한 달에 15센트 미만이 소요되므로 일반적으로 비용은 폴링 간격을 선택하는 데 영향을 미치는 요소가 아닙니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-624">However, at 200,000 transactions for $0.01 (at the time of writing), a single processor polling once every second for a month would cost less than 15 cents so cost is not typically a factor that affects your choice of polling interval.</span></span>  

<span data-ttu-id="398f3-625">최신 비용 정보는 [Azure Storage 가격 책정](https://azure.microsoft.com/pricing/details/storage/)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-625">For up-to-date cost information, see [Azure Storage Pricing](https://azure.microsoft.com/pricing/details/storage/).</span></span>  

### <span data-ttu-id="398f3-626"><a name="subheading44"></a>UpdateMessage</span><span class="sxs-lookup"><span data-stu-id="398f3-626"><a name="subheading44"></a>UpdateMessage</span></span>
<span data-ttu-id="398f3-627">**UpdateMessage** 를 사용하면 표시 안 함 시간 제한을 늘리거나 메시지의 상태 정보를 업데이트할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-627">You can use **UpdateMessage** to increase the invisibility timeout or to update state information of a message.</span></span> <span data-ttu-id="398f3-628">이 기능은 유용하기는 하지만 각 **UpdateMessage** 작업이 확장성 목표 계산에 포함된다는 점을 기억해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-628">While this is powerful, remember that each **UpdateMessage** operation counts towards the scalability target.</span></span> <span data-ttu-id="398f3-629">그러나 각 작업 단계가 완료되면 작업을 다음 큐에 순서대로 전달하는 워크플로보다는 UpdateMessage 작업이 훨씬 더 효율적인 방식일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-629">However, this can be a much more efficient approach than having a workflow that passes a job from one queue to the next, as each step of the job is completed.</span></span> <span data-ttu-id="398f3-630">**UpdateMessage** 작업을 사용하는 경우 응용 프로그램이 단계가 완료될 때마다 작업의 다음 단계를 위해 메시지를 다시 큐에 대기시키는 대신 메시지에 작업 상태를 저장한 다음 작업을 계속할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-630">Using the **UpdateMessage** operation allows your application to save the job state to the message and then continue working, instead of re-queuing the message for the next step of the job every time a step completes.</span></span>  

<span data-ttu-id="398f3-631">자세한 내용은 [방법: 대기 중인 메시지의 콘텐츠 변경](storage-dotnet-how-to-use-queues.md#change-the-contents-of-a-queued-message)문서를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="398f3-631">For more information, see the article [How to: Change the contents of a queued message](storage-dotnet-how-to-use-queues.md#change-the-contents-of-a-queued-message).</span></span>  

### <span data-ttu-id="398f3-632"><a name="subheading45"></a>응용 프로그램 아키텍처</span><span class="sxs-lookup"><span data-stu-id="398f3-632"><a name="subheading45"></a>Application architecture</span></span>
<span data-ttu-id="398f3-633">응용 프로그램 아키텍처를 확장 가능하게 설정하려면 큐를 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-633">You should use queues to make your application architecture scalable.</span></span> <span data-ttu-id="398f3-634">다음 목록에는 큐를 사용하여 응용 프로그램의 확장성을 높이는 몇 가지 방법이 나와 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-634">The following lists some ways you can use queues to make your application more scalable:</span></span>  

* <span data-ttu-id="398f3-635">큐를 사용하여 응용 프로그램에서 워크로드를 처리하고 원활하게 진행하기 위해 작업 백로그를 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-635">You can use queues to create backlogs of work for processing and smooth out workloads in your application.</span></span> <span data-ttu-id="398f3-636">예를 들어 업로드된 이미지 크기를 조정하는 등 프로세서를 많이 사용하는 작업을 수행하기 위한 사용자의 요청을 큐에 대기시킬 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-636">For example, you could queue up requests from users to perform processor intensive work such as resizing uploaded images.</span></span>
* <span data-ttu-id="398f3-637">큐를 사용하여 응용 프로그램의 각 부분을 독립적으로 확장 가능하도록 분리할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-637">You can use queues to decouple parts of your application so that you can scale them independently.</span></span> <span data-ttu-id="398f3-638">예를 들어 웹 프런트 엔드에서 나중에 분석 및 저장하기 위해 사용자의 설문 조사 결과를 큐에 저장할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-638">For example, a web front-end could place survey results from users into a queue for later analysis and storage.</span></span> <span data-ttu-id="398f3-639">필요한 경우 큐 데이터를 처리하기 위해 작업자 역할 인스턴스를 더 추가할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-639">You could add more worker role instances to process the queue data as required.</span></span>  

## <a name="conclusion"></a><span data-ttu-id="398f3-640">결론</span><span class="sxs-lookup"><span data-stu-id="398f3-640">Conclusion</span></span>
<span data-ttu-id="398f3-641">이 문서에서는 Azure 저장소 사용 시 성능을 최적화하기 위한 가장 일반적인 검증된 작업 방식 중 일부에 대해 설명했습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-641">This article discussed some of the most common, proven practices for optimizing performance when using Azure Storage.</span></span> <span data-ttu-id="398f3-642">모든 응용 프로그램 개발자는 Azure 저장소를 사용하는 응용 프로그램의 성능을 높일 수 있도록 위에서 설명한 각 작업 방식을 기준으로 응용 프로그램을 평가한 다음 권장 사항을 적용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="398f3-642">We encourage every application developer to assess their application against each of the above practices and consider acting on the recommendations to get great performance for their applications that use Azure Storage.</span></span>