---
title: "Azure Machine Learning 스튜디오에서 텍스트 분석 모델 만들기 | Microsoft Docs"
description: "텍스트 전처리, N-Gram 또는 특성 해시를 위한 모듈을 사용하여 Azure 기계 학습 스튜디오에서 텍스트 분석 모델을 만드는 방법"
services: machine-learning
documentationcenter: 
author: rastala
manager: jhubbard
editor: 
ms.assetid: 08cd6723-3ae6-4e99-a924-e650942e461b
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 12/06/2016
ms.author: roastala
ms.openlocfilehash: 342e81e2497d292ca730bea59e03182d316ffec3
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 07/11/2017
---
# <a name="create-text-analytics-models-in-azure-machine-learning-studio"></a><span data-ttu-id="e8065-103">Azure 기계 학습 스튜디오에서 텍스트 분석 모델 만들기</span><span class="sxs-lookup"><span data-stu-id="e8065-103">Create text analytics models in Azure Machine Learning Studio</span></span>
<span data-ttu-id="e8065-104">Azure 기계 학습을 사용하여 텍스트 분석 모델을 빌드하고 작동할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-104">You can use Azure Machine Learning to build and operationalize text analytics models.</span></span> <span data-ttu-id="e8065-105">예를 들어 이러한 모델은 문서 분류 또는 정서 분석 문제를 해결하는 데 유용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-105">These models can help you solve, for example, document classification or sentiment analysis problems.</span></span>

<span data-ttu-id="e8065-106">텍스트 분석 실험에서는 일반적으로 다음을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-106">In a text analytics experiment, you would typically:</span></span>

1. <span data-ttu-id="e8065-107">텍스트 데이터 집합 정리 및 전처리</span><span class="sxs-lookup"><span data-stu-id="e8065-107">Clean and preprocess text dataset</span></span>
2. <span data-ttu-id="e8065-108">전처리된 텍스트에서 숫자 특성 벡터 추출</span><span class="sxs-lookup"><span data-stu-id="e8065-108">Extract numeric feature vectors from pre-processed text</span></span>
3. <span data-ttu-id="e8065-109">분류 또는 회귀 모델 학습</span><span class="sxs-lookup"><span data-stu-id="e8065-109">Train classification or regression model</span></span>
4. <span data-ttu-id="e8065-110">모델 점수 매기기 및 유효성 검사</span><span class="sxs-lookup"><span data-stu-id="e8065-110">Score and validate the model</span></span>
5. <span data-ttu-id="e8065-111">모델을 프로덕션에 배포</span><span class="sxs-lookup"><span data-stu-id="e8065-111">Deploy the model to production</span></span>

<span data-ttu-id="e8065-112">이 자습서에서는 Amazon 도서 리뷰 데이터 집합을 사용하여 정서 분석을 진행하면서 이러한 단계를 배우게 됩니다(연구 논문 “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification”(저자: John Blitzer, Mark Dredze 및 Fernando Pereira), Association of Computational Linguistics(ACL), 2007) 참조). 이 데이터 집합은 리뷰 점수(1-2 또는 4-5) 및 자유 형식 텍스트로 구성됩니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-112">In this tutorial, you learn these steps as we walk through a sentiment analysis model using Amazon Book Reviews dataset (see this research paper “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification” by John Blitzer, Mark Dredze, and Fernando Pereira; Association of Computational Linguistics (ACL), 2007.) This dataset consists of review scores (1-2 or 4-5) and a free-form text.</span></span> <span data-ttu-id="e8065-113">그 목표는 리뷰 점수: 낮음(1-2) 또는 높음(4-5)를 예측하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-113">The goal is to predict the review score: low (1-2) or high (4-5).</span></span>

<span data-ttu-id="e8065-114">Cortana Intelligence Gallery에서 이 자습서에 나오는 실험을 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-114">You can find experiments covered in this tutorial at Cortana Intelligence Gallery:</span></span>

[<span data-ttu-id="e8065-115">도서 리뷰 예측</span><span class="sxs-lookup"><span data-stu-id="e8065-115">Predict Book Reviews</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-1)

[<span data-ttu-id="e8065-116">도서 리뷰 예측 - 예측 실험</span><span class="sxs-lookup"><span data-stu-id="e8065-116">Predict Book Reviews - Predictive Experiment</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-Predictive-Experiment-1)

## <a name="step-1-clean-and-preprocess-text-dataset"></a><span data-ttu-id="e8065-117">1단계: 텍스트 데이터 집합 정리 및 전처리</span><span class="sxs-lookup"><span data-stu-id="e8065-117">Step 1: Clean and preprocess text dataset</span></span>
<span data-ttu-id="e8065-118">리뷰 점수를 범주별 하위 및 상위 버킷으로 나누어 문제를 2클래스 분류로 형식화함으로써 실험을 시작합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-118">We begin the experiment by dividing the review scores into categorical low and high buckets to formulate the problem as two-class classification.</span></span> <span data-ttu-id="e8065-119">[메타데이터 편집](https://msdn.microsoft.com/library/azure/dn905986.aspx) 및 [범주 값 그룹화](https://msdn.microsoft.com/library/azure/dn906014.aspx) 모듈을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-119">We use [Edit Metadata](https://msdn.microsoft.com/library/azure/dn905986.aspx) and [Group Categorical Values](https://msdn.microsoft.com/library/azure/dn906014.aspx) modules.</span></span>

![레이블 만들기](./media/machine-learning-text-analytics-module-tutorial/create-label.png)

<span data-ttu-id="e8065-121">그런 다음 [텍스트 전처리](https://msdn.microsoft.com/library/azure/mt762915.aspx) 모듈을 사용하여 텍스트를 정리합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-121">Then, we clean the text using [Preprocess Text](https://msdn.microsoft.com/library/azure/mt762915.aspx) module.</span></span> <span data-ttu-id="e8065-122">이렇게 정리를 수행하면 데이터 집합의 노이즈가 감소하고, 가장 중요 한 기능을 찾는 데 도움이 되며, 최종 모델의 정확도가 높아집니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-122">The cleaning reduces the noise in the dataset, help you find the most important features, and improve the accuracy of the final model.</span></span> <span data-ttu-id="e8065-123">중지 단어("the" 또는 "a"와 같은 일반 단어)와 숫자, 특수 문자, 중복된 문자, 전자 메일 주소 및 URL을 제거합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-123">We remove stopwords - common words such as "the" or "a" - and numbers, special characters, duplicated characters, email addresses, and URLs.</span></span> <span data-ttu-id="e8065-124">또한 전처리된 텍스트에서 텍스트를 소문자로 변환하고, 단어를 분류하고, 문장 경계를 검색한 후 "|||" 기호로 표시합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-124">We also convert the text to lowercase, lemmatize the words, and detect sentence boundaries that are then indicated by "|||" symbol in pre-processed text.</span></span>

![텍스트 전처리](./media/machine-learning-text-analytics-module-tutorial/preprocess-text.png)

<span data-ttu-id="e8065-126">중지 단어의 사용자 지정 목록을 사용하려면 어떻게 해야 할까요?</span><span class="sxs-lookup"><span data-stu-id="e8065-126">What if you want to use a custom list of stopwords?</span></span> <span data-ttu-id="e8065-127">선택적 입력으로 전달할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-127">You can pass it in as optional input.</span></span> <span data-ttu-id="e8065-128">사용자 지정 C# 구문 정규식을 사용하여 부분 문자열을 바꾸고 음성 부분별로 단어(명사, 동사 또는 형용사)를 제거할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-128">You can also use custom C# syntax regular expression to replace substrings, and remove words by part of speech: nouns, verbs, or adjectives.</span></span>

<span data-ttu-id="e8065-129">전처리가 완료된 후에는 데이터를 학습 데이터 및 테스트 집합으로 분할합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-129">After the preprocessing is complete, we split the data into train and test sets.</span></span>

## <a name="step-2-extract-numeric-feature-vectors-from-pre-processed-text"></a><span data-ttu-id="e8065-130">2단계: 전처리된 텍스트에서 숫자 특성 벡터 추출</span><span class="sxs-lookup"><span data-stu-id="e8065-130">Step 2: Extract numeric feature vectors from pre-processed text</span></span>
<span data-ttu-id="e8065-131">텍스트 데이터에 대한 모델을 작성하려면 일반적으로 자유 형식 텍스트를 숫자 특성 벡터로 변환해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-131">To build a model for text data, you typically have to convert free-form text into numeric feature vectors.</span></span> <span data-ttu-id="e8065-132">이 예제에서는 [텍스트에서 N-Gram 특성 추출](https://msdn.microsoft.com/library/azure/mt762916.aspx) 모듈을 사용하여 텍스트 데이터를 이러한 형식으로 변환합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-132">In this example, we use [Extract N-Gram Features from Text](https://msdn.microsoft.com/library/azure/mt762916.aspx) module to transform the text data to such format.</span></span> <span data-ttu-id="e8065-133">이 모듈은 공백으로 구분된 단어 열을 가져온 후 데이터 집합에 나타나는 단어 사전 또는 단어 N-Gram을 계산합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-133">This module takes a column of whitespace-separated words and computes a dictionary of words, or N-grams of words, that appear in your dataset.</span></span> <span data-ttu-id="e8065-134">그런 다음 각 단어 또는 N-Gram이 이러한 레코드에 나오는 횟수를 계산하고 그 개수에서 특성 벡터를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-134">Then, it counts how many times each word, or N-gram, appears in each record, and creates feature vectors from those counts.</span></span> <span data-ttu-id="e8065-135">이 자습서에서는 N-Gram 크기를 2로 설정했으므로 특성 벡터에는 단일 단어와 연속된 두 단어의 조합이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-135">In this tutorial, we set N-gram size to 2, so our feature vectors include single words and combinations of two subsequent words.</span></span>

![N-Gram 추출](./media/machine-learning-text-analytics-module-tutorial/extract-ngrams.png)

<span data-ttu-id="e8065-137">N-Gram 개수에 TF*IDF(용어 빈도와 문서 빈도 반비례) 가중치를 적용합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-137">We apply TF*IDF (Term Frequency Inverse Document Frequency) weighting to N-gram counts.</span></span> <span data-ttu-id="e8065-138">이 접근 방법은 단일 레코드에는 자주 나타나지만 전체 데이터 집합에서는 드물게 발생하는 단어의 가중치를 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-138">This approach adds weight of words that appear frequently in a single record but are rare across the entire dataset.</span></span> <span data-ttu-id="e8065-139">다른 옵션으로는 이진, TF 및 그래프 가중이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-139">Other options include binary, TF, and graph weighing.</span></span>

<span data-ttu-id="e8065-140">이러한 텍스트 특성은 종종 차원이 매우 높습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-140">Such text features often have high dimensionality.</span></span> <span data-ttu-id="e8065-141">예를 들어 모음에 100,000개의 고유 단어가 있는 경우 특성 공간은 100,000개 차원을 가지고, N-Gram이 사용되는 경우 더 큰 공간을 갖습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-141">For example, if your corpus has 100,000 unique words, your feature space would have 100,000 dimensions, or more if N-grams are used.</span></span> <span data-ttu-id="e8065-142">N-Gram 특성 추출 모듈은 차원을 줄일 수 있는 옵션 집합을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-142">The Extract N-Gram Features module gives you a set of options to reduce the dimensionality.</span></span> <span data-ttu-id="e8065-143">짧거나 긴 단어 또는 너무 드물거나 너무 자주 나오는 단어를 제외하도록 선택하여 유의한 예측 값을 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-143">You can choose to exclude words that are short or long, or too uncommon or too frequent to have significant predictive value.</span></span> <span data-ttu-id="e8065-144">이 자습서에서는 5개보다 적은 레코드 또는 레코드의 80% 이상에서 나타나는 N-Gram을 제외합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-144">In this tutorial, we exclude N-grams that appear in fewer than 5 records or in more than 80% of records.</span></span>

<span data-ttu-id="e8065-145">또한 특성 선택을 사용하여 예측 대상과 가장 상호 연관성이 높은 특성만 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-145">Also, you can use feature selection to select only those features that are the most correlated with your prediction target.</span></span> <span data-ttu-id="e8065-146">카이제곱 특성 선택을 사용하여 1000개의 특성을 선택합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-146">We use Chi-Squared feature selection to select 1000 features.</span></span> <span data-ttu-id="e8065-147">N-Gram 추출 모듈의 올바른 출력을 클릭하여 선택한 단어의 어휘 또는 N-Gram을 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-147">You can view the vocabulary of selected words or N-grams by clicking the right output of Extract N-grams module.</span></span>

<span data-ttu-id="e8065-148">N-Gram 특성 추출을 사용하는 대신, 특성 해시 모듈을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-148">As an alternative approach to using Extract N-Gram Features, you can use Feature Hashing module.</span></span> <span data-ttu-id="e8065-149">그러나 [특성 해시](https://msdn.microsoft.com/library/azure/dn906018.aspx) 는 기본 제공 특성 선택 기능이나 TF* IDF 가중 기능이 없습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-149">Note though that [Feature Hashing](https://msdn.microsoft.com/library/azure/dn906018.aspx) does not have build-in feature selection capabilities, or TF*IDF weighing.</span></span>

## <a name="step-3-train-classification-or-regression-model"></a><span data-ttu-id="e8065-150">3단계: 분류 또는 회귀 모델 학습</span><span class="sxs-lookup"><span data-stu-id="e8065-150">Step 3: Train classification or regression model</span></span>
<span data-ttu-id="e8065-151">이제 텍스트가 숫자 특성 열로 변환되었습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-151">Now the text has been transformed to numeric feature columns.</span></span> <span data-ttu-id="e8065-152">데이터 집합에는 여전히 이전 단계의 문자열 열이 포함되어 있으므로 데이터 집합의 열 선택을 사용하여 제외시킵니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-152">The dataset still contains string columns from previous stages, so we use Select Columns in Dataset to exclude them.</span></span>

<span data-ttu-id="e8065-153">[2클래스 로지스틱 회귀](https://msdn.microsoft.com/library/azure/dn905994.aspx) 를 사용하여 목표: 높음 또는 낮음 리뷰 점수를 예측합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-153">We then use [Two-Class Logistic Regression](https://msdn.microsoft.com/library/azure/dn905994.aspx) to predict our target: high or low review score.</span></span> <span data-ttu-id="e8065-154">현재 텍스트 분석 문제가 일반 분류 문제로 변환되었습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-154">At this point, the text analytics problem has been transformed into a regular classification problem.</span></span> <span data-ttu-id="e8065-155">Azure 기계 학습에서 사용할 수 있는 도구를 사용하여 모델을 개선할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-155">You can use the tools available in Azure Machine Learning to improve the model.</span></span> <span data-ttu-id="e8065-156">예를 들어 다양한 분류자로 실험하여 얼마나 정확한 결과를 제공하는지 확인하거나, 하이퍼 매개 변수 조정을 사용하여 정확도를 향상시킬 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-156">For example, you can experiment with different classifiers to find out how accurate results they give, or use hyperparameter tuning to improve the accuracy.</span></span>

![학습 및 점수 매기기](./media/machine-learning-text-analytics-module-tutorial/scoring-text.png)

## <a name="step-4-score-and-validate-the-model"></a><span data-ttu-id="e8065-158">4단계: 모델 점수 매기기 및 유효성 검사</span><span class="sxs-lookup"><span data-stu-id="e8065-158">Step 4: Score and validate the model</span></span>
<span data-ttu-id="e8065-159">학습된 모델의 유효성은 어떻게 검사하나요?</span><span class="sxs-lookup"><span data-stu-id="e8065-159">How would you validate the trained model?</span></span> <span data-ttu-id="e8065-160">테스트 데이터 집합을 기준으로 점수를 매기고 정확도를 평가합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-160">We score it against the test dataset and evaluate the accuracy.</span></span> <span data-ttu-id="e8065-161">그러나 모델은 학습 데이터 집합에서 N-Gram의 어휘와 해당 가중치를 학습했습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-161">However, the model learned the vocabulary of N-grams and their weights from the training dataset.</span></span> <span data-ttu-id="e8065-162">따라서 어휘를 새로 만드는 대신 테스트 데이터에서 특성을 추출할 때 해당 용어와 가중치를 사용해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-162">Therefore, we should use that vocabulary and those weights when extracting features from test data, as opposed to creating the vocabulary anew.</span></span> <span data-ttu-id="e8065-163">따라서 N-Gram 특성 추출 모듈을 실험의 점수 매기기 분기에 추가하고, 학습 분기의 출력 어휘를 연결하고, 어휘 모드를 읽기 전용으로 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-163">Therefore, we add Extract N-Gram Features module to the scoring branch of the experiment, connect the output vocabulary from training branch, and set the vocabulary mode to read-only.</span></span> <span data-ttu-id="e8065-164">또한 최소값을 1개 인스턴스로, 최대값을 100%로 설정하여 빈도별 N-Gram 필터링을 사용하지 않도록 설정한 후 특성 선택을 해제합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-164">We also disable the filtering of N-grams by frequency by setting the minimum to 1 instance and maximum to 100%, and turn off the feature selection.</span></span>

<span data-ttu-id="e8065-165">테스트 데이터의 텍스트 열이 숫자 특성 열로 변환된 후에는 학습 분기에서와 마찬가지로 이전 단계의 문자열 열을 제외합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-165">After the text column in test data has been transformed to numeric feature columns, we exclude the string columns from previous stages like in training branch.</span></span> <span data-ttu-id="e8065-166">그런 다음 모델 점수 매기기 모듈을 사용하여 예측을 하고, 모델 평가 모듈을 사용하여 정확도를 평가합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-166">We then use Score Model module to make predictions and Evaluate Model module to evaluate the accuracy.</span></span>

## <a name="step-5-deploy-the-model-to-production"></a><span data-ttu-id="e8065-167">5단계: 모델을 프로덕션에 배포</span><span class="sxs-lookup"><span data-stu-id="e8065-167">Step 5: Deploy the model to production</span></span>
<span data-ttu-id="e8065-168">모델을 프로덕션에 배포할 준비가 거의 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-168">The model is almost ready to be deployed to production.</span></span> <span data-ttu-id="e8065-169">모델을 웹 서비스로 배포하면 자유 형식 텍스트 문자열을 입력으로 받은 후 예측 "높음" 또는 "낮음"을 반환합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-169">When deployed as web service, it takes free-form text string as input, and return a prediction "high" or "low."</span></span> <span data-ttu-id="e8065-170">학습한 N-Gram 어휘를 사용하여 텍스트를 특성으로 변환하고, 학습된 회귀 모델을 사용하여 해당 특성에서 예측을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-170">It uses the learned N-gram vocabulary to transform the text to features, and trained logistic regression model to make a prediction from those features.</span></span> 

<span data-ttu-id="e8065-171">예측 실험을 설정하려면 먼저, N-Gram 어휘를 데이터 집합으로 저장하고 실험의 학습 분기에서 학습된 로지스틱 회귀 모델을 저장합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-171">To set up the predictive experiment, we first save the N-gram vocabulary as dataset, and the trained logistic regression model from the training branch of the experiment.</span></span> <span data-ttu-id="e8065-172">그런 다음 “다른 이름으로 저장”을 사용하여 실험을 저장한 후 예측 실험에 대한 실험 그래프를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-172">Then, we save the experiment using "Save As" to create an experiment graph for predictive experiment.</span></span> <span data-ttu-id="e8065-173">실험에서 데이터 분할 모듈 및 학습 분기를 제거합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-173">We remove the Split Data module and the training branch from the experiment.</span></span> <span data-ttu-id="e8065-174">그런 후 앞서 저장한 N-Gram 어휘와 모델을 N-Gram 특성 추출 및 모델 점수 매기기 모듈에 각각 연결합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-174">We then connect the previously saved N-gram vocabulary and model to Extract N-Gram Features and Score Model modules, respectively.</span></span> <span data-ttu-id="e8065-175">또한 모델 평가 모듈을 제거합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-175">We also remove the Evaluate Model module.</span></span>

<span data-ttu-id="e8065-176">전처리 텍스트 모듈 앞에 데이터 집합의 열 선택 모듈을 삽입하여 레이블 열을 제거하고, 점수 매기기 모듈에서 "데이터 집합에 점수 열 추가" 옵션을 선택 취소합니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-176">We insert Select Columns in Dataset module before Preprocess Text module to remove the label column, and unselect "Append score column to dataset" option in Score Module.</span></span> <span data-ttu-id="e8065-177">이렇게 하면 웹 서비스는 예측하려고 하는 레이블을 요청하지 않고, 응답에 입력 특성을 에코하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-177">That way, the web service does not request the label it is trying to predict, and does not echo the input features in response.</span></span>

![예측 실험](./media/machine-learning-text-analytics-module-tutorial/predictive-text.png)

<span data-ttu-id="e8065-179">이제 웹 서비스로 게시되고, 요청-응답 또는 일괄 처리 실행 API를 사용하여 호출할 수 있는 실험이 생성되었습니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-179">Now we have an experiment that can be published as a web service and called using request-response or batch execution APIs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="e8065-180">다음 단계</span><span class="sxs-lookup"><span data-stu-id="e8065-180">Next Steps</span></span>
<span data-ttu-id="e8065-181">[MSDN 설명서](https://msdn.microsoft.com/library/azure/dn905886.aspx)에서 텍스트 분석 모듈에 대해 자세히 알아봅니다.</span><span class="sxs-lookup"><span data-stu-id="e8065-181">Learn about text analytics modules from [MSDN documentation](https://msdn.microsoft.com/library/azure/dn905886.aspx).</span></span>

