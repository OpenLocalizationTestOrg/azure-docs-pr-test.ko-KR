---
title: "Azure 기계 학습 스튜디오에서 aaaCreate 텍스트 분석 모델 | Microsoft Docs"
description: "텍스트 전처리, N 그램 또는 기능 해시 모듈을 사용 하 여 Azure 기계 학습 스튜디오에서 toocreate 텍스트 분석을 모델링 하는 방법"
services: machine-learning
documentationcenter: 
author: rastala
manager: jhubbard
editor: 
ms.assetid: 08cd6723-3ae6-4e99-a924-e650942e461b
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 12/06/2016
ms.author: roastala
ms.openlocfilehash: e3799f37ba54bb2ec8815ecf5ed34e145ffb20e9
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="create-text-analytics-models-in-azure-machine-learning-studio"></a><span data-ttu-id="02f2d-103">Azure 기계 학습 스튜디오에서 텍스트 분석 모델 만들기</span><span class="sxs-lookup"><span data-stu-id="02f2d-103">Create text analytics models in Azure Machine Learning Studio</span></span>
<span data-ttu-id="02f2d-104">Azure 기계 학습 toobuild를 사용할 수 있으며 텍스트 분석 모델을 운용 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-104">You can use Azure Machine Learning toobuild and operationalize text analytics models.</span></span> <span data-ttu-id="02f2d-105">예를 들어 이러한 모델은 문서 분류 또는 정서 분석 문제를 해결하는 데 유용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-105">These models can help you solve, for example, document classification or sentiment analysis problems.</span></span>

<span data-ttu-id="02f2d-106">텍스트 분석 실험에서는 일반적으로 다음을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-106">In a text analytics experiment, you would typically:</span></span>

1. <span data-ttu-id="02f2d-107">텍스트 데이터 집합 정리 및 전처리</span><span class="sxs-lookup"><span data-stu-id="02f2d-107">Clean and preprocess text dataset</span></span>
2. <span data-ttu-id="02f2d-108">전처리된 텍스트에서 숫자 특성 벡터 추출</span><span class="sxs-lookup"><span data-stu-id="02f2d-108">Extract numeric feature vectors from pre-processed text</span></span>
3. <span data-ttu-id="02f2d-109">분류 또는 회귀 모델 학습</span><span class="sxs-lookup"><span data-stu-id="02f2d-109">Train classification or regression model</span></span>
4. <span data-ttu-id="02f2d-110">점수와 hello 모델 유효성 검사</span><span class="sxs-lookup"><span data-stu-id="02f2d-110">Score and validate hello model</span></span>
5. <span data-ttu-id="02f2d-111">Hello 모델 tooproduction 배포</span><span class="sxs-lookup"><span data-stu-id="02f2d-111">Deploy hello model tooproduction</span></span>

<span data-ttu-id="02f2d-112">이 자습서에서는 Amazon 도서 리뷰 데이터 집합을 사용하여 정서 분석을 진행하면서 이러한 단계를 배우게 됩니다(연구 논문 “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification”(저자: John Blitzer, Mark Dredze 및 Fernando Pereira), Association of Computational Linguistics(ACL), 2007) 참조). 이 데이터 집합은 리뷰 점수(1-2 또는 4-5) 및 자유 형식 텍스트로 구성됩니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-112">In this tutorial, you learn these steps as we walk through a sentiment analysis model using Amazon Book Reviews dataset (see this research paper “Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification” by John Blitzer, Mark Dredze, and Fernando Pereira; Association of Computational Linguistics (ACL), 2007.) This dataset consists of review scores (1-2 or 4-5) and a free-form text.</span></span> <span data-ttu-id="02f2d-113">hello ´ ֲ toopredict hello 검토 점수: 낮은 (1-2) 또는 high (4-5).</span><span class="sxs-lookup"><span data-stu-id="02f2d-113">hello goal is toopredict hello review score: low (1-2) or high (4-5).</span></span>

<span data-ttu-id="02f2d-114">Cortana Intelligence Gallery에서 이 자습서에 나오는 실험을 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-114">You can find experiments covered in this tutorial at Cortana Intelligence Gallery:</span></span>

[<span data-ttu-id="02f2d-115">도서 리뷰 예측</span><span class="sxs-lookup"><span data-stu-id="02f2d-115">Predict Book Reviews</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-1)

[<span data-ttu-id="02f2d-116">도서 리뷰 예측 - 예측 실험</span><span class="sxs-lookup"><span data-stu-id="02f2d-116">Predict Book Reviews - Predictive Experiment</span></span>](https://gallery.cortanaintelligence.com/Experiment/Predict-Book-Reviews-Predictive-Experiment-1)

## <a name="step-1-clean-and-preprocess-text-dataset"></a><span data-ttu-id="02f2d-117">1단계: 텍스트 데이터 집합 정리 및 전처리</span><span class="sxs-lookup"><span data-stu-id="02f2d-117">Step 1: Clean and preprocess text dataset</span></span>
<span data-ttu-id="02f2d-118">2 클래스 분류로의 범주는 낮은 임계값과 높은 버킷 tooformulate hello 문제가 hello 검토 점수를 분할 하 여 hello 실험을 시작 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-118">We begin hello experiment by dividing hello review scores into categorical low and high buckets tooformulate hello problem as two-class classification.</span></span> <span data-ttu-id="02f2d-119">[메타데이터 편집](https://msdn.microsoft.com/library/azure/dn905986.aspx) 및 [범주 값 그룹화](https://msdn.microsoft.com/library/azure/dn906014.aspx) 모듈을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-119">We use [Edit Metadata](https://msdn.microsoft.com/library/azure/dn905986.aspx) and [Group Categorical Values](https://msdn.microsoft.com/library/azure/dn906014.aspx) modules.</span></span>

![레이블 만들기](./media/machine-learning-text-analytics-module-tutorial/create-label.png)

<span data-ttu-id="02f2d-121">그런 다음 사용 하 여 hello 텍스트 정리 우리 [전처리 텍스트](https://msdn.microsoft.com/library/azure/mt762915.aspx) 모듈입니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-121">Then, we clean hello text using [Preprocess Text](https://msdn.microsoft.com/library/azure/mt762915.aspx) module.</span></span> <span data-ttu-id="02f2d-122">정리 하는 hello hello 데이터 집합의 hello 노이즈, 개선 하 고 hello 가장 중요 한 기능을 찾는 데 도움이 hello hello 최종 모델의 정확도 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-122">hello cleaning reduces hello noise in hello dataset, help you find hello most important features, and improve hello accuracy of hello final model.</span></span> <span data-ttu-id="02f2d-123">중지 단어("the" 또는 "a"와 같은 일반 단어)와 숫자, 특수 문자, 중복된 문자, 전자 메일 주소 및 URL을 제거합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-123">We remove stopwords - common words such as "the" or "a" - and numbers, special characters, duplicated characters, email addresses, and URLs.</span></span> <span data-ttu-id="02f2d-124">또한 hello 텍스트 toolowercase 변환, hello 단어 lemmatize 하 고 다음으로 표시 된 문장 경계 검색 "| | |" 전처리 된 텍스트의 기호입니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-124">We also convert hello text toolowercase, lemmatize hello words, and detect sentence boundaries that are then indicated by "|||" symbol in pre-processed text.</span></span>

![텍스트 전처리](./media/machine-learning-text-analytics-module-tutorial/preprocess-text.png)

<span data-ttu-id="02f2d-126">경우에 어떻게 toouse 중지 단어의 사용자 지정 목록 시겠습니까?</span><span class="sxs-lookup"><span data-stu-id="02f2d-126">What if you want toouse a custom list of stopwords?</span></span> <span data-ttu-id="02f2d-127">선택적 입력으로 전달할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-127">You can pass it in as optional input.</span></span> <span data-ttu-id="02f2d-128">또한 사용자 지정 C# 구문 정규식 tooreplace 부분 문자열을 사용 하 고 음성 부분에서 단어를 제거할 수 있습니다: 명사, 동사 나 형용사.</span><span class="sxs-lookup"><span data-stu-id="02f2d-128">You can also use custom C# syntax regular expression tooreplace substrings, and remove words by part of speech: nouns, verbs, or adjectives.</span></span>

<span data-ttu-id="02f2d-129">완료 되 면 hello 전처리 hello 데이터 기차를 분할 및 테스트 집합 했습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-129">After hello preprocessing is complete, we split hello data into train and test sets.</span></span>

## <a name="step-2-extract-numeric-feature-vectors-from-pre-processed-text"></a><span data-ttu-id="02f2d-130">2단계: 전처리된 텍스트에서 숫자 특성 벡터 추출</span><span class="sxs-lookup"><span data-stu-id="02f2d-130">Step 2: Extract numeric feature vectors from pre-processed text</span></span>
<span data-ttu-id="02f2d-131">텍스트 데이터에 대 한 모델 toobuild 일반적으로 필요를 숫자 기능 벡터로 tooconvert 자유 형식 텍스트입니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-131">toobuild a model for text data, you typically have tooconvert free-form text into numeric feature vectors.</span></span> <span data-ttu-id="02f2d-132">이 예에서는 사용 [추출 N 그램 텍스트 기능](https://msdn.microsoft.com/library/azure/mt762916.aspx) 모듈 tootransform hello 텍스트 데이터 toosuch 형식입니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-132">In this example, we use [Extract N-Gram Features from Text](https://msdn.microsoft.com/library/azure/mt762916.aspx) module tootransform hello text data toosuch format.</span></span> <span data-ttu-id="02f2d-133">이 모듈은 공백으로 구분된 단어 열을 가져온 후 데이터 집합에 나타나는 단어 사전 또는 단어 N-Gram을 계산합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-133">This module takes a column of whitespace-separated words and computes a dictionary of words, or N-grams of words, that appear in your dataset.</span></span> <span data-ttu-id="02f2d-134">그런 다음 각 단어 또는 N-Gram이 이러한 레코드에 나오는 횟수를 계산하고 그 개수에서 특성 벡터를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-134">Then, it counts how many times each word, or N-gram, appears in each record, and creates feature vectors from those counts.</span></span> <span data-ttu-id="02f2d-135">이 자습서에서는 우리의 기능 벡터는 단일 단어 및 두 개의 후속 단어 조합을 하므로 N 그램 크기 too2를 설정 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-135">In this tutorial, we set N-gram size too2, so our feature vectors include single words and combinations of two subsequent words.</span></span>

![N-Gram 추출](./media/machine-learning-text-analytics-module-tutorial/extract-ngrams.png)

<span data-ttu-id="02f2d-137">TF 적용할 * tooN 그램 가중치 IDF (용어 빈도 역 문서 빈도)를 계산 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-137">We apply TF*IDF (Term Frequency Inverse Document Frequency) weighting tooN-gram counts.</span></span> <span data-ttu-id="02f2d-138">이 방법을 사용 하는 단일 레코드에 자주 나타나지만 있지만 hello 전체 데이터 집합에서 드물게의 가중치를 추가 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-138">This approach adds weight of words that appear frequently in a single record but are rare across hello entire dataset.</span></span> <span data-ttu-id="02f2d-139">다른 옵션으로는 이진, TF 및 그래프 가중이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-139">Other options include binary, TF, and graph weighing.</span></span>

<span data-ttu-id="02f2d-140">이러한 텍스트 특성은 종종 차원이 매우 높습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-140">Such text features often have high dimensionality.</span></span> <span data-ttu-id="02f2d-141">예를 들어 모음에 100,000개의 고유 단어가 있는 경우 특성 공간은 100,000개 차원을 가지고, N-Gram이 사용되는 경우 더 큰 공간을 갖습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-141">For example, if your corpus has 100,000 unique words, your feature space would have 100,000 dimensions, or more if N-grams are used.</span></span> <span data-ttu-id="02f2d-142">hello N 그램 기능 추출 모듈 옵션 tooreduce hello 차원 집합을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-142">hello Extract N-Gram Features module gives you a set of options tooreduce hello dimensionality.</span></span> <span data-ttu-id="02f2d-143">Tooexclude 단어는 짧은 또는 또는 일반적이 지 않은 너무 길거나 너무 자주 toohave 중요 한 예측 값을 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-143">You can choose tooexclude words that are short or long, or too uncommon or too frequent toohave significant predictive value.</span></span> <span data-ttu-id="02f2d-144">이 자습서에서는 5개보다 적은 레코드 또는 레코드의 80% 이상에서 나타나는 N-Gram을 제외합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-144">In this tutorial, we exclude N-grams that appear in fewer than 5 records or in more than 80% of records.</span></span>

<span data-ttu-id="02f2d-145">또한 예측 대상을 사용 하 여 기능 선택 tooselect 가장 hello 있는 기능만 상관 관계를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-145">Also, you can use feature selection tooselect only those features that are hello most correlated with your prediction target.</span></span> <span data-ttu-id="02f2d-146">카이 제곱 기능 선택 tooselect 1000 기능 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-146">We use Chi-Squared feature selection tooselect 1000 features.</span></span> <span data-ttu-id="02f2d-147">추출 N 그램 모듈의 hello 오른쪽 출력을 클릭 하 여 선택한 단어 또는 N 그램의 hello 어휘를 볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-147">You can view hello vocabulary of selected words or N-grams by clicking hello right output of Extract N-grams module.</span></span>

<span data-ttu-id="02f2d-148">N 그램 기능 추출에 다른 접근 방식은 toousing으로 기능 해시 모듈을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-148">As an alternative approach toousing Extract N-Gram Features, you can use Feature Hashing module.</span></span> <span data-ttu-id="02f2d-149">그러나 [특성 해시](https://msdn.microsoft.com/library/azure/dn906018.aspx) 는 기본 제공 특성 선택 기능이나 TF* IDF 가중 기능이 없습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-149">Note though that [Feature Hashing](https://msdn.microsoft.com/library/azure/dn906018.aspx) does not have build-in feature selection capabilities, or TF*IDF weighing.</span></span>

## <a name="step-3-train-classification-or-regression-model"></a><span data-ttu-id="02f2d-150">3단계: 분류 또는 회귀 모델 학습</span><span class="sxs-lookup"><span data-stu-id="02f2d-150">Step 3: Train classification or regression model</span></span>
<span data-ttu-id="02f2d-151">이제 hello 텍스트 변형 된 toonumeric 기능 열 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-151">Now hello text has been transformed toonumeric feature columns.</span></span> <span data-ttu-id="02f2d-152">데이터 집합 tooexclude에서 열 선택를 사용 하도록 여전히 이전 단계에서 문자열 열이 포함 hello 데이터 집합에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-152">hello dataset still contains string columns from previous stages, so we use Select Columns in Dataset tooexclude them.</span></span>

<span data-ttu-id="02f2d-153">사용 하 여이 [2 클래스 로지스틱 회귀](https://msdn.microsoft.com/library/azure/dn905994.aspx) toopredict 목표: 높거나 낮은 검토 점수입니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-153">We then use [Two-Class Logistic Regression](https://msdn.microsoft.com/library/azure/dn905994.aspx) toopredict our target: high or low review score.</span></span> <span data-ttu-id="02f2d-154">이 시점에서 hello 텍스트 분석 문제 일반 분류 문제의 경우에 변환 된 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-154">At this point, hello text analytics problem has been transformed into a regular classification problem.</span></span> <span data-ttu-id="02f2d-155">Azure 기계 학습 tooimprove hello 모델에서 사용할 수 있는 hello 도구를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-155">You can use hello tools available in Azure Machine Learning tooimprove hello model.</span></span> <span data-ttu-id="02f2d-156">예를 들어 다른 분류자 toofind에 게 제공 하거나 hyperparameter 튜닝 tooimprove hello 정확도 사용 하 여 이러한 정확도 결과 테스트할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-156">For example, you can experiment with different classifiers toofind out how accurate results they give, or use hyperparameter tuning tooimprove hello accuracy.</span></span>

![학습 및 점수 매기기](./media/machine-learning-text-analytics-module-tutorial/scoring-text.png)

## <a name="step-4-score-and-validate-hello-model"></a><span data-ttu-id="02f2d-158">4 단계: 점수와 hello 모델 유효성 검사</span><span class="sxs-lookup"><span data-stu-id="02f2d-158">Step 4: Score and validate hello model</span></span>
<span data-ttu-id="02f2d-159">Hello 학습 된 모델 유효성을 검사 하는 방법을?</span><span class="sxs-lookup"><span data-stu-id="02f2d-159">How would you validate hello trained model?</span></span> <span data-ttu-id="02f2d-160">Hello 테스트 데이터 집합에 대해 점수 하 고 hello 정확도 평가 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-160">We score it against hello test dataset and evaluate hello accuracy.</span></span> <span data-ttu-id="02f2d-161">그러나 hello 모델 N 그램 및 hello 학습 데이터 집합에서 해당 가중치의 hello 어휘를 배웠습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-161">However, hello model learned hello vocabulary of N-grams and their weights from hello training dataset.</span></span> <span data-ttu-id="02f2d-162">따라서 새로 toocreating hello 어휘 해도 상관 없다면 테스트 데이터에서 기능으로 추출 하는 경우 해당 용어와 이러한 가중치 사용 해야 했습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-162">Therefore, we should use that vocabulary and those weights when extracting features from test data, as opposed toocreating hello vocabulary anew.</span></span> <span data-ttu-id="02f2d-163">따라서에서는 추가 N 그램 기능 추출 모듈 toohello hello 실험 분기 점수 매기기, 교육 분기에서 hello 출력 어휘를 연결 및 tooread 전용 hello 어휘 모드를 설정 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-163">Therefore, we add Extract N-Gram Features module toohello scoring branch of hello experiment, connect hello output vocabulary from training branch, and set hello vocabulary mode tooread-only.</span></span> <span data-ttu-id="02f2d-164">또한 hello N 그램의 진동수에 의해 hello 최소 too1 인스턴스 설정 및 필터링 최대 too100 %를 사용 하지 않도록 설정 하 고 hello 기능 선택이 해제 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-164">We also disable hello filtering of N-grams by frequency by setting hello minimum too1 instance and maximum too100%, and turn off hello feature selection.</span></span>

<span data-ttu-id="02f2d-165">Hello 된 데이터는 테스트에서 텍스트 열 변환 된 후 toonumeric 기능 열을 hello 문자열 학습 분기에서와 같이 이전 단계에서 열을 제외 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-165">After hello text column in test data has been transformed toonumeric feature columns, we exclude hello string columns from previous stages like in training branch.</span></span> <span data-ttu-id="02f2d-166">그런 다음 모델 점수 매기기 모듈 toomake 예측 및 평가 모델 모듈 tooevaluate hello 정확도 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-166">We then use Score Model module toomake predictions and Evaluate Model module tooevaluate hello accuracy.</span></span>

## <a name="step-5-deploy-hello-model-tooproduction"></a><span data-ttu-id="02f2d-167">5 단계: hello 모델 tooproduction 배포</span><span class="sxs-lookup"><span data-stu-id="02f2d-167">Step 5: Deploy hello model tooproduction</span></span>
<span data-ttu-id="02f2d-168">hello 모델은 배포 된 것 같군요 toobe tooproduction입니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-168">hello model is almost ready toobe deployed tooproduction.</span></span> <span data-ttu-id="02f2d-169">모델을 웹 서비스로 배포하면 자유 형식 텍스트 문자열을 입력으로 받은 후 예측 "높음" 또는 "낮음"을 반환합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-169">When deployed as web service, it takes free-form text string as input, and return a prediction "high" or "low."</span></span> <span data-ttu-id="02f2d-170">배운 hello N 그램 어휘 tootransform hello 텍스트 toofeatures을 사용 하 고 로지스틱 회귀 모델 toomake 해당 기능에서 예측을 학습 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-170">It uses hello learned N-gram vocabulary tootransform hello text toofeatures, and trained logistic regression model toomake a prediction from those features.</span></span> 

<span data-ttu-id="02f2d-171">hello 예측 실험을 tooset를 먼저 저장 hello N 그램 어휘, 데이터 집합으로 및 hello hello 실험 hello 교육 분기에서 로지스틱 회귀 모델을 학습 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-171">tooset up hello predictive experiment, we first save hello N-gram vocabulary as dataset, and hello trained logistic regression model from hello training branch of hello experiment.</span></span> <span data-ttu-id="02f2d-172">그런 다음 "다른 이름으로 저장" toocreate를 사용 하 여 hello 실험 예측 실험에 대 한 실험 그래프를 저장 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-172">Then, we save hello experiment using "Save As" toocreate an experiment graph for predictive experiment.</span></span> <span data-ttu-id="02f2d-173">Hello 실험에서 hello 분할 데이터 모듈과 hello 교육 분기 제거합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-173">We remove hello Split Data module and hello training branch from hello experiment.</span></span> <span data-ttu-id="02f2d-174">다음 연결 hello 이전에 저장 된 N 그램 어휘 및 모델 tooExtract N 그램 기능 및 모델 점수 매기기 모듈 각각.</span><span class="sxs-lookup"><span data-stu-id="02f2d-174">We then connect hello previously saved N-gram vocabulary and model tooExtract N-Gram Features and Score Model modules, respectively.</span></span> <span data-ttu-id="02f2d-175">또한 hello 모델 평가 모듈을 제거 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-175">We also remove hello Evaluate Model module.</span></span>

<span data-ttu-id="02f2d-176">전처리 텍스트 모듈 tooremove hello 레이블 열을 하기 전에 데이터 집합 모듈에서 열 선택 삽입 하 고 점수 모듈에서 "추가 점수 열 toodataset" 옵션 선택을 취소 합니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-176">We insert Select Columns in Dataset module before Preprocess Text module tooremove hello label column, and unselect "Append score column toodataset" option in Score Module.</span></span> <span data-ttu-id="02f2d-177">이런 방식으로 hello 웹 서비스는 hello 레이블 toopredict를 시도 하 고 hello 입력된 기능에 대 한 응답에서을 표시 하지 않습니다를 요청 하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-177">That way, hello web service does not request hello label it is trying toopredict, and does not echo hello input features in response.</span></span>

![예측 실험](./media/machine-learning-text-analytics-module-tutorial/predictive-text.png)

<span data-ttu-id="02f2d-179">이제 웹 서비스로 게시되고, 요청-응답 또는 일괄 처리 실행 API를 사용하여 호출할 수 있는 실험이 생성되었습니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-179">Now we have an experiment that can be published as a web service and called using request-response or batch execution APIs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="02f2d-180">다음 단계</span><span class="sxs-lookup"><span data-stu-id="02f2d-180">Next Steps</span></span>
<span data-ttu-id="02f2d-181">[MSDN 설명서](https://msdn.microsoft.com/library/azure/dn905886.aspx)에서 텍스트 분석 모듈에 대해 자세히 알아봅니다.</span><span class="sxs-lookup"><span data-stu-id="02f2d-181">Learn about text analytics modules from [MSDN documentation](https://msdn.microsoft.com/library/azure/dn905886.aspx).</span></span>

