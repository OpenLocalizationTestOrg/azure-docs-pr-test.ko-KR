---
title: "Azure HDInsight의 Spark를 사용 하 여 데이터 과학자의 aaaOverview | Microsoft Docs"
description: "hello Spark MLlib 도구 키트는 상당한 기계 학습 기능 distributed toohello HDInsight 환경 모델링을 제공 합니다."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 515705684a46917c2741bf063d439b1cda016abb
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="e65b9-103">Azure HDInsight에서 Spark를 사용하는 데이터 과학 개요</span><span class="sxs-lookup"><span data-stu-id="e65b9-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="e65b9-104">이 도구 모음 항목의 데이터를 수집, 기능 엔지니어링, 모델링 및 모델 평가 경우 같은 toouse HDInsight Spark toocomplete 일반 데이터 과학 작업 하는 방법을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-104">This suite of topics shows how toouse HDInsight Spark toocomplete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="e65b9-105">사용 되는 hello 데이터는 hello 2013 NYC 택시 여행 및 요금 데이터 집합의 샘플입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-105">hello data used is a sample of hello 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="e65b9-106">작성 된 hello 모델에 물류 및 선형 회귀, 임의 포리스트 및 그라데이션 승격 된 트리에 포함 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-106">hello models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="e65b9-107">hello 항목도 표시 방법을 toostore 이러한 모델에서 Azure blob 저장소 (WASB)와 방법을 tooscore 하 고 예측의 성능을 평가 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-107">hello topics also show how toostore these models in Azure blob storage (WASB) and how tooscore and evaluate their predictive performance.</span></span> <span data-ttu-id="e65b9-108">고급 항목에서는 교차 유효성 검사 및 하이퍼 매개 변수 스위핑을 사용하여 모델을 학습할 수 있는 방법을 다룹니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="e65b9-109">또한이 개요 항목 tooset를 제공 하는 hello 연습에서 toocomplete hello 단계를 보려면 Spark 클러스터 hello 하는 방법을 설명 하는 hello 항목을 참조 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-109">This overview topic also references hello topics that describe how tooset up hello Spark cluster that you need toocomplete hello steps in hello walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="e65b9-110">Spark 및 MLlib</span><span class="sxs-lookup"><span data-stu-id="e65b9-110">Spark and MLlib</span></span>
<span data-ttu-id="e65b9-111">[Spark](http://spark.apache.org/) 빅 데이터 분석 응용 프로그램의 tooboost hello 성능을 처리에서 메모리를 지 원하는 오픈 소스 병렬 처리 프레임 워크입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing tooboost hello performance of big-data analytic applications.</span></span> <span data-ttu-id="e65b9-112">hello Spark 처리 엔진에 대 한 속도, 사용 및 복잡 한 분석의 용이성 만들어집니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-112">hello Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="e65b9-113">메모리 내 분산된 계산 기능으로 Spark의 게 hello 반복 알고리즘 컴퓨터 학습 및 그래프 계산에 사용 하기에 적합 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-113">Spark's in-memory distributed computation capabilities make it a good choice for hello iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="e65b9-114">[MLlib](http://spark.apache.org/mllib/) 기능 toothis 분산된 환경 모델링 Spark의 확장 가능한 시스템 학습 라이브러리 hello 알고리즘을 제공 하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings hello algorithmic modeling capabilities toothis distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="e65b9-115">HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="e65b9-115">HDInsight Spark</span></span>
<span data-ttu-id="e65b9-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) hello Azure 호스팅되는 오픈 소스 Spark의 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is hello Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="e65b9-117">에 대 한 지원도 포함 됩니다 **Jupyter PySpark 노트북** Spark SQL 변환, 필터링 및 Azure Blob (WASB)에 저장 된 데이터를 시각화에 대 한 대화형 쿼리를 실행할 수 있는 hello Spark 클러스터에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-117">It also includes support for **Jupyter PySpark notebooks** on hello Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="e65b9-118">PySpark는 hello Spark에 대 한 Python API입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-118">PySpark is hello Python API for Spark.</span></span> <span data-ttu-id="e65b9-119">hello 솔루션을 제공 하 고 여기 Jupyter 노트북 hello Spark 클러스터에 설치에서 실행 하는 hello 관련 점도 toovisualize hello 데이터를 보여 주는 hello 코드 조각입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-119">hello code snippets that provide hello solutions and show hello relevant plots toovisualize hello data here run in Jupyter notebooks installed on hello Spark clusters.</span></span> <span data-ttu-id="e65b9-120">이 항목의 hello 모델링 단계 tootrain를 평가, 저장 및 각 모델 유형에 사용 방법을 보여 주는 코드가 포함 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-120">hello modeling steps in these topics contain code that shows how tootrain, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="e65b9-121">설정: Spark 클러스터 및 Jupyter Notebook</span><span class="sxs-lookup"><span data-stu-id="e65b9-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="e65b9-122">설치 단계와 코드는 HDInsight Spark 1.6을 사용하는 이 연습에 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="e65b9-123">하지만 Jupyter Notebook은 HDInsight Spark 1.6과 Spark 2.0 클러스터 둘 다에 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="e65b9-124">Hello에 전자 필기장 및 링크 toothem hello에 대 한 설명을 제공 됩니다 [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) 이 포함 하는 hello GitHub 리포지토리에 대 한 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-124">A description of hello notebooks and links toothem are provided in hello [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for hello GitHub repository containing them.</span></span> <span data-ttu-id="e65b9-125">또한 hello 코드와 연결 된 hello 전자 필기장에서 제네릭 인데 어떤 Spark 클러스터에서 작동 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-125">Moreover, hello code here and in hello linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="e65b9-126">HDInsight Spark를 사용 하지 않는 경우 hello 클러스터 설치 및 관리 단계는 여기 표시 된에서 약간 다를 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-126">If you are not using HDInsight Spark, hello cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="e65b9-127">편의 위해 링크는 다음과 같습니다 hello Spark 1.6 (toobe hello pySpark 커널의 hello Jupyter 노트북 서버에서 실행) 및 Spark 2.0 (toobe hello pySpark3 커널의 hello Jupyter 노트북 서버에서 실행)에 대 한 toohello Jupyter 노트북:</span><span class="sxs-lookup"><span data-stu-id="e65b9-127">For convenience, here are hello links toohello Jupyter notebooks for Spark 1.6 (toobe run in hello pySpark kernel of hello Jupyter Notebook server) and  Spark 2.0 (toobe run in hello pySpark3 kernel of hello Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="e65b9-128">Spark 1.6 Notebook</span><span class="sxs-lookup"><span data-stu-id="e65b9-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="e65b9-129">이러한 전자 필기장 toobe hello pySpark 커널의 Jupyter 노트북 서버에서 실행 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-129">These notebooks are toobe run in hello pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="e65b9-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): 방법에 대해 설명 tooperform 데이터 탐색, 모델링 및 다양 한 알고리즘이 점수 매기기입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how tooperform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="e65b9-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): 노트북 #1의 토픽과 하이퍼 매개 변수 조정 및 교차 유효성 검사를 사용하는 모델 개발을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="e65b9-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): 방법을 toooperationalize HDInsight에서 Python을 사용 하 여 저장 된 모델 클러스터를 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how toooperationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="e65b9-133">Spark 2.0 Notebook</span><span class="sxs-lookup"><span data-stu-id="e65b9-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="e65b9-134">이러한 전자 필기장 toobe hello pySpark3 커널의 Jupyter 노트북 서버에서 실행 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-134">These notebooks are toobe run in hello pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="e65b9-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb):이 파일 어떻게 tooperform 데이터 탐색, 모델링 및 Spark 2.0에서 점수 매기기 클러스터 NYC 택시 여행 hello를 사용 하 여에 정보를 제공 합니다. 및 데이터 집합 설명 요금 [여기](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data)합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how tooperform data exploration, modeling, and scoring in Spark 2.0 clusters using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="e65b9-136">이 전자 필기장 신속 하 게 Spark 2.0를 제공 하는 hello 코드를 탐색 하기 위한 좋은 출발점 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-136">This notebook may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> <span data-ttu-id="e65b9-137">더 자세한 노트북 hello NYC 택시 데이터를 분석에 대 한이 목록에 다음 노트북을 hello를 참조 하십시오.</span><span class="sxs-lookup"><span data-stu-id="e65b9-137">For a more detailed notebook analyzes hello NYC Taxi data, see hello next notebook in this list.</span></span> <span data-ttu-id="e65b9-138">이러한 전자 필기장을 비교 하는이 목록 다음 되는 hello 메모를 참조 하세요.</span><span class="sxs-lookup"><span data-stu-id="e65b9-138">See hello notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="e65b9-139">[Spark2.0 pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb):이 파일은 NYC 택시 여행 및 요금 데이터 집합 설명 tooperform 데이터 wrangling (Spark SQL 및 데이터 프레임 작업) 탐색을 모델링 하 고 사용 하 여 점수 매기기 hello 하는 방법을 보여 줍니다. [ 여기](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data)합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="e65b9-140">[Spark2.0 pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb):이 파일은 tooperform 데이터 wrangling (Spark SQL 및 데이터 프레임 작업) 탐색을 모델링 하 고 사용 하 여 점수 매기기 잘 알려진 Airline 정시 출발 hello 하는 방법을 보여 줍니다. 2011 및 2012에서 데이터 집합입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how tooperform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using hello well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="e65b9-141">에서는 통합 hello airline 데이터 집합 hello 공항 날씨 데이터 (예:: windspeed, 온도, 고도 등) 이전 toomodeling, 되므로 이러한 날씨 기능 hello 모델에 포함 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-141">We integrated hello airline dataset with hello airport weather data (e.g. windspeed, temperature, altitude etc.) prior toomodeling, so these weather features can be included in hello model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="e65b9-142">hello airline 데이터 집합 추가 toohello Spark 2.0 전자 필기장 toobetter 분류 알고리즘의 hello 사용을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-142">hello airline dataset was added toohello Spark 2.0 notebooks toobetter illustrate hello use of classification algorithms.</span></span> <span data-ttu-id="e65b9-143">Airline 정시 출발 집합과 날씨 데이터 집합에 대 한 정보에 대 한 링크를 따라 hello 참조:</span><span class="sxs-lookup"><span data-stu-id="e65b9-143">See hello following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="e65b9-144">항공사 정시 출발 데이터: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="e65b9-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="e65b9-145">공항 날씨 데이터: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="e65b9-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="e65b9-146">hello NYC 택시에서 hello Spark 2.0 전자 필기장 및 airline 비행 지연 데이터 집합에는 10 분 또는 (hello의 크기에 따라 HDI 클러스터) 자세한 toorun 걸릴 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-146">hello Spark 2.0 notebooks on hello NYC taxi and airline flight delay data-sets can take 10 mins or more toorun (depending on hello size of your HDI cluster).</span></span> <span data-ttu-id="e65b9-147">hello 목록 위의 hello에서 첫 번째 노트북 hello 데이터 탐색의 다양 한 부분, 시각화 및 기계 학습 모델 교육 축소 샘플링 NYC 데이터 집합으로는 hello 택시 및 요금 파일 미리 조인 했습니다 적은 시간 toorun 받아들이는 노트북: [ Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) 이 노트북은 훨씬 더 짧은 시간 toofinish (2-3 분) 걸리고 있습니다 수 좋은 시작 지점 신속 하 게 hello 코드 탐색에 대 한 했으므로 Spark 2.0에 대 한 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-147">hello first notebook in hello above list shows many aspects of hello data exploration, visualization and ML model training in a notebook that takes less time toorun with down-sampled NYC data set, in which hello taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time toofinish (2-3 mins) and may be a good starting point for quickly exploring hello code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="e65b9-148">Spark 2.0 모델 및 점수 매기기에 대 한 모델 소비 화 hello에 대 한 지침을 참조 hello [Spark 1.6 문서 사용에 대 한](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) 필요한 hello 단계 개요 예에 대 한 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-148">For guidance on hello operationalization of a Spark 2.0 model and model consumption for scoring, see hello [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining hello steps required.</span></span> <span data-ttu-id="e65b9-149">hello Python 코드 파일을 Spark 2.0에 대 한 대체 toouse [이 파일](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py)합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-149">toouse this on Spark 2.0, replace hello Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="e65b9-150">필수 조건</span><span class="sxs-lookup"><span data-stu-id="e65b9-150">Prerequisites</span></span>
<span data-ttu-id="e65b9-151">다음 절차를 수행 하는 hello 관련된 tooSpark 1.6 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-151">hello following procedures are related tooSpark 1.6.</span></span> <span data-ttu-id="e65b9-152">사용 하 여 hello 전자 필기장 hello Spark 2.0 버전에 대 한 설명 하 고 toopreviously 연결 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-152">For  hello Spark 2.0 version, use hello notebooks described and linked toopreviously.</span></span> 

<span data-ttu-id="e65b9-153">1. Azure 구독이 있어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="e65b9-154">아직 가지고 있지 않은 경우 [Azure 평가판](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="e65b9-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="e65b9-155">2.가 연습이에서는 1.6 Spark 클러스터 toocomplete 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-155">2.You need a Spark 1.6 cluster toocomplete this walkthrough.</span></span> <span data-ttu-id="e65b9-156">toocreate 하나, 참조에 제공 된 hello 지침 [시작: Azure HDInsight의 Apache Spark 만들기](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md)합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-156">toocreate one, see hello instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="e65b9-157">hello 클러스터 유형 및 버전 hello에서 지정 된 **클러스터 유형 선택** 메뉴.</span><span class="sxs-lookup"><span data-stu-id="e65b9-157">hello cluster type and version is specified from hello **Select Cluster Type** menu.</span></span> 

![클러스터 구성](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="e65b9-159">Toouse Python 보다는 Scala toocomplete 종단 간 데이터 과학 프로세스에 대 한 작업 하는 방법을 보여 주는 항목에 대 한 참조 hello [Scala Azure의 Spark와 함께 사용 하 여 데이터 과학](machine-learning-data-science-process-scala-walkthrough.md)합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-159">For a topic that shows how toouse Scala rather than Python toocomplete tasks for an end-to-end data science process, see hello [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="hello-nyc-2013-taxi-data"></a><span data-ttu-id="e65b9-160">hello NYC 2013 택시 데이터</span><span class="sxs-lookup"><span data-stu-id="e65b9-160">hello NYC 2013 Taxi data</span></span>
<span data-ttu-id="e65b9-161">hello NYC 택시 여행 데이터는 약 20GB의 압축 된 쉼표로 구분 된 값 (CSV) 파일 (~ 48 GB 압축 되지 않음), 구성 173 백만 개 이상의 개별 라운드트립 및 hello fares 각 시에 대 한 지불 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-161">hello NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and hello fares paid for each trip.</span></span> <span data-ttu-id="e65b9-162">각 여행 레코드 hello 선택 및 자동 전송 위치 및 시간, 익명화 된 해킹 (드라이버의) 라이선스 번호 및 메달 (택시의 고유 id) 번호를 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-162">Each trip record includes hello pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="e65b9-163">hello 데이터 hello 2013 년의 모든 왕복에 설명 하 고 각 월에 대 한 두 개의 데이터 집합을 따라 hello에 제공 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-163">hello data covers all trips in hello year 2013 and is provided in hello following two datasets for each month:</span></span>

1. <span data-ttu-id="e65b9-164">hello 'trip_data' CSV 파일 승객 수와 같이 여행 세부 정보를 포함 하려면를 선택 하 고 기간과 여행 길이 여행 dropoff 가리킵니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-164">hello 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="e65b9-165">다음은 몇 가지 샘플 레코드입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="e65b9-166">hello 'trip_fare' CSV 파일 hello 요금을 지불 유형, 요금 크기, 추가 요금 및 세금, 팁 및 통행료가, 및 유료 hello 총 금액 등 각 여정에 대해 지불한의 세부 정보를 포함 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-166">hello 'trip_fare' CSV files contain details of hello fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and hello total amount paid.</span></span> <span data-ttu-id="e65b9-167">다음은 몇 가지 샘플 레코드입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="e65b9-168">이러한 파일 및 조인 된 hello 여행의 0.1% 샘플 이동\_데이터와 여행\_hello이이 연습에 대 한 입력된 데이터 집합으로 CVS 파일에 단일 데이터 집합 toouse 있어 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-168">We have taken a 0.1% sample of these files and joined hello trip\_data and trip\_fare CVS files into a single dataset toouse as hello input dataset for this walkthrough.</span></span> <span data-ttu-id="e65b9-169">hello 고유 키 toojoin 여행\_데이터와 여행\_요금 가지 hello 필드로 구성 됩니다: 메달 해킹\_사용권 및 픽업\_날짜/시간입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-169">hello unique key toojoin trip\_data and trip\_fare is composed of hello fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="e65b9-170">Hello 데이터 집합의 각 레코드는 hello를 NYC 택시 출장을 나타내는 특성에 따라 포함 되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-170">Each record of hello dataset contains hello following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="e65b9-171">필드</span><span class="sxs-lookup"><span data-stu-id="e65b9-171">Field</span></span> | <span data-ttu-id="e65b9-172">간략한 설명</span><span class="sxs-lookup"><span data-stu-id="e65b9-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="e65b9-173">medallion</span><span class="sxs-lookup"><span data-stu-id="e65b9-173">medallion</span></span> |<span data-ttu-id="e65b9-174">익명 처리된 택시 medallion(고유 택시 id)</span><span class="sxs-lookup"><span data-stu-id="e65b9-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="e65b9-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="e65b9-175">hack_license</span></span> |<span data-ttu-id="e65b9-176">익명 처리된 Hackney 운전 면허 번호</span><span class="sxs-lookup"><span data-stu-id="e65b9-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="e65b9-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="e65b9-177">vendor_id</span></span> |<span data-ttu-id="e65b9-178">택시 공급 업체 id</span><span class="sxs-lookup"><span data-stu-id="e65b9-178">Taxi vendor id</span></span> |
| <span data-ttu-id="e65b9-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="e65b9-179">rate_code</span></span> |<span data-ttu-id="e65b9-180">NYC 택시 요율</span><span class="sxs-lookup"><span data-stu-id="e65b9-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="e65b9-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="e65b9-181">store_and_fwd_flag</span></span> |<span data-ttu-id="e65b9-182">저장소 및 전달 플래그</span><span class="sxs-lookup"><span data-stu-id="e65b9-182">Store and forward flag</span></span> |
| <span data-ttu-id="e65b9-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="e65b9-183">pickup_datetime</span></span> |<span data-ttu-id="e65b9-184">승차 날짜 및 시간</span><span class="sxs-lookup"><span data-stu-id="e65b9-184">Pick up date & time</span></span> |
| <span data-ttu-id="e65b9-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="e65b9-185">dropoff_datetime</span></span> |<span data-ttu-id="e65b9-186">내린 날짜 및 시간</span><span class="sxs-lookup"><span data-stu-id="e65b9-186">Dropoff date & time</span></span> |
| <span data-ttu-id="e65b9-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="e65b9-187">pickup_hour</span></span> |<span data-ttu-id="e65b9-188">승차 시간</span><span class="sxs-lookup"><span data-stu-id="e65b9-188">Pick up hour</span></span> |
| <span data-ttu-id="e65b9-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="e65b9-189">pickup_week</span></span> |<span data-ttu-id="e65b9-190">Hello 연도의 주를 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-190">Pick up week of hello year</span></span> |
| <span data-ttu-id="e65b9-191">weekday</span><span class="sxs-lookup"><span data-stu-id="e65b9-191">weekday</span></span> |<span data-ttu-id="e65b9-192">요일(범위 1-7)</span><span class="sxs-lookup"><span data-stu-id="e65b9-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="e65b9-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="e65b9-193">passenger_count</span></span> |<span data-ttu-id="e65b9-194">택시 여정의 승객 수</span><span class="sxs-lookup"><span data-stu-id="e65b9-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="e65b9-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="e65b9-195">trip_time_in_secs</span></span> |<span data-ttu-id="e65b9-196">여정 시간(초)</span><span class="sxs-lookup"><span data-stu-id="e65b9-196">Trip time in seconds</span></span> |
| <span data-ttu-id="e65b9-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="e65b9-197">trip_distance</span></span> |<span data-ttu-id="e65b9-198">주행한 여정 거리(마일 단위)</span><span class="sxs-lookup"><span data-stu-id="e65b9-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="e65b9-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="e65b9-199">pickup_longitude</span></span> |<span data-ttu-id="e65b9-200">승차 경도</span><span class="sxs-lookup"><span data-stu-id="e65b9-200">Pick up longitude</span></span> |
| <span data-ttu-id="e65b9-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="e65b9-201">pickup_latitude</span></span> |<span data-ttu-id="e65b9-202">승차 위도</span><span class="sxs-lookup"><span data-stu-id="e65b9-202">Pick up latitude</span></span> |
| <span data-ttu-id="e65b9-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="e65b9-203">dropoff_longitude</span></span> |<span data-ttu-id="e65b9-204">내린 경도</span><span class="sxs-lookup"><span data-stu-id="e65b9-204">Dropoff longitude</span></span> |
| <span data-ttu-id="e65b9-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="e65b9-205">dropoff_latitude</span></span> |<span data-ttu-id="e65b9-206">내린 위도</span><span class="sxs-lookup"><span data-stu-id="e65b9-206">Dropoff latitude</span></span> |
| <span data-ttu-id="e65b9-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="e65b9-207">direct_distance</span></span> |<span data-ttu-id="e65b9-208">승차 및 하차 위치 사이의 직접 거리</span><span class="sxs-lookup"><span data-stu-id="e65b9-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="e65b9-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="e65b9-209">payment_type</span></span> |<span data-ttu-id="e65b9-210">지불 유형(cas, 신용 카드 등)</span><span class="sxs-lookup"><span data-stu-id="e65b9-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="e65b9-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="e65b9-211">fare_amount</span></span> |<span data-ttu-id="e65b9-212">요금 금액</span><span class="sxs-lookup"><span data-stu-id="e65b9-212">Fare amount in</span></span> |
| <span data-ttu-id="e65b9-213">surcharge</span><span class="sxs-lookup"><span data-stu-id="e65b9-213">surcharge</span></span> |<span data-ttu-id="e65b9-214">추가 요금</span><span class="sxs-lookup"><span data-stu-id="e65b9-214">Surcharge</span></span> |
| <span data-ttu-id="e65b9-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="e65b9-215">mta_tax</span></span> |<span data-ttu-id="e65b9-216">Mta 세금</span><span class="sxs-lookup"><span data-stu-id="e65b9-216">Mta tax</span></span> |
| <span data-ttu-id="e65b9-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="e65b9-217">tip_amount</span></span> |<span data-ttu-id="e65b9-218">팁 금액</span><span class="sxs-lookup"><span data-stu-id="e65b9-218">Tip amount</span></span> |
| <span data-ttu-id="e65b9-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="e65b9-219">tolls_amount</span></span> |<span data-ttu-id="e65b9-220">통행료 금액</span><span class="sxs-lookup"><span data-stu-id="e65b9-220">Tolls amount</span></span> |
| <span data-ttu-id="e65b9-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="e65b9-221">total_amount</span></span> |<span data-ttu-id="e65b9-222">총 금액</span><span class="sxs-lookup"><span data-stu-id="e65b9-222">Total amount</span></span> |
| <span data-ttu-id="e65b9-223">tipped</span><span class="sxs-lookup"><span data-stu-id="e65b9-223">tipped</span></span> |<span data-ttu-id="e65b9-224">팁 지불 여부(아니요 또는 예에 대해 0/1 지정)</span><span class="sxs-lookup"><span data-stu-id="e65b9-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="e65b9-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="e65b9-225">tip_class</span></span> |<span data-ttu-id="e65b9-226">팁 클래스(0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span><span class="sxs-lookup"><span data-stu-id="e65b9-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-hello-spark-cluster"></a><span data-ttu-id="e65b9-227">Hello Spark 클러스터에서 Jupyter 노트북에서 코드를 실행 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-227">Execute code from a Jupyter notebook on hello Spark cluster</span></span>
<span data-ttu-id="e65b9-228">Hello Jupyter 노트북 hello Azure 포털에서에서 시작할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-228">You can launch hello Jupyter Notebook from hello Azure portal.</span></span> <span data-ttu-id="e65b9-229">대시보드에 Spark 클러스터를 찾아 클러스터에 대해 tooenter 관리 페이지를 클릭 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-229">Find your Spark cluster on your dashboard and click it tooenter management page for your cluster.</span></span> <span data-ttu-id="e65b9-230">hello Spark 클러스터와 연결 된 tooopen hello 노트북 클릭 **클러스터 대시보드** -> **Jupyter 노트북** 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-230">tooopen hello notebook associated with hello Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![클러스터 대시보드](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="e65b9-232">너무 찾아볼 수도 있습니다***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Jupyter 노트북 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-232">You can also browse too***https://CLUSTERNAME.azurehdinsight.net/jupyter*** tooaccess hello Jupyter Notebooks.</span></span> <span data-ttu-id="e65b9-233">이 URL의 hello CLUSTERNAME 부분을 사용자 고유의 클러스터의 hello 이름을 바꿉니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-233">Replace hello CLUSTERNAME part of this URL with hello name of your own cluster.</span></span> <span data-ttu-id="e65b9-234">관리자 계정 tooaccess hello 전자 필기장에 대 한 hello 암호가 필요 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-234">You need hello password for your admin account tooaccess hello notebooks.</span></span>

![Jupyter 노트북 찾아보기](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="e65b9-236">PySpark toosee Spark 항목의이 도구 모음에 대 한 hello 코드 샘플이 포함 된 PySpark API.hello 전자 필기장에서 사용할 수 있는 hello를 사용 하는 패키지 전자 필기장의 몇 가지 예제가 포함 된 디렉터리를 선택 [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="e65b9-236">Select PySpark toosee a directory that contains a few examples of pre-packaged notebooks that use hello PySpark API.hello notebooks that contain hello code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="e65b9-237">Hello 전자 필기장에서 직접 업로드할 수 [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) Spark 클러스터에서 toohello Jupyter 노트북 서버입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-237">You can upload hello notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) toohello Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="e65b9-238">프로그램 Jupyter hello 홈 페이지에서 클릭 hello **업로드** hello hello 화면의 오른쪽 부분에 단추입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-238">On hello home page of your Jupyter, click hello **Upload** button on hello right part of hello screen.</span></span> <span data-ttu-id="e65b9-239">파일 탐색기가 열립니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-239">It opens a file explorer.</span></span> <span data-ttu-id="e65b9-240">Hello 노트북 한 hello GitHub (원시 콘텐츠) URL을 붙여넣을 수 여기 **열려**합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-240">Here you can paste hello GitHub (raw content) URL of hello Notebook and click **Open**.</span></span> 

<span data-ttu-id="e65b9-241">Hello 파일 이름으로 Jupyter 파일 목록에 표시 된 **업로드** 단추를 다시 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-241">You see hello file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="e65b9-242">이 **업로드** 버튼을 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-242">Click this **Upload** button.</span></span> <span data-ttu-id="e65b9-243">이제 hello 노트북을 가져왔습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-243">Now you have imported hello notebook.</span></span> <span data-ttu-id="e65b9-244">이 연습에서 다른 전자 필기장 이러한 단계 tooupload hello를 반복 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-244">Repeat these steps tooupload hello other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="e65b9-245">브라우저 및 선택 사항에 대 한 hello 링크를 마우스 오른쪽 단추로 클릭 수 **링크 복사** tooget hello github의 원시 콘텐츠 URL입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-245">You can right-click hello links on your browser and select **Copy Link** tooget hello github raw content URL.</span></span> <span data-ttu-id="e65b9-246">Hello Jupyter 업로드 파일 탐색기 대화 상자에이 URL을 붙여넣을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-246">You can paste this URL into hello Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="e65b9-247">이제 다음을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-247">Now you can:</span></span>

* <span data-ttu-id="e65b9-248">Hello 노트북을 클릭 하 여 hello 코드를 참조 하십시오.</span><span class="sxs-lookup"><span data-stu-id="e65b9-248">See hello code by clicking hello notebook.</span></span>
* <span data-ttu-id="e65b9-249">**Shift+Enter**를 눌러 각 셀을 실행합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="e65b9-250">클릭 하 여 hello 전체 전자 필기장 실행 **셀** -> **실행**합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-250">Run hello entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="e65b9-251">쿼리의 자동 시각화 hello를 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-251">Use hello automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="e65b9-252">hello PySpark 커널 hello 출력 (HiveQL) SQL 쿼리를 자동으로 시각화합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-252">hello PySpark kernel automatically visualizes hello output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="e65b9-253">Hello를 사용 하 여 다양 한 유형의 시각화 (테이블, 원형, 꺾은선형, 영역 또는 막대) 간에 hello 옵션 tooselect 증명이 **형식** hello 전자 필기장의 메뉴 단추:</span><span class="sxs-lookup"><span data-stu-id="e65b9-253">You are given hello option tooselect among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using hello **Type** menu buttons in hello notebook:</span></span>
> 
> 

![일반적인 접근 방식에 대한 로지스틱 회귀 분석 ROC 곡선](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="e65b9-255">다음 작업</span><span class="sxs-lookup"><span data-stu-id="e65b9-255">What's next?</span></span>
<span data-ttu-id="e65b9-256">HDInsight Spark 클러스터를 사용 하 여 설정 되 고 hello Jupyter 노트북 업로드 했으므로 toohello 세 PySpark 전자 필기장에 해당 하는 hello 항목을 통해 준비 toowork 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-256">Now that you are set up with an HDInsight Spark cluster and have uploaded hello Jupyter notebooks, you are ready toowork through hello topics that correspond toohello three PySpark notebooks.</span></span> <span data-ttu-id="e65b9-257">보여 줍니다 어떻게 tooexplore 데이터와 다음 방법을 toocreate 및 모델을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-257">They show how tooexplore your data and then how toocreate and consume models.</span></span> <span data-ttu-id="e65b9-258">고급 데이터 탐색 및 노트북 표시 방법을 모델링 하는 hello tooinclude 교차 유효성 검사, 하이퍼 매개 변수 비우기 및 모델 평가 합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-258">hello advanced data exploration and modeling notebook shows how tooinclude cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="e65b9-259">**데이터 탐색 및 모델링 spark:** hello 데이터 집합을 탐색 하 고, 점수를 만들고 hello 통해 작업 하 여 hello 기계 학습 모델을 평가 [hello Spark 데이터에 대 한 이진 분류 및 회귀 모델 만들기 MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) 항목입니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-259">**Data Exploration and modeling with Spark:** Explore hello dataset and create, score, and evaluate hello machine learning models by working through hello [Create binary classification and regression models for data with hello Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="e65b9-260">**소비 모델:** toolearn tooscore hello 분류 및 회귀 모델은이 항목에서 생성 하는 방법 참조 [점수 Spark 작성 기계 학습 모델을 평가 하 고](machine-learning-data-science-spark-model-consumption.md)합니다.</span><span class="sxs-lookup"><span data-stu-id="e65b9-260">**Model consumption:** toolearn how tooscore hello classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="e65b9-261">**교차 유효성 검사 및 하이퍼 매개 변수 비우기**: 교차 유효성 검사 및 하이퍼 매개 변수 비우기를 사용하여 모델을 학습하는 방법은 [Spark로 고급 데이터 탐색 및 모델링](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) 을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="e65b9-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

