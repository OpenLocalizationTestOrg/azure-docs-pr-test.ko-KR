---
title: "aaaFeature 엔지니어링 및 Azure 기계 학습에서 선택 | Microsoft Docs"
description: "기능 선택 및 기능 엔지니어링의 hello 목적에 설명 하 고 기계 학습의 hello 데이터 향상 프로세스에서 해당 역할의 예를 제공 합니다."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: 9ceb524d-842e-4f77-9eae-a18e599442d6
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 01/18/2017
ms.author: zhangya;bradsev
ROBOTS: NOINDEX
redirect_url: machine-learning-data-science-create-features
redirect_document_id: True
ms.openlocfilehash: e3e59329bf46f334396f5975b4e656137362d7ce
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/06/2017
---
# <a name="feature-engineering-and-selection-in-azure-machine-learning"></a><span data-ttu-id="50725-103">Azure 기계 학습의 기능 엔지니어링 및 선택</span><span class="sxs-lookup"><span data-stu-id="50725-103">Feature engineering and selection in Azure Machine Learning</span></span>
<span data-ttu-id="50725-104">이 기능 엔지니어링 및 기계 학습의 hello 데이터 개선 프로세스의 기능 선택의 hello 목적으로 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-104">This topic explains hello purposes of feature engineering and feature selection in hello data-enhancement process of machine learning.</span></span> <span data-ttu-id="50725-105">Azure Machine Learning 스튜디오에서 제공하는 예제를 사용하여 이러한 프로세스와 관련된 내용을 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-105">It illustrates what these processes involve by using examples provided by Azure Machine Learning Studio.</span></span>

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="50725-106">기계 학습에서 사용 되는 hello 학습 데이터 hello 선택 영역이 나 hello 수집 되는 원시 데이터에서 기능 추출 종종 향상 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-106">hello training data used in machine learning can often be enhanced by hello selection or extraction of features from hello raw data collected.</span></span> <span data-ttu-id="50725-107">Hello 원시 비트 배포 데이터에서 필기 문자의 tooclassify hello 이미지는 방법을 학습의 hello 컨텍스트에서 엔지니어링 기능의 예로 비트 밀도 지도 구성 됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-107">An example of an engineered feature in hello context of learning how tooclassify hello images of handwritten characters is a bit-density map constructed from hello raw bit distribution data.</span></span> <span data-ttu-id="50725-108">이 맵은 hello 문자의 hello 가장자리 hello 원시 배포 보다 더 효율적으로 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-108">This map can help locate hello edges of hello characters more efficiently than hello raw distribution.</span></span>

<span data-ttu-id="50725-109">엔지니어링 및 선택한 기능 hello 데이터에 포함 된 tooextract hello 키 정보를 시도 하는 hello 학습 프로세스의 hello 효율성을 향상 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-109">Engineered and selected features increase hello efficiency of hello training process, which attempts tooextract hello key information contained in hello data.</span></span> <span data-ttu-id="50725-110">이러한 모델 tooclassify hello 입력된 데이터의 hello 거듭제곱을 정확 하 게 향상 시킬 및 toopredict 결과 관심 더 강력 하 게 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-110">They also improve hello power of these models tooclassify hello input data accurately and toopredict outcomes of interest more robustly.</span></span> <span data-ttu-id="50725-111">기능 엔지니어링 및 선택 toomake hello 학습 더 계산 tractable 결합할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-111">Feature engineering and selection can also combine toomake hello learning more computationally tractable.</span></span> <span data-ttu-id="50725-112">이 작업을 수행 하 여 향상 하 고 toocalibrate 또는 모델을 학습 필요 hello 기능 수를 줄이면 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-112">It does so by enhancing and then reducing hello number of features needed toocalibrate or train a model.</span></span> <span data-ttu-id="50725-113">Hello 기능 선택한 tootrain hello 모델에 최소한의 hello 데이터의 hello 패턴을 설명 하 고 다음 결과 성공적으로 예측 하는 독립 변수 집합은 수학적으로 말하자면, 있습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-113">Mathematically speaking, hello features selected tootrain hello model are a minimal set of independent variables that explain hello patterns in hello data and then predict outcomes successfully.</span></span>

<span data-ttu-id="50725-114">hello 엔지니어링 및 기능 선택은 일반적으로 네 단계로 구성 되는 대규모 프로세스의 한 부분.</span><span class="sxs-lookup"><span data-stu-id="50725-114">hello engineering and selection of features is one part of a larger process, which typically consists of four steps:</span></span>

* <span data-ttu-id="50725-115">데이터 수집</span><span class="sxs-lookup"><span data-stu-id="50725-115">Data collection</span></span>
* <span data-ttu-id="50725-116">데이터 향상</span><span class="sxs-lookup"><span data-stu-id="50725-116">Data enhancement</span></span>
* <span data-ttu-id="50725-117">모델 생성</span><span class="sxs-lookup"><span data-stu-id="50725-117">Model construction</span></span>
* <span data-ttu-id="50725-118">후처리</span><span class="sxs-lookup"><span data-stu-id="50725-118">Post-processing</span></span>

<span data-ttu-id="50725-119">엔지니어링 및 선택 기계 학습의 hello 데이터 개선 단계를 구성 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-119">Engineering and selection make up hello data enhancement step of machine learning.</span></span> <span data-ttu-id="50725-120">이 프로세스의 세 가지 요소는 목적에 따라 다음과 같이 구별할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-120">Three aspects of this process may be distinguished for our purposes:</span></span>

* <span data-ttu-id="50725-121">**데이터 사전 처리**:이 프로세스 수집 된 데이터를 hello 시도 tooensure 명확 하 고 일관 됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-121">**Data pre-processing**: This process tries tooensure that hello collected data is clean and consistent.</span></span> <span data-ttu-id="50725-122">여러 데이터 집합 통합, 누락된 데이터 처리, 일관되지 않은 데이터 처리 및 데이터 유형 변환과 같은 작업이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-122">It includes tasks such as integrating multiple data sets, handling missing data, handling inconsistent data, and converting data types.</span></span>
* <span data-ttu-id="50725-123">**엔지니어링 기능**:이 프로세스가 hello hello 데이터와 tooincrease 예측 력이 toohello 학습 알고리즘의에서 기존 원시 기능에서 toocreate 추가 관련 기능을 시도 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-123">**Feature engineering**: This process attempts toocreate additional relevant features from hello existing raw features in hello data and tooincrease predictive power toohello learning algorithm.</span></span>
* <span data-ttu-id="50725-124">**기능 선택**:이 프로세스에서는 hello 학습 문제의 원래 데이터 기능 tooreduce hello 차원 hello 키 일부를 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-124">**Feature selection**: This process selects hello key subset of original data features tooreduce hello dimensionality of hello training problem.</span></span>

<span data-ttu-id="50725-125">이 항목에서는 hello 데이터 향상 프로세스의 hello 기능 엔지니어링 및 기능 선택 측면에 대해서만 다룹니다.</span><span class="sxs-lookup"><span data-stu-id="50725-125">This topic only covers hello feature engineering and feature selection aspects of hello data enhancement process.</span></span> <span data-ttu-id="50725-126">Hello 데이터 전처리 단계에 대 한 자세한 내용은 참조 하십시오. [Azure 기계 학습 스튜디오에서 데이터를 전처리](https://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/)합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-126">For more information on hello data pre-processing step, see [Pre-processing data in Azure Machine Learning Studio](https://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/).</span></span>

## <a name="creating-features-from-your-data--feature-engineering"></a><span data-ttu-id="50725-127">데이터에서 기능 만들기--기능 엔지니어링</span><span class="sxs-lookup"><span data-stu-id="50725-127">Creating features from your data--feature engineering</span></span>
<span data-ttu-id="50725-128">hello 학습 데이터 행렬 (레코드 또는 행에 저장 된 관측 치를) 예제는 구성 하며 각각의 기능 (변수 또는 열에 저장 된 필드) 집합으로 이루어져 있습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-128">hello training data consists of a matrix composed of examples (records or observations stored in rows), each of which has a set of features (variables or fields stored in columns).</span></span> <span data-ttu-id="50725-129">hello hello 실험적 디자인에 지정 된 기능은 hello 데이터의 예상된 toocharacterize hello 패턴입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-129">hello features specified in hello experimental design are expected toocharacterize hello patterns in hello data.</span></span> <span data-ttu-id="50725-130">선택한 기능 사용 되는 집합 tootrain 모델을 hello 다양 한 hello 원시 데이터 필드에 직접 포함 될 수 있지만 추가 엔지니어링된 기능 toobe hello 원시 데이터 toogenerate 향상 된 학습 데이터 집합의에서 hello 기능에서 생성 된 필요한 경우가 많습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-130">Although many of hello raw data fields can be directly included in hello selected feature set used tootrain a model, additional engineered features often need toobe constructed from hello features in hello raw data toogenerate an enhanced training data set.</span></span>

<span data-ttu-id="50725-131">모델을 학습 하는 경우 어떤 유형의 기능 tooenhance hello 데이터 집합을 생성 해야?</span><span class="sxs-lookup"><span data-stu-id="50725-131">What kind of features should be created tooenhance hello data set when training a model?</span></span> <span data-ttu-id="50725-132">Hello 교육을 향상 시키는 엔지니어링된 기능 hello 데이터의 hello 패턴을 더 잘 구분할 수 있는 정보를 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-132">Engineered features that enhance hello training provide information that better differentiates hello patterns in hello data.</span></span> <span data-ttu-id="50725-133">Hello 새 기능 tooprovide 추가 정보를 기대 명확 하 게 캡처된 또는 원래 hello에 명백 하지 않은 또는 기존 기능 설정 했지만이 프로세스는 아트 만들어집니다.</span><span class="sxs-lookup"><span data-stu-id="50725-133">You expect hello new features tooprovide additional information that is not clearly captured or easily apparent in hello original or existing feature set, but this process is something of an art.</span></span> <span data-ttu-id="50725-134">안정되고 생산성이 있는 결정을 내리려면 도메인에 대한 전문 지식이 필요한 경우가 많습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-134">Sound and productive decisions often require some domain expertise.</span></span>

<span data-ttu-id="50725-135">Azure 기계 학습을 시작할 때 기계 학습 스튜디오에 제공 된 샘플을 사용 하 여 구체적으로이 프로세스는 가장 쉬운 toograsp 됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-135">When starting with Azure Machine Learning, it is easiest toograsp this process concretely by using samples provided in Machine Learning Studio.</span></span> <span data-ttu-id="50725-136">다음은 제공되는 두 가지 예입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-136">Two examples are presented here:</span></span>

* <span data-ttu-id="50725-137">회귀 예제 ([자전거 여 hello 수의 예측](http://gallery.cortanaintelligence.com/Experiment/Regression-Demand-estimation-4)) hello 대상 값은 알려진 하는 감독 된 실험에서</span><span class="sxs-lookup"><span data-stu-id="50725-137">A regression example ([Prediction of hello number of bike rentals](http://gallery.cortanaintelligence.com/Experiment/Regression-Demand-estimation-4)) in a supervised experiment where hello target values are known</span></span>
* <span data-ttu-id="50725-138">[기능 해싱][feature-hashing]을 사용하는 텍스트 마이닝 분류 예제</span><span class="sxs-lookup"><span data-stu-id="50725-138">A text-mining classification example using [Feature Hashing][feature-hashing]</span></span>

### <a name="example-1-adding-temporal-features-for-a-regression-model"></a><span data-ttu-id="50725-139">예 1: 회귀 모델을 위해 시간 기능 추가</span><span class="sxs-lookup"><span data-stu-id="50725-139">Example 1: Adding temporal features for a regression model</span></span>
<span data-ttu-id="50725-140">toodemonstrate는 tooengineer 회귀 작업에 대 한 기능을 어떻게 사용 hello 실험 "수요 예측 자전거의" Azure 기계 학습 스튜디오에서 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-140">toodemonstrate how tooengineer features for a regression task, let's use hello experiment "Demand forecasting of bikes" in Azure Machine Learning Studio.</span></span> <span data-ttu-id="50725-141">hello이이 실험은 hello 자전거, 자전거 여 내 특정 월, 일 또는 시간인 hello 수,에 대 한 toopredict hello 요구 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-141">hello objective of this experiment is toopredict hello demand for hello bikes, that is, hello number of bike rentals within a specific month, day, or hour.</span></span> <span data-ttu-id="50725-142">데이터 집합 hello **자전거 임대 UCI 데이터 집합** hello 원시 입력 데이터로 사용 됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-142">hello data set **Bike Rental UCI data set** is used as hello raw input data.</span></span>

<span data-ttu-id="50725-143">이 데이터 집합 hello hello 미국에에서 워싱턴 DC에서 자전거 임대 네트워크를 유지 하는 대문자 자전거 공유 회사에서에서 실제 데이터를 기반으로 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-143">This data set is based on real data from hello Capital Bikeshare company that maintains a bike rental network in Washington DC in hello United States.</span></span> <span data-ttu-id="50725-144">hello 데이터 집합 자전거 여 hello 수는 하루 중 특정 시간 내에서 2011 too2012 나타내며 17379 행과 17 열을 포함 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-144">hello data set represents hello number of bike rentals within a specific hour of a day, from 2011 too2012, and it contains 17379 rows and 17 columns.</span></span> <span data-ttu-id="50725-145">날씨 조건 (온도, 습도, 풍속) 및 (공휴일 또는 평일) hello 날짜 hello 종류 hello 원시 기능 집합에 포함 되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-145">hello raw feature set contains weather conditions (temperature, humidity, wind speed) and hello type of hello day (holiday or weekday).</span></span> <span data-ttu-id="50725-146">hello 필드 toopredict은 **cnt**, 개수는 특정 시간 내에서 hello 자전거 대 여 나타내며 1 too977에서 사이의 정수입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-146">hello field toopredict is **cnt**, a count that represents hello bike rentals within a specific hour and that ranges from 1 too977.</span></span>

<span data-ttu-id="50725-147">tooconstruct hello 학습 데이터의 효과적인 기능을 4 개의 회귀 모델이 hello를 사용 하 여 생성 된 동일한 알고리즘을 이지만 네 개의 서로 다른 학습 데이터 집합입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-147">tooconstruct effective features in hello training data, four regression models are built by using hello same algorithm, but with four different training data sets.</span></span> <span data-ttu-id="50725-148">4 hello 데이터 집합을 나타내는 원시 입력된 데이터를 동일한 hello 되지만 기능의 증가 함에 설정은.</span><span class="sxs-lookup"><span data-stu-id="50725-148">hello four data sets represent hello same raw input data, but with an increasing number of features set.</span></span> <span data-ttu-id="50725-149">이러한 기능은 다음 네 가지 범주로 그룹화됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-149">These features are grouped into four categories:</span></span>

1. <span data-ttu-id="50725-150">A = 날씨 + 휴일 + 평일 + hello 예측 된 날에 대 한 주말 기능</span><span class="sxs-lookup"><span data-stu-id="50725-150">A = weather + holiday + weekday + weekend features for hello predicted day</span></span>
2. <span data-ttu-id="50725-151">B = 12 시간 동안 이전 각 hello 임대 된 자전거 수</span><span class="sxs-lookup"><span data-stu-id="50725-151">B = number of bikes that were rented in each of hello previous 12 hours</span></span>
3. <span data-ttu-id="50725-152">C = 된 임대 각 hello hello에 12 일 이전 동일 자전거 수 시간</span><span class="sxs-lookup"><span data-stu-id="50725-152">C = number of bikes that were rented in each of hello previous 12 days at hello same hour</span></span>
4. <span data-ttu-id="50725-153">D = 된 임대 각 hello hello에 12 일로, 이전 동일 자전거 수 시간 및 hello 같은 날</span><span class="sxs-lookup"><span data-stu-id="50725-153">D = number of bikes that were rented in each of hello previous 12 weeks at hello same hour and hello same day</span></span>

<span data-ttu-id="50725-154">Hello 원래 원시 데이터에 이미 존재, 기능 집합 A 외에도 hello 다른 세 가지 기능을 만듭니다 hello 기능 엔지니어링 프로세스.</span><span class="sxs-lookup"><span data-stu-id="50725-154">Besides feature set A, which already exists in hello original raw data, hello other three sets of features are created through hello feature engineering process.</span></span> <span data-ttu-id="50725-155">기능 B 캡처 hello hello 자전거에 대 한 최근 요청을 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-155">Feature set B captures hello recent demand for hello bikes.</span></span> <span data-ttu-id="50725-156">기능 C 캡처 자전거에 대 한 hello 요구 한 특정 시간에 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-156">Feature set C captures hello demand for bikes at a particular hour.</span></span> <span data-ttu-id="50725-157">특정 시간 및 특정 요일 hello 자전거에 대 한 캡처 수요가 D를 설정 하는 기능.</span><span class="sxs-lookup"><span data-stu-id="50725-157">Feature set D captures demand for bikes at particular hour and particular day of hello week.</span></span> <span data-ttu-id="50725-158">각각 4 hello 학습 데이터 집합의 포함 기능 집합 A "," A + B "," A + B + C "및" A + B + C + D, 각각.</span><span class="sxs-lookup"><span data-stu-id="50725-158">Each of hello four training data sets includes feature sets A, A+B, A+B+C, and A+B+C+D, respectively.</span></span>

<span data-ttu-id="50725-159">Azure 기계 학습 실험 hello에 hello 미리 처리 된 입력된 데이터 집합에서 4 개의 분기를 통해 이러한 4 개의 학습 데이터 집합을 구성 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-159">In hello Azure Machine Learning experiment, these four training data sets are formed via four branches from hello pre-processed input data set.</span></span> <span data-ttu-id="50725-160">이러한 분기 중 각각가 포함 된 hello 맨 왼쪽 분기를 제외 하 고는 [R 스크립트 실행] [ execute-r-script] 집합이 있는 (기능 B, C 및 D 설정) 하는 기능을 파생 모듈 각각 구현 되 고 추가 toohello는 데이터 집합을 가져옵니다.</span><span class="sxs-lookup"><span data-stu-id="50725-160">Except for hello leftmost branch, each of these branches contains an [Execute R Script][execute-r-script] module in which a set of derived features (feature sets B, C, and D) is respectively constructed and appended toohello imported data set.</span></span> <span data-ttu-id="50725-161">hello 다음 그림 hello 두 번째 왼쪽된 분기 toocreate 기능 집합 B hello R 스크립트를 사용 하는 방법을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="50725-161">hello following figure demonstrates hello R script used toocreate feature set B in hello second left branch.</span></span>

![기능 집합 만들기](./media/machine-learning-feature-selection-and-engineering/addFeature-Rscripts.png)

<span data-ttu-id="50725-163">hello 다음 표에 요약 되어 hello 4 개의 모델의 hello 성능 결과의 hello 비교 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-163">hello following table summarizes hello comparison of hello performance results of hello four models.</span></span> <span data-ttu-id="50725-164">최상의 결과 얻으려면 hello A + B + C 기능으로 표시 됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-164">hello best results are shown by features A+B+C.</span></span> <span data-ttu-id="50725-165">추가 기능 집합 hello 학습 데이터에 포함 되 면 해당 hello 오류율 감소 note 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-165">Note that hello error rate decreases when additional feature sets are included in hello training data.</span></span> <span data-ttu-id="50725-166">이 확인 B와 C hello 회귀 작업에 대 한 추가 관련 정보를 제공 하는 기능 집합을 hello 우리의 가정 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-166">This verifies our presumption that hello feature sets B and C provide additional relevant information for hello regression task.</span></span> <span data-ttu-id="50725-167">Hello D 기능 집합을 추가 하지 않는 것 tooprovide hello 오류율 추가 감소 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-167">Adding hello D feature set does not seem tooprovide any additional reduction in hello error rate.</span></span>

![성능 결과 비교](./media/machine-learning-feature-selection-and-engineering/result1.png)

### <span data-ttu-id="50725-169"><a name="example2"></a> 예 2: 텍스트 마이닝에 기능 만들기</span><span class="sxs-lookup"><span data-stu-id="50725-169"><a name="example2"></a> Example 2: Creating features in text mining</span></span>
<span data-ttu-id="50725-170">기능 엔지니어링 마이닝, 문서 분류 및 감성 분석 등 작업 관련된 tootext에서 광범위 하 게 적용 됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-170">Feature engineering is widely applied in tasks related tootext mining, such as document classification and sentiment analysis.</span></span> <span data-ttu-id="50725-171">예를 들어 여러 범주로 tooclassify 문서를 사용할 때 일반적인 가정은 hello 단어 또는 구를 하나의 문서 범주에 포함 된 않는다는 다른 문서 범주에 가능성이 더 낮아집니다 toooccur입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-171">For example, when you want tooclassify documents into several categories, a typical assumption is that hello words or phrases included in one document category are less likely toooccur in another document category.</span></span> <span data-ttu-id="50725-172">즉, hello hello 단어 또는 구를 분포의 빈도가 수 toocharacterize 다른 문서 범주입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-172">In other words, hello frequency of hello word or phrase distribution is able toocharacterize different document categories.</span></span> <span data-ttu-id="50725-173">텍스트 마이닝 응용 프로그램에서는 hello 엔지니어링 프로세스 기능은 개별 항목의 텍스트 내용을 일반적으로 역할을 하므로 입력된 데이터 hello 때문에 단어 또는 구를 주파수와 관련 된 필요한 toocreate hello 기능 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-173">In text mining applications, hello feature engineering process is needed toocreate hello features involving word or phrase frequencies because individual pieces of text-contents usually serve as hello input data.</span></span>

<span data-ttu-id="50725-174">tooachieve이 작업을 호출 하는 기술을 *기능 해시* 가 적용 된 tooefficiently 인덱스에 임의의 텍스트 형식 기능을 설정 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-174">tooachieve this task, a technique called *feature hashing* is applied tooefficiently turn arbitrary text features into indices.</span></span> <span data-ttu-id="50725-175">대신 각 텍스트 기능 (단어 또는 구를) tooa 특정 인덱스, 해시 함수 toohello 기능을 적용 하 여 및 직접 인덱스로 해당 해시 값을 사용 하 여이 메서드 함수를 연결 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-175">Instead of associating each text feature (words or phrases) tooa particular index, this method functions by applying a hash function toohello features and by using their hash values as indices directly.</span></span>

<span data-ttu-id="50725-176">Azure Machine Learning에는 이러한 단어 또는 문구 기능을 편리하게 생성하는 [기능 해싱][feature-hashing] 모듈이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-176">In Azure Machine Learning, there is a [Feature Hashing][feature-hashing] module that creates these word or phrase features.</span></span> <span data-ttu-id="50725-177">hello 다음 그림은이 모듈을 사용 하는 예제.</span><span class="sxs-lookup"><span data-stu-id="50725-177">hello following figure shows an example of using this module.</span></span> <span data-ttu-id="50725-178">두 개의 열을 포함 하는 hello 입력된 데이터 집합: hello 책 등급 1 too5 및 hello 실제 검토 콘텐츠에서 사이의 값입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-178">hello input data set contains two columns: hello book rating ranging from 1 too5 and hello actual review content.</span></span> <span data-ttu-id="50725-179">이 hello 목표 [기능 해시] [ feature-hashing] 모듈은 tooretrieve hello 특정 우수에서 hello 해당 단어 또는 구를의 hello 발생 빈도 표시 하는 새로운 기능입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-179">hello goal of this [Feature Hashing][feature-hashing] module is tooretrieve new features that show hello occurrence frequency of hello corresponding words or phrases within hello particular book review.</span></span> <span data-ttu-id="50725-180">toouse toocomplete hello 단계를 수행 해야이 모듈:</span><span class="sxs-lookup"><span data-stu-id="50725-180">toouse this module, you need toocomplete hello following steps:</span></span>

1. <span data-ttu-id="50725-181">Hello 입력된 텍스트가 포함 된 select hello 열 (**Col2** 이 예에서).</span><span class="sxs-lookup"><span data-stu-id="50725-181">Select hello column that contains hello input text (**Col2** in this example).</span></span>
2. <span data-ttu-id="50725-182">설정 *해시 비트 크기* too8 즉, 2 ^8 = 256 기능 만들어집니다.</span><span class="sxs-lookup"><span data-stu-id="50725-182">Set *Hashing bitsize* too8, which means 2^8=256 features are created.</span></span> <span data-ttu-id="50725-183">hello hello 텍스트에서 단어 또는 구를 다음 too256 인덱스 해시 됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-183">hello word or phrase in hello text is then hashed too256 indices.</span></span> <span data-ttu-id="50725-184">매개 변수를 hello *해시 비트 크기* 범위는 1 too31에서 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-184">hello parameter *Hashing bitsize* ranges from 1 too31.</span></span> <span data-ttu-id="50725-185">Hello 매개 변수 설정 tooa 더 큰 숫자를 hello 단어 또는 구를 가능성이 낮습니다 toobe 해시 hello에 동일한 인덱스입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-185">If hello parameter is set tooa larger number, hello words or phrases are less likely toobe hashed into hello same index.</span></span>
3. <span data-ttu-id="50725-186">Hello 매개 변수를 설정 *N 그램* too2 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-186">Set hello parameter *N-grams* too2.</span></span> <span data-ttu-id="50725-187">Hello 입력된 텍스트에서 그램이 (모든 단일 단어에 대 한 기능) 유 니 그램과 바이 (인접 한 단어의 모든 쌍에 대 한 기능)의 발생 빈도 hello를 검색 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-187">This retrieves hello occurrence frequency of unigrams (a feature for every single word) and bigrams (a feature for every pair of adjacent words) from hello input text.</span></span> <span data-ttu-id="50725-188">매개 변수를 hello *N 그램* hello 순차적 단어 toobe 기능에 포함 된 최대 수를 나타내는 0 too10 범위입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-188">hello parameter *N-grams* ranges from 0 too10, which indicates hello maximum number of sequential words toobe included in a feature.</span></span>  

![기능 해싱 모듈](./media/machine-learning-feature-selection-and-engineering/feature-Hashing1.png)

<span data-ttu-id="50725-190">hello 다음 그림은 이러한 새 기능은 표시 되는 같습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-190">hello following figure shows what these new features look like.</span></span>

![기능 해싱 예제](./media/machine-learning-feature-selection-and-engineering/feature-Hashing2.png)

## <a name="filtering-features-from-your-data--feature-selection"></a><span data-ttu-id="50725-192">데이터에서 기능 필터링--기능 선택</span><span class="sxs-lookup"><span data-stu-id="50725-192">Filtering features from your data--feature selection</span></span>
<span data-ttu-id="50725-193">*기능 선택* 일반적으로 된 프로세스를 적용할 분류 또는 회귀 작업 같은 예측 모델링 태스크에 대 한 학습 데이터 집합의 toohello 생성입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-193">*Feature selection* is a process that is commonly applied toohello construction of training data sets for predictive modeling tasks such as classification or regression tasks.</span></span> <span data-ttu-id="50725-194">hello 목표 tooselect hello 데이터에서 기능 toorepresent hello 분산의 최대 크기의 최소 집합을 사용 하 여 크기를 줄여 주는 hello 원래 데이터 집합에서 hello 기능의 하위 집합입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-194">hello goal is tooselect a subset of hello features from hello original data set that reduces its dimensions by using a minimal set of features toorepresent hello maximum amount of variance in hello data.</span></span> <span data-ttu-id="50725-195">이 하위 집합의 기능 hello 전용 기능 포함 toobe tootrain hello 모델을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-195">This subset of features contains hello only features toobe included tootrain hello model.</span></span> <span data-ttu-id="50725-196">기능 선택은 두 가지 기본 용도로 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-196">Feature selection serves two main purposes:</span></span>

* <span data-ttu-id="50725-197">기능 선택을 수행하면 관련이 없는 중복된 기능이나 고도로 상관된 기능을 제거하여 분류 정확도를 높입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-197">Feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</span></span>
* <span data-ttu-id="50725-198">기능 선택은 감소 hello 여러 가지 기능을 하면 hello 모델 학습 프로세스를 보다 효율적입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-198">Feature selection decreases hello number of features, which makes hello model training process more efficient.</span></span> <span data-ttu-id="50725-199">지원 벡터 컴퓨터 같은 비용이 많이 드는 tootrain 않은 학습자에 특히 유용 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-199">This is particularly important for learners that are expensive tootrain such as support vector machines.</span></span>

<span data-ttu-id="50725-200">기능 선택 tooreduce hello hello 사용 되는 데이터 집합 tootrain hello 모델의 기능 수를 검색 하지만 일반적으로 tooby hello 용어를 참조 *차원 감소 합니다.*</span><span class="sxs-lookup"><span data-stu-id="50725-200">Although feature selection seeks tooreduce hello number of features in hello data set used tootrain hello model, it is not usually referred tooby hello term *dimensionality reduction.*</span></span> <span data-ttu-id="50725-201">기능 선택 방법을 변경 하지 않은 hello 데이터의 원래 기능 하위 집합을 추출 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-201">Feature selection methods extract a subset of original features in hello data without changing them.</span></span>  <span data-ttu-id="50725-202">차원성 감소 방법을 hello 초기 기능을 변환 하 고 있으므로 수정할 수 있는 엔지니어링된 기능을 사용 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-202">Dimensionality reduction methods employ engineered features that can transform hello original features and thus modify them.</span></span> <span data-ttu-id="50725-203">차원 수 감소 메서드의 예로는 주성분 분석, 표준 상관 분석 및 특이값 분해가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-203">Examples of dimensionality reduction methods include principal component analysis, canonical correlation analysis, and singular value decomposition.</span></span>

<span data-ttu-id="50725-204">감독된 컨텍스트에서 가장 널리 적용되는 기능 선택 메서드 범주는 필터 기반 기능 선택입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-204">One widely applied category of feature selection methods in a supervised context is filter-based feature selection.</span></span> <span data-ttu-id="50725-205">각 기능 및 hello 대상 특성 간의 hello 상관 관계를 평가 하 여 이러한 메서드는 통계 측정값 tooassign 점수 tooeach 기능을 적용 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-205">By evaluating hello correlation between each feature and hello target attribute, these methods apply a statistical measure tooassign a score tooeach feature.</span></span> <span data-ttu-id="50725-206">hello 기능은 다음을 기준으로 사용할 수 있는 hello 점수 tooset hello 임계값을 유지 하거나 특정 기능을 제거 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-206">hello features are then ranked by hello score, which you can use tooset hello threshold for keeping or eliminating a specific feature.</span></span> <span data-ttu-id="50725-207">이러한 방법에 사용 된 hello 통계 측정값의 예로 피어슨 상관 관계, 상호 정보 및 카이 제곱 검정 hello 들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="50725-207">Examples of hello statistical measures used in these methods include Pearson Correlation, mutual information, and hello Chi-squared test.</span></span>

<span data-ttu-id="50725-208">Azure Machine Learning 스튜디오에서는 기능 선택의 모듈을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-208">Azure Machine Learning Studio provides modules for feature selection.</span></span> <span data-ttu-id="50725-209">이러한 모듈에는 hello 다음 그림에에서 나와 있는 것 처럼 [필터 기반 기능 선택] [ filter-based-feature-selection] 및 [피셔 선형 판별 분석] [ fisher-linear-discriminant-analysis].</span><span class="sxs-lookup"><span data-stu-id="50725-209">As shown in hello following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</span></span>

![기능 선택 예](./media/machine-learning-feature-selection-and-engineering/feature-Selection.png)

<span data-ttu-id="50725-211">예를 들어 hello를 사용 하 여 [필터 기반 기능 선택] [ filter-based-feature-selection] 앞부분에 설명 된 hello 텍스트 마이닝 예제를 사용 하 여 모듈입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-211">For example, use hello [Filter-Based Feature Selection][filter-based-feature-selection] module with hello text mining example outlined previously.</span></span> <span data-ttu-id="50725-212">한다고 가정 toobuild 회귀 모델은 256 기능 집합이 hello를 통해 만들어진 후 [기능 해시] [ feature-hashing] 모듈 및 해당 hello 응답 변수는 **Col1**책을 나타내는 등급 1 too5에서 범위의 검토 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-212">Assume that you want toobuild a regression model after a set of 256 features is created through hello [Feature Hashing][feature-hashing] module, and that hello response variable is **Col1** and represents a book review rating ranging from 1 too5.</span></span> <span data-ttu-id="50725-213">설정 **기능 점수 매기기 방법** 너무**피어슨 상관 관계**, **대상 열** 너무**Col1**, 및 **수가 필요한 기능** 너무**50**합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-213">Set **Feature scoring method** too**Pearson Correlation**, **Target column** too**Col1**, and **Number of desired features** too**50**.</span></span> <span data-ttu-id="50725-214">hello 모듈 [필터 기반 기능 선택] [ filter-based-feature-selection] hello 대상 특성와 함께 50 기능을 포함 하는 데이터 집합을 생성 한 다음 **Col1**합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-214">hello module [Filter-Based Feature Selection][filter-based-feature-selection] then produces a data set containing 50 features together with hello target attribute **Col1**.</span></span> <span data-ttu-id="50725-215">hello 다음이 실험에서는 hello 흐름 알아보고 hello 입력된 매개 변수.</span><span class="sxs-lookup"><span data-stu-id="50725-215">hello following figure shows hello flow of this experiment and hello input parameters.</span></span>

![기능 선택 예](./media/machine-learning-feature-selection-and-engineering/feature-Selection1.png)

<span data-ttu-id="50725-217">hello 다음 그림은 hello 결과 데이터 집합.</span><span class="sxs-lookup"><span data-stu-id="50725-217">hello following figure shows hello resulting data sets.</span></span> <span data-ttu-id="50725-218">각 기능 hello 자신과 hello 사이의 피어슨 상관 관계를 기반으로 점수는 대상 특성 **Col1**합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-218">Each feature is scored based on hello Pearson Correlation between itself and hello target attribute **Col1**.</span></span> <span data-ttu-id="50725-219">최고 점수와 hello 기능이 유지 됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-219">hello features with top scores are kept.</span></span>

![필터 기반 기능 선택 데이터 집합](./media/machine-learning-feature-selection-and-engineering/feature-Selection2.png)

<span data-ttu-id="50725-221">다음 그림에서는 hello hello 해당 점수 hello 선택 기능입니다.</span><span class="sxs-lookup"><span data-stu-id="50725-221">hello following figure shows hello corresponding scores of hello selected features.</span></span>

![선택한 기능 점수](./media/machine-learning-feature-selection-and-engineering/feature-Selection3.png)

<span data-ttu-id="50725-223">이 적용 하 여 [필터 기반 기능 선택] [ filter-based-feature-selection] 모듈을 50의 256 기능을 대부분의 기능은 hello 대상 변수 상호 연관 hello 했기 때문에 선택한 **Col1** hello 점수 매기기 방법에 따라 **피어슨 상관 관계**합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-223">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have hello most features correlated with hello target variable **Col1** based on hello scoring method **Pearson Correlation**.</span></span>

## <a name="conclusion"></a><span data-ttu-id="50725-224">결론</span><span class="sxs-lookup"><span data-stu-id="50725-224">Conclusion</span></span>
<span data-ttu-id="50725-225">기능 엔지니어링 및 기능 선택 기계 학습 모델을 작성할 때 다음 두 단계로 tooprepare hello 학습 데이터에서 일반적 수행 됩니다.</span><span class="sxs-lookup"><span data-stu-id="50725-225">Feature engineering and feature selection are two steps commonly performed tooprepare hello training data when building a machine learning model.</span></span> <span data-ttu-id="50725-226">일반적으로 기능 엔지니어링이 적용 된 첫 번째 toogenerate 추가 기능을 한 다음 hello 기능 선택 단계 수행된 tooeliminate 관련이 없는, 중복 또는 밀접된 기능.</span><span class="sxs-lookup"><span data-stu-id="50725-226">Normally, feature engineering is applied first toogenerate additional features, and then hello feature selection step is performed tooeliminate irrelevant, redundant, or highly correlated features.</span></span>

<span data-ttu-id="50725-227">필요는 없습니다 항상 tooperform 기능 엔지니어링 이나 기능 선택 합니다.</span><span class="sxs-lookup"><span data-stu-id="50725-227">It is not always necessarily tooperform feature engineering or feature selection.</span></span> <span data-ttu-id="50725-228">필요한 지 여부 또는 hello 알고리즘을 선택 하면를 수집 했으며 hello 실험의 hello hello 데이터에 따라 달라 집니다.</span><span class="sxs-lookup"><span data-stu-id="50725-228">Whether it is needed depends on hello data you have or collect, hello algorithm you pick, and hello objective of hello experiment.</span></span>

<!-- Module References -->
[execute-r-script]: https://msdn.microsoft.com/library/azure/30806023-392b-42e0-94d6-6b775a6e0fd5/
[feature-hashing]: https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/
[filter-based-feature-selection]: https://msdn.microsoft.com/library/azure/918b356b-045c-412b-aa12-94a1d2dad90f/
[fisher-linear-discriminant-analysis]: https://msdn.microsoft.com/library/azure/dcaab0b2-59ca-4bec-bb66-79fd23540080/
