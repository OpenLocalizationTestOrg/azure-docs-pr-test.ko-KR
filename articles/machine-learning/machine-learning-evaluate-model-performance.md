---
title: "Machine Learning에서 모델 성능 평가 | Microsoft Docs"
description: "Azure 기계 학습에서 모델 성능을 평가하는 방법에 대해 설명합니다."
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
ms.assetid: 5dc5348a-4488-4536-99eb-ff105be9b160
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/20/2017
ms.author: bradsev;garye
ms.openlocfilehash: d9576e0059f2e77a684e518389182e713f0a4f09
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 07/11/2017
---
# <a name="how-to-evaluate-model-performance-in-azure-machine-learning"></a><span data-ttu-id="3c3f2-103">Azure 기계 학습에서 모델 성능을 평가하는 방법</span><span class="sxs-lookup"><span data-stu-id="3c3f2-103">How to evaluate model performance in Azure Machine Learning</span></span>
<span data-ttu-id="3c3f2-104">이 문서에서는 Azure Machine Learning Studio에서 모델의 성능을 평가하는 방법을 살펴본 다음 이 작업에 사용할 수 있는 메트릭을 간략하게 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-104">This article demonstrates how to evaluate the performance of a model in Azure Machine Learning Studio and provides a brief explanation of the metrics available for this task.</span></span> <span data-ttu-id="3c3f2-105">다음 세 가지 일반적인 감독 학습 시나리오가 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-105">Three common supervised learning scenarios are presented:</span></span> 

* <span data-ttu-id="3c3f2-106">회귀</span><span class="sxs-lookup"><span data-stu-id="3c3f2-106">regression</span></span>
* <span data-ttu-id="3c3f2-107">이진 분류</span><span class="sxs-lookup"><span data-stu-id="3c3f2-107">binary classification</span></span> 
* <span data-ttu-id="3c3f2-108">다중 클래스 분류</span><span class="sxs-lookup"><span data-stu-id="3c3f2-108">multiclass classification</span></span>

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

<span data-ttu-id="3c3f2-109">모델 성능 평가는 데이터 과학 프로세스의 핵심 단계 중 하나입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-109">Evaluating the performance of a model is one of the core stages in the data science process.</span></span> <span data-ttu-id="3c3f2-110">이는 학습된 모델에서 데이터 집합 점수 매기기(예측)에 성공한 정도를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-110">It indicates how successful the scoring (predictions) of a dataset has been by a trained model.</span></span> 

<span data-ttu-id="3c3f2-111">Azure Machine Learning에서는 해당 기본 Machine Learning 모듈 중 두 가지 모듈인 [모델 평가][evaluate-model] 및 [모델 교차 유효성 검사][cross-validate-model]를 통한 모델 평가를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-111">Azure Machine Learning supports model evaluation through two of its main machine learning modules: [Evaluate Model][evaluate-model] and [Cross-Validate Model][cross-validate-model].</span></span> <span data-ttu-id="3c3f2-112">이러한 모듈을 사용하여 기계 학습 및 통계에서 일반적으로 사용되는 여러 메트릭 면에서 모델의 성능을 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-112">These modules allow you to see how your model performs in terms of a number of metrics that are commonly used in machine learning and statistics.</span></span>

## <a name="evaluation-vs-cross-validation"></a><span data-ttu-id="3c3f2-113">평가 및 교차 유효성 검사</span><span class="sxs-lookup"><span data-stu-id="3c3f2-113">Evaluation vs. Cross Validation</span></span>
<span data-ttu-id="3c3f2-114">평가 및 교차 유효성 검사는 모델의 성능을 측정하는 표준 방법입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-114">Evaluation and cross validation are standard ways to measure the performance of your model.</span></span> <span data-ttu-id="3c3f2-115">둘 다 검사하거나 다른 모델과 비교할 수 있는 평가 메트릭을 생성합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-115">They both generate evaluation metrics that you can inspect or compare against those of other models.</span></span>

<span data-ttu-id="3c3f2-116">[모델 평가][evaluate-model]에서는 점수가 매겨진 데이터 집합을 입력으로 사용해야 합니다(또는 두 가지 모델의 성능을 비교하려는 경우 두 개의 데이터 집합 필요).</span><span class="sxs-lookup"><span data-stu-id="3c3f2-116">[Evaluate Model][evaluate-model] expects a scored dataset as input (or 2 in case you would like to compare the performance of 2 different models).</span></span> <span data-ttu-id="3c3f2-117">따라서 결과를 평가하려면 먼저 [모델 학습][train-model] 모듈을 사용하여 모델을 학습하고 [모델 점수 매기기][score-model] 모듈을 사용하여 일부 데이터 집합을 예측해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-117">This means that you need to train your model using the [Train Model][train-model] module and make predictions on some dataset using the [Score Model][score-model] module, before you can evaluate the results.</span></span> <span data-ttu-id="3c3f2-118">평가는 true 레이블과 함께 점수가 매겨진 레이블/확률을 기반으로 하며, 이 모두는 [모델 점수 매기기][score-model] 모듈에서 출력됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-118">The evaluation is based on the scored labels/probabilities along with the true labels, all of which are output by the [Score Model][score-model] module.</span></span>

<span data-ttu-id="3c3f2-119">또는 교차 유효성 검사를 사용하여 입력 데이터의 여러 하위 집합에서 여러 학습-점수 매기기-평가 작업(접기 수 10)을 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-119">Alternatively, you can use cross validation to perform a number of train-score-evaluate operations (10 folds) automatically on different subsets of the input data.</span></span> <span data-ttu-id="3c3f2-120">입력 데이터는 10개의 부분으로 분할되며, 하나는 테스트용으로 예약되고 나머지 9개는 학습용으로 예약됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-120">The input data is split into 10 parts, where one is reserved for testing, and the other 9 for training.</span></span> <span data-ttu-id="3c3f2-121">이 프로세스가 10번 반복되어 평가 메트릭의 평균이 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-121">This process is repeated 10 times and the evaluation metrics are averaged.</span></span> <span data-ttu-id="3c3f2-122">이는 모델이 새 데이터 집합에 얼마나 잘 일반화되는지를 결정하는 데 도움이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-122">This helps in determining how well a model would generalize to new datasets.</span></span> <span data-ttu-id="3c3f2-123">[모델 교차 유효성 검사][cross-validate-model] 모듈은 학습되지 않은 모델 및 레이블이 지정된 일부 데이터 집합을 사용하여 10번의 접기 각각에 대한 평가 결과를 평균 결과와 함께 출력합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-123">The [Cross-Validate Model][cross-validate-model] module takes in an untrained model and some labeled dataset and outputs the evaluation results of each of the 10 folds, in addition to the averaged results.</span></span>

<span data-ttu-id="3c3f2-124">다음 섹션에서는 간단한 회귀 및 분류 모델을 빌드하고 [모델 평가][evaluate-model] 및 [모델 교차 유효성 검사][cross-validate-model] 모듈을 둘 다 사용하여 해당 성능을 평가합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-124">In the following sections, we will build simple regression and classification models and evaluate their performance, using both the [Evaluate Model][evaluate-model] and the [Cross-Validate Model][cross-validate-model] modules.</span></span>

## <a name="evaluating-a-regression-model"></a><span data-ttu-id="3c3f2-125">회귀 모델 평가</span><span class="sxs-lookup"><span data-stu-id="3c3f2-125">Evaluating a Regression Model</span></span>
<span data-ttu-id="3c3f2-126">크기, 마력, 엔진 사양 등의 몇 가지 기능을 사용하여 자동차 가격을 예측하려고 합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-126">Assume we want to predict a car’s price using some features such as dimensions, horsepower, engine specs, and so on.</span></span> <span data-ttu-id="3c3f2-127">이는 대상 변수(*price*)가 연속 숫자 값인 일반적인 회귀 문제입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-127">This is a typical regression problem, where the target variable (*price*) is a continuous numeric value.</span></span> <span data-ttu-id="3c3f2-128">특정 자동차의 기능 값이 주어진 경우 해당 자동차의 가격을 예측할 수 있는 간단한 선형 회귀 모델을 적합화할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-128">We can fit a simple linear regression model that, given the feature values of a certain car, can predict the price of that car.</span></span> <span data-ttu-id="3c3f2-129">이 회귀 모델을 사용하여 학습한 동일한 데이터 집합의 점수를 매길 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-129">This regression model can be used to score the same dataset we trained on.</span></span> <span data-ttu-id="3c3f2-130">모든 자동차의 가격을 예측한 후에는 예측이 실제 가격에서 평균적으로 어느 정도 벗어났는지 확인하여 모델의 성능을 평가할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-130">Once we have the predicted prices for all of the cars, we can evaluate the performance of the model by looking at how much the predictions deviate from the actual prices on average.</span></span> <span data-ttu-id="3c3f2-131">이 예에서는 Azure 기계 학습 스튜디오의 *저장된 데이터 집합* 섹션에서 제공된 **자동차 가격 데이터(원시)** 를 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-131">To illustrate this, we use the *Automobile price data (Raw) dataset* available in the **Saved Datasets** section in Azure Machine Learning Studio.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="3c3f2-132">실험 만들기</span><span class="sxs-lookup"><span data-stu-id="3c3f2-132">Creating the Experiment</span></span>
<span data-ttu-id="3c3f2-133">다음 모듈을 Azure 기계 학습 스튜디오의 작업 영역에 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-133">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="3c3f2-134">자동차 가격 데이터(원시)</span><span class="sxs-lookup"><span data-stu-id="3c3f2-134">Automobile price data (Raw)</span></span>
* <span data-ttu-id="3c3f2-135">[선형 회귀][linear-regression]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-135">[Linear Regression][linear-regression]</span></span>
* <span data-ttu-id="3c3f2-136">[모델 학습][train-model]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-136">[Train Model][train-model]</span></span>
* <span data-ttu-id="3c3f2-137">[모델 점수 매기기][score-model]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-137">[Score Model][score-model]</span></span>
* <span data-ttu-id="3c3f2-138">[모델 평가][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-138">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="3c3f2-139">아래 그림 1에 표시된 대로 포트를 연결하고 [모델 학습][train-model] 모듈의 레이블 열을 *price*로 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-139">Connect the ports as shown below in Figure 1 and set the Label column of the [Train Model][train-model] module to *price*.</span></span>

![회귀 모델 평가](media/machine-learning-evaluate-model-performance/1.png)

<span data-ttu-id="3c3f2-141">그림 1.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-141">Figure 1.</span></span> <span data-ttu-id="3c3f2-142">회귀 모델 평가</span><span class="sxs-lookup"><span data-stu-id="3c3f2-142">Evaluating a Regression Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="3c3f2-143">평가 결과 검사</span><span class="sxs-lookup"><span data-stu-id="3c3f2-143">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="3c3f2-144">실험을 실행한 후 [모델 평가][evaluate-model] 모듈의 출력 포트를 클릭하고 *시각화*를 선택하여 평가 결과를 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-144">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results.</span></span> <span data-ttu-id="3c3f2-145">회귀 모델에 사용할 수 있는 평가 메트릭은 *절대 평균 오차*, *루트 절대 평균 오차*, *상대 절대 오차*, *상대 제곱된 오차* 및 *결정 계수*입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-145">The evaluation metrics available for regression models are: *Mean Absolute Error*, *Root Mean Absolute Error*, *Relative Absolute Error*, *Relative Squared Error*, and the *Coefficient of Determination*.</span></span>

<span data-ttu-id="3c3f2-146">여기서 "오차"는 예측 값과 실제 값 간의 차이를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-146">The term "error" here represents the difference between the predicted value and the true value.</span></span> <span data-ttu-id="3c3f2-147">예측 값과 실제 값 간의 차이는 경우에 따라 음수일 수 있으므로 모든 인스턴스에서 오차의 총 크기를 캡처하기 위해 일반적으로 이 차이의 절대값 또는 제곱이 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-147">The absolute value or the square of this difference are usually computed to capture the total magnitude of error across all instances, as the difference between the predicted and true value could be negative in some cases.</span></span> <span data-ttu-id="3c3f2-148">오차 메트릭은 실제 값에서 예측 값의 평균 편차로 회귀 모델의 예측 성능을 측정합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-148">The error metrics measure the predictive performance of a regression model in terms of the mean deviation of its predictions from the true values.</span></span> <span data-ttu-id="3c3f2-149">오차 값이 낮을수록 모델의 예측이 더 정확함을 의미합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-149">Lower error values mean the model is more accurate in making predictions.</span></span> <span data-ttu-id="3c3f2-150">전체 오차 메트릭 0은 모델이 데이터에 완벽하게 적합함을 의미합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-150">An overall error metric of 0 means that the model fits the data perfectly.</span></span>

<span data-ttu-id="3c3f2-151">R 제곱이라고도 하는 결정 계수도 모델이 데이터에 적합한 정도를 측정하는 표준 방법입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-151">The coefficient of determination, which is also known as R squared, is also a standard way of measuring how well the model fits the data.</span></span> <span data-ttu-id="3c3f2-152">이는 모델에서 설명하는 변형의 비율로 해석될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-152">It can be interpreted as the proportion of variation explained by the model.</span></span> <span data-ttu-id="3c3f2-153">이 경우 비율이 높을수록 좋으며, 1은 완벽한 적합을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-153">A higher proportion is better in this case, where 1 indicates a perfect fit.</span></span>

![선형 회귀 평가 메트릭](media/machine-learning-evaluate-model-performance/2.png)

<span data-ttu-id="3c3f2-155">그림 2.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-155">Figure 2.</span></span> <span data-ttu-id="3c3f2-156">선형 회귀 평가 메트릭</span><span class="sxs-lookup"><span data-stu-id="3c3f2-156">Linear Regression Evaluation Metrics.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="3c3f2-157">교차 유효성 검사 사용</span><span class="sxs-lookup"><span data-stu-id="3c3f2-157">Using Cross Validation</span></span>
<span data-ttu-id="3c3f2-158">앞서 설명한 바와 같이 [모델 교차 유효성 검사][cross-validate-model] 모듈을 사용하여 반복적인 학습, 점수 매기기 및 평가를 자동으로 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-158">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="3c3f2-159">이 경우에는 데이터 집합, 학습되지 않은 모델 및 [모델 교차 유효성 검사][cross-validate-model] 모듈만 있으면 됩니다(아래 그림 참조).</span><span class="sxs-lookup"><span data-stu-id="3c3f2-159">All you need in this case is a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="3c3f2-160">[모델 교차 유효성 검사][cross-validate-model] 모듈에서 레이블 열을 *price*로 설정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-160">Note that you need to set the label column to *price* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span>

![회귀 모델 교차 유효성 검사](media/machine-learning-evaluate-model-performance/3.png)

<span data-ttu-id="3c3f2-162">그림 3.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-162">Figure 3.</span></span> <span data-ttu-id="3c3f2-163">회귀 모델 교차 유효성 검사</span><span class="sxs-lookup"><span data-stu-id="3c3f2-163">Cross-Validating a Regression Model.</span></span>

<span data-ttu-id="3c3f2-164">실험을 실행한 후 [모델 교차 유효성 검사][cross-validate-model] 모듈의 오른쪽 출력 포트를 클릭하여 평가 결과를 검사할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-164">After running the experiment, you can inspect the evaluation results by clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="3c3f2-165">각 반복(접기)에 대한 메트릭과 각 메트릭의 평균 결과에 대한 상세 보기가 제공됩니다(그림 4).</span><span class="sxs-lookup"><span data-stu-id="3c3f2-165">This will provide a detailed view of the metrics for each iteration (fold), and the averaged results of each of the metrics (Figure 4).</span></span>

![회귀 모델의 교차 유효성 검사 결과](media/machine-learning-evaluate-model-performance/4.png)

<span data-ttu-id="3c3f2-167">그림 4.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-167">Figure 4.</span></span> <span data-ttu-id="3c3f2-168">회귀 모델의 교차 유효성 검사 결과</span><span class="sxs-lookup"><span data-stu-id="3c3f2-168">Cross-Validation Results of a Regression Model.</span></span>

## <a name="evaluating-a-binary-classification-model"></a><span data-ttu-id="3c3f2-169">이진 분류 모델 평가</span><span class="sxs-lookup"><span data-stu-id="3c3f2-169">Evaluating a Binary Classification Model</span></span>
<span data-ttu-id="3c3f2-170">이진 분류 시나리오에서는 대상 변수의 가능한 결과가 두 가지뿐입니다. 예를 들면 {0, 1} 또는 {false, true}, {negative, positive}입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-170">In a binary classification scenario, the target variable has only two possible outcomes, for example: {0, 1} or {false, true}, {negative, positive}.</span></span> <span data-ttu-id="3c3f2-171">일부 인구 통계 및 고용 변수가 있는 성인 직원의 데이터 집합에서 소득 수준(값이 {“<=50K”, “>50K”}인 이진 변수)을 예측해 보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-171">Assume you are given a dataset of adult employees with some demographic and employment variables, and that you are asked to predict the income level, a binary variable with the values {“<=50K”, “>50K”}.</span></span> <span data-ttu-id="3c3f2-172">즉, 부정 클래스는 소득이 연간 50K 이하인 직원을 나타내고, 긍정 클래스는 다른 모든 직원을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-172">In other words, the negative class represents the employees who make less than or equal to 50K per year, and the positive class represents all other employees.</span></span> <span data-ttu-id="3c3f2-173">회귀 시나리오와 마찬가지로 모델을 학습하고, 일부 데이터의 점수를 매긴 다음, 결과를 평가합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-173">As in the regression scenario, we would train a model, score some data, and evaluate the results.</span></span> <span data-ttu-id="3c3f2-174">가장 큰 차이점은 Azure 기계 학습에서 계산하고 출력하는 메트릭의 선택입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-174">The main difference here is the choice of metrics Azure Machine Learning computes and outputs.</span></span> <span data-ttu-id="3c3f2-175">소득 수준 예측 시나리오를 보여 주기 위해 [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) 데이터 집합을 사용하여 Azure Machine Learning 실험을 만들고, 일반적으로 사용되는 이진 분류자인 2클래스 로지스틱 회귀 모델의 성능을 평가합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-175">To illustrate the income level prediction scenario, we will use the [Adult](http://archive.ics.uci.edu/ml/datasets/Adult) dataset to create an Azure Machine Learning experiment and evaluate the performance of a two-class logistic regression model, a commonly used binary classifier.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="3c3f2-176">실험 만들기</span><span class="sxs-lookup"><span data-stu-id="3c3f2-176">Creating the Experiment</span></span>
<span data-ttu-id="3c3f2-177">다음 모듈을 Azure 기계 학습 스튜디오의 작업 영역에 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-177">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="3c3f2-178">성인 인구 조사 소득 이진 분류 데이터 집합</span><span class="sxs-lookup"><span data-stu-id="3c3f2-178">Adult Census Income Binary Classification dataset</span></span>
* <span data-ttu-id="3c3f2-179">[2클래스 로지스틱 회귀 분석][two-class-logistic-regression]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-179">[Two-Class Logistic Regression][two-class-logistic-regression]</span></span>
* <span data-ttu-id="3c3f2-180">[모델 학습][train-model]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-180">[Train Model][train-model]</span></span>
* <span data-ttu-id="3c3f2-181">[모델 점수 매기기][score-model]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-181">[Score Model][score-model]</span></span>
* <span data-ttu-id="3c3f2-182">[모델 평가][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-182">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="3c3f2-183">아래 그림 5에 표시된 대로 포트를 연결하고 [모델 학습][train-model] 모듈의 레이블 열을 *income*으로 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-183">Connect the ports as shown below in Figure 5 and set the Label column of the [Train Model][train-model] module to *income*.</span></span>

![이진 분류 모델 평가](media/machine-learning-evaluate-model-performance/5.png)

<span data-ttu-id="3c3f2-185">그림 5.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-185">Figure 5.</span></span> <span data-ttu-id="3c3f2-186">이진 분류 모델 평가</span><span class="sxs-lookup"><span data-stu-id="3c3f2-186">Evaluating a Binary Classification Model.</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="3c3f2-187">평가 결과 검사</span><span class="sxs-lookup"><span data-stu-id="3c3f2-187">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="3c3f2-188">실험을 실행한 후 [모델 평가][evaluate-model] 모듈의 출력 포트를 클릭하고 *시각화*를 선택하여 평가 결과를 확인할 수 있습니다(그림 7).</span><span class="sxs-lookup"><span data-stu-id="3c3f2-188">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select *Visualize* to see the evaluation results (Figure 7).</span></span> <span data-ttu-id="3c3f2-189">이진 분류 모델에 사용할 수 있는 평가 메트릭은 *정확도*, *전체 자릿수*, *재현율*, *F1 점수* 및 *AUC*입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-189">The evaluation metrics available for binary classification models are: *Accuracy*, *Precision*, *Recall*, *F1 Score*, and *AUC*.</span></span> <span data-ttu-id="3c3f2-190">또한 이 모듈은 *ROC*, *전체 자릿수/재현율* 및 *양력* 곡선뿐만 아니라 참 긍정, 거짓 부정, 거짓 긍정 및 참 부정 수를 보여 주는 혼동 행렬을 출력합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-190">In addition, the module outputs a confusion matrix showing the number of true positives, false negatives, false positives, and true negatives, as well as *ROC*, *Precision/Recall*, and *Lift* curves.</span></span>

<span data-ttu-id="3c3f2-191">정확도는 올바르게 분류된 인스턴스의 비율일 뿐입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-191">Accuracy is simply the proportion of correctly classified instances.</span></span> <span data-ttu-id="3c3f2-192">이는 일반적으로 분류자를 평가할 때 확인하는 첫 번째 메트릭입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-192">It is usually the first metric you look at when evaluating a classifier.</span></span> <span data-ttu-id="3c3f2-193">그러나 테스트 데이터가 불균형하거나(대부분의 인스턴스가 클래스 중 하나에 속한 경우) 클래스 중 하나에 대한 성능에 더 많은 관심이 있는 경우 정확도는 실제로 분류자의 효과를 캡처하지 못합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-193">However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn’t really capture the effectiveness of a classifier.</span></span> <span data-ttu-id="3c3f2-194">소득 수준 분류 시나리오에서는 인스턴스의 99%가 연간 소득이 50K 이하인 사람을 나타내는 일부 데이터를 테스트하는 것으로 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-194">In the income level classification scenario, assume you are testing on some data where 99% of the instances represent people who earn less than or equal to 50K per year.</span></span> <span data-ttu-id="3c3f2-195">0.99의 정확도는 모든 인스턴스에 대해 “<=50K” 클래스를 예측하여 달성할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-195">It is possible to achieve a 0.99 accuracy by predicting the class “<=50K” for all instances.</span></span> <span data-ttu-id="3c3f2-196">이 경우 분류자는 전반적으로 양호한 것처럼 보이지만 실제로는 고소득자(1%)를 올바르게 분류하지 못합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-196">The classifier in this case appears to be doing a good job overall, but in reality, it fails to classify any of the high-income individuals (the 1%) correctly.</span></span>

<span data-ttu-id="3c3f2-197">따라서 평가의 보다 특정한 측면을 캡처하는 추가 메트릭을 계산하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-197">For that reason, it is helpful to compute additional metrics that capture more specific aspects of the evaluation.</span></span> <span data-ttu-id="3c3f2-198">이러한 메트릭에 대해 자세히 알아보기 전에 이진 분류 평가의 혼동 행렬을 이해해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-198">Before going into the details of such metrics, it is important to understand the confusion matrix of a binary classification evaluation.</span></span> <span data-ttu-id="3c3f2-199">학습 집합의 클래스 레이블은 일반적으로 긍정 또는 부정이라는 두 가지 가능한 값만 취할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-199">The class labels in the training set can take on only 2 possible values, which we usually refer to as positive or negative.</span></span> <span data-ttu-id="3c3f2-200">분류자가 올바르게 예측한 긍정 및 부정 인스턴스를 각각 TP(참 긍정) 및 TN(참 부정)이라고 합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-200">The positive and negative instances that a classifier predicts correctly are called true positives (TP) and true negatives (TN), respectively.</span></span> <span data-ttu-id="3c3f2-201">마찬가지로 잘못 분류된 인스턴스는 FP(거짓 긍정) 및 FN(거짓 부정)이라고 합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-201">Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN).</span></span> <span data-ttu-id="3c3f2-202">혼동 행렬은 이 네 가지 범주 각각에 속하는 인스턴스 수를 보여 주는 테이블입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-202">The confusion matrix is simply a table showing the number of instances that fall under each of these 4 categories.</span></span> <span data-ttu-id="3c3f2-203">Azure 기계 학습에서는 데이터 집합의 두 클래스 중 긍정 클래스를 자동으로 결정합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-203">Azure Machine Learning automatically decides which of the two classes in the dataset is the positive class.</span></span> <span data-ttu-id="3c3f2-204">클래스 레이블이 부울 또는 정수인 경우에는 ‘true’ 또는 ‘1’ 레이블이 지정된 인스턴스에 긍정 클래스가 할당됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-204">If the class labels are Boolean or integers, then the ‘true’ or ‘1’ labeled instances are assigned the positive class.</span></span> <span data-ttu-id="3c3f2-205">레이블이 문자열인 경우에는 income 데이터 집합의 경우처럼 레이블이 사전순으로 정렬되고 첫 번째 수준은 부정 클래스로, 두 번째 수준은 긍정 클래스로 선택됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-205">If the labels are strings, as in the case of the income dataset, the labels are sorted alphabetically and the first level is chosen to be the negative class while the second level is the positive class.</span></span>

![이진 분류 혼동 행렬](media/machine-learning-evaluate-model-performance/6a.png)

<span data-ttu-id="3c3f2-207">그림 6.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-207">Figure 6.</span></span> <span data-ttu-id="3c3f2-208">이진 분류 혼동 행렬</span><span class="sxs-lookup"><span data-stu-id="3c3f2-208">Binary Classification Confusion Matrix.</span></span>

<span data-ttu-id="3c3f2-209">소득 분류 문제로 다시 돌아가, 사용된 분류자의 성능을 이해하는 데 도움이 되는 몇 가지 평가 질문을 해보겠습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-209">Going back to the income classification problem, we would want to ask several evaluation questions that help us understand the performance of the classifier used.</span></span> <span data-ttu-id="3c3f2-210">매우 자연스러운 질문은 ‘모델에서 50K(TP+FP)를 초과할 것으로 예측한 개인 중 올바르게 분류된(TP) 개인은 몇 명입니까?’입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-210">A very natural question is: ‘Out of the individuals whom the model predicted to be earning >50K (TP+FP), how many were classified correctly (TP)?’</span></span> <span data-ttu-id="3c3f2-211">이 질문에 대한 답은 올바르게 분류된 긍정의 비율인 모델의 **정확도** , 즉 TP/(TP+FP)를 확인하여 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-211">This question can be answered by looking at the **Precision** of the model, which is the proportion of positives that are classified correctly: TP/(TP+FP).</span></span> <span data-ttu-id="3c3f2-212">또 다른 일반적인 질문은 “소득이 50k(TP+FN)를 초과하는 모든 고소득 직원 중 분류자가 올바르게 분류한(TP) 직원은 몇 명입니까?”입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-212">Another common question is “Out of all the high earning employees with income >50k (TP+FN), how many did the classifier classify correctly (TP)”.</span></span> <span data-ttu-id="3c3f2-213">이는 실제로 **재현율**또는 참 긍정 비율, 즉 분류자의 TP/(TP+FN)입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-213">This is actually the **Recall**, or the true positive rate: TP/(TP+FN) of the classifier.</span></span> <span data-ttu-id="3c3f2-214">정확도와 재현율 사이에는 명확한 반비례 관계가 있는 것을 볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-214">You might notice that there is an obvious trade-off between precision and recall.</span></span> <span data-ttu-id="3c3f2-215">예를 들어 비교적 균형 잡힌 데이터 집합에서 주로 긍정 인스턴스를 예측하는 분류자는 재현율이 높지만 대부분의 거짓 인스턴스가 잘못 분류되어 많은 거짓 긍정이 발생하므로 정확도가 낮습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-215">For example, given a relatively balanced dataset, a classifier that predicts mostly positive instances, would have a high recall, but a rather low precision as many of the negative instances would be misclassified resulting in a large number of false positives.</span></span> <span data-ttu-id="3c3f2-216">이 두 메트릭이 어떻게 달라지는지에 대한 그림을 보려면 평가 결과 출력 페이지에서 ‘정확도/재현율’ 곡선(그림 7의 왼쪽 위)을 클릭하면 됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-216">To see a plot of how these two metrics vary, you can click on the ‘PRECISION/RECALL’ curve in the evaluation result output page (top left part of Figure 7).</span></span>

![이진 분류 평가 결과](media/machine-learning-evaluate-model-performance/7.png)

<span data-ttu-id="3c3f2-218">그림 7.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-218">Figure 7.</span></span> <span data-ttu-id="3c3f2-219">이진 분류 평가 결과</span><span class="sxs-lookup"><span data-stu-id="3c3f2-219">Binary Classification Evaluation Results.</span></span>

<span data-ttu-id="3c3f2-220">자주 사용되는 또 다른 관련 메트릭은 정확도와 재현율을 둘 다 고려하는 **F1 점수**입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-220">Another related metric that is often used is the **F1 Score**, which takes both precision and recall into consideration.</span></span> <span data-ttu-id="3c3f2-221">이는 이 두 메트릭의 조화 평균이며, 다음과 같이 계산됩니다. F1 = 2 (정확도 x 재현율) / (정확도 + 재현율).</span><span class="sxs-lookup"><span data-stu-id="3c3f2-221">It is the harmonic mean of these 2 metrics and is computed as such: F1 = 2 (precision x recall) / (precision + recall).</span></span> <span data-ttu-id="3c3f2-222">F1 점수는 평가를 단일 숫자로 요약하는 데 적합한 방법이지만 분류자의 동작 방식을 보다 잘 이해하려면 항상 정확도와 재현율을 함께 확인하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-222">The F1 score is a good way to summarize the evaluation in a single number, but it’s always a good practice to look at both precision and recall together to better understand how a classifier behaves.</span></span>

<span data-ttu-id="3c3f2-223">또한 **ROC(Receiver Operating Characteristic)** 곡선에서 참 긍정 비율과 거짓 긍정 비율을 검사하고 해당 **AUC(Area Under the Curve)** 값을 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-223">In addition, one can inspect the true positive rate vs. the false positive rate in the **Receiver Operating Characteristic (ROC)** curve and the corresponding **Area Under the Curve (AUC)** value.</span></span> <span data-ttu-id="3c3f2-224">이 곡선이 왼쪽 위 모서리에 가까울수록 분류자의 성능이 좋습니다(참 긍정 비율이 최대화되고 거짓 긍정 비율이 최소화됨).</span><span class="sxs-lookup"><span data-stu-id="3c3f2-224">The closer this curve is to the upper left corner, the better the classifier’s performance is (that is maximizing the true positive rate while minimizing the false positive rate).</span></span> <span data-ttu-id="3c3f2-225">그림의 대각선에 가까운 곡선은 예측 경향이 임의 추측에 가까운 분류자의 결과입니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-225">Curves that are close to the diagonal of the plot, result from classifiers that tend to make predictions that are close to random guessing.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="3c3f2-226">교차 유효성 검사 사용</span><span class="sxs-lookup"><span data-stu-id="3c3f2-226">Using Cross Validation</span></span>
<span data-ttu-id="3c3f2-227">회귀 예제처럼 교차 유효성 검사를 수행하여 데이터의 여러 하위 집합에 대해 반복적인 학습, 점수 매기기 및 평가를 자동으로 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-227">As in the regression example, we can perform cross validation to repeatedly train, score and evaluate different subsets of the data automatically.</span></span> <span data-ttu-id="3c3f2-228">마찬가지로 [모델 교차 유효성 검사][cross-validate-model] 모듈, 학습되지 않은 로지스틱 회귀 분석 모델 및 데이터 집합을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-228">Similarly, we can use the [Cross-Validate Model][cross-validate-model] module, an untrained logistic regression model, and a dataset.</span></span> <span data-ttu-id="3c3f2-229">레이블 열은 [모델 교차 유효성 검사][cross-validate-model] 모듈의 속성에서 *income*으로 설정되어야 합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-229">The label column must be set to *income* in the [Cross-Validate Model][cross-validate-model] module’s properties.</span></span> <span data-ttu-id="3c3f2-230">실험을 실행한 후 [모델 교차 유효성 검사][cross-validate-model] 모듈의 오른쪽 출력 포트를 클릭하면 각 접기에 대한 이진 분류 메트릭 값과 각각의 평균 및 표준 편차를 볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-230">After running the experiment and clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module, we can see the binary classification metric values for each fold, in addition to the mean and standard deviation of each.</span></span> 

![이진 분류 모델 교차 유효성 검사](media/machine-learning-evaluate-model-performance/8.png)

<span data-ttu-id="3c3f2-232">그림 8.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-232">Figure 8.</span></span> <span data-ttu-id="3c3f2-233">이진 분류 모델 교차 유효성 검사</span><span class="sxs-lookup"><span data-stu-id="3c3f2-233">Cross-Validating a Binary Classification Model.</span></span>

![이진 분류자의 교차 유효성 검사 결과](media/machine-learning-evaluate-model-performance/9.png)

<span data-ttu-id="3c3f2-235">그림 9.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-235">Figure 9.</span></span> <span data-ttu-id="3c3f2-236">이진 분류자의 교차 유효성 검사 결과</span><span class="sxs-lookup"><span data-stu-id="3c3f2-236">Cross-Validation Results of a Binary Classifier.</span></span>

## <a name="evaluating-a-multiclass-classification-model"></a><span data-ttu-id="3c3f2-237">다중 클래스 분류 모델 평가</span><span class="sxs-lookup"><span data-stu-id="3c3f2-237">Evaluating a Multiclass Classification Model</span></span>
<span data-ttu-id="3c3f2-238">이 실험에서는 세 가지 유형(클래스)의 붓꽃 인스턴스가 포함된 일반적인 [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") 데이터 집합을 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-238">In this experiment we will use the popular [Iris](http://archive.ics.uci.edu/ml/datasets/Iris "Iris") dataset which contains instances of 3 different types (classes) of the iris plant.</span></span> <span data-ttu-id="3c3f2-239">각 인스턴스에 대해 4개의 기능 값(꽃받침 길이/너비 및 꽃잎 길이/너비)이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-239">There are 4 feature values (sepal length/width and petal length/width) for each instance.</span></span> <span data-ttu-id="3c3f2-240">이전 실험에서 동일한 데이터 집합을 사용하여 모델을 학습하고 테스트했습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-240">In the previous experiments we trained and tested the models using the same datasets.</span></span> <span data-ttu-id="3c3f2-241">여기에서는 [데이터 분할][split] 모듈을 사용하여 데이터의 하위 집합 2개를 만들고 첫 번째 하위 집합을 학습한 후 두 번째 하위 집합의 점수를 매기고 평가합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-241">Here, we will use the [Split Data][split] module to create 2 subsets of the data, train on the first, and score and evaluate on the second.</span></span> <span data-ttu-id="3c3f2-242">Iris 데이터 집합은 [UCI Machine Learning 리포지토리](http://archive.ics.uci.edu/ml/index.html)에서 공개적으로 사용할 수 있으며, [데이터 가져오기][import-data] 모듈을 사용하여 다운로드할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-242">The Iris dataset is publicly available on the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.html), and can be downloaded using an [Import Data][import-data] module.</span></span>

### <a name="creating-the-experiment"></a><span data-ttu-id="3c3f2-243">실험 만들기</span><span class="sxs-lookup"><span data-stu-id="3c3f2-243">Creating the Experiment</span></span>
<span data-ttu-id="3c3f2-244">다음 모듈을 Azure 기계 학습 스튜디오의 작업 영역에 추가합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-244">Add the following modules to your workspace in Azure Machine Learning Studio:</span></span>

* <span data-ttu-id="3c3f2-245">[데이터 가져오기][import-data]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-245">[Import Data][import-data]</span></span>
* <span data-ttu-id="3c3f2-246">[다중 클래스 의사 결정 포리스트][multiclass-decision-forest]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-246">[Multiclass Decision Forest][multiclass-decision-forest]</span></span>
* <span data-ttu-id="3c3f2-247">[데이터 분할][split]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-247">[Split Data][split]</span></span>
* <span data-ttu-id="3c3f2-248">[모델 학습][train-model]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-248">[Train Model][train-model]</span></span>
* <span data-ttu-id="3c3f2-249">[모델 점수 매기기][score-model]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-249">[Score Model][score-model]</span></span>
* <span data-ttu-id="3c3f2-250">[모델 평가][evaluate-model]</span><span class="sxs-lookup"><span data-stu-id="3c3f2-250">[Evaluate Model][evaluate-model]</span></span>

<span data-ttu-id="3c3f2-251">아래의 그림 10과 같이 포트를 연결합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-251">Connect the ports as shown below in Figure 10.</span></span>

<span data-ttu-id="3c3f2-252">[모델 학습][train-model] 모듈의 레이블 열 인덱스를 5로 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-252">Set the Label column index of the [Train Model][train-model] module to 5.</span></span> <span data-ttu-id="3c3f2-253">이 데이터 집합에는 헤더 행이 없지만 클래스 레이블이 다섯 번째 열에 있다는 것을 알고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-253">The dataset has no header row but we know that the class labels are in the fifth column.</span></span>

<span data-ttu-id="3c3f2-254">[데이터 가져오기][import-data] 모듈을 클릭하고 *데이터 원본* 속성을 *HTTP를 통한 웹 URL*로, *URL*을 http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data로 설정합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-254">Click on the [Import Data][import-data] module and set the *Data source* property to *Web URL via HTTP*, and the *URL* to http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</span></span>

<span data-ttu-id="3c3f2-255">[데이터 분할][split] 모듈에서 학습에 사용할 인스턴스 부분을 설정합니다(이 예의 경우 0.7).</span><span class="sxs-lookup"><span data-stu-id="3c3f2-255">Set the fraction of instances to be used for training in the [Split Data][split] module (0.7 for example).</span></span>

![다중 클래스 분류자 평가](media/machine-learning-evaluate-model-performance/10.png)

<span data-ttu-id="3c3f2-257">그림 10.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-257">Figure 10.</span></span> <span data-ttu-id="3c3f2-258">다중 클래스 분류자 평가</span><span class="sxs-lookup"><span data-stu-id="3c3f2-258">Evaluating a Multiclass Classifier</span></span>

### <a name="inspecting-the-evaluation-results"></a><span data-ttu-id="3c3f2-259">평가 결과 검사</span><span class="sxs-lookup"><span data-stu-id="3c3f2-259">Inspecting the Evaluation Results</span></span>
<span data-ttu-id="3c3f2-260">실험을 실행하고 [모델 평가][evaluate-model]의 출력 포트를 클릭합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-260">Run the experiment and click on the output port of [Evaluate Model][evaluate-model].</span></span> <span data-ttu-id="3c3f2-261">이 경우 평가 결과가 혼동 행렬 형식으로 제공됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-261">The evaluation results are presented in the form of a confusion matrix, in this case.</span></span> <span data-ttu-id="3c3f2-262">행렬에는 세 클래스 모두에 대해 실제 인스턴스와 예측 인스턴스가 표시됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-262">The matrix shows the actual vs. predicted instances for all 3 classes.</span></span>

![다중 클래스 분류 평가 결과](media/machine-learning-evaluate-model-performance/11.png)

<span data-ttu-id="3c3f2-264">그림 11.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-264">Figure 11.</span></span> <span data-ttu-id="3c3f2-265">다중 클래스 분류 평가 결과</span><span class="sxs-lookup"><span data-stu-id="3c3f2-265">Multiclass Classification Evaluation Results.</span></span>

### <a name="using-cross-validation"></a><span data-ttu-id="3c3f2-266">교차 유효성 검사 사용</span><span class="sxs-lookup"><span data-stu-id="3c3f2-266">Using Cross Validation</span></span>
<span data-ttu-id="3c3f2-267">앞서 설명한 바와 같이 [모델 교차 유효성 검사][cross-validate-model] 모듈을 사용하여 반복적인 학습, 점수 매기기 및 평가를 자동으로 수행할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-267">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</span></span> <span data-ttu-id="3c3f2-268">데이터 집합, 학습되지 않은 모델 및 [모델 교차 유효성 검사][cross-validate-model] 모듈이 필요합니다(아래 그림 참조).</span><span class="sxs-lookup"><span data-stu-id="3c3f2-268">You would need a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</span></span> <span data-ttu-id="3c3f2-269">[모델 교차 유효성 검사][cross-validate-model] 모듈의 레이블 열을 설정해야 합니다(이 예의 경우 열 인덱스 5).</span><span class="sxs-lookup"><span data-stu-id="3c3f2-269">Again you need to set the label column of the [Cross-Validate Model][cross-validate-model] module (column index 5 in this case).</span></span> <span data-ttu-id="3c3f2-270">실험을 실행한 후 [모델 교차 유효성 검사][cross-validate-model] 모듈의 오른쪽 출력 포트를 클릭하면 각 접기에 대한 메트릭 값과 평균 및 표준 편차를 검사할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-270">After running the experiment and clicking the right output port of the [Cross-Validate Model][cross-validate-model], you can inspect the metric values for each fold as well as the mean and standard deviation.</span></span> <span data-ttu-id="3c3f2-271">여기에 표시된 메트릭은 이진 분류 예제에서 설명한 메트릭과 유사합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-271">The metrics displayed here are the similar to the ones discussed in the binary classification case.</span></span> <span data-ttu-id="3c3f2-272">그러나 다중 클래스 분류에서는 전체 긍정 또는 부정 클래스가 없기 때문에 참 긍정/부정 및 거짓 긍정/부정이 클래스 단위로 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-272">However, note that in multiclass classification, computing the true positives/negatives and false positives/negatives is done by counting on a per-class basis, as there is no overall positive or negative class.</span></span> <span data-ttu-id="3c3f2-273">예를 들어 ‘Iris-setosa’ 클래스의 정확도 또는 재현율을 계산할 때 이것은 긍정 클래스이고 나머지는 모두 부정 클래스인 것으로 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-273">For example, when computing the precision or recall of the ‘Iris-setosa’ class, it is assumed that this is the positive class and all others as negative.</span></span>

![다중 클래스 분류 모델 교차 유효성 검사](media/machine-learning-evaluate-model-performance/12.png)

<span data-ttu-id="3c3f2-275">그림 12.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-275">Figure 12.</span></span> <span data-ttu-id="3c3f2-276">다중 클래스 분류 모델 교차 유효성 검사</span><span class="sxs-lookup"><span data-stu-id="3c3f2-276">Cross-Validating a Multiclass Classification Model.</span></span>

![다중 클래스 분류 모델의 교차 유효성 검사 결과](media/machine-learning-evaluate-model-performance/13.png)

<span data-ttu-id="3c3f2-278">그림 13.</span><span class="sxs-lookup"><span data-stu-id="3c3f2-278">Figure 13.</span></span> <span data-ttu-id="3c3f2-279">다중 클래스 분류 모델의 교차 유효성 검사 결과</span><span class="sxs-lookup"><span data-stu-id="3c3f2-279">Cross-Validation Results of a Multiclass Classification Model.</span></span>

<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/

